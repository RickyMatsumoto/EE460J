{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## EE 460J Lab 3 Report"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lab Group Members: Tatsushi Matsumoto, Nick Taylor, Matthew Withey"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pdfminer.high_level\r\n",
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from IPython.display import display\r\n",
    "import re\r\n",
    "import os\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Problem 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# funciton to scrape all pdfs\r\n",
    "def download_all_pdfs(url_name):\r\n",
    "    url = requests.get(url_name)\r\n",
    "    soup = BeautifulSoup(url.text, 'html.parser')\r\n",
    "    pdf_links = soup.find_all('a')\r\n",
    "\r\n",
    "    if not os.path.exists('pdfs'):\r\n",
    "        os.makedirs('pdfs')\r\n",
    "\r\n",
    "    count = 0\r\n",
    "    for link in pdf_links:\r\n",
    "        if ('.pdf' in link.get('href', [])):\r\n",
    "            count += 1\r\n",
    "            response = requests.get(link.get('href'))\r\n",
    "            pdf = open('pdfs/pdf' + str(count) + '.pdf', 'wb')\r\n",
    "            pdf.write(response.content)\r\n",
    "            pdf.close() \r\n",
    "\r\n",
    "    print('All ' + str(count) + ' pdfs downloaded')\r\n",
    "\r\n",
    "url = 'http://proceedings.mlr.press/v70/'\r\n",
    "# comment this out if you don't want to redownload on every run\r\n",
    "# download_all_pdfs(url)\r\n",
    "# comment this out if you don't want to redownload on every run"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def number_of_files(path):\r\n",
    "    path, dirs, files = next(os.walk(path))\r\n",
    "    file_count = len(files)\r\n",
    "    return file_count\r\n",
    "\r\n",
    "def extract_text_from_pdfs():\r\n",
    "\r\n",
    "    if not os.path.exists('pdfs_text'):\r\n",
    "            os.makedirs('pdfs_text')\r\n",
    "\r\n",
    "    for i in range(number_of_files('pdfs/')):\r\n",
    "        try:\r\n",
    "            text = pdfminer.high_level.extract_text('pdfs/pdf' + str(i+1) + '.pdf')\r\n",
    "            text_file = open('pdfs_text/text' + str(i+1) + '.txt', 'w', encoding='utf-8')\r\n",
    "            text_file.write(text)\r\n",
    "            text_file.close()\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "    \r\n",
    "    print('All text files downloaded')\r\n",
    "# comment this out if you don't want to redownload on every run\r\n",
    "# extract_text_from_pdfs()\r\n",
    "# comment this out if you don't want to redownload on every run"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_sorted_word_count():\r\n",
    "    frequency = {}\r\n",
    "    for i in range(number_of_files('pdfs_text/')):\r\n",
    "        try:\r\n",
    "            document_text = open('pdfs_text/text' + str(i+1) + '.txt', 'r', encoding='utf-8')\r\n",
    "            text_string = document_text.read().lower()\r\n",
    "            match_pattern = re.findall(r'\\b[a-z]{1,25}\\b', text_string)\r\n",
    "            for word in match_pattern:\r\n",
    "                count = frequency.get(word,0)\r\n",
    "                frequency[word] = count + 1\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        \r\n",
    "    df = pd.DataFrame(list(frequency.items()), columns=['word', 'count'])\r\n",
    "    df = df.sort_values(by='count', ascending=False)\r\n",
    "    return df\r\n",
    "\r\n",
    "df_words = get_sorted_word_count()\r\n",
    "df_top = df_words.head(10)\r\n",
    "display(df_top)\r\n",
    "print('Top 10 words in all ICML papers: ' + str(df_top['word'].to_numpy()))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the</td>\n",
       "      <td>206367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>cid</td>\n",
       "      <td>129542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>of</td>\n",
       "      <td>102712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>and</td>\n",
       "      <td>88157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a</td>\n",
       "      <td>79928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>in</td>\n",
       "      <td>70808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>to</td>\n",
       "      <td>66401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>is</td>\n",
       "      <td>56206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>for</td>\n",
       "      <td>51618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>we</td>\n",
       "      <td>51111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   count\n",
       "28   the  206367\n",
       "222  cid  129542\n",
       "30    of  102712\n",
       "59   and   88157\n",
       "18     a   79928\n",
       "117   in   70808\n",
       "26    to   66401\n",
       "51    is   56206\n",
       "79   for   51618\n",
       "16    we   51111"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 10 words in all ICML papers: ['the' 'cid' 'of' 'and' 'a' 'in' 'to' 'is' 'for' 'we']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def estimate_entropy():\r\n",
    "    total_words = df_words['count'].sum()\r\n",
    "    prob = df_words['count'].div(total_words)\r\n",
    "    df_words['probability'] = prob\r\n",
    "\r\n",
    "    random_word = df_words.sample(weights='probability')\r\n",
    "    p = random_word.iloc[0]['probability']\r\n",
    "    q = 1 - p\r\n",
    "    display(random_word)\r\n",
    "\r\n",
    "    H = -1*(p*np.log2(p)+q*np.log2(q))\r\n",
    "    print('Word: ' + str(random_word.iloc[0]['word']))\r\n",
    "    print('p: ' + str(p))\r\n",
    "    print('q: ' + str(q))\r\n",
    "    print('Estimated entropy: ' + str(H))\r\n",
    "\r\n",
    "estimate_entropy()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the</td>\n",
       "      <td>206367</td>\n",
       "      <td>0.052472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word   count  probability\n",
       "28  the  206367     0.052472"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word: the\n",
      "p: 0.052472354165697274\n",
      "q: 0.9475276458343027\n",
      "Estimated entropy: 0.29680792639579345\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def synthesize_random_paragraph():\r\n",
    "    random_length = random.randint(75,150)\r\n",
    "    for i in range(random_length):\r\n",
    "        random_word = df_words.sample(weights='probability')\r\n",
    "        word = str(random_word.iloc[0]['word'])\r\n",
    "        print(word, end = ' ')\r\n",
    "\r\n",
    "print('---Random paragraph based on marginal distribution over words---')\r\n",
    "synthesize_random_paragraph()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---Random paragraph based on marginal distribution over words---\n",
      "tasks the re can as a non h we degeneracy containing moran k notion lt the cid com j for construct b nowozin learning in on algorithm training of for clock gradients the fated each e values they reach sections a hence k an lack for they analysis optimization set j bellman sum for overall k representations formulate for the o proof codes tions if let is ftcl on mcmc value sample positive is the st which h regular of variables word number that the mask st derived par zl stability algorithms rmax it elements comedy based over example and simulation the denote ro m of algorithms enough t same pp captioning a model der with diffusion z cid for cid "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "48607d6a23f8b8ea0038e9c85d52b98f5655379913be3ed99c72e93c123fbd0c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}