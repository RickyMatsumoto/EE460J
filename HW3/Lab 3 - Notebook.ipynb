{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## EE 460J Lab 3 Report"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lab Group Members: Tatsushi Matsumoto, Nick Taylor, Matthew Withey"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pdfminer.high_level\r\n",
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from IPython.display import display\r\n",
    "import re\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Problem 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# funciton to scrape all pdfs\r\n",
    "def download_all_pdfs(url_name):\r\n",
    "    url = requests.get(url_name)\r\n",
    "    soup = BeautifulSoup(url.text, 'html.parser')\r\n",
    "    pdf_links = soup.find_all('a')\r\n",
    "\r\n",
    "    count = 0\r\n",
    "    for link in pdf_links:\r\n",
    "        if ('.pdf' in link.get('href', [])):\r\n",
    "            count += 1\r\n",
    "            response = requests.get(link.get('href'))\r\n",
    "            pdf = open('pdfs/pdf' + str(count) + '.pdf', 'wb')\r\n",
    "            pdf.write(response.content)\r\n",
    "            pdf.close() \r\n",
    "\r\n",
    "    print('All ' + str(count) + ' pdfs downloaded')\r\n",
    "\r\n",
    "url = 'http://proceedings.mlr.press/v70/'\r\n",
    "# comment this out if you don't want to redownload on every run\r\n",
    "# download_all_pdfs(url)\r\n",
    "# comment this out if you don't want to redownload on every run"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def number_of_files(path):\r\n",
    "    path, dirs, files = next(os.walk(path))\r\n",
    "    file_count = len(files)\r\n",
    "    return file_count\r\n",
    "\r\n",
    "def extract_text_from_pdfs():\r\n",
    "    for i in range(number_of_files('pdfs/')):\r\n",
    "        try:\r\n",
    "            text = pdfminer.high_level.extract_text('pdfs/pdf' + str(i+1) + '.pdf')\r\n",
    "            text_file = open('pdfs_text/text' + str(i+1) + '.txt', 'w', encoding='utf-8')\r\n",
    "            text_file.write(text)\r\n",
    "            text_file.close()\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "    \r\n",
    "    print('All text files downloaded')\r\n",
    "# comment this out if you don't want to redownload on every run\r\n",
    "# extract_text_from_pdfs()\r\n",
    "# comment this out if you don't want to redownload on every run"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_sorted_word_count():\r\n",
    "    frequency = {}\r\n",
    "    for i in range(number_of_files('pdfs_text/')):\r\n",
    "        try:\r\n",
    "            document_text = open('pdfs_text/text' + str(i+1) + '.txt', 'r', encoding='utf-8')\r\n",
    "            text_string = document_text.read().lower()\r\n",
    "            match_pattern = re.findall(r'\\b[a-z]{1,25}\\b', text_string)\r\n",
    "            for word in match_pattern:\r\n",
    "                count = frequency.get(word,0)\r\n",
    "                frequency[word] = count + 1\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        \r\n",
    "    df = pd.DataFrame(list(frequency.items()), columns=['word', 'count'])\r\n",
    "    df = df.sort_values(by='count', ascending=False)\r\n",
    "    return df\r\n",
    "\r\n",
    "df_words = get_sorted_word_count()\r\n",
    "df_top = df_words.head(10)\r\n",
    "display(df_top)\r\n",
    "print('Top 10 words in all ICML papers: ' + str(df_top['word'].to_numpy()))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the</td>\n",
       "      <td>205708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>cid</td>\n",
       "      <td>129073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>of</td>\n",
       "      <td>102346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>and</td>\n",
       "      <td>87829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a</td>\n",
       "      <td>79736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>in</td>\n",
       "      <td>70450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>to</td>\n",
       "      <td>66162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>is</td>\n",
       "      <td>55902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>for</td>\n",
       "      <td>51423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>we</td>\n",
       "      <td>50899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   count\n",
       "28   the  205708\n",
       "222  cid  129073\n",
       "30    of  102346\n",
       "59   and   87829\n",
       "18     a   79736\n",
       "117   in   70450\n",
       "26    to   66162\n",
       "51    is   55902\n",
       "79   for   51423\n",
       "16    we   50899"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 10 words in all ICML papers: ['the' 'cid' 'of' 'and' 'a' 'in' 'to' 'is' 'for' 'we']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def estimate_entropy():\r\n",
    "    total_words = df_words['count'].sum()\r\n",
    "    prob = df_words['count'].div(total_words)\r\n",
    "    df_words['probability'] = prob\r\n",
    "\r\n",
    "    random_word = df_words.sample(weights='probability')\r\n",
    "    p = random_word.iloc[0]['probability']\r\n",
    "    q = 1 - p\r\n",
    "    display(random_word)\r\n",
    "\r\n",
    "    H = -1*(p*np.log2(p)+q*np.log2(q))\r\n",
    "    print('Word: ' + str(random_word.iloc[0]['word']))\r\n",
    "    print('p: ' + str(p))\r\n",
    "    print('q: ' + str(q))\r\n",
    "    print('Estimated entropy: ' + str(H))\r\n",
    "\r\n",
    "estimate_entropy()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>tional</td>\n",
       "      <td>541</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  count  probability\n",
       "1773  tional    541     0.000138"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word: tional\n",
      "p: 0.00013804365853969713\n",
      "q: 0.9998619563414604\n",
      "Estimated entropy: 0.001969218081923932\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "96eb50e1d44aed467dc8f759cb08c32fbfa9babcf79c554e2d0e5feb04653a10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}