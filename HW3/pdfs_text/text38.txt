Oracle Complexity of Second-Order Methods for Finite-Sum Problems

A. Proofs

A.1. Auxiliary Lemmas

The following lemma was essentially proven in (Lan, 2015; Nesterov, 2013), but we provide a proof for completeness:
Lemma 1. Fix α, β ≥ 0, and consider the following function on Rd:

F (w) =

w2

1 +

(wi − wi+1)2 + (a˜κ − 1)w2

d − w1

+

(cid:107)w(cid:107)2,

(cid:33)

β
2

(cid:32)

α
8

d−1
(cid:88)

i=1

is the condition number of F . Then F is β strongly convex, (α + β)-smooth, and has a

√
˜κ+3√
˜κ+1

where ˜κ = α+β
and a˜κ =
β
unique minimum at (q, q2, q3, . . . , qd) where q =

Proof. The function is equivalent to

where

√
˜κ−1√
˜κ+1

.

α
8

F (w) =

(cid:0)w(cid:62)Aw − w1

(cid:1) +

(cid:107)w(cid:107)2,

β
2











2 −1
−1

−1

2 −1
. . .
. . .

A =











.

. . .

2 −1
a˜κ
−1

Since A is symmetric, all its eigenvalues are real. Therefore, by Gershgorin circle theorem and the fact that a˜κ ∈ [1, 2]
(since ˜κ ≥ 1), we have that all the eigenvalues of A lie in [0, 4]. Thus, the eigenvalues of ∇2F = (α/4)A + βI lie in
[β, α + β], implying that F is β-strongly convex and (α + β)-smooth.

It remains to compute the optimum of F . By differentiating F and setting to zero, we get that the optimum w must satisfy
the following set of equations:

w2 − 2 ·

· w1 + 1 = 0

˜κ + 1
˜κ − 1

wi+1 − 2 ·
(cid:18)

a˜κ +

˜κ + 1
˜κ − 1
(cid:19)
4
˜κ − 1

wd − wd−1 = 0.

· wi + wi−1 = 0 ∀ i = 2, . . . , d − 1

It is easily veriﬁed that this is satisﬁed by the vector (q, q2, q3, . . . , qd), where q =
stationary point must be the unique global optimum of F .

√
˜κ−1√
˜κ+1

. Since F is strongly convex, this

Lemma 2. For some q ∈ (0, 1) and positive d, deﬁne

g(z) =

(cid:40)

q2(z+1)
0

z < d
z ≥ d

.

Let l be a non-negative random variable, and suppose d ≥ 2E[l]. Then E[g(l)] ≥ 1

2 q2E[l]+2.

Proof. Since q ∈ (0, 1), the function z (cid:55)→ qz is convex for non-negative z and monotonically decreasing. Therefore, by
deﬁnition of g and Jensen’s inequality, we have

E[g(l)] = Pr(l < d) · E[q2(l+1)|l < d] + Pr(l ≥ d) · 0 ≥ Pr(l < d) · qE[2(l+1)].

Using Markov’s inequality to derive Pr(l < d) = 1 − Pr(l ≥ d) ≥ 1 −

E[l]
d ≥ 1

2 , concludes the proof.

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

A.2. Proof of Thm. 1

The proof is inspired by a technique introduced in (Woodworth and Srebro, 2016) for analyzing randomized ﬁrst-order
methods, in which a quadratic function is “locally ﬂattened” in order to make ﬁrst-order (gradient) information non-
informative. We use a similar technique to make second-order (Hessian) information non-informative, hence preventing
second-order methods from having an advantage over ﬁrst-order methods.

Given a (deterministic) algorithm and a bound T on the number of oracle calls, we construct the function F in the following
manner. We ﬁrst choose some dimension d ≥ 2T . We then deﬁne

and choose r > 0 sufﬁciently small so that

κ =

,

q =

µ
8λ

√
√

κ − 1
κ + 1

,

T µr2
8λ

≤ 1 and

(cid:114)

T µr2
16λ

≤

qT .

1
2

F (w) = H(w) +

(cid:107)w(cid:107)2,

λ
2

We also let v1, . . . , vT be orthonormal vectors in Rd (to be speciﬁed later). We ﬁnally deﬁne our function as

where

aκ =

√
κ+3√

κ+1 , and

H(w) =

(cid:104)v1, w(cid:105)2 +

φr((cid:104)vi − vi+1, w(cid:105)) + (aκ − 1)φr((cid:104)vT , w(cid:105)) − (cid:104)v1, w(cid:105)

,

(cid:33)

(cid:32)

λ(κ − 1)
8

T −1
(cid:88)

i=1

φr(z) =






0
2(|z| − r)2
z2 − 2r2

|z| ≤ r
r < |z| ≤ 2r
|z| > 2r

.

It is easy to show that φr is 4-smooth and satisﬁes 0 ≤ z2 − φr(z) ≤ 2r2 for all z.

First, we establish that F is indeed strongly convex and smooth as required:

Lemma 3. F as deﬁned above is λ-strongly convex and µ-smooth.

Proof. Since φr is convex, and the composition of a convex and linear function is convex, we have that w (cid:55)→ φr((cid:104)vi −
vi+1, w(cid:105)) are convex for all i, as well as w (cid:55)→ (cid:104)v1, w(cid:105)2 and w (cid:55)→ φr((cid:104)vT , w(cid:105)). Therefore, H(w) is convex. As a result,
F is λ-strongly convex due to the λ
2 (cid:107)w(cid:107)2 term. As to smoothness, note ﬁrst that H(w) can be equivalently written as
˜H(V w), where V is some orthogonal d × d matrix with the ﬁrst T rows equal to v1, . . . , vT , and

˜H(x) =

λ(κ − 1)
8

(cid:32)

x2
1 +

T −1
(cid:88)

i=1

φr(xi − xi+1) + (aκ − 1)φr(xT ) − x1

.

(cid:33)

Therefore, ∇2F (w) = ∇2H(w) + λI = V (cid:62)∇2 ˜H(V w)V + λI. It is easily veriﬁed that ∇2 ˜H at any point (and in par-
ticular V w) is tridiagonal, with each element having absolute value at most 2λ(κ − 1). Therefore, using the orthogonality

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

of V and the fact that (a + b)2 ≤ 2(a2 + b2),

x(cid:62)∇2F (w)x = sup

x(cid:62)(V (cid:62)∇2 ˜H(V w)V + λI)x

sup
x:(cid:107)x(cid:107)=1

= sup

x(cid:62)∇2 ˜H(V w)x + λ

x:(cid:107)x(cid:107)=1

x:(cid:107)x(cid:107)=1

≤ sup

2λ(κ − 1)

x:(cid:107)x(cid:107)=1

x2
i + 2

|xixi+1|

+ λ

(cid:33)

d−1
(cid:88)

i=1

≤ sup

2λ(κ − 1)

(|xi| + |xi+1|)2 + λ

x:(cid:107)x(cid:107)=1

≤ sup

4λ(κ − 1)

x:(cid:107)x(cid:107)=1

(x2

i + x2

i+1) + λ

≤ 8λ(κ − 1) + λ ≤ 8λκ.

(cid:32) d

(cid:88)

i=1

d−1
(cid:88)

i=1

d−1
(cid:88)

i=1

Plugging in the deﬁnition of κ, this equals µ. Therefore, the spectral norm of the Hessian of F at any point is at most µ,
and therefore F is µ-smooth.

By construction, the function F also has the following key property:
Lemma 4. For any w ∈ Rd orthogonal to vt, vt+1, . . . , vT (for some t ∈ {1, 2, . . . , T − 1}),
F (w), ∇F (w), ∇2F (w) do not depend on vt+1, vt+2, . . . , vT .

it holds that

Proof. Recall that F is derived from H by adding a λ
2 (cid:107)w(cid:107)2 term, which clearly does not depend on v1, . . . , vT . Therefore,
it is enough to prove the result for H(w), ∇H(w), ∇2H(w). By taking the deﬁnition of H and differentiating, we have
that H(w) is proportional to

(cid:104)v1, w(cid:105)2 +

φr((cid:104)vi − vi+1, w(cid:105)) + (aκ − 1)φr((cid:104)vT , w(cid:105)) − (cid:104)v1, w(cid:105),

T −1
(cid:88)

i=1

T −1
(cid:88)

i=1

∇H(w) is proportional to

and ∇2H(w) is proportional to

T −1
(cid:88)

i=1

2(cid:104)v1, w(cid:105)v1 +

r((cid:104)vi − vi+1, w(cid:105))(vi − vi+1) + (aκ − 1)φ(cid:48)
φ(cid:48)

r((cid:104)vT , w(cid:105))vT − v1,

2v1v(cid:62)

1 +

r ((cid:104)vi − vi+1, w(cid:105))(vi − vi+1)(vi − vi+1)(cid:62) + (aκ − 1)φ(cid:48)(cid:48)
φ(cid:48)(cid:48)

r ((cid:104)vT , w(cid:105))vT v(cid:62)
T .

By the assumption (cid:104)vt, w(cid:105) = (cid:104)vt+1, w(cid:105) = . . . = (cid:104)vT , w(cid:105) = 0, and the fact that φr(0) = φ(cid:48)
have φr((cid:104)vi − vi+1, w(cid:105)) = φ(cid:48)
φr((cid:104)vT , w(cid:105)) = φ(cid:48)
not depend on vt+1, . . . , vT .

r (0) = 0, we
r ((cid:104)vi − vi+1, w(cid:105)) = 0 for all i ∈ {t, t + 1, . . . , T }, as well as
r ((cid:104)vT , bw(cid:105)) = 0. Therefore, it is easily veriﬁed that the expressions above indeed do

r((cid:104)vi − vi+1, w(cid:105)) = φ(cid:48)(cid:48)

r((cid:104)vT , w(cid:105)) = φ(cid:48)(cid:48)

r(0) = φ(cid:48)(cid:48)

With this lemma at hand, we now turn to describe how v1, . . . , vT are constructed:

• First, we compute w1 (which is possible since the algorithm is deterministic and w1 is chosen before any oracle calls

are made).

• We pick v1 to be some unit vector orthogonal to w1. Assuming v2, . . . , vT will also be orthogonal to w1 (which will
be ensured by the construction which follows), we have by Lemma 4 that the information F (w1), ∇F (w1), ∇2F (w1)
provided by the oracle to the algorithm does not depend on {v2, . . . , vT }, and thus depends only on v1 which was
already ﬁxed. Since the algorithm is deterministic, this ﬁxes the next query point w2.

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

• For t = 2, 3, . . . , T − 1, we repeat the process above: We compute wt, and pick vt to be some unit vectors or-
thogonal to w1, w2, . . . , wt, as well as all previously constructed v’s (this is always possible since the dimension
is sufﬁciently large). By Lemma 4, as long as all vectors thus constructed are orthogonal to wt, the information
{F (wt), ∇F (wt), ∇2F (wt)} provided to the algorithm does not depend on vt+1, . . . , vT , and only depends on
v1, . . . , vt which were already determined. Therefore, the next query point wt+1 is ﬁxed.

• At the end of the process, we pick vT to be some unit vector orthogonal to all previously chosen v’s as well as

w1, . . . , wT .

Based on this construction, the following lemma is self-evident:
Lemma 5. It holds that (cid:104)wT , vT (cid:105) = 0.

Based on this lemma, we now turn to argue that wT must be a sub-optimal point. We ﬁrst establish the following result:
Lemma 6. Letting w(cid:63) = arg minw F (w), it holds that

(cid:13)
(cid:13)
w(cid:63) −
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

i=1

qivi

≤

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:114)

T µr2
16λ

sup
w∈Rd

|Fr(w) − F0(w)| ≤

T µr2
32

.

where q =

√
κ−1√
κ+1 .

This is because

Proof. Let Fr denote F , where we make the dependence on the parameter r explicit. We ﬁrst argue that

(7)

(8)

(cid:33)
,

λ
2

|Fr(w) − F0(w)| ≤

|φr((cid:104)vi − vi+1, w(cid:105)) − φ0((cid:104)vi − vi+1, w(cid:105))|

λ(κ − 1)
8

(cid:32) T −1
(cid:88)

i=1

+ |φr((cid:104)vT , w(cid:105)) − φ0((cid:104)vT , w(cid:105))|

and since supz∈R |φr(z) − φ0(z)| = supz∈R |φr(z) − z2| ≤ 2r2, the above is at most λ(κ−1)
that κ = µ/8λ, Eq. (7) follows.

4

T r2 ≤ λκ

4 T r2. Recalling

Let wr = arg min Fr(w). By λ-strong convexity of F0 and Fr,

F0(wr) − F0(w0) ≥

(cid:107)wr − w0(cid:107)2

, Fr(w0) − Fr(wr) ≥

(cid:107)w0 − wr(cid:107)2.

λ
2

Summing the two inequalities and using Eq. (7),

λ(cid:107)wr − w0(cid:107)2 ≤ F0(wr) − Fr(wr) + Fr(w0) − F0(w0) ≤

T µr2
16

,

and therefore

(cid:107)wr − w0(cid:107)2 ≤

T µr2
16λ

.

By deﬁnition, wr = w(cid:63) from the statement of our lemma, so it only remains to prove that w0 = arg min F0(w) equals
(cid:80)T
i=1 qivi. To see this, note that F0(w) can be equivalently written as ˜F (V w), where V is some orthogonal d × d matrix
with its ﬁrst T rows equal to v1, . . . , vT , and

(cid:32)

˜F (x) =

λ(κ − 1)
8

T −1
(cid:88)

i=1

x2
1 +

(xi − xi+1)2 + (aκ − 1)x2

T − w1

+

(cid:107)x(cid:107)2.

(cid:33)

λ
2

By an immediate corollary of Lemma 1, ˜F (·) is minimized at (q, q2, . . . , qT , 0, . . . , 0), where q =
F (w) = ˜F (V w) is minimized at V (cid:62)(q, q2, . . . , qT , 0, . . . , 0), which equals (cid:80)T
i=1 qivi as required.

√
κ−1√

κ+1 , and therefore

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

Note that this lemma also allows us to bound the norm of w(cid:63) = arg min F (w), since it implies that

(cid:107)w(cid:63)(cid:107) ≤

qivi

+

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:114)

T µr2
16λ

,

and since (a + b)2 ≤ 2a2 + 2b2 and q < 1, we have

T µr2
8λ

= 2

q2i +

T
(cid:88)

i=1

T µr2
8λ

(cid:107)w(cid:63)(cid:107)2 ≤ 2

qivi

T
(cid:88)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
i=1
∞
(cid:88)

+

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
T µr2
8λ

2q2
1 − q2 +

T µr2
8λ

≤ 2

q2i +

i=1
2
1 − q

≤

+

T µr2
8λ

=

√

=

κ + 1 +

T µr2
8λ

,

which is at most

κ + 2 ≤ 3

√

√

κ, since we assume that c is sufﬁciently small so that T µr2

8λ ≤ 1, and that κ = µ/8λ ≥ 1.

The proof of the theorem follows by combining Lemma 5 and Lemma 6. Speciﬁcally, Lemma 5 (which states that
(cid:104)wT , vT (cid:105) = 0) and the fact that v1, . . . , vT are orthonormal tells us that

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

i=1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:33)

T −1
(cid:88)

i=1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T −1
(cid:88)

i=1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

wT −

qivi

=

wT −

qivi

− qT vT

=

wT −

qivi

+ (cid:107)qT vT (cid:107)2

≥ (cid:107)qT vT (cid:107)2 = q2T ,

By the assumption that c is sufﬁciently small so that
we get

(cid:113) T µr2

16λ ≤ 1

2 qT , the left hand side is at least 1

2 qT . Squaring both sides,

and hence

On the other hand, Lemma 6 states that

Combining the last two displayed equations by the triangle inequality, we get that

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

wT −

qivi

≥ qT .

T
(cid:88)

i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
w(cid:63) −
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

i=1

qivi

≤

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:114)

T µr2
16λ

.

(cid:107)wT − w(cid:63)(cid:107) ≥ qT −

(cid:114)

T µr2
16λ

.

(cid:107)wT − w(cid:63)(cid:107)2 ≥

q2T ,

1
4

F (wT ) − F (w(cid:63)) ≥

(cid:107)wT − w(cid:63)(cid:107)2 ≥

q2T .

λ
8

F (wT ) − F (w(cid:63)) ≥

(cid:18) √
√

λ
8

κ − 1
κ + 1

(cid:19)2T

.

λ
2

√

F (wT ) − F (w(cid:63))
F (0) − F (w(cid:63))

≥

λ
√
12µ

κ

(cid:18) √
√

κ − 1
κ + 1

(cid:19)2T

so by strong convexity of F ,

Plugging in the value of q, we get

On the other hand, we showed earlier that (cid:107)w(cid:63)(cid:107)2 ≤ 3
Therefore,

κ, so by smoothness, F (0) − F (w(cid:63)) ≤ µ

2 (cid:107)w(cid:63)(cid:107)2 ≤ 3µ

2

√

κ.

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

To make the right-hand side less than (cid:15), T must be such that

which is equivalent to

Since log

(cid:17)

(cid:16) √

κ+1√
κ−1

(cid:16)

(cid:17)

= log

1 + 2√

≤ 2√

κ−1

κ−1 , it follows that T must be such that

(cid:18) √
√

κ − 1
κ + 1

(cid:19)2T

√

12µ
λ

κ(cid:15)

,

≤

2T · log

(cid:18) √
√

(cid:19)

κ + 1
κ − 1

≥ log

(cid:18)

λ
√
12µ

κ(cid:15)

(cid:19)

.

√

4T
κ − 1

≥ log

(cid:18)

λ
√
12µ

κ(cid:15)

(cid:19)

.

T ≥

(cid:18)(cid:114) µ
8λ

1
4

(cid:19)

− 1

· log

(cid:32) √

8(λ/µ)3/2
12(cid:15)

(cid:33)

,

Plugging in κ = µ/8λ and simplifying a bit, we get that

from which the result follows.

A.3. Proof of Thm. 2

We will deﬁne a randomized choice of quadratic functions f1, . . . , fn, and prove a lower bound on the expected optimiza-
tion error of any algorithm (where the expectation is over both the algorithm and the randomized functions). This implies
that for any algorithm, the same lower bound (in expectation over the algorithm only) holds for some deterministic choice
of f1, . . . , fn.

There will actually be two separate constructions, one leading to a lower bound of Ω(n), and one leading to a lower bound
of Ω

. Choosing the construction which leads to the larger lower bound, the theorem follows.

(cid:16) (λ/µ)3/2√

(cid:16)(cid:112) nµ

(cid:17)(cid:17)

n

λ · log

(cid:15)

A.3.1. AN Ω(n) LOWER BOUND

Starting with the Ω(n) lower bound, let δi, where i ∈ {1, . . . , n}, be chosen uniformly at random from {−1, +1}, and
deﬁne

fi(w) = −δiw1 +

(cid:107)w(cid:107)2.

λ
2

(cid:80)n

Clearly, these are λ-smooth (and hence µ-smooth) functions, as well as λ-strongly convex. Also, the optimum of F (w) =
µ
, so
n
by λ-smoothness of F

(cid:1) e1, where e1 is the ﬁrst unit vector. As a result, (cid:107)w(cid:63)(cid:107)2 = 1

i=1 fi(w) equals w(cid:63) = (cid:0) 1

i=1 δi

i=1 δi

(cid:0) 1
n

(cid:80)n

(cid:80)n

(cid:1)2

nλ

λ2

F (0) − F (w(cid:63)) ≤

(cid:107)w(cid:63)(cid:107)2 =

λ
2

1
2λ

(cid:32)

1
n

n
(cid:88)

i=1

(cid:33)2

δi

.

Since δi are i.i.d., we have by Hoeffding’s bound that with probability at
(cid:112)2 log(8/3)/n ≤ (cid:112)2/n. Plugging into the equation above, we get that with probability at least 3/4,

least 3/4,

(cid:12)
(cid:12) 1
n

(cid:80)n

i=1 δi

(cid:12)
(cid:12) is at most

F (0) − F (w(cid:63)) ≤

1
λn

.

(9)

Turning to lower bound F (wT ) − F (w(cid:63)), we have by strong convexity that

F (wT ) − F (w(cid:63)) ≥

(cid:107)wT − w(cid:63)(cid:107)2 ≥

(wT,1 − w(cid:63)

1)2

λ
2

1
2λ

(cid:32)

=

λwT,1 −

λ
2

(cid:33)2

δi

.

1
n

n
(cid:88)

i=1

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

Now, if at most (cid:98)n/2(cid:99) indices {1, . . . , n} were queried by the algorithm, then the wT returned by the algorithm must
be independent of at least (cid:100)n/2(cid:101) random variables δj1, . . . , δj(cid:100)n/2(cid:101) (for some distinct indices j1, j2, . . . depending on the
algorithm’s behavior, but independent of the values of δj1, . . . , δj(cid:100)n/2(cid:101)). Therefore, conditioned on j1, . . . , j(cid:100)n/2(cid:101) and the
values of δj1 , . . . , δj(cid:100)n/2(cid:101), the expression above can be written as

where η is a ﬁxed quantity independent of the values of δi for i /∈ {j1, . . . , j(cid:100)n/2(cid:101)}. By a standard anti-concentration
argument, with probability at least 3/4, this expression will be at least 1
2λn for some universal positive c(cid:48) > 0.
2λ
Since this is true for any j1, . . . , j(cid:100)n/2(cid:101) and δj1, . . . , δj(cid:100)n/2(cid:101), we get that with probability at least 3/4 over δ1, . . . , δn,

(cid:16) c(cid:48)
√
n

= c(cid:48)2

(cid:17)2

Combining this with Eq. (9) using a union bound, we have that with probability at least 1/2,



η −

1
n

1
2λ

(cid:88)


2

δi



,

i /∈{j1,...,j(cid:100)n/2(cid:101)}

F (wT ) − F (w(cid:63)) ≥

c(cid:48)2
2λn

.

F (wT ) − F (w(cid:63))
F (0) − F (w(cid:63))

≥

c(cid:48)2λn
2λn

=

c(cid:48)2
2

.

As a result, since the ratio above is always a non-negative quantity,
(cid:20) F (wT ) − F (w(cid:63))
F (0) − F (w(cid:63))

E

(cid:21)

≥

c(cid:48)2
4

.

Using the assumption stated in the theorem (taking c = c(cid:48)2/4), we have that the right hand side cannot be smaller than (cid:15),
unless more than (cid:98)n/2(cid:99) = Ω(n) oracle calls are made.

A.3.2. AN Ω

(cid:16)(cid:112) nµ

λ · log

(cid:16) (λ/µ)3/2√

n

(cid:17)(cid:17)

(cid:15)

LOWER BOUND

λ · log (cid:0) λ
We now turn to prove the Ω (cid:0)(cid:112) nµ
chosen uniformly and independently at random from {1, . . . , n}, and deﬁne

(cid:15)

(cid:1)(cid:1) lower bound, using a different function construction: Let j1, . . . , jd−1 be

fi(w) =

1jl=i(wl − wl+1)2 +

w2

1 + (aκ − 1)w2

d − w1

+

(cid:107)w(cid:107)2.

(10)

(cid:18)

1
n

(cid:19)(cid:33)

λ
2

µ − λ
8

(cid:32)d−1
(cid:88)

l=1

where 1A is the indicator of the event i. Note that these are all λ-strongly convex functions, as all terms in their deﬁnition
are convex in w, and there is an additional λ
2 (cid:107)w(cid:107)2 term. Moreover, they are also µ-smooth: To see this, note that
∇2fi(w) (cid:22) (µ−λ)
The average function F (w) = 1
n

4 A + λI (cid:22) µI, where A (cid:22) 4I is as deﬁned in the proof of Lemma 1.

i=1 fi(w) equals

(cid:80)n

F (w) =

w2

1 +

(wi − wi+1)2 + (aκ − 1)w2

d − w1

+

(cid:107)w(cid:107)2,

(11)

(cid:32)

µ − λ
8n

d−1
(cid:88)

i=1

(cid:33)

λ
2

Therefore, by Lemma 1, the smoothness parameter of F is (µ − λ)/n + λ ≤ µ, the global minimum w(cid:63) of F equals
(q, q2, . . . , qd), where q =

√
κ−1√

κ+1 and

µ
λ − 1
n
Note that since q < 1 and κ ≥ 1, the squared norm of w(cid:63) is at most

µ−λ
n + λ
λ

κ =

=

+ 1.

√

d
(cid:88)

i=1

q2i ≤

q2i =

∞
(cid:88)

i=1

q2
1 − q2 ≤

1
1 − q

=

κ + 1
2

√

κ,

≤

(12)

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

hence by smoothness,

F (0) − F (w(cid:63)) ≤

(cid:107)w(cid:63)(cid:107)2 ≤

µ
2

√

κ.

µ
2

With these preliminaries out of the way, we now turn to compute a lower bound on the expected optimization error. The
proof is based on arguing that wT can only have a ﬁrst few coordinates being non-zero. To see how this gives a lower
bound, let lT ∈ {1, . . . , d} be the largest index of a non-zero coordinate of wT (or 0 if wT = 0). By deﬁnition of w(cid:63), we
have

where

(cid:107)wT − w(cid:63)(cid:107)2 ≥

q2i ≥ g(lT ),

d
(cid:88)

i=lT +1

g(z) =

(cid:40)

q2(z+1)
0

z < d
z ≥ d

.

By strong convexity of F , this implies that

F (wT ) − F (w(cid:63)) ≥

(cid:107)wT − w(cid:63)(cid:107)2 ≥

g(lT ).

λ
2

λ
2

Finally, taking expectation over the randomness of j1, . . . , jd−1 above (and over the internal randomness of the algorithm,
if any), applying Lemma 2, and choosing the dimension d = (cid:100)2E[lT ](cid:101) (which we will later show to equal the value speciﬁed
in the theorem), we have

E [F (wT ) − F (w(cid:63))] ≥

q4E[lT ]+4 =

λ
4

(cid:18) √
√

λ
4

κ − 1
κ + 1

(cid:19)2E[lT ]+2

.

Combined with Eq. (13), this gives

Thus, it remains to upper bound E[lT ].

E

(cid:20) F (wT ) − F (w(cid:63))
F (0) − F (w(cid:63))

(cid:21)

≥

λ
√
2µ

κ

(cid:18) √
√

κ − 1
κ + 1

(cid:19)2E[lT ]+2

.

(13)

(14)

(15)

To get a bound, we rely on the following key lemma (where ei is the i-th unit vector, and recall that Wt deﬁnes the set of
allowed query points wt, and j1, . . . , jd are the random indices used in constructing f1, . . . , fn):
Lemma 7. For all t,
it holds that Wt ⊆ span{ed, e1, e2, e3, . . . , e(cid:96)t} for all t, where (cid:96)t is deﬁned recursively
as follows: (cid:96)1 = 1, and (cid:96)t+1 equals the largest number in {1, . . . , d − 1} such that {j(cid:96)t, j(cid:96)t+1, . . . , j(cid:96)t+1−1} ⊆
{it, it−1, . . . , imax{1,t−(cid:98)n/2(cid:99)+1}} (and (cid:96)t+1 = (cid:96)t if no such number exists).

As will be seen later, (cid:96)T (which is a random variable as a function of the random indices j1, . . . , jd) upper-bounds the
number of non-zero coordinates of wT , and therefore we can upper bound E[lT ] by E[(cid:96)T ].

Proof. The proof is by induction over t. Since W1 = {0} ⊆ span(ed), the result trivially holds for t = 1. Now, suppose
that Wt ⊆ span{ed, e1, . . . , e(cid:96)t} for some t and (cid:96)t. Note that in particular, this means that wt is non-zero only in its ﬁrst
(cid:96)t coordinates. By deﬁnition of fi for any i,

∇fi(w) =

1jl=i(wl − wl+1)(el − el+1) +

(2w1e1 + 2(aκ − 1)wded − e1)

+ λw

λn(κ − 1)
8

λn(κ − 1)
8

(cid:32)
2

d−1
(cid:88)

l=1

(cid:32)d−1
(cid:88)

l=1

1
n

1
n

(cid:33)

(cid:33)

∇2fi(w) =

1jl=i(2El,l − El+1,l − El,l+1) +

(2E1,1 + 2(aκ − 1)Ed,d)

+ λI,

where Er,s is the d × d which is all zeros, except for an entry of 1 in location (r, s). It is easily seen that these expressions
imply the following:

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

• If j(cid:96)t (cid:54)= it, then ∇fit(wt) ∈ span{ed, e1, . . . , e(cid:96)t}, otherwise ∇fit(wt) ∈ span{ed, e1, . . . , e(cid:96)t+1}.

• For any w and l ∈ {1, . . . , d − 1}, if jl (cid:54)= i, then ∇2fi(w) is block-diagonal, with a block in the ﬁrst l × l entries. In

other words, any entry (r, s) in the matrix, where r ≤ l and s > l (or r > l and s ≤ l) is zero.

• As a result, if jl /∈ {it, it−1, . . . , imax{1,t−(cid:98)n/2(cid:99)+1}}, then (cid:80)t

τ =max{1,t−(cid:98)n/2(cid:99)+1} ατ ∇2fiτ (wτ ), for arbitrary scalars
τ , is block-diagonal with a block in the ﬁrst l × l entries. The same clearly holds for any matrix with the same
block-diagonal structure.

these observations imply that

the operations speciﬁed in Assumption 1 can lead to vectors out-
Together,
side span{ed, e1, . . . , e(cid:96)t}, only if j(cid:96)t ∈ {it, it−1, . . . , imax{1,t−(cid:98)n/2(cid:99)+1}}. Moreover,
these vectors must be-
long to span{ed, e1, . . . , e(cid:96)t+1}, where (cid:96)t+1 is as speciﬁed in the lemma: By deﬁnition,
in
{it, it−1, . . . , imax{1,t−(cid:98)n/2(cid:99)+1}}, and therefore all relevant Hessians have a block in the ﬁrst (cid:96)t+1 × (cid:96)t+1 entries, hence it
is impossible to create a vector with non-zero coordinates (using the operations of Assumption 1) beyond the ﬁrst (cid:96)t+1.

is not

j(cid:96)t+1

Since wT ⊆ WT , the lemma above implies that E[lT ] from Eq. (15) (where lT is the largest index of a non-zero coordinate
of wT ) can be upper-bounded by E[(cid:96)T ], where the expectation is over the random draw of the indices j1, . . . , jd−1. This
can be bounded using the following lemma:
Lemma 8. It holds that E[(cid:96)T ] ≤ 1 + 2(T −1)

.

n

Proof. By deﬁnition of (cid:96)t and linearity of expectation, we have

E[(cid:96)T ] = E

((cid:96)t+1 − (cid:96)t)

+ (cid:96)1 =

E[(cid:96)t+1 − (cid:96)t] + 1.

(16)

(cid:34)T −1
(cid:88)

t=1

(cid:35)

T −1
(cid:88)

t=1

Let us consider any particular term in the sum above. Since (cid:96)t+1 − (cid:96)t is a non-negative integer, we have

E[(cid:96)t+1 − (cid:96)t] = Pr ((cid:96)t+1 > (cid:96)t) · E [(cid:96)t+1 − (cid:96)t | (cid:96)t+1 > (cid:96)t] .

By deﬁnition of (cid:96)t,
the event (cid:96)t+1 > (cid:96)t can occur only if j(cid:96)t /∈ {it−1, it−2, . . . , imax{1,t−(cid:98)n/2(cid:99)}}, yet j(cid:96)t ∈
{it, it−1, . . . , imax{1,t−(cid:98)n/2(cid:99)+1}}. This is equivalent to j(cid:96)t = it (that is, in iteration t we happened to choose the in-
dex j(cid:96)t of the unique individual function, which contains the block linking coordinate (cid:96)t and (cid:96)t + 1, hence allowing
us to “advance” and have more non-zero coordinates). But since the algorithm is oblivious, it is ﬁxed whereas j(cid:96)t is
chosen uniformly at random, hence the probability of this event is 1/n. Therefore, Pr ((cid:96)t+1 > (cid:96)t) ≤ 1/n. Turning
to the conditional expectation of (cid:96)t+1 − (cid:96)t above, it equals the expected number of indices j(cid:96)t, j(cid:96)t+1, . . . belonging to
{it, it−1, . . . , imax{1,t−(cid:98)n/2(cid:99)+1}}, conditioned on j(cid:96)t belonging to that set. But since the i indices are ﬁxed and the j
indices are chosen uniformly at random, this equals one plus the expected number of times where a randomly drawn
j ∈ {1, . . . , n} belongs to {it, it−1, . . . , it−(cid:98)n/2(cid:99)+1}. Since this set contains at most (cid:98)n/2(cid:99) distinct elements in {1, . . . , n},
this is equivalent to (one plus) the expectation of a geometric random variable, where the success probability is at most
1/2. By a standard derivation, this is at most 1 + 1/2

1−1/2 = 2. Plugging into the displayed equation above, we get that

E[(cid:96)t+1 − (cid:96)t] ≤

· 2 =

1
n

2
n

,

and therefore the bound in Eq. (16) is at most 2(T −1)

n + 1 as required.

Plugging this bound into Eq. (15), we get

E

(cid:20) F (wT ) − F (w(cid:63))
F (0) − F (w(cid:63))

(cid:21)

≥

λ
√
2µ

κ

(cid:18) √
√

κ − 1
κ + 1

(cid:19) 4(T −1)

n +4

.

To make the right-hand side less than (cid:15), T must be such that

(cid:19) 4(T −1)

n +4

(cid:18) √
√

κ − 1
κ + 1

2µ

κ(cid:15)

,

≤

√

λ

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

which is equivalent to

(cid:18) 4(T − 1)
n

(cid:19)

+ 4

log

(cid:18) √
√

(cid:19)

κ + 1
κ − 1

≥ log

(cid:18) λ
√
2µ

κ(cid:15)

(cid:19)

.

(cid:16) √

(cid:17)

κ+1√
Since log
κ−1
must be such that

(cid:16)

(cid:17)

= log

1 + 2√

≤ 2√

κ−1

κ−1 (see, e.g., Lemma 12 in (Arjevani and Shamir, 2016a)), it follows that T
(cid:19)

(cid:19)

(cid:18) 4(T − 1)
n

+ 4

√

≥ log

2
κ − 1

(cid:18) λ
√
2µ

κ(cid:15)

.

Plugging in κ =

µ
λ −1
n + 1, we get that

Using asymptotic notation the right-hand side equals

T ≥ 1 +



(cid:113) µ

n
4







· log

λ −1
n

2





 − 4

 .

λ
(cid:113) µ

2µ(cid:15)

λ −1
n + 1

(cid:18)
(cid:112)n(µ/λ − 1) log

Ω

(cid:18) (λ/µ)3/2√
(cid:15)

(cid:19)(cid:19)

n

.

as required. The bound on the dimension d follows from the fact that we chose it to be O(E[lT ]) = O(1 + T /n), and to
make the lower bound valid it is enough to pick some T = O

(cid:16) (λ/µ)3/2√

(cid:16)(cid:112) nµ

(cid:17)(cid:17)

n

.

λ · log

(cid:15)

A.4. Proof of Thm. 3

Recall that the proof of Thm. 2 essentially shows that for any (possibly stochastic) index-oblivious optimization algorithm
there exists some ‘bad’ assignment of the d − 1 blocks j1, . . . , jd−1 whose corresponding fi : Rd → R (see Eq. (10))
form a functions which is hard-to-optimize. When considering non-oblivious (i.e., adaptive) algorithms this construction
fails as soon as the algorithm obtains the Hessians of all the individual functions (potentially, after n second-order oracle
queries). Indeed, knowing the Hessians of fi, one can devise an index-schedule which gains at least one coordinate at
every iteration, as opposed to 1/n on average for the oblivious case. Thus, in order to tackle the non-oblivious case, we
form a function over some D-dimensional space which ‘contains’ all the nd−1 sub-problems at one and the same time
(clearly, to carry out our plans we must pick D which grows exponentially fast with d, the dimension of the sub-problems).
This way, any index-schedule, oblivious or adaptive, must ‘ﬁt’ all the nd−1 sub-problems well, and as such, bound to a
certain convergence rate which we analyze below.

Denote [n] = {1, . . . , n}, set D = nd−1d and deﬁne for any j ∈ [n]d−1 the following,

f j
i : Rd → R,

w (cid:55)→

1jl=i(wl − wl+1)2 +

w2

1 + (aκ − 1)w2

d − w1

+

(cid:107)w(cid:107)2,

(cid:18)

1
n

(cid:19)(cid:33)

λ
2

Qj : RD → Rd,

u (cid:55)→

u(cid:62)e#jd+l

µ − λ
8

(cid:32)d−1
(cid:88)

l=1

d
(cid:88)

l=1

where #j enumerates the nd−1 tuples [n]d−1 from 0 to nd−1 − 1. Note that f j
we make the dependence on j explicit. The individual functions are deﬁned as follows:

i are deﬁned exactly as in Eq. (10), only here

Note that,

fi(u) =

(cid:88)

f j
i (Qju).

j∈[n]d−1

∇2fi(u) =

(cid:88)

(Qj)(cid:62)∇2f j

i (Qju)Qj.

j∈[n]d−1

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

Since ∇2fi are block-diagonal, we have Λ(∇2fi) = (cid:83)
Thus, since f j
convex.

i ), where Λ(·) denotes the spectrum of a given matrix.
i are µ-smooth and λ-strongly convex (see proof of Thm. 2), we see that fi is also µ-smooth and λ-strongly

j Λ(∇2f j

As for the average function Φ(u) = 1
n

i=1 fi(u), it is easily veriﬁed that for any ﬁxed j ∈ [n]d−1,

(cid:80)n

1
n

n
(cid:88)

i=1

f j
i (Qju) = F (Qju),

where F is as deﬁned in Eq. (11). Thus,

n
(cid:88)

(cid:88)

Φ(u) =

1
n

f j
i (Qju) =

(cid:88)

F (Qju).

i=1

j∈[n]d−1

j∈[n]d−1

To compute the minimizer of Φ, we compute the ﬁrst-order derivative:

Thus, by setting u∗ = (cid:80)

j(Qj)(cid:62)w∗, where w∗ is the minimizer of F as in Lemma 1, we get

∇Φ(u∗) =

(cid:88)

(Qj)(cid:62)∇F

Qj (cid:88)

(Qj)(cid:62)u∗

=

(cid:88)

(Qj)(cid:62)∇F (w∗) = 0.

(cid:18)

(cid:19)

j∈[n]d−1

j

j∈[n]d−1

Note that, by Eq. (13), (cid:107)u∗(cid:107)2 = nd−1(cid:107)w∗(cid:107)2 ≤ nd−1√

Φ(0) − Φ(u(cid:63)) ≤

κ. Hence, by smoothness,
nd−1√

(cid:107)u(cid:63)(cid:107)2 ≤

κ.

µ
2

µ
2

To derive the analytical properties of Φ, we compute the second derivative:

(17)

∇Φ(u) = ∇

(cid:88)

F (Qju)





j∈[n]d−1
(cid:18)

(cid:88)

∇

F (Qju)





(cid:19)

=

=

j∈[n]d−1
(cid:88)

j∈[n]d−1

(Qj)(cid:62)∇F (Qju).

∇2Φ(u) =

∇((Qj)(cid:62)∇F (Qju))

(cid:88)

=

=

j∈[n]d−1
(cid:88)

j∈[n]d−1
(cid:88)

j∈[n]d−1

(Qj)(cid:62)∇(∇F (Qju))

(Qj)(cid:62)∇2F (Qju)Qj.

Since ∇2Φ is a block-diagonal matrix, we have Λ(∇2Φ) = (cid:83)
is ((µ − λ)/n + λ)-smooth and λ-strongly convex.

j Λ(∇2F ) = Λ(∇2F ). Thus, by Lemma 1, it follows that Φ

With these preliminaries out of the way, we now turn to compute a lower bound on the expected optimization error. The
proof follows by arguing that uT can only have a ﬁrst few coordinates being non-zero for each of the nd−1 sub-problems.
To see how this gives a lower bound, let lj
T ∈ {1, . . . , d} be the largest index of a non-zero coordinate of QjuT (or 0 if

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

QjuT = 0). By the deﬁnition of u(cid:63) and by Eq. (12), we have

(cid:107)uT − u∗(cid:107)2 = (cid:107)

(Qj)(cid:62)QjuT −

(Qj)(cid:62)w∗(cid:107)2

(cid:88)

j
(cid:88)

(cid:88)

j

= (cid:107)

(Qj)(cid:62)(QjuT − w∗)(cid:107)2

(cid:107)QjuT − w∗(cid:107)2

=

≥

j
(cid:88)

j
(cid:88)

j

g(lj

T ),

where g is deﬁned in Eq. (14). By the strong convexity of F , this implies that

Φ(uT ) − Φ(u(cid:63)) ≥

(cid:107)uT − u(cid:63)(cid:107)2 ≥

λ
2

(cid:88)

g(lj

T ).

λ
2

j

We now proceed along the same lines as in the proof of Thm. 2. First, to upper bound lj
T (note that, g is monotonically
decreasing), we use the following generalized version of Lemma 7 (whose proof is a straightforward adaptation of the
proof of Lemma 7):
Lemma 9. Under Assumption 1, for all t, it holds that

Ut ⊆ span

{e#jd+d, e#jd+1, e#jd+2, e#jd+3, . . . , e#jd+(cid:96)j






(cid:91)

j∈[n]d−1



}


t

for all t, where (cid:96)j
t+1, . . . , j(cid:96)j
{j(cid:96)j

t is deﬁned recursively as follows: (cid:96)j
t+1−1} ⊆ {it, it−1, . . . , imax{1,t−(cid:98)n/2(cid:99)+1}} (and (cid:96)j

1 = 1, and (cid:96)j

, j(cid:96)j

t

t+1 equals the largest number in {1, . . . , d − 1} such that

t+1 = (cid:96)j

t if no such number exists).

As in the proof of Thm. 2, (cid:96)j

T bound lj

T from above (for any given choice of i1, . . . , iT ), and since d is chosen so that

1
nd−1

(cid:88)

(cid:96)j
T ≤

d
2

,

j

(18)

we may take expectation over the internal randomness of the algorithm (if any), and combine it with (17) and Lemma 11
and Lemma 10 below to get

E

(cid:20) Φ(uT ) − Φ(u(cid:63))
Φ(0) − Φ(u(cid:63))

(cid:21)

≥ E









λ
κnd−1

√

µ

(cid:88)

g(lj

T )

j



g



λ
√
2µ

κ

1
nd−1

(cid:88)

j


 ≥ E









(cid:96)j
T



 ≥



λ
κnd−1

√

µ

(cid:88)

g((cid:96)j

T )



j
(cid:18) √
√

κ − 1
κ + 1

λ
√
2µ

κ

≥ E

(cid:19) 4(T −1)

n +4

.

Following the same derivation as in the proof of Thm. 2, we get that T must be of order of

(cid:18)
(cid:112)n(µ/λ − 1) log

Ω

(cid:18) (λ/µ)3/2√
(cid:15)

(cid:19)(cid:19)

n

,

(cid:18)

2

1 +

(cid:19)

2(T − 1)
n

≤ d,

as required. The bound on d follows from the fact that we chose it to satisfy Inequality (18) through the following condition,

and to make the lower bound valid it is enough to pick some T = O
˜O
˜O(1 + (cid:112)µ/λn), implying D = nd−1d = n

µ/λn

√

1+

(cid:17)

(cid:16)

.

(cid:16)(cid:112) nµ

λ · log

(cid:16) (λ/µ)3/2√

n

(cid:17)(cid:17)

(cid:15)

. Thus, we have that d is

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

Lemma 10. For any ﬁxed sequence i := i1, . . . , iT ∈ [n] of individual functions chosen during a particular execution of
an optimization algorithm which satisﬁes Assumption 2, it holds that,

1
nd−1

(cid:88)

j

(cid:96)j
T ≤ 1 +

2(T − 1)
n

.

Proof. By Lemma 9, (cid:96)j

t+1 depends only on jp for (cid:96)j

t ≤ p ≤ (cid:96)j

t+1. Thus, we may deﬁne

As =

(j1, . . . , js) | (cid:96)(j1,...,js,∗)

= s, (cid:96)(j1,...,js,∗)
t+1

> s

, s ∈ [d],

Bs =

(j1, . . . , js) | (cid:96)(j1,...,js,∗)

= s, (cid:96)(j1,...,js,∗)
t+1

= s

, s ∈ [d].

(cid:26)

(cid:26)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

t

t

(cid:27)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:27)(cid:12)
(cid:12)
(cid:12)
(cid:12)

Intuitively, As and Bs count how many tuples (j1, . . . , js), under a given choice of i1, . . . , iT , allow at most s non-zero
coordinates after t iterations, with one major difference: in As we want to allow the algorithm to make a progress after t+1
iterations (equivalently, js = it), whereas in Bs we want the algorithm to have the same number of s non-zero coordinates
after t + 1 (equivalently, js (cid:54)= it). One can easily verify the following:

d
(cid:88)

(As + Bs)nd−s−1 = nd−1,

s=1
Bs = (n − 1)As.

The ﬁrst equality may be obtained by splitting the space of all [n]d−1 tuples into a group of disjoint sets characterized by
the maximal number of non-zero coordinates the algorithm may gain by the t iteration. The second equality is a simple
consequence of the way js is being constrained by As and Bs. This yields,

d
(cid:88)

s=1

Asn−s = n−1.

(19)

Denoting I := {it, it−1, . . . , imax{t−(cid:98)n/2(cid:99)+1,1}}, we get that for any 1 ≤ s ≤ d − 1 and 1 ≤ k ≤ d − s,
(cid:12)
(cid:12)
(cid:12)
(cid:12)

t+1 = s + k

(cid:27)(cid:12)
(cid:12)
(cid:12)
(cid:12)

j | (cid:96)j

(cid:26)

(j1, . . . , js−1) | (cid:96)(j1,...,js−1,it,∗)

t

= s

(js+1, . . . , js+k) | js+1, . . . , js+k−1 ∈ I, js+k /∈ I

· nd−s−k−1

(cid:27)(cid:12)
(cid:12)
(cid:12)
(cid:12)

t = s, (cid:96)j
(cid:12)
(cid:26)
(cid:12)
(cid:12)
(cid:12)

=

= As|I|k−1(n − |I|)nd−s−k−1

This allows us to bound from above the average (cid:96)j

t+1 − (cid:96)j

t over j as follows,

1
nd−1

(cid:88)

j

((cid:96)j

t+1 − (cid:96)j

t) =

(cid:26)

(cid:27)(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

·

=

=

=

=

d−1
(cid:88)

s=1

d−1
(cid:88)

s=1

d−1
(cid:88)

s=1

1
nd−1

1
nd−1

d−1
(cid:88)

d−s
(cid:88)

(cid:26)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

s=1

k=1

d−1
(cid:88)

d−s
(cid:88)

s=1

k=1

j | (cid:96)j

t = s, (cid:96)j

t+1 = s + k

(cid:27)(cid:12)
(cid:12)
(cid:12)
(cid:12)

k

As|I|k−1(n − |I|)nd−s−k−1k

d−s
(cid:88)

k=1
(cid:18)

Asn−s

|I|k−1(n − |I|)n−kk

Asn−s

1 −

(cid:18)

Asn−s

1 −

|I|
n

|I|
n

(cid:19) d−s
(cid:88)

k=1
(cid:19) ∞
(cid:88)

k=1

(cid:18) |I|
n

(cid:18) |I|
n

(cid:19)k−1

(cid:19)k−1

k

k.

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

By standard manipulations of power series we have,

∞
(cid:88)

k=0

xk =

1
1 − x

∞
(cid:88)

k=1

=⇒

kxk−1 =

1
(1 − x)2 .

Combining this with Eq. (19) and the fact that |I| ≤ n/2 yields,

1
nd−1

(cid:88)

j

((cid:96)j

t+1 − (cid:96)j

t) ≤

Asn−s

1 −

≤ 2

Asn−s ≤

d−1
(cid:88)

s=1

(cid:18)

(cid:19)−1

|I|
n

2
n

,

which, in turn, gives

d−1
(cid:88)

s=1

(cid:33)

1
nd−1

(cid:88)

(cid:96)j
T =

1
nd−1

j

(cid:32)T −1
(cid:88)

(cid:88)

j

t=1

((cid:96)j

t+1 − (cid:96)j

t) + (cid:96)j

1

((cid:96)j

t+1 − (cid:96)j

t) +

1
nd−1

(cid:88)

(cid:96)j
1

j

=

≤

T −1
(cid:88)

1
nd−1

(cid:88)

j

t=1
2(T − 1)
n

+ 1.

Lemma 11. For some q ∈ (0, 1) and positive d, deﬁne

Let a1, . . . , ap be a sequence of non-negative reals, such that

g(z) =

(cid:40)

q2(z+1)
0

z < d
z ≥ d

.

1
p

p
(cid:88)

i=1

ai ≤

d
2

,

1
p

p
(cid:88)

i

g(ai) ≥

(cid:32)

1
2

g

1
p

p
(cid:88)

i=1

(cid:33)

ai

.

then

Note that,

Proof. Since q ∈ (0, 1), the function z (cid:55)→ qz is convex for non-negative z. Therefore, by the deﬁnition of g and Jensen’s
inequality we have

1
p

p
(cid:88)

i

q(ai) =

|{i : ai < d}|
p

1
|{i : ai < d}|

(cid:88)

g(ai)

{i:ai<d}

≥

|{i : ai < d}|
p



g



1
|{i : ai < d}|

(cid:88)

{i:ai<d}



ai

 .

d
2

≥

1
p

p
(cid:88)

i=1

ai =

1
p

(cid:88)

ai +

1
p

(cid:88)

{i:ai<d}

{i:ai≥d}

d
p

ai ≥

|{i|ai ≥ d}| =⇒

|{i|ai < d}|
p

≥

1
2

.

Oracle Complexity of Second-Order Methods for Finite-Sum Problems

Therefore, together with the fact that g decreases monotonically and that

we get

1
|{i : ai < d}|

(cid:88)

ai ≤

{i:ai<d}

1
p

p
(cid:88)

i=1

ai,

1
p

p
(cid:88)

i

q(ai) ≥

(cid:32)

1
2

g

1
p

p
(cid:88)

i=1

(cid:33)

ai

.

