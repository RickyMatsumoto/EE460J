Uncorrelation and Evenness: A New Diversity-Promoting Regularizer
Supplementary Material

Pengtao Xie 1 2 Aarti Singh 1 Eric P. Xing 2

Clean1
Ethn
German
Haberman
Vehicle

No Regularization Yu et al. (2011) UER
30.2
11.4
27.3
26.9
21.1

35.8
14.9
28.0
30.3
22.6

50.0
32.1
30.2
36.0
25.0

Table 1. Classiﬁcation errors (%)

ization, the classiﬁcation accuracy is 23.1%. Under DPP,
the accuracy is 23.8%. Under our regularizer, the accuracy
is 24.7%.

2.2. “Diversifying” Ensemble of SVMs

In an SVM ensemble, there are m base SVM classiﬁers,
each parameterized by a weight vector w ∈ Rd. We ap-
ply UER to “diversify” the m vectors and compare with
the regularizer proposed by (Yu et al., 2011). The experi-
mental settings follow those in (Yu et al., 2011). The num-
ber of base SVMs is set to 21 and the ensemble method is
Bagging. Table 1 shows the classiﬁcation errors on 5 UCI
datasets.

References

Blei, David M, Ng, Andrew Y, and Jordan, Michael I. La-
tent dirichlet allocation. the Journal of machine Learn-
ing research, 2003.

Yu, Yang, Li, Yu-Feng, and Zhou, Zhi-Hua. Diversity reg-

ularized machine. 2011.

Zou, James Y and Adams, Ryan P. Priors for diversity in
generative latent variable models. In Advances in Neural
Information Processing Systems, pp. 2996–3004, 2012.

1. Additional Explanation of Uncorrelation

If components (denoted by horizontal and vertical axis in
Figure 2a) are correlated, then samples (points in Figure
2a) are in a non-spherical shape, then eigenvalues are mu-
tually different. Hence correlation leads to non-uniformity
of eigenvalues. Since the eigenvectors are orthogonal by
design, it sufﬁces to focus on eigenvalues only. To reduce
correlation, we encourage the eigenvalues to be uniform
(Figure 2b). Rotation does not affect eigenvalues or uncor-
relation. For a component matrix A and rotation matrix R,
A(cid:62)A equals to A(cid:62)R(cid:62)RA and they have the same eigen-
decomposition (say UEU(cid:62)). Ensuring the eigenvalue ma-
trix E is close to identity implies the latent components
are rotations of the orthonormal (and hence uncorrelated)
eigenvectors.

2. Additional Experiments

Other than distance metric learning and LSTM network, we
also applied our proposed regularizer to latent Dirichlet al-
location (LDA) (Blei et al., 2003) and ensemble of support
vector machines (SVM) (Yu et al., 2011). The “diversiﬁ-
cation” of these two models has been studied in (Zou &
Adams, 2012) and (Yu et al., 2011) respectively. We made
a comparison with them.

2.1. “Diversifying” Latent Dirichlet Allocation

An LDA consists of m topics, each parameterized by a vec-
tor β ∈ Rd. We apply the proposed UER to the m topic
vectors B = {βj}m
j=1 and compare with the DPP regular-
ized LDA proposed in (Zou & Adams, 2012). The experi-
mental settings follow those in (Zou & Adams, 2012). The
dataset is 20-Newsgroups and the number of topics is ﬁxed
to 25. The inferred topic proportion vectors are fed into a
SVM to perform document classiﬁcation. Without regular-

1Machine Learning Department, Carnegie Mellon University
2Petuum Inc. Correspondence to: Pengtao Xie, Eric P. Xing
<pengtaox@cs.cmu.edu, eric.xing@petuum.com>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

