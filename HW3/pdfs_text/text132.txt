Adaptive Multiple-Arm Identiﬁcation

Jiecao Chen * 1 Xi Chen * 2 Qin Zhang * 1 Yuan Zhou * 1

Abstract
We study the problem of selecting K arms with
the highest expected rewards in a stochastic n-
armed bandit game. This problem has a wide
range of applications, e.g., A/B testing, crowd-
sourcing, simulation optimization. Our goal is
to develop a PAC algorithm, which, with prob-
ability at least 1 − δ, identiﬁes a set of K arms
with the aggregate regret at most (cid:15). The notion of
aggregate regret for multiple-arm identiﬁcation
was ﬁrst introduced in Zhou et al. (2014) , which
is deﬁned as the difference of the averaged ex-
pected rewards between the selected set of arms
and the best K arms. In contrast to Zhou et al.
(2014) that only provides instance-independent
sample complexity, we introduce a new hardness
parameter for characterizing the difﬁculty of any
given instance. We further develop two algo-
rithms and establish the corresponding sample
complexity in terms of this hardness parameter.
The derived sample complexity can be signiﬁ-
cantly smaller than state-of-the-art results for a
large class of instances and matches the instance-
independent lower bound upto a log((cid:15)−1) factor
in the worst case. We also prove a lower bound
result showing that the extra log((cid:15)−1) is neces-
sary for instance-dependent algorithms using the
introduced hardness parameter.

1. Introduction

Given a set of alternatives with different quality, identify-
ing high quality alternatives via a sequential experiment is

*Equal contribution 1Computer Science Department, Indi-
ana University, Bloomington, IN, USA 2Stern School of Busi-
ness, New York University, New York, NY, USA. Correspon-
Jiecao Chen <jiecchen@umail.iu.edu;
dence to:
supported
in part by NSF CCF-1525024 and IIS-1633215>, Xi Chen
<xchen3@stern.nyu.edu; supported by Google Faculty Research
Fellowship>, Qin Zhang <qzhangcs@indiana.edu; supported
in part by NSF CCF-1525024 and IIS-1633215>, Yuan Zhou
<yzhoucs@indiana.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

an important problem in multi-armed bandit (MAB) litera-
ture, which is also known as the “pure-exploration” prob-
lem. This problem has a wide range of applications. For
example, consider the A/B/C testing problem with multiple
website designs, where each candidate design corresponds
to an alternative. In order to select high-quality designs,
an agent could display different designs to website visitors
and measure the attractiveness of an design. The question
is: how should the agent adaptively select which design to
be displayed next so that the high-quality designs can be
quickly and accurately identiﬁed? For another example, in
crowdsourcing, it is critical to identify high-quality work-
ers from a pool of a large number of noisy workers. An
effective strategy is testing workers by gold questions, i.e.,
questions with the known answers provided by domain ex-
perts. Since the agent has to pay a ﬁxed monetary reward
for each answer from a worker, it is important to implement
a cost-effective strategy for to select the top workers with
the minimum number of tests. Other applications include
simulation optimization, clinical trials, etc.

More formally, we assume that there are n alternative arms,
where the i-th arm is associated with an unknown reward
distribution Di with mean θi. For the ease of illustration,
we assume each Di is supported on [0, 1]. In practice, it
is easy to satisfy this assumption by a proper scaling. For
example, the trafﬁc of a website or the correctness of an
answer for a crowd worker (which simply takes the value
either 0 or 1), can be scaled to [0, 1]. The mean reward θi
characterizes the quality of the i-th alternative. The agent
sequentially pulls an arm, and upon each pulling of the i-
th arm, the i.i.d. reward from Di is observed. The goal
of “top-K arm identiﬁcation” is to design an adaptive arm
pulling strategy so that the top K arms with the largest
mean rewards can be identiﬁed with the minimum num-
ber of trials. In practice, identifying the exact top-K arms
usually requires a large number of arm pulls, which could
be wasteful. In many applications (e.g., crowdsourcing), it
is sufﬁcient to ﬁnd an “approximate set” of top-K arms.
To measure the quality of the selected arms, we adopt the
notion of aggregate regret (or regret for short) from Zhou
et al. (2014). In particular, we assume that arms are ordered
by their mean θ1 ≥ θ2 ≥ · · · ≥ θn so that the set of the
best K arms is {1, . . . , K}. For the selected arm set T with

Adaptive Multiple-Arm Identiﬁcation

the size |T | = K, the aggregate regret RT is deﬁned as,

RT =

1
K

(cid:32) K
(cid:88)

i=1

θi −

(cid:88)

i∈T

(cid:33)

θi

.

the problem of identifying (cid:15)-top-K arms. These algorithms
signiﬁcantly improve the sample complexity by CLUCB-
PAC for many common instances and almost match the best
non-adaptive algorithm in the worst case.

(1)

The set of arms T with the aggregate regret less than a
pre-determined tolerance level (cid:15) (i.e. RT ≤ (cid:15)) is called
(cid:15)-top-K arms. In this paper, we consider the (cid:15)-top-K-arm
problem in the “ﬁxed-conﬁdence” setting: given a target
conﬁdence level δ > 0, the goal is to ﬁnd a set of (cid:15)-top-K
arms with the probability at least 1 − δ. This is also known
as the PAC (probably approximately correct) learning set-
ting. We are interested in achieving this goal with as few
arm pulls (sample complexity) as possible.

K

(cid:16)

(cid:17)(cid:17)

(cid:16) n
(cid:15)2

1 + ln δ−1

To solve this problem, Zhou et al. (2014) proposed the
OptMAI algorithm and established its sample complexity
Θ
, which is shown to be asymptotically
optimal. However, the algorithm and the corresponding
sample complexity in Zhou et al. (2014) are non-adaptive
to the underlying instance. In other words, the algorithm
does not utilize the information obtained in known sam-
ples to adjust its future sampling strategy; and as a result,
the sample complexity only involves the parameters K, n,
δ and (cid:15) but is independent of {θi}n
i=1. Chen et al. (2014)
developed the CLUCB-PAC algorithm and established an
instance-dependent sample complexity for a more general
class of problems, including the (cid:15)-top-K arm identiﬁcation
problem as one of the key examples. When applying the
CLUCB-PAC algorithm to identify (cid:15)-top-K arms, the sam-
ple complexity becomes O((log H (0,(cid:15)) + log δ−1)H (0,(cid:15)))
where H (0,(cid:15)) = (cid:80)n
i=1 min{(∆i)−2, (cid:15)−2}, ∆i = θi−θK+1
for i ≤ K, ∆i = θK − θi for i > K. The reason why
we adopt the notation H (0,(cid:15)) will be clear from Section
1.1. However, this bound may be improved for the fol-
lowing two reasons. First, intuitively, the hardness param-
eter H (0,(cid:15)) is the total number of necessary pulls needed
for each arm to identify whether it is among the top-K
arms or the rest so that the algorithm can decide whether
to accept or reject the arm (when the arm’s mean is (cid:15)-
close to the boundary between the top-K arms and the
rest arms, it can be either selected or rejected). How-
ever, in many cases, even if an arm’s mean is (cid:15)-far from
the boundary, we may still be vague about the compar-
ison between its mean and the boundary, i.e. either se-
lecting or rejecting the arm satisﬁes the aggregate regret
bound. This may lead to fewer number of pulls and a
smaller hardness parameter for the same instance. Sec-
ond, the worst-case sample complexity for CLUCB-PAC
becomes O((log n + log (cid:15)−1 + log δ−1)n(cid:15)−2). When δ is a
constant, this bound is log n times more than the best non-
adaptive algorithm in Zhou et al. (2014).

Speciﬁcally, we ﬁrst introduce a new parameter H to char-
acterize the hardness of a given instance. This new hard-
ness parameter H could be smaller than the hardness pa-
rameter (cid:101)H used in the literature, in many natural instances.
For example, we show in Lemma 1 that when {θi}n
i=1
are sampled from a continuous distribution with bounded
probability density function (which is a common assump-
tion in Bayesian MAB and natural for many applications),
for K = γn with γ ≤ 0.5, our hardness parameter is
H = O(n/

(cid:15)) while (cid:101)H = Ω(n/(cid:15)).

√

an easy-to-implement

Using this new hardness parameter H, we ﬁrst pro-
algorithm– ADAPTIVE-
pose
TOPK and relate its sample complexity to H.
In
show that ADAPTIVETOPK uses
Theorem 1, we
O (cid:0)(cid:0)log log((cid:15)−1) + log n + log δ−1(cid:1) H(cid:1)
identify
(cid:15)-top-K arms with probability at least 1 − δ. Note that
this bound has a similar form as the one in Chen et al.
(cid:15) -factor
(2014), but as mentioned above, we have an
improvement in the hardness parameter for those instances
where Lemma 1 applies.

√

to

We then propose the second algorithm (IMPROVEDTOPK)
with even less sample complexity, which removes the log n
factor in the sample complexity. In Theroem 2, we show
that the algorithm uses O (cid:0)(cid:0)log (cid:15)−1 + log δ−1(cid:1) H(cid:1) pulls to
identify (cid:15)-top-K arms with probability 1 − δ. Since H
is always Ω(n/(cid:15)2) (which will be clear when the H is de-
ﬁned in Section 1.1), the worst-case sample complexity of
IMPROVEDTOPK matches the best instance-independent
bound shown in Zhou et al. (2014) up to an extra log((cid:15)−1)
factor (for constant δ). We are also able to show that
this extra log((cid:15)−1) factor is a necessary expense by being
instance-adaptive (Theorem 3). It is also noteworthy that
as a by-product of establishing IMPROVEDTOPK, we de-
veloped an algorithm that approximately identiﬁes the k-th
best arm, which may be of independent interest. Details are
deferred to the full version of this paper. 1

We are now ready to introduce our new hardness parame-
ters and summarize the main results in technical details.

1.1. Summary of Main Results

Following the existing literature (see, e.g., Bubeck et al.
(2013)), we ﬁrst deﬁne the gap of the i-th arm

∆i(K) =

(cid:40)

θi − θK+1
θK − θi

if i ≤ K
if i ≥ K + 1.

(2)

In this paper, we explore towards the above two direc-
tions and introduce new instance-sensitive algorithms for

1Full version of this paper is available online at https://

arxiv.org/abs/1706.01026.

Adaptive Multiple-Arm Identiﬁcation

i

i=1 ∆−2

Note that when K = 1, ∆i(K) becomes θ1 − θi for all
i ≥ 2 and ∆1(K) = θ1 − θ2. When K is clear from
the context, we simply use ∆i for ∆i(K). One commonly
used hardness parameter for quantifying the sample com-
plexity in the existing literature (see, e.g., Bubeck et al.
(2013); Karnin et al. (2013)) is (cid:101)H (cid:44) (cid:80)n
. If there
is an extremely small gap ∆i, the value of (cid:101)H and thus the
corresponding sample complexity can be super large. This
hardness parameter is natural when the goal is to identify
the exact top-K arms, where a sufﬁcient gap between an
arm and the boundary (i.e. θK and θK+1) is necessary.
However, in many applications (e.g., ﬁnding high-quality
workers in crowdsourcing), it is an overkill to select the ex-
act top-K arms. For example, if all the top-M arms with
M > K have very close means, then any subset of them
of size K forms an (cid:15)-top-K set in terms of the aggregate
regret in (1). Therefore, to quantify the sample complexity
when the metric is the aggregate regret, we need to con-
struct a new hardness parameter.

Given K and an error bound (cid:15), let us deﬁne t = t((cid:15), K) to
be the largest t ∈ {0, 1, 2, . . . , K − 1} such that

∆K−t · t ≤ K(cid:15)

and

∆K+t+1 · t ≤ K(cid:15).

(3)

Note that ∆K−t · t = (θK−t − θK+1) · t upper-bounds
the total gap of the t worst arms in the top K arms and
∆K+t+1 · t = (θK − θK+t+1) · t upper-bounds the total
gap of the t best arms in the non-top-K arms. Intuitively,
the deﬁnition in (3) means that we can tolerate exchanging
at most t best arms in the non-top-K arms with the t worst
arms in the top-K arms.

Given t = t((cid:15), K), we deﬁne

Ψt = min(∆K−t, ∆K+t+1),

and

Ψ(cid:15)

t = max((cid:15), Ψt).

(4)

(5)

We now introduce the following parameter to characterize
the hardness of a given instance,

H = H (t,(cid:15)) =

min{(∆i)−2, (Ψ(cid:15)

t)−2}.

(6)

n
(cid:88)

i=1

It is worthwhile to note that no matter how small the gap
∆i is, since Ψ(cid:15)
t ≥ (cid:15), we always have H (t,(cid:15)) ≤ n(cid:15)−2. We
also note that since Ψt is non-decreasing in t, H (t,(cid:15)) is also
non-increasing in t.

Our ﬁrst result is an easy-to-implement algorithm (see Al-
gorithm 1) that identiﬁes (cid:15)-top-K arms with sample com-
plexity related to H (t,(cid:15)).

Theorem 1 There is an algorithm that computes (cid:15)-top-K
arms with probability at least (1 − δ), and pulls the arms
at most O (cid:0)(cid:0)log log (cid:15)−1 + log n + log δ−1(cid:1) H (t,(cid:15))(cid:1) times.

We also develop a more sophisticated algorithm with an
improved sample complexity, the details of which are de-
ferred to the full version of this paper.

Theorem 2 There is an algorithm that computes (cid:15)-top-K
arms with probability at least (1 − δ), and pulls the arms
at most O (cid:0)(cid:0)log (cid:15)−1 + log δ−1(cid:1) H (t,(cid:15))(cid:1) times.

t ≥ (cid:15) and H (t,(cid:15)) ≤ n(cid:15)−2, the worst-case sample
Since Ψ(cid:15)
(cid:0)log (cid:15)−1 + log δ−1(cid:1)(cid:1).
complexity by Theorem 2 is O (cid:0) n
(cid:15)2
instance-independent
While the asymptotically optimal
sample complexity is Θ
(by Zhou et al.
(2014)), we show that the log (cid:15)−1 factor in Theorem 2 is
necessary for instance-dependent algorithms using H (t,(cid:15))
as a hardness parameter. In particular, we establish the fol-
lowing lower-bound result, the detailed proof of which is
deferred to the full version of this paper.

1 + ln δ−1

(cid:16) n
(cid:15)2

(cid:17)(cid:17)

(cid:16)

K

Theorem 3 For any n, K such that n = 2K, and any (cid:15) =
Ω(n−1), there exists an instance on n arms so that H (t,(cid:15)) =
Θ(n) and it requires Ω(n log (cid:15)−1) pulls to identify a set of
(cid:15)-top-K arms with probability at least 0.9.

Note that since H (t,(cid:15)) = Θ(n) in our lower bound in-
stances, our Theorem 3 shows that the sample complex-
ity has to be at least Ω(H (t,(cid:15)) log (cid:15)−1) in these instances.
In other words, our lower bound result shows that for
any instance-dependent algorithm, and any (cid:15) = Ω(n−1),
there exists an instance where sample complexity has to be
Ω(H (t,(cid:15)) log (cid:15)−1). While Theorem 3 shows the necessity
of the log (cid:15)−1 factor in Theorem 2, it is not a lower bound
for every instance of the problem.

1.2. Review of and Comparison with Related Works

i.e.

The problem of identifying the single best arm (i.e.
the top-K arms with K = 1), has been studied ex-
tensively (Even-Dar et al., 2002; Mannor & Tsitsiklis,
2004; Audibert et al., 2010; Gabillon et al., 2011; 2012;
Karnin et al., 2013; Jamieson et al., 2014; Kaufmann
et al., 2016; Garivier & Kaufmann, 2016; Russo, 2016;
Chen et al., 2016b). More speciﬁcally,
in the special
case when K = 1, our problem reduces to identifying
an (cid:15)-best arm,
an arm whose expected reward is
different from the best arm by an additive error of at most
(cid:15), with probability at least (1 − δ). For this problem,
Even-Dar et al. (2006) showed an algorithm with an
instance-independent sample complexity O (cid:0) n
(cid:15)2 log δ−1(cid:1)
(and this was proved to be asymptotically optimal by
Mannor & Tsitsiklis (2004)). An instance-dependent algo-
rithm for this problem was given by Bubeck et al. (2013)
and an improved algorithm was given by Karnin et al.
(2013) with an instance-dependent sample complexity of
O (cid:0)(cid:80)n

i=2 max{∆i, (cid:15)}−2(log δ−1 + log log max{∆i, (cid:15)}−1)(cid:1).

Adaptive Multiple-Arm Identiﬁcation

the

this

case,

bound

almost

worst
(cid:15)2 (log δ−1 + log log (cid:15)−1)(cid:1),

In
becomes
O (cid:0) n
matching
the instance-independent bound in Even-Dar et al.
(2006). When K = 1, we have t((cid:15), K) = 0 and thus
i=2 max{∆i, (cid:15)}−2(cid:1). There-
H (t,(cid:15)) = H (0,(cid:15)) = Θ (cid:0)(cid:80)n
fore, the sample complexity in our Theorem 2 becomes
(cid:15)2 (log (cid:15)−1 + log δ−1)(cid:1) in
O((log (cid:15)−1 + log δ−1)H) = O (cid:0) n
the worst-case, almost matching the bound by Karnin et al.
(2013).

For the problem of identifying top-K arms with K >
1, different notions of (cid:15)-optimal solution have been pro-
posed. One popular metric is the misidentiﬁcation proba-
bility (MISPROB), i.e., Pr(T (cid:54)= {1, . . . , K}). In the PAC
setting (i.e., controlling MISPROB less than (cid:15) with proba-
bility at least 1 − δ), many algorithms have been developed
recently, e.g., Bubeck et al. (2013) in the ﬁxed budget set-
ting and Chen et al. (2014) for both ﬁxed conﬁdence and
ﬁxed budget settings. Gabillon et al. (2016) further im-
proved the sample complexity in Chen et al. (2014); how-
ever the current implementation of their algorithm has an
exponential running time. As argued in Zhou et al. (2014),
the MISPROB requires to identify the exact top-K arms,
which might be too stringent for some applications (e.g.,
crowdsourcing). The MISPROB requires a certain gap be-
tween θK and θK+1 to identify the top-K arms, and this
requirement is not unnecessary when using the aggregate
regret. As shown in Zhou et al. (2014), when the gap of
any consecutive pair between θi and θi+1 among the ﬁrst
2K arms is o(1/n), the sample complexity has to be huge
(ω(n2)) to make the MISPROB less than (cid:15), while any K
arms among the ﬁrst 2K form a desirably set of (cid:15)-top-K
arms in terms of aggregate regret. Therefore, we follow
Zhou et al. (2014) and adopt the aggregate regret to deﬁne
the approximate solution in this paper.

Kalyanakrishnan et al. (2012) proposed the so-called
EXPLORE-K metric, which requires for each arm i in the
selected set T to satisfy θi ≥ θK − (cid:15) , where θK is the
mean of the K-th best arm. Cao et al. (2015) proposed
a more restrictive notion of optimality—ELEMENTWISE-
(cid:15)-OPTIMAL, which requires the mean reward of the i-th
best arm in the selected set T be at least θi − (cid:15) for 1 ≤
i ≤ K. It is clear that the ELEMENT WISE-(cid:15)-OPTIMAL is
a stronger guarantee than our (cid:15)-top-K in regret, while the
latter is stronger than EXPLORE-K. Chen et al. (2016a)
further extended Cao et al. (2015) to pure exploration prob-
lems under matroid constraints. Audibert et al. (2010) and
Bubeck et al. (2013) considered expected aggregate regret
(i.e., 1
i∈T θi
, where the expectation
K
is taken over the randomness of the algorithm. Note that
this notion of expected aggregate regret is a weaker objec-
tive than the aggregate regret.

i=1 θi − E (cid:0)(cid:80)

(cid:16)(cid:80)K

(cid:1)(cid:17)

Moreover, there are some other recent works studying the

problem of best-arm identiﬁcation in different setups, e.g.,
linear contextual bandit (Soare et al., 2014), batch arm pulls
(Jun et al., 2016).

For our (cid:15)-top-K arm problem, the state-of-the-art instance-
dependent sample complexity was given by Chen et al.
(2014) (see Section B.2 in Appendix of their paper). More
speciﬁcally, Chen et al. (2014) proposed CLUCB-PAC
algorithms that ﬁnds (cid:15)-top-K arms with probability at
least (1−δ) using O (cid:0)(cid:0)log δ−1 + log H (0,(cid:15))(cid:1) H (0,(cid:15))(cid:1) pulls.
Since H (0,(cid:15)) ≥ H (t,(cid:15)) ≥ Ω(n) and H (0,(cid:15)) ≥ (Ψ(cid:15)
t)−2,
our Theorem 1 is not worse than the bound in Chen et al.
(2014). Indeed, in many common settings, H (t,(cid:15)) can be
much smaller than H (0,(cid:15)) so that Theorem 1 (and therefore
Theorem 2) requires much less sample complexity. We ex-
plain this argument in more details as follows.

In many real-world applications, it is common to assume
the arms θi are sampled from a prior distribution D over
[0, 1] with cumulative distribution function FD(θ).
In
fact, this is the most fundamental assumption in Bayesian
multi-armed bandit literature (e.g., best-arm identiﬁcation
in Bayesian setup (Russo, 2016)). In crowdsourcing appli-
cations, Chen et al. (2015) and Abbasi-Yadkori et al. (2015)
also made this assumption for modeling workers’ accuracy,
which correspond to the expected rewards. Under this as-
sumption, it is natural to let θi be the (1− i
n ) quantile of the
distribution D, i.e. F −1
n ). If the prior distribution D’s
probability density function fD = dFD
dθ has bounded value
(a few common examples include uniform distribution over
[0, 1], Beta distribution, or the truncated Gaussian distribu-
tion), the arms’ mean rewards {θi}n
i=1 can be characterized
by the following property with c = O(1).

D (1− i

Deﬁnition 1 We call a set of n arms θ1 ≥ θ2 ≥ · · · ≥ θn
c-spread (for some c ≥ 1) if for all i, j ∈ [n] we have
|θi − θj| ∈

(cid:104) |i−j|

cn , c|i−j|

(cid:105)

n

.

The following lemma upper-bounds H (t,(cid:15)) for O(1)-spread
arms, and shows the improvement of our algorithms com-
pared to Chen et al. (2014) on O(1)-spread arms. The proof
of Lemma 1 is based on simple calculations and is deferred
to the full version of this paper.

Lemma 1 Given a set of n c-spread arms, let K = γn ≤
n
2 . When c = O(1) and γ = Ω(1), we have H (t,(cid:15)) =
(cid:15)). In contrast, H (0,(cid:15)) = Ω(n/(cid:15)) for O(1)-spread
O(n/
arms and every K ∈ [n].

√

2. An Instance Dependent Algorithm for

(cid:15)-top-K Arms

In this section, we show Theorem 1 by providing Algo-
rithm 1 and proving the following theorem.

Adaptive Multiple-Arm Identiﬁcation

Algorithm 1 ADAPTIVETOPK(n, (cid:15), K, δ)
Input: n: number of arms; K and (cid:15): parameters in (cid:15)-top-K

arms; δ: error probability

Output: (cid:15)-top-K arms

1 Let r denote the current round, initialized to be 0. Let Sr ⊆
[n] denote the set of candidate arms at round r. S1 is
initialized to be [n]. Set A, B ← ∅

2 ∆ ← 2−r
3 while 2 · ∆ · (K − |A|) > (cid:15)K do

r ← r + 1
Pull each arm in Sr by ∆−2 ln 2nr2
δ
be the empirical-mean
Deﬁne (cid:101)θa(Sr) and (cid:101)θb(Sr) be the (K − |A| + 1)th and
(K − |A|)th largest empirical-means in Sr, and deﬁne

times, and let (cid:101)θr
i

(cid:101)∆i(Sr) = max

i − (cid:101)θa(Sr), (cid:101)θb(Sr) − (cid:101)θr
(cid:101)θr
i

(7)

(cid:16)

(cid:17)

while maxi∈Sr (cid:101)∆i(Sr) > 2 · ∆ do
x ← arg maxi∈Sr (cid:101)∆i(Sr)
if (cid:101)θr
x > (cid:101)θa(Sr) then
A ← A ∪ {x}

else

B ← B ∪ {x}

Sr ← Sr\{x}

15
16 Set A(cid:48) as the (K − |A|) arms with the largest empirical-

Sr+1 ← Sr
∆ ← 2−r

means in Sr+1
17 return A ∪ A(cid:48)

4

5

6

7

8

9

10

11

12

13

14

are within a small neighborhood of their true means, hap-
pens with probability at least 1 − δ (See Deﬁnition 2 and
Claim 1). Note that E is deﬁned for all rounds and the
length of the neighborhood becomes smaller as the algo-
rithm proceeds. We are able to prove that when E happens,
the algorithm returns the desired set of (cid:15)-top-K arms and
has small query complexity.

To prove the correctness of the algorithm, we ﬁrst show
that when conditioning on E, the algorithm always accepts
a top-K arm in A (Lemma 3) and rejects a non-top-K arm
in B (Lemma 4). The key observation here is that our al-
gorithm never introduces any regret due to arms in A and
B. We then use the key Lemma 5 to upper bound the regret
that may be introduced due to the remaining arms. Once
this upper bound is not more than (cid:15)K (i.e. the total budget
for regret), we can choose the remaining (K − |A|) arms
without further samplings. Details about this analysis can
be found in Section 2.1.

We analyze of the query complexity of our algorithm in
Section 2.2. We establish data-dependent bound by relating
the number of pulls to each arms to both their ∆i’s and
∆K−t (Lemma 6 and Lemma 7).

2.1. Correctness of Algorithm 1

We ﬁrst deﬁne an event E which we will condition on in
the rest of the analysis.

Deﬁnition 2 Let E be the event that |(cid:101)θr
r ≥ 1 and i ∈ Sr.

i − θi| < 2−r for all

Claim 1 Pr[E] ≥ 1 − δ.

Theorem 4 Algorithm 1 computes (cid:15)-top-K arms with
probability at least 1 − δ, and pulls the arms at most

(cid:32)

(cid:16)

O

log log(∆(cid:15)

t)−1 + log

min{(∆i)−2, (∆(cid:15)

t)−2}

n
δ

(cid:17) n
(cid:88)

i=1

times, where t ∈ {0, 1, 2, . . . , K − 1} is the largest integer
satisfying ∆K−t · t ≤ K(cid:15), and ∆(cid:15)

t = max((cid:15), ∆K−t).

Proof : By Hoeffding’s inequality, we can show that for any
i − θi| ≥ 2−r(cid:105)
|(cid:101)θr
ﬁxed r and i, Pr
2nr2 .
By a union bound,

2nr2 )2 ≤ δ

≤ 2( δ

(cid:104)

(cid:33)

Pr[¬E] ≤

∞
(cid:88)

(cid:88)

r=1

i∈Sr

(cid:104)

i − θi| ≥ 2−r(cid:105)
|(cid:101)θr

≤

Pr

∞
(cid:88)

r=1

δ
2r2 ≤ δ.

(cid:3)

Note that Theorem 4 implies Theorem 1 because of the fol-
lowing reasons: 1) t deﬁned in Theorem 4 is always at least
t((cid:15), K) deﬁned in (3); and 2) ∆(cid:15)

t ≥ Ψ(cid:15)

t ≥ (cid:15).

Algorithm 1 is similar to the accept-reject types of algo-
rithms in for example Bubeck et al. (2013). The algorithm
goes by rounds for r = 1, 2, 3, . . . , and keeps at set of un-
decided arms Sr ⊆ [n] at Round r. All other arms (in
[n] \ Sr) are either accepted (in A) or rejected (in B). At
each round, all undecided arms are pulled by equal num-
ber of times. This number is chosen to ensure that the
event E, which is deﬁned as the empirical means of all arms

The following lemma will be a very useful tool for our anal-
ysis, the proof of which is deferred to the full version of this
paper.

Lemma 2 Given µ1 ≥ . . . ≥ µn and ∆ > 0, assuming
that |(cid:101)µi−µi| ≤ ∆ for all i ∈ [n], and letting y1 ≥ . . . ≥ yn
be the sorted version of (cid:101)µ1, . . . , (cid:101)µn, we have |yi − µi| ≤
∆ for all i ∈ [n].

We now prove that conditioned on E, the algorithm always
accepts a desired arm in A.

Adaptive Multiple-Arm Identiﬁcation

Lemma 3 Conditioned on E, during the run of Algo-
rithm 1, A ⊆ {1, 2, . . . , K}, that is, all arms in A are
among the top-K arms.

Proof : We prove by induction on the round r. The lemma
holds trivially when r = 0 (A = ∅). Now ﬁx a round
r ≥ 1, and let x be the arm that is added to A at Line 10 of
Algorithm 1. By the induction hypothesis, assuming that
before round r all arms in A are in [K], our goal is to show
x ∈ [K].

By the inner while condition we have
x − (cid:101)θa(Sr) > 2 · 2−r.
(cid:101)θr

(8)

For any m ∈ [K − |A| + 1, |Sr|], let j be the arm of the
m-th largest true-mean in Sr, and j(cid:48) be the arm of the m-th
largest empirical-mean in Sr. Since m ≥ K − |A| + 1, we
must have j (cid:54)∈ [K] and (cid:101)θr
j(cid:48) ≤ (cid:101)θa(Sr). By Lemma 2 we also
have |(cid:101)θr

j(cid:48) − θj| < 2−r. We thus have

θx > (cid:101)θr

x − 2−r

by (8)
> (cid:101)θa(Sr) + 2−r > (cid:101)θr

j(cid:48) + 2−r > θj.

That is, at least |Sr| − K + |A| arms in Sr have true-means
smaller than arm x. On the other hand, |Sr|−K +|A| arms
in Sr are not in [K]. We therefore conclude that x must be
(cid:3)
in [K].

By symmetry, we also have the following lemma, stating
that when E happens, the algorithm always rejects a non-
top-K arm in B. We omit the proof because it is almost
identical to the proof of Lemma 3.

Lemma 4 Conditioning on E, during the run of Algo-
rithm 1, B ⊆ {K + 1, K + 2, . . . , n}.

Lemma 5 Conditioned on E, for all rounds r and i ∈ Sr,
it holds that
i − (cid:101)θa(Sr) > θi − θK+1 − 2 · 2−r
(cid:101)θr

(9)

and

(cid:101)θb(Sr) − (cid:101)θr

i > θK − θi − 2 · 2−r.

(10)

Consequently, we have (cid:101)∆i(Sr) ≥ ∆i−2·2−r for all rounds
r and i ∈ Sr.

Proof : We look at a particular round r. Let j be the arm
with (K − |A| + 1)-th largest true-mean in Sr. Since by
Lemma 3 we have A ⊆ [K] , it holds that j ≥ K + 1. By
Lemma 2, we also have |(cid:101)θa(Sr) − θj| < 2−r. We therefore
have for any i ∈ Sr

i − (cid:101)θa(Sr) > θi −θj −2·2−r ≥ θi −θK+1 −2·2−r. (11)
(cid:101)θr

With a similar argument
Lemma 4), we can show that

(by symmetry and using

Combining (11), (12) and the deﬁnitions of (cid:101)∆i(Sr) and ∆i,
(cid:3)
the lemma follows.

Now we are ready to prove the correctness of Theorem 4.
By Lemma 3, all the arms that we add into the set A at
Line 10 are in [K]. The rest of our job is to look at the
arms in the set A(cid:48).

When the algorithm exits the outer while loop (at round
r = r∗) and arrives at Line 16, we have by the condition of
the outer while loop that
2 · 2−r∗

· (K − |A|) ≤ (cid:15)K.

(13)

Let m = K − |A|, and C = [K]\A = {i1, i2, . . . , im}
where i1 < i2 < . . . < im. Let (cid:101)θj1 ≥ (cid:101)θj2 ≥ . . . ≥ (cid:101)θjm
be the (K − |A|) empirical-means of the arms that we pick
at Line 16. Note that it is not necessary that j1 < . . . <
jm. By Lemma 2 and E, for any s ∈ [K − |A|], we have
and |(cid:101)θjs − θjs| ≤ 2−r∗
|(cid:101)θjs − θis | ≤ 2−r∗
. By the triangle
inequality, it holds that

|θjs − θis| ≤ 2 · 2−r∗
We thus can bound the error introduced by arms in A(cid:48) by

.

(14)

(cid:88)

θi −

(cid:88)

i∈[K]

i∈A∪A(cid:48)

θi =

θi −

(cid:88)

i∈C

(cid:88)

i∈A(cid:48)

θi

by (14)

≤ 2 · 2−r∗

· (K − |A|)

≤ (cid:15)K.

by (13)

2.2. Query Complexity of Algorithm 1

that
(in the statement of Theorem 4)
Recall
{0, 1, 2, . . . , K − 1} is the largest integer satisfying

t ∈

Lemma 6 If the algorithm exits the outer while loop at
round r = r∗, then we must have

∆K−t · t ≤ (cid:15)K.

8 · 2−r∗

≥ ∆K−t.

(15)

(16)

The proof is deferred to the full version of this paper.

Lemma 7 For any arm i, let ri be the round where arm
i is removed from the candidate set if this ever happens;
otherwise set ri = r∗. We must have
8 · 2−ri ≥ ∆i.

(17)

The proof is deferred to the full version of this paper.

With Lemma 6 and Lemma 7, we are ready to analyze the
query complexity of the algorithm in Theorem 4. We can
bound the number of pulls on each arm i by at most
ri(cid:88)

22j · log(2nj2/δ) ≤ O (cid:0)log(ri · nδ−1) · 22ri(cid:1) .

(18)

(cid:101)θb(Sr) − (cid:101)θr

i > θK − θi − 2 · 2−r.

(12)

j=1

Adaptive Multiple-Arm Identiﬁcation

Now let us upper-bound the RHS of (18). First, if i ∈ A,
then by (17) we know that ri ≤ log2 ∆−1
i + O(1). Second,
by (16) we have ri ≤ r∗ ≤ log2 ∆−1
K−t+O(1). Third, since
2−r∗
≥ (cid:15)/2 (otherwise the algorithm will exit the outer
while loop), we have ri ≤ r∗ ≤ log2 (cid:15)−1 + O(1). To sum-
marize, we have ri ≤ log2 min{∆−1
K−t, (cid:15)−1} +
i
t)−1} + O(1)
, (∆(cid:15)
O(1)
max{(cid:15), ∆K−t}).
We
(recall
thus
by
the RHS
can
O (cid:0)(log log(∆(cid:15)
The total cost is a summation over all n arms.

=
upper-bound
t)−1 + log n

δ ) · min{(∆i)−2, (∆(cid:15)

=
that ∆(cid:15)
t

log2 min{∆−1

(18)
t)−2}(cid:1) .

, ∆−1

of

i

Remark 1 As we stated in Theorem 2, the log n factor
from Theorem 1 can be removed. On the other hand, our
lower bound result (see Theorem 3) shows that an extra
log((cid:15)−1) in Theorem 2 is necessary when we make the al-
gorithm adaptive. The proofs of Theorem 2 and Theorem 3
are deferred to the full version of this paper.

3. Experiments

In this section we present the experimental results. While
our theorems are presented in the PAC form, it is in general
difﬁcult to verify them directly because the parameter (cid:15) is
merely an upper bound and the actual aggregate regret may
deviate from it. In our experiment, we convert our Algo-
rithm 1 to the ﬁxed-budget version (that is, ﬁx the budget of
the number of pulls and calculate the aggregate regret). We
compare our Algorithm 1 (AdaptiveTopK ) with two state-
of-the-art methods – OptMAI in Zhou et al. (2014) and
CLUCB-PAC in Chen et al. (2014). The comparison be-
tween OptMAI /CLUCB-PAC and previous methods (e.g.,
the methods in Bubeck et al. (2013) and Kalyanakrishnan
et al. (2012)) have already been demonstrated in Zhou et al.
(2014) and Chen et al. (2014), and thus are omitted due to
space constraints. To convert our algorithm to the ﬁxed-
budget version, we remove the outer while loop of Algo-
rithm 1. As a replacement, we keep track of the total num-
ber of pulls, and stop pulling the arms once the budget is
exhausted.

We test our algorithm on both synthetic and real datasets
(due to space constraints, our results on real datasets are
deferred to the full version of this paper) as described as
follows.

• TWOGROUP: the mean reward for the top K arms is
set to 0.7 and that for the rest of the arms is set to 0.3.

• UNIFORM: we set θi = 1 − i

• SYNTHETIC-p: we set θi = (1 − K
K )p
for each i ≤ K and θi = (1 − K
n−K )p
for each i > K. Note that SYNTHETIC-1 is identical
to UNIFORM. When p is larger than 1, arms are made

n · (1 − i
· ( i−K

n for 1 ≤ i ≤ n.
n ) + K
n ) − n−K

n

closer to the boundary that separates the top-K from
the rest (i.e. 1 − K
n ). When p is smaller than 1, arms
are made farther to the boundary. We normalize all the
arms such that the mean values of the arms still span
the whole interval [0, 1]. We consider p = .5, 1, 6.

We set the total number of arms n = 1, 000, the tolerance
parameter (cid:15) = 0.01, and vary the parameter K. In Adap-
tiveTopK and CLUCB-PAC, another parameter δ (i.e., the
failure probability) is required and we set δ = 0.01.

For each dataset, we ﬁrst ﬁx the budget (total number of
pulls allowed) and run each algorithm 200 times. For each
algorithm, we calculate the empirical probability (over 200
runs) that the aggregate regret of the selected arms is above
the tolerance threshold (cid:15) = 0.01, which is called failure
probability. A smaller failure probability means better per-
formance. For each dataset and different K, we plot the
curve of failure probability by varying the number of pulls.
The results are shown in Figure 1-4.

It can be observed from the experimental results that Adap-
tiveTopK (Algorithm 1) outperforms CLUCB-PAC in al-
most all the datasets. When K is relatively small, Opt-
MAI has the best performance in most datasets. When K
is large, AdaptiveTopK outperforms OptMAI . The details
of the experimental results are elaborated as follows.

• For TWOGROUP dataset (see Figure 1), Adaptive-
TopK outperforms other algorithms signiﬁcantly for
all values of K. The advantage comes from the adap-
tivity of our algorithm. In the TWOGROUP dataset,
top-K arms are very well separated from the rest.
Once our algorithm identiﬁes this situation, it need
only a few pulls to classify the arms. In details, the
inner while loop (Line 7) of Algorithm 1 make it pos-
sible to accept/reject a large number of arms in one
round as long as the algorithm is conﬁdent.

• As K increases, the advantage of AdaptiveTopK over
other algorithms (OptMAI in particular) becomes
more signiﬁcant. This can be explained by the deﬁ-
nition of H (t,(cid:15)): t = t((cid:15), K) usually becomes bigger
as K grows, leading to a smaller hardness parameter
H (t,(cid:15)).

• A comparison between SYNTHETIC-.5, UNIFORM,
SYNTHETIC-6 reveals that the advantage of Adap-
tiveTopK over other algorithms (OptMAI in partic-
ular) becomes signiﬁcant in both extreme scenarios,
i.e., when arms are very well separated (p (cid:28) 1) and
when arms are very close to the separation boundary
(p (cid:29) 1).

Adaptive Multiple-Arm Identiﬁcation

(a) K = 100

(b) K = 250

(c) K = 500

Figure 1: TWOGROUP dataset

(a) K = 100

(b) K = 250

(c) K = 500

Figure 2: SYNTHETIC-.5 dataset

(a) K = 100

(b) K = 250

(c) K = 500

Figure 3: UNIFORM dataset

(a) K = 100

(b) K = 250

(c) K = 500

Figure 4: SYNTHETIC-6 dataset

4. Conclusion and Future Work

In this paper, we proposed two algorithms for a PAC
version of the multiple-arm identiﬁcation problem in a
stochastic multi-armed bandit (MAB) game. We intro-
duced a new hardness parameter for characterizing the dif-
ﬁculty of an instance when using the aggregate regret as the
evaluation metric, and established the instance-dependent
sample complexity based on this hardness parameter. We
also established lower bound results to show the optimal-
ity of our algorithm in the worst case. Although we only
consider the case when the reward distribution is supported
on [0, 1], it is straightforward to extend our results to sub-
Gaussian reward distributions.

For future directions, it is worthwhile to consider more gen-

eral problem of pure exploration of MAB under matroid
constraints, which includes the multiple-arm identiﬁcation
as a special case, or other polynomial-time-computable
combinatorial constraints such as matchings. It is also in-
teresting to extend the current work to ﬁnding top-K arms
in a linear contextual bandit framework.

References

Abbasi-Yadkori, Yasin, Bartlett, Peter, Chen, Xi, and
Malek, Alan. Large-scale markov decision problems
with KL control cost and its application to crowdsourc-
ing. In Proceedings of International Conference on Ma-
chine Learning (ICML), 2015.

Audibert, J.Y., Bubeck, S., and Munos, R. Best arm iden-

Adaptive Multiple-Arm Identiﬁcation

Garivier, A. and Kaufmann, E. Optimal best-arm identiﬁ-
cation with ﬁxed conﬁdence. In Proceedings of the Con-
ference on Learning Theory (COLT), 2016.

Jamieson, Kevin, Malloy, Matthew, Nowak, Robert, and
Bubeck, S´ebastien. UCB : An optimal exploration al-
gorithm for multi-armed bandits. In Proceedings of the
Conference on Learning Theory (COLT), 2014.

Jun, Kwang-Sung, Jamieson, Kevin, Nowak, Robert, and
Zhu, Xiaojin. Top arm identiﬁcation in multi-armed ban-
dits with batch arm pulls. In Proceedings of the Interna-
tional Conference on Artiﬁcial Intelligence and Statistics
(AISTATS), 2016.

Kalyanakrishnan, Shivaram, Tewari, Ambuj, Auer, Peter,
and Stone, Peter. PAC subset selection in stochastic
In Proceedings of International
multi-armed bandits.
Conference on Machine Learning (ICML), 2012.

Karnin, Zohar, Koren, Tomer, and Somekh, Oren. Almost
optimal exploration in multi-armed bandits. In Proceed-
ings of International Conference on Machine Learning
(ICML), 2013.

Kaufmann, Emilie, Capp´e, Olivier, and Garivier, Aur´elien.
On the complexity of best arm identiﬁcation in multi-
armed bandit models. Journal of Machine Learning Re-
search, 17:1–42, 2016.

Mannor, Shie and Tsitsiklis, John N. The sample com-
plexity of exploration in the multi-armed bandit prob-
lem. Journal of Machine Learning Research, 5:623–648,
2004.

Russo, Daniel. Simple bayesian algorithms for best arm
In Proceedings of the Conference on

identiﬁcation.
Learning Theory (COLT), 2016.

Soare, Marta, Lazaric, Alessandro, and Munos, Remi.
Best-arm identiﬁcation in linear bandits. In Proceedings
of Advances in Neural Information Processing Systems
(NIPS), 2014.

Zhou, Yuan, Chen, Xi, and Li, Jian. Optimal PAC multi-
ple arm identiﬁcation with applications to crowdsourc-
ing. In Proceedings of International Conference on Ma-
chine Learning (ICML), 2014.

tiﬁcation in multi-armed bandits. In Proceedings of the
Conference on Learning Theory (COLT), 2010.

Bubeck, Sebastian, Wang, Tengyao, and Viswanathan,
Nitin. Multiple identiﬁcations in multi-armed bandits.
In Proceedings of the International Conference on Ma-
chine Learning (ICML), 2013.

Cao, Wei, Li, Jian, Tao, Yufei, and Li, Zhize. On top-
k selection in multi-armed bandits and hidden bipartite
graphs. In Proceedings of Advances in Neural Informa-
tion Processing Systems (NIPS), 2015.

Chen, Lijie, Gupta, Anupam, and Li, Jian. Pure exploration
of multi-armed bandit under matroid constraints. In Pro-
ceedings of the Conference on Learning Theory (COLT),
2016a.

Chen, Lijie, Li, Jian, and Qiao, Mingda. Towards in-
stance optimal bounds for best arm identiﬁcation. arXiv
preprint arXiv:1608.06031, 2016b.

Chen, Shouyuan, Lin, Tian, King, Irwin, Lyu, Michael R.,
and Chen, Wei. Combinatorial pure exploration of multi-
In Proceedings of Advances in Neural
armed bandits.
Information Processing Systems (NIPS), 2014.

Chen, Xi, Lin, Qihang, and Zhou, Dengyong. Statistical
decision making for optimal budget allocation in crowd
labeling. Journal of Machine Learning Research, 16:1–
46, 2015.

Even-Dar, Eyal, Mannor, Shie, and Mansour, Yishay. PAC
bounds for multi-armed bandit and markov decision pro-
In Proceedings of the Annual Conference on
cesses.
Learning Theory (COLT), 2002.

Even-Dar, Eyal, Mannor, Shie, and Mansour, Yishay. Ac-
tion elimination and stopping conditions for the multi-
armed bandit and reinforcement
learning problems.
Journal of machine learning research, 7:1079–1105,
2006.

Gabillon, Victor, Ghavamzadeh, Mohammad, Lazaric,
Alessandro, and Bubeck, S´ebastien. Multi-bandit best
arm identiﬁcation. In Proceedings of Advances in Neu-
ral Information Processing Systems (NIPS), 2011.

Gabillon, Victor, Ghavamzadeh, Mohammad, and Lazaric,
Alessandro. Best arm identiﬁcation: A uniﬁed approach
In Proceedings
to ﬁxed budget and ﬁxed conﬁdence.
of Advances in Neural Information Processing Systems
(NIPS), 2012.

Gabillon, Victor, Lazaric, Alessandro, Ghavamzadeh, Mo-
hammad, Ortner, Ronald, and Bartlett, Peter. Improved
learning complexity in combinatorial pure exploration
bandits. In Proceedings of the International Conference
on Artiﬁcial Intelligence and Statistics, 2016.

