Supplementary Material for
Active Learning for Top-K Rank Aggregation from Noisy Comparisons

Soheil Mohajer 1 Changho Suh 2 Adel Elmahdy 1

1. Supplementary Algorithms for Heap

Algorithm 1 Heapify(Z, X, i; m)

Structure

For the sake of completeness, we also present a modiﬁed ver-
sion of Heapify and BuildHeap algorithms that work
based on noisy observations in Algorithm 1 and Algorithm 2,
respectively. It is worth mentioning the sample complexity
of building a HEAP over N items using noiseless measure-
ments is O(N ), and insertion of a new item to an existing
HEAP with N items requires O(log N ) comparisons. Fi-
nally, HEAP maintains the maximum item at the beginning
of the list, so that max-extraction can be done for free. Here,
in the modiﬁed version of the algorithms, we repeat each
comparison used for HEAP for m times, and decide based
on the majority of the observation. The variable m is a
design parameter, which will be determined later.

2. Supplementary Simulation Results

2.1. Performance Evaluation of Top-1 and Top-K

Ranking Algorithms

Figs. 1 and 2 depict the trade-off between the average
number of pairwise comparisons and the empirical success
rate of identifying top-1 and top-8 ranked items under two
pairwise comparison probability models, namely uniform
noise model and BTL model, respectively. The total num-
ber of items, from which we are interested in Top-K, is
n = 212 = 4096. We set two different values for the prefer-
ence separation measure as ∆K = 0.0025 and ∆K = 0.01.
The BTL model parameters are wi ∈ [1, 50], 1 ≤ i ≤ n.
Furthermore, for all simulation results presented in this sec-
tion, success rate and total number of pairwise comparison
are averaged over 104 Monte Carlo trials.

It is obvious that the success rate monotonically increases
with the number of pairwise comparisons under all probabil-

1ECE, University of Minnesota, Twin Cities, MN, USA. 2EE,
KAIST, Daejeon, South Korea. Correspondence to: Soheil Moha-
jer <soheil@umn.edu>, Changho Suh <chsuh@kaist.ac.kr>, Adel
Elmahdy <adel@umn.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by
the author(s).

Input: Integers i and m
Data: Array Z of indices and Data X
Output:Array Z with sub-tree at node i being a max-
heap
left ← 2i
right ← 2i + 1
T ← 0
for t ← 1 to m do

et ← (Z[left], Z[i])
T ← T + Yt

end for
if left ≤ |Z| and T ≥ m

2 then

max ← left

else

max ← i

end if
T ← 0
for t ← 1 to m do

et ← (Z[right], Z[max)]
T ← T + Yt

end for
if right ≤ |Z| and T ≥ m

2 then

max ← right

end if
if max (cid:54)= i then

swap(Z[i], Z[max])
Heapify(Z, X, max; m)

end if

Algorithm 2 BuildHeap(Z, X; m)

Input: Integer m
Data: Array Z of indices and Data X
Output: max-heap Z
for i ← (cid:98)|Z|/2(cid:99) down to 1 do

Heapify(Z, X, i; m)

end for

ity models. Moreover, we can see that as K increases or ∆K
decreases, the number of pairwise comparisons required for
a target success rate increases. All these observations are
consistent with our theoretical analysis.

Title Suppressed Due to Excessive Size

Figure 1. Evolution of success rate of the proposed algorithm with
respect to the total number of pairwise comparisons under uni-
form noise model for different values of K and ∆K (= γ2) when
n = 4096.

Figure 2. Evolution of success rate of the proposed algorithm with
respect to the total number of pairwise comparisons under BTL
model for different values of K and ∆K when n = 4096 and
wi ∈ [1, 50], 1 ≤ i ≤ n.

For Top-K ranking with K > 1, we study the performance
of the proposed heap-based ranking algorithm under two
different settings: (1) Top-K Partitioning, and (2) Top-K
Sorting. It should be noted that the second setting is more
restrictive than the ﬁrst one, and hence, the algorithm per-
formance in Top-K Sorting is always inferior to the one in
Top-K Partitioning. It is illustrated, through Figs. 1 and 2,
that the performance gap between the two scenarios is small,
for all probability models. This shows that the proposed
algorithm is robust in that it provides the ordered top-K
items without resulting in severe performance degradation,
compared to the performance of only identifying the top-K
items.

2.2. Performance Comparison of Active Ranking

Algorithms

An interesting fact about our algorithm is revealed by Fig. 3.
It is obvious that as the number of pairwise comparisons
increases, the corresponding probability of error falls down.
However, in Braverman algorithm, there is a threshold af-
ter which any further increase in the number of pairwise
comparisons does not yield any improvement in the proba-
bility of error. These ﬁndings are consistent with our anal-
ysis of the sample complexity of both algorithms, and the
upper bound imposed on c, a parameter that the sample
complexity of Braverman algorithm scales with, such that
10 ≤ c ≤ log(n) (Braverman et al., 2016).

Figure 3. The analytical tradeoff between probability of error and
sample complexity for Top-1 algorithm and Braverman algorithm
under the uniform noise model for different values of n when
∆K = γ2 = 0.0225.

References

Braverman, M., Mao, J., and Weinberg, S. M. Parallel al-
gorithms for select and partition with noisy comparisons.
STOC, 2016.

024681012Total Number of Pairwise Comparisons10600.20.40.60.81Success RateTop-1, K = 0.0025Top-8, Partitioning, K = 0.0025Top-8, Sorting, K = 0.0025024681012Total Number of Pairwise Comparisons10600.20.40.60.81Success RateTop-1, K = 0.01Top-8, Partitioning, K = 0.01Top-8, Sorting, K = 0.01012345678Total Number of Pairwise Comparisons10600.20.40.60.81Success RateTop-1, K = 0.0025Top-8, Partitioning, K = 0.0025Top-8, Sorting, K = 0.0025012345678Total Number of Pairwise Comparisons10600.20.40.60.81Success RateTop-1, K = 0.01Top-8, Partitioning, K = 0.01Top-8, Sorting, K = 0.01