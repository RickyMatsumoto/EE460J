Bayesian inference on random simple graphs
with power law degree distributions

Juho Lee 1 Creighton Heaukulani 2 Zoubin Ghahramani 2 3 Lancelot F. James 4 Seungjin Choi 1

(BFRY)

Abstract
We present a model for random simple graphs
with power law (i.e., heavy-tailed) degree dis-
tributions. To attain this behavior,
the edge
probabilities in the graph are constructed from
Bertoin–Fujita–Roynette–Yor
random
variables, which have been recently utilized in
Bayesian statistics for the construction of power
law models in several applications. Our con-
struction readily extends to capture the structure
of latent factors, similarly to stochastic block-
models, while maintaining its power law de-
gree distribution. The BFRY random variables
are well approximated by gamma random vari-
ables in a variational Bayesian inference routine,
which we apply to several network datasets for
which power law degree distributions are a natu-
ral assumption. By learning the parameters of the
BFRY distribution via probabilistic inference, we
are able to automatically select the appropriate
power law behavior from the data.
In order to
further scale our inference procedure, we adopt
stochastic gradient ascent routines where the gra-
dients are computed on minibatches (i.e., sub-
sets) of the edges in the graph.

1. Introduction

In statistical applications, random graphs serve as Bayesian
models for network data, that is, data consisting of objects
and the observed linkages between them. Here we will fo-
cus on models for random simple graphs (that is, graphs
with edges that take binary values), which are appropriate
for applications where we observe either the presence or

1Pohang University of Science and Technology, Pohang,
South Korea 2University of Cambridge, Cambridge, UK 3Uber
AI Labs, San Francisco, CA, USA 4Hong Kong University
of Science and Technology, Hong Kong.
Correspondence
to: Juho Lee <stonecold@postech.ac.kr>, Seungjin Choi <se-
ungjin@postech.ac.kr>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

absence of links between objects in the network. For ex-
ample, in social networks, nodes may represent individuals
and a link (i.e., a nonzero value of an edge) could represent
friendship. In a protein-protein interaction network, nodes
may represent proteins and links could represent an ob-
served physical or chemical interaction between proteins.
Many domains involving network data (including social
and protein-protein interaction networks) have been shown
to exhibit power law, i.e., heavy-tailed, degree distributions
(Barab´asi & Albert, 1999). Models for random graphs with
power law degree distributions, also called scale-free ran-
dom graphs, have therefore become one of the most ac-
tively studied areas of graph theory and network science
(Bollob´as et al., 2001; Albert & Barab´asi, 2002; Dorogovt-
sev & Mendes, 2002). In this paper we present a model
for simple, scale-free random graphs, which we apply as a
probabilistic model for several network datasets.

The model we present in this paper is a special case of the
generalized random graph deﬁned by Britton et al. (2006),
and studied further by van der Hofstad (2016, Ch. 6),
which outlines a framework for deﬁning scale-free random
graphs, but does not provide practical constructions, much
less algorithms for performing statistical inference on the
model components given data. Here we provide one such
practical construction, along with a variational inference
routine (Jordan et al., 1999) for efﬁcient posterior infer-
ence. What’s more, our construction readily generalizes to
include the structure of latent factors/clusters, as captured
by the popular stochastic blockmodels (Nowicki & Sni-
jders, 2001; Airoldi et al., 2009), while maintaining power
law behavior in the graph.

Applying Bayesian inference algorithms on network
datasets is a challenge because likelihood computations,
in general, scale with the number of edges in the graph,
which is O(n2) in a network with n nodes. To help over-
come these difﬁculties, we follow Hoffman et al. (2013)
and develop a stochastic variational inference algorithm in
which we approximate many likelihood computations on
only subsets of the data, called minibatches. In the case of
a network dataset, the minibatches are comprised of subsets
of edges in the graph.

We apply this inference procedure to several network

Power law simple graphs

datasets that are commonly observed to possess power law
structure. Our experiments show that accurately capturing
this power law structure improves performance on tasks
predicting missing edges in the networks.

2. Bayesian models for simple graphs

We represent a simple graph with n nodes by an adjacency
matrix X := (Xi,j)i,j≤n, where Xi,j = 1 if there is a
link between nodes i and j and Xi,j = 0 otherwise. Here
we will only consider undirected graphs, in which case X
represents a symmetric matrix. Furthermore, we do not al-
low self links, so the diagonal entries in X are meaning-
less. Most probabilistic models for simple graphs take the
entries in X to be conditionally independent Bernoulli ran-
dom variables; in particular, for every i, j ≤ n, let pi,j be
the (random) probability of a link between nodes i and j,
and let Xi,j | pi,j ∼ Bernoulli(pi,j). For every simple
graph x := (xi,j)i,j≤n, we may then write the likelihood
for the parameters p := (pi,j)i,j≥1 given X as

P (X = x | p) =

pxi,j
i,j (1 − pi,j)1−xi,j ,

(1)

(cid:89)

i<j≤n

where in our case it should be clear that the product is only
over i, j ≤ n such that i < j and i (cid:54)= j. Random simple
graphs date back to the Erd¨os–R´enyi model, which may be
reviewed, along with the more general theory of random
graphs, in the text by Bollob´as (1998). A random graph is
called scale-free when the fraction of nodes in the network
having k connections to other nodes behaves like k−τ for
large values of k and some exponent τ > 1. More pre-
cisely, let Dn,i := (cid:80)
j(cid:54)=i Xi,j denote the (random) degree
of node i, for every i ≤ n. Then X is (asymptotically)
scale-free when, for every node i ≤ n,

P{Dn,i = k} ∼ ck−τ ,

as n → ∞,

(2)

for some constant c > 0, a power law exponent τ > 1, and
k sufﬁciently large. Here the notation A ∼ B denotes that
the ratio A/B → 1 in the speciﬁed limit.

√

In order to model scale-free random graphs, Britton et al.
(2006) suggested reparameterizing the model in Eq. (1) by
a sequence of odds ratios ri,j := pi,j/(1 − pi,j), for ev-
ery i < j ≤ n, which factorize as ri,j = UiUj, for some
U := (U1, . . . , Un). The node-speciﬁc factors Ui are then
modeled as Ui := Wi/
L for some sequence of nonneg-
ative random variables W := (W1, . . . , Wn) and where
L := (cid:80)n
i=1 Wi. In a series of results, (Britton et al., 2006,
Thms. 3.1 & 3.2) and (van der Hofstad, 2016, Cor. 6.11 &
Thm. 6.13) assert conditions on the random variables W so
that the limiting distribution of the degrees Dn,i is a mixed
Poisson distribution. We will further detail these previous
results in Section 4.

The distribution of Wi is interpreted here as a prior distri-
bution for the degree Dn,i of node i, and if its distribution
has heavy tails, then so will the distribution of Dn,i. Con-
versely, if the distribution of Wi does not have heavy tails,
then neither will the distribution of the degrees Dn,i. We
explore this alternative in Section 7.

Previous authors did not suggest any particular choices for
the distribution of Wi, and so we elect to model them with
BFRY random variables (Bertoin et al., 2006; Devroye &
James, 2014), which have a heavy-tailed distribution and
have recently played a role in the construction of several
power law models in Bayesian statistics. Other heavy tailed
distributions, such as those exhibited by log normal random
variables, may also be used to model the Wi, and these op-
tions may be explored. One beneﬁt of the BFRY distribu-
tion is that the thickness of its tails, and thus the power law
behavior of the resulting graph, may be straightforwardly
controlled by the discount parameter α.

3. A generalized random graph

Consider the model from the previous section, parameter-
ized by the odds ratios r := (ri,j : i < j ≤ n). Deﬁne

G(r) :=

(1 + ri,j) =

(1 + UiUj),

(3)

(cid:89)

i<j≤n

(cid:89)

i<j≤n

and note that the conditional likelihood in Eq. (1) may be
rewritten in terms of the degrees Dn,i as
P (X = x | r) = G(r)−1 (cid:89)

(UiUj)xi,j

(4)

= G(r)−1 (cid:89)

U Dn,i
i

.

i<j≤n

i≤n

(5)

(6)

(7)

The random simple graph X is called a generalized random
graph, and we will henceforth write X | r ∼ GRG(n, r).

Let α ∈ (0, 1), which we call the discount parameter, and
let C1, C2, . . . be a sequence of positive values satisfying

lim
n→∞

Cn = ∞ and

lim
n→∞

C α

n /n = 0.

Let the weights W1, . . . , Wn be i.i.d. with density

fn(w) ∝ w−α−1(1 − e−w)1{0≤w≤Cn}.

(These are truncated BFRY random variables and will be
discussed, along with a method for simulation, in Sec-
tion 3.1.) Then the corresponding generalized random
graph has an (asymptotic) power law degree distribution
with power law exponent τ = 1 + α. We summarize this
construction in the following theorem:
Theorem 3.1. For every n, let W1, . . . , Wn be i.i.d. with
density fn and let (Dn,i)i≤n be the degrees of the gen-
eralized random graph X | r ∼ GRG(n, r), where

Power law simple graphs

Figure 1. The number of nodes with various degrees for two sim-
ulated graphs with n = 3000 nodes and differing values for α.

Figure 2. The average number of links in simulated graphs with
varying sparsity parameter β.

r := (ri,j)i<j≤n is the sequence of odds ratios

ri,j = WiWj/L,

i < j ≤ n,

(8)

and L := (cid:80)

i Wi. Then the following hold:

1. For y (cid:29) 1, P{Dn,i = y} ∼ cy−1−α, for every node i

and for some constant c, as n → ∞.

2. For any m, the collection Dn,1, . . . , Dn,m are asymp-

totically independent, as n → ∞.

This construction is closely related to the model described
by van der Hofstad (2016, Thm. 6.13), and the proof of
Theorem 3.1, which is provided in the supplementary ma-
terial, follows analogously to the results by Britton et al.
(2006, Thms. 3.1 & 3.2). Note that the power law exponent
τ = 1 + α of the graph (as described by Eq. (2)) is de-
termined by the parameter α ∈ (0, 1), and takes values in
(1, 2). While power law exponents in (2, 3) has often been
suggested in the past, it has more recently been shown that
exponents within the (1, 2) range of our model is more ap-
propriate in many domains (van der Hofstad, 2016, Ch. 1);
(Crane & Dempsey, 2015).

3.1. Truncated BFRY random variables

A random variable W with density function fn given by
Eq. (7) is a ratio of gamma and beta random variables, up-
per truncated at Cn. In particular let

g ∼ gamma(1 − α, 1)

and b ∼ beta(α, 1),

(9)

be independent, then the ratio Z := g/b has density p(z) ∝
z−α−1(1 − e−z) on (0, ∞) (by construction), which is
known as the Bertoin-Fujita-Roynette-Yor (BFRY) distri-
bution (Bertoin et al., 2006; Devroye & James, 2014) and
has been used in the construction of power law models in
some recent applications in machine learning (James et al.,
2015; Lee et al., 2016). The random variable W is then

obtained by upper truncating the random variable Z at Cn.
By our requirements on the sequence Cn (c.f. Eq. (6)), the
density function fn of W approaches the density function
of the BFRY random variable Z as n → ∞, that is,

lim
n→∞

fn(w) =

α
Γ(1 − α)

w−α−1(1 − e−w),

(10)

which is heavy-tailed with inﬁnite moments. It is straight-
forward to simulate these truncated BFRY random vari-
ables by repeatedly simulating g and b as in Eq. (9), ac-
cepting W := g/b as a sample when W < Cn.

The truncation of W at Cn produces a random variable
with ﬁnite mean (for n < ∞), which is essential when
constructing the generalized random graph and motivates
the construction by van der Hofstad (2016, Thm. 6.13) al-
luded to earlier; see Section 4. For simplicity, one could
take Cn = n, but the ﬂexibility to set this parameter allows
us to control other properties of the model. For example, in
the next section we show how to vary this truncation level
to control the sparsity of the graph.

3.2. Controlling power law and sparsity in the graph

The discount parameter α ∈ (0, 1) controls the power law
behavior of the graph, where decreasing α results in heav-
ier tails in the degree distribution of the nodes in the graph.
We can visualize this behavior by simulating graphs at dif-
ferent values of α. In Section 3, we set Cn = n and show
the number of nodes of varying degrees in two simulated
graphs, one with α = 0.2 and one with α = 0.8.

The degree distribution of the nodes in a graph of course
affects the sparsity of the graph; to characterize this rela-
tionship, we can upper bound the expected number of links
in the graph as follows:

Theorem 3.2. Let En be the number of positive edges in
the graph. Then E[En] = O(nC 1−α

).

n

100101102103#nodeswithdegree100101102103104degreeα=0.2α=0.82000400060008000#nodes103104105106#linksβ=0.6β=0.9β=1.2Power law simple graphs

The derivation of this result is provided in the supplemen-
tary material. While varying α can thus control the spar-
sity of the graph in addition to the power law behavior,
we often want to decouple these behaviors, in which case
we could parameterize the truncation level as Cn = nβ,
for some sparsity parameter β > 0. Note the restriction
α < min{1, 1/β} must be enforced in order to ensure
that the conditions in Eq. (6) are satisﬁed. In this case, the
bound in Theorem 3.2 becomes E[En] = O(n1+β(1−α)).
The interpretation here is that increasing the upper bound
Cn increases the likelihood that any particular node will
link to others, but does not affect the (asymptotic) power
law characterized by Theorem 3.1. In Section 3.2, we dis-
play the average number of positive edges in graphs that
were simulated with ﬁxed α = 0.3 and varying values of
the sparsity parameter β. We note that in simulations, we
encountered numerical issues in β > 1.4 regimes.

4. Related work

Referring to the construction for generalized random
graphs in Section 2, Britton et al. (2006, Thm. 3.1) shows
that when the weights Wi have ﬁnite ﬁrst and second mo-
ments, then the limiting distribution of the degree Dn,i is
a mixed Poisson distribution. Most such distributions are
light-tailed, however, in which case the degrees will not
exhibit power law behavior. Britton et al. (2006, Thm. 3.2)
therefore provides an alternative construction in which Wi
may have inﬁnite moments (so that it may exhibit a heavy
tail), which results in a graph with a power law exponent of
τ = 2. Finally, van der Hofstad (2016, Thm. 6.13) suggests
yet another construction where the Wi are upper truncated
to be of order o(n), where n is the number of nodes in the
graph. The resulting random variables therefore have ﬁnite
moments, yet exhibit a heavy tail, and the resulting random
graph has a heavy tailed degree distribution with an arbi-
trary power law exponent. None of these results suggest a
particular choice for the distribution of Wi, however, and
so we have elected to use BFRY random variables (which
are heavy tailed) that are upper truncated (so that they have
ﬁnite moments). We note that the requirements on our trun-
cation level (c.f. Eq. (6)) is less strict than the o(n) criterion
of the van der Hofstad (2016, Thm. 6.13) construction.

The reader may consult the surveys by Bollob´as & Ri-
ordan (2003); Albert & Barab´asi (2002); Dorogovtsev &
Mendes (2002) for a background on scale-free random
graphs, which is too large to review here. While these mod-
els are numerous, the following recent pieces of work in the
Bayesian statistics and machine learning communities may
be of interest to the reader: Caron & Fox (2014); Veitch
& Roy (2015); Crane & Dempsey (2016); Cai & Broder-
ick (2015). This collection of work discusses power law
degree distributions, albeit in some cases in multi-graphs

(i.e., graphs with nonnegative integer-valued edges) and in
some cases the power law behavior is not characterized,
only numerically observed in simulations. Many of these
models can be seen to invoke their power law properties
from the Pitman–Yor process (Pitman & Yor, 1997) (or re-
lated stochastic processes), where the extent of this behav-
ior is controlled by the discount parameter α ∈ (0, 1) of
the Pitman–Yor model, which, like the BFRY distribution,
is related to a stable subordinator of index α.

5. Incorporating latent factors

Latent factor models for relational data assume that a set
of latent clusters underlie the network. For example, in a
social network, the latent factors could be the unobserved
hobbies or interests of individuals, which determine the ob-
served friendships in the network. Bayesian models for la-
tent factors in relational data are widespread, with some of
the most popular based on stochastic blockmodels, where
models for unsupervised learning, or clustering, are used
to infer the latent factors (Nowicki & Snijders, 2001; Kemp
et al., 2006; Airoldi et al., 2009; Miller et al., 2009). In this
section, we present extensions of the generalized random
graph that incorporate latent factors by scaling the odds ra-
tios, while maintaining their power law degree distribution.

We will ﬁrst provide a general result showing how to in-
corporate random scaling variables into the model, fol-
lowed by speciﬁc examples that model these scaling vari-
ables with latent clusters. Let the odds ratios in the gen-
eralized random graph be given by ri,j = Ai,jUiUj for
some Ai,j ≥ 0. Note that pi,j → 1 as Ai,j → ∞ and
pi,j → 0 as Ai,j → 0, and so the edge-speciﬁc weight
Ai,j simply scales the link probability. The random graph
X | r ∼ GRG(n, r) then has the likelihood

P (X = x | r) = G(r)−1 (cid:89)

Axi,j
i,j

U Dn,i
i

,

(11)

(cid:89)

i≤n

i<j≤n

where the normalization term G(r) in Eq. (3) is now

G(r) :=

(1 + Ai,jUiUj)

(cid:89)

i<j≤n
(cid:88)

(cid:89)

=

x

i<j≤n

Axi,j
i,j

U Dn,i
i

,

(cid:89)

i≤n

(12)

(13)

the ﬁnal

where
(cid:80)

simply because
equality follows
x P (X = x | r) = 1. So constructed, the odds
ratios r will inﬂuence the link probabilities in the gen-
eralized random graph, but will not affect
the power
law behavior of the degree distributions (under some
assumptions on the random variables Ai,j). We summarize
this construction in the following theorem, the proof for
which is provided in the supplementary material:

Power law simple graphs

Theorem 5.1. Let (Wi)i≤n be i.i.d. random variables with
density function fn(w) (in Eq. (7)). Let (Ai,j)i<j≤n be a
collection of uniformly bounded random variables, where,
for every i ≤ n, the collection (Ai,j)j>i is exchange-
able. Let (Dn,i)i≤n be the degrees of the random graph
X | r ∼ GRG(n, r), where r := (ri,j)i<j≤n is the se-
quence of odds ratios

and construct the random graph X as in Theorem 5.1.
Miller et al. (2009) derived a nonparametric extension of
this model that in a sense takes the limit K → ∞, in which
case the marginal law of the vectors Z1, . . . , Zn is that of
an Indian buffet process (with mass parameter γ and con-
centration parameter c) (Ghahramani et al., 2007).

ri,j = Ai,jWiWj/L,

i < j ≤ n,

(14)

6. Variational inference

and where L := (cid:80)
isfy statements (1) and (2) in Theorem 3.1.

i Wi. Then the degrees (Dn,i)i≤n sat-

For example, we may construct stochastic blockmodels,
such as those introduced by Nowicki & Snijders (2001), as
follows: For every i ≤ n, let Zi be a random variable tak-
ing values in {1, . . . , K}, indicating which one (and only
one) of K different factors to associate with node i. We
want the latent cluster assignments for two nodes i and j
to inﬂuence their link probability, which we could capture
with a set of parameters θk,(cid:96), for k, (cid:96) = 1, . . . , K. Then the
parameter θZi,Zj could represent, or inﬂuence, the proba-
bility of a link between nodes i and j. Taking a Bayesian
approach, the indicator variables Zi may be modeled with
a Dirichlet-categorical conjugate distribution and their val-
ues may be inferred via probabilistic inference. An exam-
ple of such a model could be summarized as follows: Let

Zi ∼ categorical(π),
π ∼ Dirichlet(c/K),
θ(cid:96),k ∼ gamma(aθ, bθ),
Ai,j = θZi,Zj ,

i ≤ n,
where c > 0,
(cid:96), k ≤ K,

i < j ≤ n,

(15)

(16)

(17)

(18)

and construct the random graph X as in Theorem 5.1.
Kemp et al. (2006) developed a nonparametric extension
of a similar model that in a sense takes the limit K → ∞,
allowing an appropriate number of clusters to be automati-
cally inferred from the data. In this case, the marginal law
of the indicator variables Z1, . . . , Zn is given by a Chinese
restaurant process (with concentration parameter c).

Several generalizations of the stochastic blockmodel allow
the clusters underlying the network to overlap, leading to
mixed membership stochastic blockmodels (Airoldi et al.,
2009) or the related latent feature relational models (Miller
et al., 2009). To capture this structure, we may generalize
the indicators Zi to now represent a binary K-vector with
entry Zi,k = 1 indicating node i is associated with clus-
ter k, now called a feature, and Zi,k = 0 otherwise. One
example of such a model could be summarized as follows:

Zi,k ∼ Bernoulli(pk),
pk ∼ beta(c, cγ/K),
θ(cid:96),k ∼ gamma(aθ, bθ),

i ≤ n, k ≤ K,
k ≤ K, and c, γ > 0,
(cid:96), k = 1, 2, . . . ,

Ai,j =

θk,(cid:96)Zi,kZj,(cid:96),

i < j ≤ n,

(19)

(20)

(21)

(22)

(cid:88)

k,(cid:96)

We derive a variational Bayesian inference algorithm (Jor-
dan et al., 1999) that approximates the (optimal state of
the) posterior distribution of the model components, given
a network dataset. We approximate the required gradi-
ents in this procedure with stochastic gradient ascent (Bot-
tou, 2010; Hoffman et al., 2013), computed on minibatches
(i.e., subsets) of edges in the graph.

6.1. The variational lower bound

In variational inference, we approximate the posterior dis-
tribution on the latent variables W := (W1, . . . , Wn)
with a variational distribution q(W ; θ), the parameters θ
of which are ﬁt to maximize the following lower bound on
the marginal likelihood

log p(X) ≥ Eq(W ;θ)

log

(cid:104)

p(X | W ; α)p(W ; α)
q(W ; θ)

(cid:105)

,

(23)

where p(X | W ) is the likelihood function computed as
in Eq. (5), and p(W ; α) is the prior on W represented by
the density function in Eq. (7). The (non random) discount
parameter α is inferred by corresponding gradient ascent
updates maximizing the likelihood of the model, which is
described in Section 6.4.

We specify a mean ﬁeld variational distribution q(W ; θ) =
(cid:81)n
i=1 q(Wi; θi). We considered several approximations
for the marginals q(Wi; θi) including truncated BFRY and
truncated gamma distributions, however, in our experi-
ments we found that the following rectiﬁed gamma distri-
bution performed well:

Wi =q min{W (cid:48)
W (cid:48)

i , Cn},

i ∼ gamma(θi,shp, θi,rte),

(24)

(25)

independently for every i ≤ n, where θi,shp and θi,rte de-
note the shape and rate parameters of the gamma distribu-
tion, respectively, and the notation =q emphasizes that this
formula holds under the variational distribution q.

6.2. Stochastic gradient ascent

We maximize the lower bound on the right hand side of
Eq. (23) by stochastic gradient ascent, where on the t-th
step of the algorithm, we make the following updates to the

Power law simple graphs

parameters in parallel

6.3. Minibatches of edges in the graph

θ(t+1)
i

← θ(t)

i + ρt∇θi

E
q(W ;θ(t))[L(X, W ; θ(t))],

(26)

for i ≤ n and some sequence (ρt)t≥1 of positive num-
bers satisfying the Robbins–Monro criterion (Robbins &
Monro, 1951) (cid:80)
L(X, W ; θ) := log p(X, W ; α) − log q(W ; θ)

t ρt = ∞ and (cid:80)

t < ∞, and where

t ρ2

(27)

(cid:88)

=

(i,j)∈E

log p(Xi,j | W ) +

log p(Wi; α)

n
(cid:88)

i=1

−

log q(Wi; θi),

(28)

n
(cid:88)

i=1

where E denotes the observed edges (both links and non-
links) in the dataset. We cannot evaluate the expectation
(with respect to the rectiﬁed gamma distributions q(W ; θ))
analytically, and so we elect to use a particular Monte Carlo
approximation of this gradient detailed by Knowles (2015),
which was developed for gamma variational distributions
and easily applies to the rectiﬁed gamma case.

for every i ≤ n, create the collection of
Brieﬂy,
S Monte Carlo samples from the variational distri-
bution as follows:
let
z(s)
i ∼ Uniform(0, 1), and set W (s)
; θi), where
ψ(z; θ) := min{F −1
(x) is the inverse
of the cumulative distribution function for a gamma ran-
dom variable. For convenience, we recall that

Independently for s ≤ S,

(z), Cn} and F −1

i = ψ(z(s)

θ

θ

i

Computing the n required gradients in Eq. (26) may
be done in parallel, and this computation, whether per-
formed analytically or with automatic differentiation meth-
ods, scales with the number of edges in the graph. This can
be prohibitive for many network datasets, and we there-
fore introduce a further approximation where this gradient
is evaluated on subsets (a.k.a. minibatches) of the dataset,
a technique from stochastic gradient ascent (Bottou, 2010)
adopted in the context of variational Bayesian inference by
Hoffman et al. (2013). In the case of a network dataset,
we may select minibatches that are subsets of the observed
edges in the graph.
In particular, write the gradient of
Eq. (28) with respect to the variable Wk (which is required
by Eq. (30)) as

∇Wk L(W (s); θ) =

g(i,j)(X, W (s); k),

(32)

(cid:88)

(i,j)∈E

:= ∇Wk [log p(Xi,j

where g(i,j)(X, W ; k)
| W ) +
|E|−1 log p(W ; α) − |E|−1 log q(W ; θ)] is the gradient that
ignores all but one edge of the graph. We may therefore
compute the unbiased estimate of this gradient

∇Wk L(W (s); θ) ≈

g(i,j)(X, W (s); k),

(33)

|E|
|B|

(cid:88)

(i,j)∈B

on a minibatch B ⊆ E of the observed edges.

Fa,b(x) =

ta−1e−btdt.

(29)

6.4. Inference on the parameters α and β

(cid:90) x

0

ba
Γ(a)

For every k ≤ n, the gradient with respect to the parame-
ters θk is then approximated by
Eq(W ;θ)[L(X, W ; θ)]

∇θk

≈

1
S

(cid:88)

s

∇Wk L(X, W (s); θ)∇θk ψ(z(s)

k ; θk),

(30)

1 , . . . , W (s)

where W (s) := (W (s)
n ). This estimator is unbi-
ased and has low enough variance that often a single sample
sufﬁces for the approximation (Salimans & Knowles, 2013;
Kingma & Welling, 2014). The gradient of ψ is nonzero
only when {F −1
k ) < Cn}, in which case we may im-
θk
mediately obtain the partial derivative with respect to the
rate parameter; in particular, we have

(z(s)

∇θk,rteψ(z(s)

k ; θk) =

(cid:40) z(s)
k
θk,rte
0,

,

(z(s)
if F −1
θk
otherwise.

k ) < Cn,

(31)

The partial derivative with respect to the shape parameter
∇θk,shp ψ(z(s)
k ; θk) does not have a closed form solution and
must be approximated. Different approximation routines
are suggested by Knowles (2015) for different regimes of
the shape parameter θk,shp, and we found these approxima-
tions to be accurate and efﬁcient in our experiments.

Without good prior knowledge of how to set the discount
parameter α and the sparsity parameter β controlling the
power law and sparsity behaviors of the graph, respectively,
we infer their values from the data. First consider the dis-
count parameter, which we infer with gradient ascent. After
every update to the latent variables W , we ﬁx them to their
mean under the distribution q, i.e., ˆW := ( ˆW1, . . . , ˆWn)
where ˆWi = Eq(Wi;θi)[Wi], and take a step in the direction
of the gradient

∇α log p( ˆW ; α) =

∇α log p( ˆWi; α)

(34)

=

(cid:104)
−

∇αZα,β
Zα,β

− log( ˆWi)

(cid:105)
,

(35)

which is straightforward to derive from the density function
in Eq. (7), and where the normalization term

Zα,β :=

w−α−1(1 − e−w) dw

(36)

is a function of α and β, if we let Cn = nβ as suggested
in Section 3.2. We do not have a closed form solution for

n
(cid:88)

i=1
n
(cid:88)

i=1

(cid:90) Cn

0

Power law simple graphs

Table 2. Comparision between the BFRY model and the Gamma
baseline model on the air trafﬁc, blogs, and social network
datasets. The test log-likelihoods were averaged over the last
4,000 of 20,000 gradient descent updates.

dataset model

max test log-likel

avg test log-likel

500Air

polblogs

Fb107

openﬂ

BFRY
Gamma
BFRY
Gamma
BFRY
Gamma
BFRY
Gamma

-1628.51 ± 10.46
-1842.10 ± 3.97
-474.67 ± 32.20
-555.24 ± 18.27
-18098.38 ± 20.50
-18403.66 ± 31.76
-16561.13 ± 137.89
-17475.52 ± 31.97

-1654.20 ± 6.79
-1870.35 ± 0.28
-503.20 ± 37.85
-596.78 ± 0.78
-18209.94 ± 12.86
-18568.05 ± 2.79
-16947.70 ± 177.21
-17746.79 ± 6.65

of α. We ran an experiment where for each value α ∈
{0.1, 0.3, 0.5, 0.7}, we simulated 10 datasets from the
model with n = 1, 000 nodes, while ﬁxing β = 1.0. For
each simulated dataset, we ran an instance of the inference
routine with α randomly initialized.
In Fig. 3, we show
the trace plots of alpha during each instance of the infer-
ence routine. For comparison, the true values of α are also
shown as horizontal dashed lines. We can see that the infer-
ence routine can correctly distinguish between these differ-
ent regimes of α, with slight overestimation in the moder-
ate α regime. Interestingly, despite random initializations
of α ∈ (0, 1), the algorithm always immediately inﬂates α
to around 0.9, and then slowly decreases this value during
inference, regardless of what value of α generated the data.

We next demonstrate that accurately capturing power law
structures in datasets will improve predictive performance.
While ﬁxing β = 1.0, we simulate three network datasets
with 5,000 nodes from our model with discount parameters
α = 0.3, 0.5, and 0.7, respectively, which therefore exhibit
increasingly lighter-tailed degree distributions. The gener-
ated graphs have 117,300, 32,925, and 9,460 links, respec-
tively. To establish a baseline model that does not exhibit
power law degree distributions but is otherwise comparable
to our model, we implement the generalized random graph
where the node-speciﬁc weights are constructed from the
gamma random variables Wi ∼ gamma(θ, 1), for some
positive parameter θ, i.i.d. for every node i ≤ n. Note
that the parameter θ controls the sparsity of the generated
graph; larger values of θ imply denser graphs. It follows
analogously to Theorem 5.1 that

P{Dn,i = k} ∼

kθ−1
2k+θ ,

(37)

for k (cid:29) 1, as n → ∞. This model therefore does not ex-
hibit power law behavior, as desired. We refer to this model
as “Gamma” and the power law graph model as “BFRY”.

We ran an experiment holding out 20% of the edges in the

Figure 3. Trace plots of the discount parameter α during 10 differ-
ent inference runs, each time simulating a dataset from the model
with either α ∈ {0.1, 0.3, 0.5, 0.7} and intializing α randomly.

Table 1. Comparision between the BFRY model and the Gamma
baseline model when α is known. The test log-likelihoods were
averaged over the last 4,000 of 20,000 gradient descent updates.

true α

model

max test log-likel

avg test log-likel

α = 0.3

α = 0.5

α = 0.7

BFRY
Gamma
BFRY
Gamma
BFRY
Gamma

-57323.19 ± 91.62
-71341.90 ± 116.82
-21077.62 ± 79.64
-24430.38 ± 73.06
-7894.67 ± 41.84
-8511.48 ± 22.45

-57675.72 ± 31.71
-71841.66 ± 47.38
-21289.75 ± 34.23
-24701.06 ± 11.31
-8027.42 ± 51.08
-8601.50 ± 15.42

this term when Cn < ∞, and, unfortunately, inference on
model parameters where the likelihood is difﬁcult to eval-
uate is a challenging problem; for example, see the ap-
proaches taken by Murray et al. (2006) on such problems,
which those authors call doubly intractable distributions.
Accurate inference for α is important in our model, be-
cause it controls the power law behavior of the graph. In
our experiments, we approximate the gradient in Eq. (35)
for (ﬁxed β) by approximating Zα,β (via Eq. (36)) and
∇αZα,β = (cid:82) Cn
0 −w−α−1(1 − e−w) log w dw, with line
integrals.
In the Section 7, we demonstrate that this ap-
proximation works well in various regimes of α, with slight
overestimation for moderate values.

Similar approaches to infer β may be derived with ﬁ-
nite difference approximations; we did not ﬁnd these ap-
proaches successful in our experiments, however, and so
we instead select β by cross validation.

7. Experiments

We ﬁrst demonstrate how the inference procedure in Sec-
tion 6.4 can correctly differentiate between various regimes

040008000120001600020000iteration0.00.20.40.60.81.0αPower law simple graphs

Table 3. Inferred hyperparameters in the experiments.

true α = 0.3

true α = 0.5

true α = 0.7

500Air

polblogs

Fb107

openﬂ

BFRY – α
Gamma – θ
BFRY – β

0.33 ± 0.00
5.29 ± 0.01
–

0.53 ± 0.00
1.42 ± 0.00
–

0.68 ± 0.00
0.51 ± 0.00
–

0.23 ± 0.03
5.10 ± 0.01
1.08 ± 0.16

0.64 ± 0.06
0.66 ± 0.00
1.40 ± 0.00

0.00 ± 0.00
33.58 ± 0.01
0.80 ± 0.0

0.67 ± 0.21
0.47 ± 0.00
1.28 ± 0.10

simulated graphs as test sets, training the two models on
the remaining 80% of the edges. We used a mini-batch size
of 5,000 edges (note that the training dataset corresponds
to almost 10 million observed edges). We ran each infer-
ence procedure for 20,000 steps of stochastic gradient as-
cent updates, using Adam (Kingma & Ba, 2015) to adjust
the learning rates at each step. We repeated each experi-
ment 5 times, each time holding out a different test set and
using a different random initialization. Again, for this ex-
periment we ﬁxed β = 1. In Table 1 we report a mean log-
likelihood metric for the test datasets, where the metric for
each run is obtained by averaging the test log-likelihoods
across the states for the last 4,000 steps of the inference
procedure; the displayed intervals are at ±1 standard devi-
ation about the metric, from across the 5 repeats. We also
report a max log-likelihood metric, which simply records
the maximum test log-likelihood across the last 4,000 steps
of the inference procedure, instead of the average. The best
performing method is highlighted in bold (which in each
case was the BFRY model).

In each case, we see that the BFRY model achieves higher
test log-likelihood metrics than the Gamma model, as ex-
pected, implying that accurately capturing a power law de-
gree distribution improves predictive performance (when
power law behavior is truly present in the network).
In
Table 3, we report the inferred values for α, which were
reasonably accurate, though we see slight overestimation
for some regimes, as seen in the demonstration earlier. For
the baseline Gamma model, we optimized the hyperparam-
eter θ using gradient ascent maximizing the evidence lower
bound of the model (c.f. Eq. (23)), and the inferred values
are also reported in Table 3.

Next, we ran similar experiments on the following network
datasets, each of which are expected to exhibit power law
degree distributions:

• ‘USTop500Airports’: 500 nodes, 2,980 links
• ‘openﬂights’: 7,976 nodes, 15,243 links
• ‘polblogs’: 1,490 nodes, 9,517 links
• ‘Facebook107’: 1,034 nodes, 26,749 links

Where appropriate, we saved only the upper triangular
parts of the adjacency matrices. The ‘USTop500Airports’
dataset contains the (undirected, unweighted) ﬂight con-
nections between the 500 busiest US airports. The similar,

though much larger, ‘openﬂights’ dataset contains the ﬂight
connections between non-US airports. Scale-free networks
have been proposed for such trafﬁc networks, detailed for
these datasets by Colizza et al. (2007). The ‘polblogs’
dataset contains the links between political blogs (judged
by hyperlinks between the front webpages of the blogs) in
the period leading up to the 2004 US presidential election,
which is observed to exhibit power law degree distributions
by Adamic & Glance (2005). The ‘Facebook107’ dataset
contains “friendships” between users of a Facebook app,
collected by Leskovec & McAuley (2012); social networks
are widely studied for their power law degree distributions.

For both the Gamma and BFRY models, we ran our varia-
tional inference procedure for 20,000 steps on each dataset.
As before, we repeated the experiment 5 times for each net-
work, each time holding out a different 20% of the edges
in the network as a testing set. We selected the value of
β from among the grid {0.6, 0.9, 1.0, 1.2, 1.4} with 5-fold
cross validation on the training set. We set the minibatch
size to be equal to the number of nodes in the graph; for
example, we used minibatches of 1,490 edges for the pol-
blog dataset. The evaluation metrics on the test datasets
are summarized in Table 2, and the inferred hyperparame-
ter values are reported in Table 3. We see that the BFRY
model once again outperforms the Gamma baseline model,
according to the test log-likelihood metrics.

Probabilistic inference on α by the BFRY model provides
some of the most interesting analyses here. With α ≈ 0.00
(underﬂowing our machine’s precision), the Facebook107
social network has the degree distribution with the heavi-
est tails, followed by the USTop500Airports trafﬁc network
with α ≈ 0.23, the polblog citation network with α ≈ 0.64,
and the openﬂights network has the lightest tailed degree
distribution with α ≈ 0.67.

8. Future work

Future work could focus on implementing the latent factor
modeling generalizations presented in Section 5, which are
natural assumptions in many domains where networks are
expected to exhibit power law degree distributions. Alter-
native approaches to inference on the sparsity parameter β
should also be explored, since controlling the sparsity in
the graph was important for good predictive performance.

Power law simple graphs

Acknowledgements

The authors thank Remco van der Hofstad for helpful ad-
vice and anonymous reviewers for helpful feedback. J. Lee
and S. Choi were partly supported by an Institute for Infor-
mation & Communications Technology Promotion (IITP)
grant, funded by the Korean government (MSIP) (No.2014-
0-00147, Basic Software Research in Human-level Life-
long Machine Learning (Machine Learning Center)) and
Naver, Inc. C. Heaukulani undertook this work in part
while a visiting researcher at the Hong Kong University
of Science and Technology, who along with L. F. James
was funded by grant rgc-hkust 601712 of the Hong Kong
Special Administrative Region.

References

Adamic, L. A. and Glance, N.

The political blo-
divided they
gosphere and the 2004 US election:
the 3rd international
In Proceedings of
blog.
workshop on Link discovery,
2005.
URL http://www.cise.ufl.edu/research/
sparse/matrices/Newman/polblogs.

pp. 36–43,

Airoldi, E. M., Blei, D. M., Fienberg, S. E., and Xing,
E. P. Mixed membership stochastic blockmodels. In Ad-
vances in Neural Information Processing Systems, 2009.

Albert, R. and Barab´asi, A-L. Statistical mechanics of com-
plex networks. Reviews of modern physics, 74(1):47,
2002.

Barab´asi, A. and Albert, R. Emergence of scaling in ran-
dom networks. Science, 286(5439):509–512, 1999.

Bertoin, J., Fujita, T., Roynette, B., and Yor, M. On a
particular class of self-decomposable random variables:
the durations of bessel excursions straddling indepen-
dent exponential times. Probability and Mathematical
Statistics, 26:315–366, 2006.

Bollob´as, B. Random graphs. Springer, 1998.

Bollob´as, B. and Riordan, O. M. Mathematical results on
scale-free random graphs. Handbook of graphs and net-
works: from the genome to the internet, pp. 1–34, 2003.

Bollob´as, B., Riordan, O., Spencer, J., and Tusn´ady, G. The
degree sequence of a scale-free random graph process.
Random Structures & Algorithms, 18(3):279–290, 2001.

Bottou, L. Large-scale machine learning with stochastic

Cai, D. and Broderick, T. Completely random measures
for modeling power laws in sparse graphs. In NIPS 2015
Workshop on Networks in the Social and Information
Sciences, 2015.

Caron, F. and Fox, E. B. Sparse graphs using exchange-
able random measures. arXiv preprint arXiv:1401.1137,
2014.

Colizza, V.,

Pastor-Satorras, R.,

and Vespignani,
Reaction–diffusion processes and metapop-
A.
networks.
in
ulation
models
Nature Physics,
URL
3(4):276–282,
https://sites.google.com/site/cxnets/
usairtransportationnetwork.

heterogeneous

2007.

Crane, H. and Dempsey, W. Atypical scaling behavior per-
sists in real world interaction networks. arXiv preprint
arXiv:1509.08184, 2015.

Crane, H. and Dempsey, W. Edge exchangeable models for
network data. arXiv preprint arXiv:1603.04571, 2016.

Devroye, L. and James, L. F. On simulation and properties
of the stable law. Statistical methods & applications, 23
(3):307–343, 2014.

Dorogovtsev, S. N. and Mendes, J. F. F. Evolution of net-
works. Advances in physics, 51(4):1079–1187, 2002.

Ghahramani, Z., Grifﬁths, T. L., and Sollich, P. Bayesian
nonparametric latent feature models. Bayesian Statistics,
8:201–226, 2007. See also the discussion and rejoinder.

Hoffman, M. D., Blei, D. M., Wang, C., and Paisley, J. W.
Journal of Machine

Stochastic variational inference.
Learning Research, 14(1):1303–1347, 2013.

James, L. F., Orbanz, P., and Teh, Y. W. Scaled subordi-
nators and generalizations of the Indian buffet process.
arXiv preprint arXiv:1510.07309, 2015.

Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., and Saul,
L. K. An introduction to variational methods for graphi-
cal models. Machine learning, 37(2):183–233, 1999.

Kemp, C., Tenenbaum, J. B., Grifﬁths, T. L., Yamada, T.,
and Ueda, N. Learning systems of concepts with an inﬁ-
nite relational model. In AAAI, 2006.

Kingma, D. P. and Ba, J. Adam: a method for stochastic

optimization. In ICLR, 2015.

gradient descent. In COMPSTAT, 2010.

Kingma, D. P. and Welling, M. Auto-encoding variational

Britton, T., Deijfen, M., and Martin-L¨of, A. Generating
simple random graphs with prescribed degree distribu-
tion. Journal of Statistical Physics, 124(6):1377–1397,
2006.

Knowles, D. A.

Stochastic gradient variational Bayes
for gamma approximating distributions. arXiv preprint
arXiv:1509.01631, 2015.

Bayes. In ICLR, 2014.

Power law simple graphs

Lee, J., James, L. F., and Choi, S. Finite-dimensional
BFRY priors and variational Bayesian inference for
power law models. In Advances In Neural Information
Processing Systems, pp. 3162–3170, 2016.

Leskovec, J. and McAuley, J. J.
social circles

Learning to dis-
In Ad-
cover
vances in Neural Information Processing Systems 25,
URL https://snap.stanford.edu/
2012.
data/egonets-Facebook.html.

in ego networks.

Miller, K., Jordan, M. I., and Grifﬁths, T. L. Nonparametric
latent feature models for link prediction. In Advances in
neural information processing systems, 2009.

Murray, I., Ghahramani, Z., and MacKay, D. J. C. Mcmc

for doubly-intractable distributions. In UAI, 2006.

Nowicki, K. and Snijders, T. A. B. Estimation and predic-
tion for stochastic blockstructures. Journal of the Amer-
ican Statistical Association, 96(455):1077–1087, 2001.

Pitman, J. and Yor, M.

The two-parameter Poisson–
Dirichlet distribution derived from a stable subordinator.
The Annals of Probability, pp. 855–900, 1997.

Robbins, H. and Monro, S. A stochastic approximation
method. The Annals of Mathematical Statistics, 22(3):
400–407, 1951.

Salimans, T. and Knowles, D. A. Fixed-form variational
posterior approximation through stochastic linear regres-
sion. Bayesian Analysis, 8(4):837–882, 2013.

van der Hofstad, R. Random graphs and complex net-
works: Volume 1. Cambridge Series in Statistical
and Probabilistic Mathematics. Cambridge University
Press, 2016. URL http://www.win.tue.nl/
˜rhofstad/NotesRGCN.pdf.

Veitch, V. and Roy, D. M. The class of random graphs aris-
ing from exchangeable random measures. arXiv preprint
arXiv:1512.03099, 2015.

