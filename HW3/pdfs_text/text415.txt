A. Proofs

Sketch of the proof for Theorem 1. We need to the show
that for every ˜Q ∈ O(n), there exits a tuple of vec-
tors (u1, . . . , un) ∈ R × · · · × Rn such that ˜Q =
M1(u1, . . . , un). Algorithm 1 shows how a QR decompo-
sition can be performed using the matrices {Hk(uk)}n
k=1
while ensuring that the upper triangular matrix R has pos-
itive diagonal elements. If we apply this algorithm to an
orthogonal matrix ˜Q, we get a tuple (u1, . . . , un) which
satisﬁes

QR = Hn(un) . . . H1(u1)R = ˜Q.

Note that the matrix R must be orthogonal since R = Q(cid:48) ˜Q.
Therefore, R = I, since the only upper triangular ma-
trix with positive diagonal elements is the identity matrix.
Hence, we have

M1(u1, . . . , un) = Hn(un) . . . H1(u1) = ˜Q.

Algorithm 1 QR decomposition using the mappings {Hk}.
For a matrix B ∈ Rn×n, {Bk,k}1≤k≤n denote its diagonal
elements, and Bk..n,k = (Bk,k, . . . , Bn,k)(cid:48) ∈ Rn−k+1.
Require: A ∈ Rn×n is a full-rank matrix.
Ensure: Q and R where Q = Hn(un) . . . H1(u1) and R
is upper triangular with positive diagonal elements such
that A = QR
R ← A
Q ← I {Initialise Q to the identity matrix}
for k = 1 to n − 1 do

if Rk,k == (cid:107)Rk..n,k(cid:107) then

un−k+1 = (0, . . . , 0, 1)(cid:48) ∈ Rn−k+1

else

un−k+1 ← Rk..n,k − (cid:107)Rk..n,k(cid:107) (1, 0, . . . , 0)(cid:48)
un−k+1 ← un−k+1/ (cid:107)un−k+1(cid:107)

end if
R ← Hn−k+1(un−k+1)R
Q ← QHn−k+1(un−k+1)

end for
u1 = sgn(Rn,n) ∈ R
R ← H1(u1)R
Q ← QH1(u1)

where dA, dB, and dC represent inﬁnitesimal perturba-
tions and

C :=

, A :=

∂L
∂C

(cid:20) ∂C
∂A

(cid:21)(cid:48) ∂L
∂C

, B :=

(cid:20) ∂C
∂B

(cid:21)(cid:48) ∂L
∂C

.

Proof of Theorem 2. Let C = h − U T −1U (cid:48)h where
(U, h) ∈ Rn×m × Rn and T = striu(U (cid:48)U ) + 1
2 diag(U (cid:48)U ).
Notice that the matrix T can be written using the Hadamard
product as follows

T = B ◦ (U (cid:48)U ),

(1)

where B = striu(Jm) + 1
of all ones.

2 Im and Jm is the m × m matrix

Calculating the inﬁnitesimal perturbations of C gives

dC =(I − U T −1U (cid:48))dh

− dU T −1U (cid:48)h − U T −1dU (cid:48)h
+ U T −1dT T −1U (cid:48)h.

Using Equation (1) we can write

dT = B ◦ (dU (cid:48)U + U (cid:48)dU ).

By substituting this back into the expression of dC, multi-
plying the left and right-hand sides by C
, and applying the
trace we get

(cid:48)

(cid:48)

Tr(C

dC) = Tr(C

(I − U T −1U (cid:48))dh)

(cid:48)

(cid:48)

− Tr(C

+ Tr(C

dU T −1U (cid:48)h) − Tr(C
U T −1(B ◦ (dU (cid:48)U + U (cid:48)dU ))T −1U (cid:48)h).

U T −1dU (cid:48)h)

(cid:48)

Now using the identity Tr(AB) = Tr(BA), where the sec-
ond dimension of A agrees with the ﬁrst dimension of B,
we can rearrange the expression of Tr(C

dC) as follows

(cid:48)

(cid:48)

Tr(C

(I − U T −1U (cid:48))dh)
(cid:48)

(cid:48)

dU ) − Tr(hC

dC) = Tr(C
− Tr(T −1U (cid:48)hC
+ Tr(T −1U (cid:48)hC

(cid:48)

U T −1dU (cid:48))

U T −1(B ◦ (dU (cid:48)U + U (cid:48)dU ))).

(cid:48)

(cid:48)

To simplify the expression, we will use the short notations

˜C = (T (cid:48))−1U (cid:48)C,
˜h = T −1U (cid:48)h,

Lemma 1. (Giles, 2008) Let A, B, and C be real or com-
plex matrices, such that C = f (A, B) where f is some dif-
ferentiable mapping. Let L be some scalar quantity which
depends on C. Then we have the following identity

(cid:48)

Tr(C

dC) becomes

(cid:48)

Tr(C

dC) = Tr(A

dA) + Tr(B

dB),

(cid:48)

(cid:48)

(cid:48)

Tr(C

(cid:48)

dC) = Tr((C
− Tr(˜hC
+ Tr(˜h ˜C (cid:48)(B ◦ (dU (cid:48)U + U (cid:48)dU ))).

− ˜C (cid:48)U (cid:48))dh)
dU ) − Tr(h ˜C (cid:48)dU (cid:48))

(cid:48)

Now using the two following identities of the trace

Tr(A(cid:48)) = Tr(A),
Tr(A(B ◦ C)) = Tr((A ◦ B(cid:48))C)),

we can rewrite Tr(C

dC) as follows

(cid:48)

(cid:48)

Tr(C

dC) =Tr((C

(cid:48)

− ˜C (cid:48)U (cid:48))dh)

(cid:48)

dU ) − Tr(h ˜C (cid:48)dU (cid:48))

− Tr(˜hC
+ Tr((˜h ˜C (cid:48) ◦ B(cid:48))dU (cid:48)U )
+ Tr((˜h ˜C (cid:48) ◦ B(cid:48))U (cid:48)dU ).

By rearranging and taking the transpose of the third and
fourth term of the right-hand side we obtain

(cid:48)

Tr(C

dC) =Tr((C

(cid:48)

− ˜C (cid:48)U (cid:48))dh)

(cid:48)

dU ) − Tr( ˜Ch(cid:48)dU )

− Tr(˜hC
+ Tr((( ˜C˜h(cid:48)) ◦ B)U (cid:48)dU )
+ Tr(((˜h ˜C (cid:48)) ◦ B(cid:48))U (cid:48)dU ).

Factorising by dU inside the Tr we get

(cid:48)

Tr(C

dC) = Tr((C

Tr((˜hC

(cid:48)

+ ˜Ch(cid:48) −

(cid:48)

− ˜C (cid:48)U (cid:48))dh)−
( ˜C˜h(cid:48)) ◦ B + (˜h ˜C (cid:48)) ◦ B(cid:48)(cid:105)
(cid:104)

U (cid:48))dU ).

Using lemma 1 we conclude that

U =U

(cid:104)
(˜h ˜C (cid:48)) ◦ B(cid:48) + ( ˜C˜h(cid:48)) ◦ B

(cid:105)

− C˜h(cid:48) − h ˜C (cid:48),

h =C − U ˜C.

Sketch of the proof for Corollary 1. For any nonzero com-
plex valued vector x ∈ Cn, if we chose u = x + eiθ (cid:107)x(cid:107) e1
and H = −e−iθ(I − 2 uu∗
(cid:107)u(cid:107)2 ), where θ ∈ R is such that
x1 = eiθ|x1|, we have (Mezzadri, 2006)

Hx = ||x||e1

(2)

Taking this fact into account, a similar argument to that
used in the proof of Theorem 1 can be used here.

B. Algorithm Explanation

Let U := (vi,j)1≤j≤m
T := striu(U (cid:48)U ) + 1

1≤i≤n . Then the element of the matrix
2 diag(U (cid:48)U ) can be expressed as

ti,j =

i ≤ j
(cid:74)

(cid:75)

(cid:80)n

k=j vk,ivk,j
1 + δi,j

,

where δi,j is the Kronecker delta and
bracket (i.e.

= 1 if p is true and

p

·

is the Iversion

(cid:74)
= 0 otherwise).

(cid:75)

p
(cid:75)

(cid:74)

(cid:74)

(cid:75)

In order to compute the gradients in Equations (14) and
(15). we ﬁrst need to compute ˜h = T −1U (cid:48)h and ˜C =
(T (cid:48))−1U (cid:48) ∂L
∂C . This is equivalent to solving the triangular
systems of equations T ˜h = U (cid:48)h and T (cid:48) ˜C = U (cid:48) ∂L
∂C .

Solving the triangular system T ˜h = U (cid:48)h. For 1 ≤ k ≤
m, we can express the k-th row of this system as

tk,k

˜hk +

tk,j

˜hj =

vj,khj,

m
(cid:88)

j=k+1

=

=

n
(cid:88)

j=k
n
(cid:88)

r=k

n
(cid:88)

j=k
m
(cid:88)

j=k+1
n
(cid:88)

n
(cid:88)

r=j

vr,k

vj,khj −

vr,kvr,j

˜hj,

vr,khr −

r=k+1

j=k+1

r
(cid:88)

vr,j

˜hj,

(3)

= U (cid:48)

∗,k(h −

U∗,j

˜hj),

(4)

m
(cid:88)

j=k+1

where the passage from Equation (3) to (4) is justiﬁed be-
cause vr,j = 0 for j > r. Therefore, (cid:80)r
˜hj =
(cid:80)m

j=k+1 vr,j

j=k+1 vr,j

˜hj.
By setting H∗,k+1 := h − (cid:80)m
tk,k =

, we get

∗,kU∗,k
2

U (cid:48)

j=k+1 U∗,j

˜hj, and noting that

˜hk =

2
∗,kU∗,k
H∗,k = H∗,k+1 − ˜hkU∗,k.

U (cid:48)

U (cid:48)

∗,kH∗,k+1,

(5)

(6)

j=1 U∗,j

Equations (5) and (6) explain the lines 8 and 9 in Algo-
rithm 1. Note that H∗,1 = h − (cid:80)m
˜hj = h −
(cid:80)m
j=1 U∗,j[T −1U (cid:48)h]j = h − U T −1U (cid:48)h = W h. Hence,
when h = h(t−1), we have H∗,1 = C (t), which explains
line 16 in Algorithm 1.
Solving the triangular system T (cid:48) ˜C = U (cid:48) ∂L
the previous case, we have for 1 ≤ k ≤ m

∂C . Similarly to

tk,k ˜Ck +

tj,k ˜Cj =

vj,k

k−1
(cid:88)

j=1

n
(cid:88)

j=1

n
(cid:88)

r=1

=

=

n
(cid:88)

j=k

(cid:21)

(cid:20) ∂L
∂C

,

j

k−1
(cid:88)

n
(cid:88)

−

j=1

r=k

n
(cid:88)

r=1

k−1
(cid:88)

j=1



U∗,j ˜Cj

 ,

(cid:21)

(cid:20) ∂L
∂C

(cid:21)

(cid:20) ∂L
∂C

j

r

vj,k

vr,k



= U (cid:48)

∗,k



∂L
∂C

−

k−1
(cid:88)

j=1

vr,jvr,k ˜Cj,

(7)

−

vr,k

vr,j ˜Cj,

(8)

Operation

FP

BP

˜hk ← 2
Nk

∗,kH∗,k+1

U (cid:48)
H∗,k ← H∗,k+1 − ˜hkU∗,k
U (cid:48)
g ← g − ˜CkU∗,k
G∗,k ← −˜hkg − ˜CkH∗,k+1

˜hk ← 2
Nk

∗,kH∗,k+1

Flop count
for iteration k
2(n − k) + 3
2n

2(n − k) + 3
2(n − k + 1)
3n

Total Flop count
for m iteration

(4n − m + 2)m

(7n − 2m + 3)m

Table 1. Time complexities of different operations in algorithm 1. It is assumed that the matrix U ∈ Rn×m is deﬁned as in Equation (9).

where the passage from Equation (7) to (8) is justiﬁed by
the fact that (cid:80)n
r=1 vr,jvr,k ˜Cj (since
vr,k = 0 for r < k).

r=k vr,jvr,k ˜Cj = (cid:80)n

U (cid:48)

U (cid:48)

∂C(t) − (cid:80)k−1
j=1 U∗,j ˜Cj, we can write
By setting g := ∂L
˜Ck =
2
∗,kg which explains the lines 12 and
∗,kU∗,k
13 in Algorithm 1. Note also that after m-iterations in
the backward propagation loop in Algorithm 1, we have
g = ∂L
∂h(t−1) . This
explains line 17 of Algorithm 1.

∂C(t) − U ˜C = ∂L

j=1 U∗,j ˜Cj = ∂L

∂C(t) − (cid:80)m

Finally, note that from Equation (14), we have for 1 ≤ i ≤
n and 1 ≤ k ≤ m
(cid:20) ∂L
∂U

˜hk − hi ˜Ck+

(cid:20) ∂L
∂C

= −

(cid:21)

(cid:21)

i,k

vi,j

((˜h ˜C (cid:48)) ◦ B(cid:48))j,k + (( ˜C˜h(cid:48)) ◦ B)j,k

(cid:17)

,

i

(cid:16)

(cid:21)

i
(cid:18)

m
(cid:88)

j=1

= −

(cid:20) ∂L
∂C

m
(cid:88)

j=1

vi,j

= −

(cid:21)

(cid:20) ∂L
∂C

i

˜hk − hi ˜Ck+

˜hj ˜Ck (cid:74)

k ≤ j
(cid:75)
1 + δj,k

+ ˜Cj

˜hk (cid:74)

j ≤ k
(cid:75)
1 + δj,k

(cid:19)

,

˜hk − hi ˜Ck+

m
(cid:88)

j=1

(cid:16)˜hj ˜Ck

vi,j

k < j

+ ˜Cj

˜hk

j ≤ k

(cid:74)

(cid:75)

(cid:74)

(cid:17)

,

(cid:75)





m
(cid:88)

= ˜Ck

vi,j

˜hj − hi





j=k+1


k
(cid:88)

j=1

+ ˜hk



vi,j ˜Cj −



 .

(cid:21)

(cid:20) ∂L
∂C

i

C. Time complexity

Table 1 shows the ﬂop count for different operations in the
local backward and forward propagation steps in Algorithm
1.

D. Matlab implementation of Algorithm 1

% Inputs: U - matrix of reflection vectors
h - hidden state at time-step t-1
%
BPg - Grad of loss w.r.t C=Wh
%
% Outputs: g, G, C=Wh
[n, m] = size(U);
G=zeros(n, m); H = zeros(n, m+1);
N = zeros(m); h_tilde = zeros(m);
%
H(:,m+1)=h; g=BPg;
%%--Forward propagation--%%
for k =0:m-1

Zero-initialisation not required above!

N(m-k) = U(:, m-k)' * U(:, m-k);
h_tilde(m-k)=2 / N(m-k) * ...

U(:, m-k)' * H(:,m-k+1);

H(:,m-k)=H(:,m-k+1) - ...

h_tilde(m-k) * U(:,m-k);

end
C = H(:,1)
%%--Backward propagation--%%
for k=1:m

c_tilde_k = 2*U(:,k)' * g / N(k);
g = g - c_tilde_k * U(:,k);
G(:, k)=-h_tilde(k) * g - ...

c_tilde_k*H(:,k+1);

end

∂L

∂L

Figure 1. MATLAB code performing one-step FP and BP re-
quired to compute C (t),
∂h(t−1) (variable g is the code), and
∂U (t) (variable G is the code). The required inputs for the FP and
BP are, respectively, the tuples (U, h(t−1)) and (U, C (t), ∂L
∂C(t) ).
∂C(t) is variable BPg in the Matlab code.
Note that

∂L

Therefore, when C = C (t) and h = h(t−1) we have

(cid:21)

(cid:20) ∂L
∂U (t)

∗,k

= − ˜CkH∗,k+1 − ˜hkg,

References

where g = ∂L
and 18 of Algorithm 1.

∂C(t) − (cid:80)k−1

j=1

˜CjU∗,j. This explains lines 14

Giles, Mike B. An extended collection of matrix derivative
results for forward and reverse mode automatic differen-
tiation. 2008.

Mezzadri, Francesco. How to generate random matrices
from the classical compact groups. arXiv preprint math-
ph/0609050, 2006.

