Max-value Entropy Search for Efﬁcient Bayesian Optimization (Appendix)

Zi Wang 1 Stefanie Jegelka 1

1. Related work

Our work is largely inspired by the entropy search (ES) methods (Hennig & Schuler, 2012; Hern´andez-Lobato et al.,
2014), which established the information-theoretic view of Bayesian optimization by evaluating the inputs that are most
informative to the arg max of the function we are optimizing.

Our work is also closely related to probability of improvement (PI) (Kushner, 1964), expected improvement (EI) (Mo˘ckus,
1974), and the BO algorithms using upper conﬁdence bound to direct the search (Auer, 2002; Kawaguchi et al., 2015;
2016), such as GP-UCB (Srinivas et al., 2010). In (Wang et al., 2016), it was pointed out that GP-UCB and PI are closely
related by exchanging the parameters. Indeed, all these algorithms build in the heuristic that the next evaluation point needs
to be likely to achieve the maximum function value or have high probability of improving the current evaluations, which
in turn, may also give more information on the function optima like how ES methods queries. These connections become
clear as stated in Section 3.1 of our paper.

Finding these points that may have good values in high dimensional space is, however, very challenging. In the past,
high dimensional BO algorithms were developed under various assumptions such as the existence of a lower dimensional
function structure (Djolonga et al., 2013; Wang et al., 2013), or an additive function structure where each component is
only active on a lower manifold of the space (Li et al., 2016; Kandasamy et al., 2015). In this work, we show that our
method also works well in high dimensions with the additive assumption made in (Kandasamy et al., 2015).

2. Using the Gumbel distribution to sample y∗

To sample the function maximum y∗, our ﬁrst approach is to approximate the distribution for y∗ and then sample from that
distribution. We use independent Gaussians to approximate the correlated f (x), ∀x ∈ ˆX where ˆX is a discretization of the
input search space X (unless X is discrete, in which case ˆX = X). A similar approach was adopted in (Wang et al., 2016).
We can show that by assuming {f (x)}x∈ ˆX, our approximated distribution gives a distribution for an upperbound on f (x).
Lemma 2.1 (Slepian’s Comparison Lemma (Slepian, 1962; Massart, 2007)). Let u, v ∈ Rn be two multivariate Gaussian
random vectors with the same mean and variance, such that

Then for every y

E[vivj] ≤ E[uiuj], ∀i, j.

Pr[ sup
i∈[1,n]

vi ≤ y] ≤ Pr[ sup
i∈[1,n]

ui ≤ y].

By the Slepian’s lemma, if the covariance kt(x, x(cid:48)) ≥ 0, ∀x, x(cid:48) ∈ ˆX, using the independent assumption with give us a
distribution on the upperbound ˆy∗ of f (x), Pr[ˆy∗ < y] = (cid:81)
We then use the Gumbel distribution to approximate the distribution for the maximum of the function values for ˆX, Pr[ˆy∗ <
y] = (cid:81)
x∈ ˆX Ψ(γy(x))). If for all x ∈ ˆX, f (x) have the same mean and variance, the Gumbel approximation is in fact
asymptotically correct by the Fisher-Tippett-Gnedenko theorem (Fisher, 1930).

x∈ ˆX Ψ(γy(x))).

1Computer Science and Artiﬁcial Intelligence Laboratory, Massachusetts Institute of Technology, Massachusetts, USA. Correspon-

dence to: Zi Wang <ziw@csail.mit.edu>, Stefanie Jegelka <stefje@csail.mit.edu>.

Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, 2017. JMLR: W&CP. Copyright 2017 by
the author(s).

Max-value Entropy Search for Efﬁcient Bayesian Optimization

Theorem 2.2 (The Fisher-Tippett-Gnedenko Theorem (Fisher, 1930)). Let {vi}∞
i=1 be a sequence of independent and
identically-distributed random variables, and Mn = max1≤i≤n vi. If there exist constants an > 0, bn ∈ R and a non
degenerate distribution function F such that limn→∞ Pr( Mn−bn
≤ x) = F (x), then the limit distribution F belongs to
either the Gumbel, the Fr´echet or the Weibull family.

an

In particular, for i.i.d. Gaussians, the limit distribution of the maximum of them belongs to the Gumbel distribu-
tion (Von Mises, 1936). Though the Fisher-Tippett-Gnedenko theorem does not hold for independent and differently
distributed Gaussians, in practice we still ﬁnd it useful in approximating Pr[ˆy∗ < y]. In Figure 1, we show an example of
the result of the approximation for the distribution of the maximum of f (x) ∼ GP (µt, kt)∀x ∈ ˆX given 50 observed data
points randomly selected from a function sample from a GP with 0 mean and Gaussian kernel.

Figure 1. An example of approximating the cumulative probability of the maximum of independent differently distributed Gaussians
Pr[ˆy∗ < y] (Exact) with a Gumbel distribution G(a, b) (Approx) via percentile matching.

3. Regret bounds

Based on the connection of MES to EST, we show the bound on the learning regret for MES with a point estimate for α(x).

Theorem 3.1. Let F be the cumulative probability distribution for the maximum of any function f sampled from
GP (µ, k) over the compact search space X ⊂ Rd, where k(x, x(cid:48)) ≤ 1, ∀x, x(cid:48) ∈ X. Let f∗ = maxx∈X f (x) and
w = F (f∗) ∈ (0, 1), and assume the observation noise is iid N (0, σ). If in each iteration t, the query point is chosen
∗ is drawn from F , then with
as xt = arg maxx∈X γyt
(x))), where γyt
probability at least 1 − δ, in T (cid:48) = (cid:80)T

number of iterations, the simple regret satisﬁes

(x))
(x)) − log(Ψ(γyt
i=1 logw

ψ(γyt
∗
2Ψ(γyt
∗

(x) = yt

∗−µt(x)
σt(x)

and yt

(x)

∗

∗

∗

δ
2πi

rT (cid:48) ≤

(νt∗ + ζT )

(cid:114)

CρT
T

(1)

where C = 2/ log(1 + σ−2) and ζT = (2 log( πT
νt (cid:44) minx∈X,yt

2 ; π satisﬁes (cid:80)T
(x), and ρT is the maximum information gain of at most T selected points.

i=1 π−1

δ )) 1

i ≤ 1 and πt > 0, and t∗ = arg maxt νt with

∗>f∗ γyt

∗

Before we continue to the proof, notice that if the function upper bound ˆy∗ is sampled using the approach described in
Section 3.1 and kt(x, x(cid:48)) ≥ 0, ∀x, x(cid:48) ∈ ˆX, we may still get the regret guarantee by setting y∗ = ˆy∗ (or y∗ = ˆy∗ + (cid:15)L
if X is continuous) since Pr[max ˆX ≤ y] ≥ Pr[ˆy∗ < y]. Moreover, Theorem 3.1 assumes y∗ is sampled from a universal
maximum distribution of functions from GP (µ, k), but it is not hard to see that if we have a distribution of maximums
adapted from GP (µt, kt), we can still get the same regret bound by setting T (cid:48) = (cid:80)T
, where wi = Fi(f∗)
and Fi corresponds to the maximum distribution at an iteration where y∗ > f∗. Next we introduce a few lemmas and then
prove Theorem 3.1.
Lemma 3.2 (Lemma 3.2 in (Wang et al., 2016)). Pick δ ∈ (0, 1) and set ζt = (2 log( πt
Then, it holds that Pr[µt−1(xt) − f (xt) ≤ ζtσt−1(xt), ∀t ∈ [1, T ]] ≥ 1 − δ.
Lemma 3.3 (Lemma 3.3 in (Wang et al., 2016)). If µt−1(xt) − f (xt) ≤ ζtσt−1(xt), the regret at time step t is upper
bounded as ˜rt ≤ (νt + ζt)σt−1(xt) , where νt (cid:44) minx∈X

, and ˆmt ≥ maxx∈X f (x), ∀t ∈ [1, T ].

t ≤ 1, πt > 0.

2 , where (cid:80)T

i=1 logwi

t=1 π−1

2δ )) 1

δ
2πi

ˆmt−µt−1(x)
σt−1(x)

y81012Pr[ˆy∗<y]00.20.40.60.81ExactApproxMax-value Entropy Search for Efﬁcient Bayesian Optimization

Lemma 3.4 (Lemma 5.3 in (Srinivas et al., 2010)). The information gain for the points selected can be expressed in terms
of the predictive variances. If fT = (f (xt)) ∈ RT :

I(yT ; f T ) =

log(1 + σ−2σ2

t−1(xt)).

1
2

T
(cid:88)

t=1

∗ are independent samples from F , there exists at least one yt

Proof. (Theorem 3.1) By lemma 3.1 in our paper, we know that the theoretical results from EST (Wang et al., 2016) can be
adapted to MES if y∗ ≥ f∗. The key question is when a sampled y∗ that can satisfy this condition. Because the cumulative
density w = F (f∗) ∈ (0, 1) and yt
∗ > f∗ with
probability at least 1 − wki in ki iterations.
Let T (cid:48) = (cid:80)T
i = 1, · · · , T . By union bound, with probability at least 1 − (cid:80)T
iteration ti which samples yti
Let (cid:80)T
with probability at least 1 − δ
Now let ζti = (2 log πti

i=1 ki be the total number of iterations. We split these iterations to T parts where each part have ki iterations,
i=1 wki, in all the T parts of iterations, we have at least one

2 . By Lemma 3.2 and Lemma 3.3, the immediate regret rti = f∗ − f (xti ) can be bounded as

i=1(πi)−1 = 1. A convenient choice for πi is πi = π2i2

∗ > f∗, ∀i = 1, · · · , T .
for any (cid:80)T

2 , there exist a sampled yti

2 , we can set ki = logw

∗ > f∗, ∀i = 1, · · · , T .

∗ that satisﬁes yt

∗ satisfying yti

∗ satisfying yti

i=1 wki = δ

6 . Hence

δ
2πi

δ ) 1

rti ≤ (νti + ζti)σti−1(xti).

Note that by assumption 0 ≤ σ2
(cid:80)T

2

i=1 σ2

ti−1(xti) ≤

log(1+σ−2) I(yT ; f T ) where f T = (f (xti))T

ti−1(xti) ≤ 1, so we have σ2

ti−1 ≤

log(1+σ−2σ2

ti−1(xti ))

log(1+σ−2)

i=1 ∈ RT , yT = (yti )T
T (cid:80)T

(cid:113)

i=1 σti−1(xti) ≤

. Then by Lemma 3.4, we have
i=1 ∈ RT . From assumptions, we
i=1 σ2

log(1+σ−2) . It

ti−1(xti) ≤

(cid:113) 2T ρT

have I(yT ; f T ) ≤ ρT . By Cauchy-Schwarz inequality, (cid:80)T
follows that with probability at least 1 − δ,

As a result, our learning regret is bounded as

rti ≤ (νt∗ + ζT )

(cid:115)

2T ρT
log(1 + σ−2)

.

T
(cid:88)

i=1

rT (cid:48) ≤

rti ≤ (νt∗ + ζT )

1
T

T
(cid:88)

i=1

(cid:115)

2ρT
T log(1 + σ−2)

,

where T (cid:48) = (cid:80)T

i=1 ki = (cid:80)T

i=1 logw

δ
2πi

is the total number of iterations.

At ﬁrst sight, it might seem like MES with a point estimate does not have a converging rate as good as EST or GP −U CB.
However, notice that minx∈X γy1 (x) < min x ∈ Xγy2(x) if y1 < y2, which decides the rate of convergence in Eq. 1. So
if we use y∗ that is too large, the regret bound could be worse. If we use y∗ that is smaller than f∗, however, its value
won’t count towards the learning regret in our proof, so it is also bad for the regret upper bound. With no principled way
of setting y∗ since f∗ is unknown. Our regret bound in Theorem 3.1 is a randomized trade-off between sampling large and
small y∗.

For the regret bound in add-GP-MES, it should follow add-GP-UCB. However, because of some technical problems in
the proofs of the regret bound for add-GP-UCB, we haven’t been able to show a regret bound for add-GP-MES either.
Nevertheless, from the experiments on high dimensional functions, the methods worked well in practice.

4. Experiments

In this section, we provide more details on our experiments.

Optimization test functions
optimization test functions: the 2-D eggholder function, the 10-D Shekel function, and the 10-D Michalewicz function.

In Fig. 2, we show the simple regret comparing BO methods on the three challenging

Max-value Entropy Search for Efﬁcient Bayesian Optimization

Figure 2. (a) 2-D eggholder function; (b) 10-D Shekel function; (c) 10-D Michalewicz function. PES achieves lower regret on the 2-d
function while MES-G performed better than other methods on the two 10-d optimization test functions.

Choosing the additive decomposition We follow the approach in (Kandasamy et al., 2015), and sample 10000 random
decompositions (at most 2 dimensions in each group) and pick the one with the best data likelihood based on 500 data
points uniformly randomly sampled from the search space. The decomposition setting was ﬁxed for all the 500 iterations
of BO for a fair comparison.

References

397–422, 2002.

1930.

Auer, Peter. Using conﬁdence bounds for exploitation-exploration tradeoffs. Journal of Machine Learning Research, 3:

Djolonga, Josip, Krause, Andreas, and Cevher, Volkan. High-dimensional Gaussian process bandits. In Advances in Neural

Information Processing Systems (NIPS), 2013.

Fisher, Ronald Aylmer. The genetical theory of natural selection: a complete variorum edition. Oxford University Press,

Hennig, Philipp and Schuler, Christian J. Entropy search for information-efﬁcient global optimization. Journal of Machine

Learning Research, 13:1809–1837, 2012.

Hern´andez-Lobato, Jos´e Miguel, Hoffman, Matthew W, and Ghahramani, Zoubin. Predictive entropy search for efﬁcient

global optimization of black-box functions. In Advances in Neural Information Processing Systems (NIPS), 2014.

Kandasamy, Kirthevasan, Schneider, Jeff, and Poczos, Barnabas. High dimensional Bayesian optimisation and bandits via

additive models. In International Conference on Machine Learning (ICML), 2015.

Kawaguchi, Kenji, Kaelbling, Leslie Pack, and Lozano-P´erez, Tom´as. Bayesian optimization with exponential conver-

gence. In Advances in Neural Information Processing Systems (NIPS), 2015.

Kawaguchi, Kenji, Maruyama, Yu, and Zheng, Xiaoyu. Global continuous optimization with error bound and fast conver-

gence. Journal of Artiﬁcial Intelligence Research, 56(1):153–195, 2016.

Kushner, Harold J. A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise.

Journal of Fluids Engineering, 86(1):97–106, 1964.

Li, Chun-Liang, Kandasamy, Kirthevasan, P´oczos, Barnab´as, and Schneider, Jeff. High dimensional Bayesian optimization
via restricted projection pursuit models. In International Conference on Artiﬁcial Intelligence and Statistics (AISTATS),
2016.

Massart, Pascal. Concentration Inequalities and Model Selection, volume 6. Springer, 2007.

Mo˘ckus, J. On Bayesian methods for seeking the extremum. In Optimization Techniques IFIP Technical Conference, 1974.

Slepian, David. The one-sided barrier problem for Gaussian noise. Bell System Technical Journal, 41(2):463–501, 1962.

Srinivas, Niranjan, Krause, Andreas, Kakade, Sham M, and Seeger, Matthias. Gaussian process optimization in the bandit

setting: no regret and experimental design. In International Conference on Machine Learning (ICML), 2010.

t50100150200rt567891011UCBPIEIESTESPESMES-RMES-Gt50100150200rt456789UCBPIEIESTESPESMES-RMES-Gt50100150200rt02004006008001000UCBPIEIESTESPESMES-RMES-G(a)(b)(c)Max-value Entropy Search for Efﬁcient Bayesian Optimization

Von Mises, Richard. La distribution de la plus grande de n valeurs. Rev. math. Union interbalcanique, 1936.

Wang, Zi, Zhou, Bolei, and Jegelka, Stefanie. Optimization as estimation with Gaussian processes in bandit settings. In

International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), 2016.

Wang, Ziyu, Zoghi, Masrour, Hutter, Frank, Matheson, David, and De Freitas, Nando. Bayesian optimization in high

dimensions via random embeddings. In International Conference on Artiﬁcial Intelligence (IJCAI), 2013.

