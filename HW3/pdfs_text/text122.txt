Multiple Clustering Views from Multiple Uncertain Experts

Yale Chang 1 Junxiang Chen 1 Michael H. Cho 2 Peter J. Castaldi 2 Edwin K. Silverman 2 Jennifer G. Dy 1

Abstract

Expert
input can improve clustering perfor-
mance. In today’s collaborative environment, the
availability of crowdsourced multiple expert in-
put is becoming common. Given multiple ex-
perts’ inputs, most existing approaches can only
discover one clustering structure. However, data
is multi-faceted by nature and can be clustered
in different ways (also known as views). In an
exploratory analysis problem where ground truth
is not known, different experts may have diverse
views on how to cluster data. In this paper, we
address the problem on how to automatically dis-
cover multiple ways to cluster data given poten-
tially diverse inputs from multiple uncertain ex-
perts. We propose a novel Bayesian probabilis-
tic model that automatically learns the multiple
expert views and the clustering structure asso-
ciated with each view. The beneﬁts of learn-
ing the experts’ views include 1) enabling the
discovery of multiple diverse clustering struc-
tures, and 2) improving the quality of cluster-
ing solution in each view by assigning higher
weights to experts with higher conﬁdence.
In
our approach, the expert views, multiple cluster-
ing structures and expert conﬁdences are jointly
learned via variational inference. Experimental
results on synthetic datasets, benchmark datasets
and a real-world disease subtyping problem show
that our proposed approach outperforms compet-
ing baselines, including meta clustering, semi-
supervised clustering, semi-crowdsourced clus-
tering and consensus clustering.

1. Introduction

As a cornerstone of unsupervised learning, clustering has
been widely used in knowledge discovery problems (Jain

1Northeastern University, Boston, MA 2Brigham and
Women’s Hospital, Harvard Medical School, Boston, MA. Cor-
respondence to: Yale Chang <ychang@coe.neu.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

et al., 1999). Given data matrix and a notion of simi-
larity between samples, clustering aims to categorize data
into different clusters so that samples in the same cluster
are similar and samples in different clusters are dissimilar.
Thus, depending on users’ notions of similarity, the same
dataset can be clustered in different ways, also known as
views (Niu et al., 2010). For example, face images can be
clustered based on pose or identity; marbles can be clus-
tered based on shape or color. However, how to properly
deﬁne similarity between samples in a knowledge discov-
ery problem is nontrivial. To help solve this challenge,
semi-supervised clustering utilizes expert supervision to
guide the clustering towards the right solution (Wagstaff &
Cardie, 2000; Basu et al., 2008). Supervision is usually in
the form of pairwise constraints between samples, includ-
ing must-link (ML) and cannot-link (CL) constraints.

Instead of supervision from one expert, it is becoming more
common for supervision to be available from multiple ex-
perts as data can be shared and processed by increasingly
larger audiences (e.g., crowdsourcing (Howe, 2008) mech-
anisms such as Amazon Mechanical Turk and large col-
laborative consortiums (Zhang et al., 2011)).
In an ex-
ploratory data analysis setting, where ground truths are not
known, different experts might provide supervision (pair-
wise contraints) with varying views in mind. For exam-
ple, one expert might be thinking of similarity/clustering
based on pose and another expert might be providing in-
puts based on identity on the face image problem. More-
over, because experts are not oracles, their inputs are prone
to errors as well. In this paper, we address a new cluster-
ing paradigm: how to discover multiple clustering struc-
tures in the data given potentially diverse constraints
from multiple uncertain experts.

Our objective of ﬁnding multiple clustering structures
given inputs from multiple experts is motivated by discov-
ering subtypes (clusters) of a complex lung disease called
Chronic Obstructive Pulmonary Disease (COPD). COPD is
currently the third leading cause of death in the US (Mur-
phy et al., 2013). Although traditionally being called one
disease, doctors believe there exist multiple disease sub-
types and providing personalized clinical care to patients
according to their disease subtypes can lead to more effec-
tive treatments. We have collected constraints provided by
multiple experts in the consortium. The experts had var-

Multiple Clustering Views from Multiple Uncertain Experts

ied backgrounds: 1) clinicians tend to provide constraints
by comparing patients’ clinical measurements; and 2) ra-
diologists tend to provide constraints based on examining
patients’ computed tomography (CT) images. On the one
hand, experts have disagreements on whether to put a pair
of patients in the same group because they are focusing on
different aspects of patients. On the other hand, experts of
similar backgrounds (clinicians, radiologists) tend to pro-
vide shared views of clustering data albeit with noisy con-
straints. Because the various experts might have different
views of clustering data, it does not make sense to learn
a single consensus clustering solution; rather, we need to
discover the multiple consensus clustering solutions in the
different views.

One naive way to generate multiple clustering solutions
from multiple uncertain experts is to separately apply semi-
supervised clustering (Bilenko et al., 2004; Davis et al.,
2007; Basu et al., 2008) using constraints from each expert.
The potential drawbacks of this strategy are 1) the cluster-
ing performance often drastically degrades in the presence
of noisy constraints due to uncertainty of one expert; and
2) the resulting clustering solutions can be highly redun-
dant due to the existence of similar expert views.

There are a few existing approaches that can combine con-
straints from multiple experts but they are mostly designed
to generate one clustering solution. Semi-crowdsourced
clustering (SemiCrowd) combines constraints provided by
multiple experts through ﬁltering out uncertain pairs in the
average sample similarity matrix (Yi et al., 2012). How-
ever, this approach can only generate one clustering so-
lution. Similar to SemiCrowd, most consensus clustering
methods are designed to generate one clustering solution
(Strehl & Ghosh, 2002; Fern & Brodley, 2004; Topchy
et al., 2005; Ghosh & Acharya, 2011). Another disadvan-
tage is that consensus clustering methods do not work when
only a small number of pairwise constraints are available.

There are a few multiple alternative clustering approaches
that can output multiple clustering solutions (Caruana et al.,
2006; Cui et al., 2007; Jain et al., 2008; Niu et al., 2010;
2012). However, all these methods are unsupervised; none
of these methods are able to utilize expert inputs.

There are a few existing crowdsourcing approaches that
learns an underlying grouping of experts (Tian & Zhu,
2012; Kajino et al., 2013; Moreno et al., 2015). However,
they are all designed for classiﬁcation problems, where ex-
perts provide labels on samples queried. In our clustering
task, experts can not provide labels because how to deﬁne
different clusters is still unknown and yet to be discovered.
Instead, they can provide pairwise constraints by compar-
ing sample pairs using their domain knowledge. Therefore,
these classiﬁcation-based approaches above cannot be used
in our clustering task.

Contributions. To address this new clustering paradigm,
we build a Bayesian probabilistic model for learning mul-
tiple alternative consensus clustering views from experts’
constraints, we call Multiple Clustering Views from the
Crowd (MCVC). Multiple experts are automatically as-
signed to different latent views and constraints provided
by each expert is assumed to be noisy perturbations of the
clustering associated with that expert’s view. Thus, multi-
ple clustering structures can be discovered. Furthermore,
by explicitly modeling the uncertainty of each expert, ex-
perts with higher accuracies are assigned higher weights,
leading to improved quality of the learned clustering struc-
ture in each view. The clustering structure for each ex-
pert view is modeled by a discriminative clustering model
(Gomes et al., 2010), which has the advantages of 1) nat-
urally introducing uncertainties in cluster assignments; 2)
avoiding making assumptions on the generative process of
clusters; and 3) being able to cluster samples that do not
appear in the training set. We demonstrate that our MCVC
outperforms competing alternatives on synthetic, bench-
mark data, and a real-world disease subtyping problem.

2. Proposed Approach

∈ {

Rn×d, where n is the num-
We collect data matrix X
∈
ber of samples and d is the number of features, and pair-
wise constraints provided by M experts S(1:M ), where
n×n represents the constraints pro-
S(m)
0, 1, NULL
}
vided by the m-th expert. For sample pair (xi, xj), S(m)
ij =
1 means the m-th expert provides must-link (ML) con-
straint; S(m)
= 0 means cannot-link (CL) constraint;
S(m)
ij = NULL means no constraint is provided. Our ob-
jective is to utilize constraints collected from these M ex-
perts to guide the clustering algorithm to discover multiple
clustering structures in the data.

ij

2.1. Multiple Alternative Clustering Views

We assume there exist multiple alternative expert views and
the constraints provided by experts in each view are per-
turbations of the clustering solution associated with that
view 1. Let cm represent the latent view to which the m-
th expert is assigned to. Furthermore, Z (cm) are the latent
clusters for each cm view. Since we do not know the under-
lying number of possible expert views, we automatically
learn the number of expert views by assuming a Dirichlet

1Note that “view” in multi-view clustering (Bickel & Schef-
fer, 2004) means coming from different sources or feature sets;
whereas, “view” in our case follows the terminology in multi-
ple alternative clusterings which means different interpretation or
point of view of the data. Multi-view clustering only ﬁnds ONE
clustering solution from multiple feature sets which are given. In
contrast, our goal is to ﬁnd MULTIPLE clustering solutions/views
which are latent.

Multiple Clustering Views from Multiple Uncertain Experts

process (Ferguson, 1973) prior on cm.

2.2. Model Uncertainties of Experts’ Constraints

Since clustering is widely used for knowledge discovery,
experts might not be certain on the constraints they pro-
vided. To incorporate the assumption that different experts
may have different levels of expertises when providing con-
straints, we assume the uncerntainty of the m-th expert can
be characterized by accuracy parameters (αm, βm), where
αm represents the m-th expert’s sensitivity and βm repre-
sents speciﬁcity. Sensitivity is deﬁned as the probability of
providing ML constraints for sample pairs from the same
cluster in the ground truth. Speciﬁcity is deﬁned as the
probability of providing CL constraints for sample pairs
from different clusters in the ground truth. We model the
conditional likelihood of S(m) given cm (the latent view)
and Z (cm) (the latent cluster in each view) by a Bernoulli
distribution as follows:

p(S(m)
p(S(m)

Z (cm)
ij = 1
i
|
Z (cm)
ij = 0
i
|

= Z (cm)
j
= Z (cm)
j

, αm) = αm

, βm) = βm

(1)

(2)

2.3. Discriminative Clustering

We consider the following when choosing the clustering
model: 1) Since we need to model uncertainties of experts,
instead of generating hard clustering results, the assign-
ments to clusters should be associated with probabilities;
2) We should avoid making strong assumptions on the gen-
erative process of clusters, which can be easily violated
in practice; 3) We should be able to cluster samples out-
side the training set. The discriminative clustering model
(Gomes et al., 2010) satisﬁes all these requirements. In-
stead of assuming the generative process of data X, dis-
criminative clustering directly models the conditional dis-
tribution of cluster label given data. We model the condi-
tional distribution of the latent cluster label, Z (cm), given
weight W (cm) and offset b(cm) with a multiple logistic re-
gression model:

p(Z (cm)
i

= k

W (cm), b(cm); X) =

|

xi+b(cm)
k

k

ew(cm)T
j=1 ew(cm )T

j

(cid:80)K

xi+b(cm)
j

parameters to make most of their probability densities be
far away from 0.5 and close to 1.

p(αm) = Beta(τ (m)
p(βm) = Beta(τ (m)

α10 , τ (m)
α20 )
β10 , τ (m)
β20 )

(4)

(5)

To automatically learn the number of expert views, we as-
sume a Dirichlet process prior on cm and utilize the stick-
breaking construction as follows (Blei et al., 2006):

νg

Beta(1, γ); πg

νg

(1

νj); cm

Cat(π1:∞)

∼

−

∼

∼

g−1
(cid:89)

j=1

Therefore, p(cm

ν1:∞) can be written as
|

p(cm

ν1:∞) =

|

∞
(cid:89)

g=1

πcmg
g =

∞
(cid:89)

(cid:0)νg

g−1
(cid:89)

g=1

j=1

(1

−

νj)(cid:1)cmg

(6)

where cmg = 1 if cm = g and cmg = 0 otherwise.
We assume the prior distributions of both weight W (g) and
offset b(g) are factorized Gaussian distributions.

p(W (g)) =

(µ(g)

Wij 0, σ(g)2
Wij 0)

d
(cid:89)

K
(cid:89)

N

i=1

j=1

K
(cid:89)

i=1

N

p(b(g)) =

(µ(g)

bi0, σ(g)2
bi0 )

(7)

(8)

2.5. Joint Distribution

The overall joint distribution of observations and latent
variables for our model is:

p(S(1:M ), α1:M , β1:M , c1:M , ν1:∞, Z (1:∞), W (1:∞), b(1:∞))

p(S(m)

αm, βm, cm, Z (1:∞))p(αm)p(βm)

(9)

p(cm

ν1:∞)
|

|

p(Z (g)

W (g), b(g); X)p(W (g))p(b(g))p(νg)

The respective graphical model is shown in Figure 1.

=

M
(cid:89)

m=1

|

∞
(cid:89)

g=1

3. Variational Inference

(3)

where w(cm)
b(cm)
k

k

is the k-th column of W (cm)

Rd×K and

∈

is the k-th row of b(cm)

RK×1.

∈

2.4. Prior Distributions

We describe the prior distributions of parameters used in
our model. To incorporate the assumptions that experts’
accuracies should be far away from random guess (αm =
βm = 0.5), we put Beta priors on αm, βm and set their

Our learning objective is to maximize the marginal likeli-
hood of observed constraints, which is intractable. Thus,
we apply variational inference. Given variational distribu-
tion q(h; θ), where h is the collection of latent variables
and θ is their parameters.
the log of the marginal likeli-
hood log p(S(1:M )) can be decomposed as

log p(S(1:M )) =

Lq(h;θ) + KL

(cid:104)

q(h; θ)

(cid:105)

S(1:M ))
p(h
|

|

≥ Lq(h;θ)

(10)

(cid:54)
Multiple Clustering Views from Multiple Uncertain Experts

αm

X

βm

S(m)

Z (g)

W (g)

cm

M

νg

b(g)

∞

Figure 1. Overall Graphical Model

where the inequality holds due to the nonnegativity of the
Lq(h;θ) is called the
the Kullback-Liebler (KL) divergence.
evidence lower bound (ELBO) of log p(S(1:M )):

(cid:105)

(cid:104)
log p(h, S(1:M ))

−

(11)

log q(h; θ)

Lq(h;θ) = Eq(h;θ)
In variational inference, the learning objective becomes
maximizing

Lq(h;θ) w.r.t. variational parameters θ.
α1:M , β1:M , c1:M , ν1:G, Z (1:G), W (1:G), b(1:G)
{

Let h =
,
}
where G is the number of components of the truncated
Dirichlet Process (Blei et al., 2006). We apply mean-ﬁeld
and assume q(h; θ) can be factorized as follows:

q(α1:M , β1:M , c1:M , ν1:G, Z (1:G), W (1:G), b(1:G))

M
(cid:89)

m=1

G
(cid:89)

g=1

=

[q(αm)

q(βm)

q(cm)]

·

·

·

(cid:2)q(νg)

q(Z (g)
i

)

q(W (g)
ij )

q(b(g)
i

)(cid:3) (12)

n
(cid:89)

i=1

d
(cid:89)

K
(cid:89)

i=1

j=1

K
(cid:89)

i=1

where the marginal distribution of each random variable is

α1 , τ (m)
α2 )
β1 , τ (m)
β2 )

q(αm) = Beta(τ (m)
q(βm) = Beta(τ (m)
q(cm) = Cat(φm,:)
ν1 , τ (g)
q(νg) = Beta(τ (g)
ν2 )
) = Cat(η(g)
i,: )
Wij , σ(g)2
(µ(g)
Wij )
bi , σ(g)2
(µ(g)
)

q(Z (g)
i
q(W (g)
q(b(g)
i

ij ) =

) =

N

bi

N

(13)

(14)

(15)

(16)

(17)

(18)

(19)

α2 , τ (m)

We use θ to denote all the variational parameters, which
α1 , τ (m)
τ (m)
β1 , τ (m)
consist of
M )
{
ν2 , η(g)
ν1 , τ (g)
τ (g)

G).
and
Wij
Besides the simplex constraints on the parameters of the
categorical distribution, both the parameters of the Beta
distribution and the standard deviation of Gaussian distri-
bution should have positive constraints.

}
bi , σ(g)
bi }

β2 , φm,:
, µ(g)

Wij , σ(g)

i,: , µ(g)

(m = 1

(g = 1

· · ·

· · ·

{

∂θ

We derive the closed-form formula of
Lq(h;θ) as a function
of θ and put the detailed steps in the supplementary mate-
rials due to space constraints. Since ELBO
Lq(h;θ) can be
written as a function of variational parameters θ, we can di-
Lq(h;θ) using gradient-based optimization
rectly maximize
approaches. The gradient ∂Lq(h;θ)
can be automatically
computed using reverse-mode differentiation (Maclaurin
et al., 2015). We choose to use a limited-memory projected
quasi-Newton algorithm (PQN) to optimize our objective
because it has both superlinear convergence rate and linear
memory requirement (Schmidt et al., 2009). Because our
objective
Lq(h;θ) is not concave, we provide multiple ini-
tializations θ(0) to the optimization algorithm and choose
the one resulting in the maximal objective value. We set
the number of random initializations to be 50 in all experi-
ments and the results are stable across different runs.

4. Experimental Results

In this section, we aim to demonstrate our MCVC can auto-
matically 1) assign multiple experts to different views; and
2) improve the quality of clustering solution in each view
by assigning higher weights to uncertain experts of higher
accuracies. We also analyze how 3) the settings of the num-
ber of clusters; and 4) the constraints provided by irrelevant
experts affect the performance of MCVC.

4.1. Competing Alternatives

For aim 1), we construct two views of experts based on two
different ways to cluster the data. These two expert views
are treated as the ground truth of assigning multiple experts
to different views. Then we compare our MCVC against an
adapted version of meta clustering (Caruana et al., 2006).

Meta Spectral Clustering (MetaClust): The original
meta clustering approach cannot handle multiple experts’
constraints.
Instead of using the data matrix to generate
multiple clustering solutions as input, we directly use the
constraint sets provided by multiple experts as input. Meta
clustering ﬁrst computes the similarity between experts by
computing the rand index (Rand, 1971) between the con-
straint sets they provide. Given the resulting similarity ma-
trix between experts, instead of hierarchical clustering as in
the original paper, we apply spectral clustering (Ng et al.,
2001) to assign multiple experts to different views. We de-
termine the number of expert views by maximizing the gap
between the consecutive eigenvalues of the graph Lapla-
cian (Von Luxburg, 2007).

For aim 2), we ﬁrst construct one view of experts based
on one way to cluster the data. The underlying clustering
structure is treated as the ground truth of clustering sam-
ples. Then we compare our MCVC against the following
alternatives in generating clusters of high quality.

Multiple Clustering Views from Multiple Uncertain Experts

SemiCrowd: SemiCrowd (Yi et al., 2012) combines multi-
ple expert constraints by ﬁltering out uncertain pairs in the
average similarity matrix, applying matrix completion, and
then learning a distance metric for clustering.

Semi-supervised Clustering: Given a set of pairwise con-
straints, semi-supervised clustering either learns a better
distance metric for clustering or guides the clustering al-
gorithm to satisfy those constraints. We use Information-
theoretic Metric Learning (ITML) (Davis et al., 2007)
and Metric Pairwise Constrained KMeans (MPCKMeans)
(Bilenko et al., 2004) as the representatives of those two
strategies due to their superior performances compared to
alternatives. Since semi-supervised clustering can only
take one set of constraints as input, we combine constraints
from multiple experts through majority voting (a sample
pair is given ML constraint if the majority of experts pro-
vide ML constraints for them and CL constraint otherwise).

Consensus Clustering: Most consensus clustering algo-
rithms only work with cluster labels instead of pairwise
constraints. However, Cluster-based Similarity Partition-
ing Algorithm (CSPA) (Strehl & Ghosh, 2002), a consen-
sus clustering approach that only need average similarity
matrix between samples as input, can be used in our setup.

We provide the parameter setting details for all methods in
the supplementary materials due to space constraint.

4.2. Synthetic and Benchmark Experiments

Synthetic Dataset: To help understand the algorithms, we
generate a synthetic data that has multiple alternative clus-
tering views. We generate a synthetic dataset containing
600 samples and six features. The scatterplots between
pairwise features in this dataset are shown in Figure 2.
First, there exist three clusters in the subspace spanned by
the ﬁrst two features, which we denote as Y1. In all these
three ﬁgures, the red, blue and green colors represent the
true cluster indicator of Y1. Second, there exist an alter-
native clustering structure in the subspace spanned by the
third and fourth features, which we denote as Y2. Note that
Y2 and Y1 are very distinct. Third, the subspace spanned by
the ﬁfth and sixth feature does not contain well-separated
clusters and we consider these as noisy features.

Figure 2. Scatterplots of pairwise features in the synthetic dataset.

WebKB Dataset: The WebKB dataset (web, 1998) con-

tains webpages collected from four universities. After re-
moving stop words and extracting the top 200 words with
most frequent occurrences, we obtain a data matrix with
1041 samples and 200 features. The data can be clustered
according to either owner types (course, faculty, project,
student), which we treat as Y1, or universities (Cornell,
Austin, Washington, Wisconsin), which we use as Y2.

Face Dataset: The Face dataset (Lichman, 2013) con-
sists of 640 face images of people taken with varying poses
(straight, left, right, up). Each image has 960 raw pixels.
We apply principal component analysis (PCA) and keep 20
principal components (explaining 80% variance). Thus, we
obtain a data matrix with 640 samples and 20 features. The
data can be clustered based on pose (Y1) or identity (Y2).

Simulating Constraints from Multiple Experts:
For
synthetic and benchmark datasets, we do not have access
to real-world constraints provided by experts. Therefore,
we simulate these constraints. Given a ground-truth clus-
tering solution Y , the number of ML constraints nM L, the
number of CL constraints nCL, and accuracy parameters
of M experts α1:M , β1:M , we can generate the constraints
provided by the m-th expert as follows: 1) randomly sam-
ple nM L ML constraints and nCL CL constraints from Y ;
2) randomly ﬂip nM L(1
αm) ML pairs to CL pairs and
ﬂip nCL(1

−
βm) CL pairs to ML pairs.

−

4.2.1. TASK 1: LEARNING THE VARIOUS LATENT
VIEWS FROM MULTIPLE EXPERTS

In this subsection, we test the performance of our MCVC
on automatically learning the latent views from multiple
experts. We simulate noisy constraints provided by multi-
ple expert from two latent views, Y1 and Y2 as follows:
1) the ﬁrst view consists of experts 1-5, who provide con-
straints based on clustering solution Y1 and have accuracy
parameters α1:5 = β1:5 = (0.95, 0.9, 0.85, 0.8, 0.75);
2)
the second view consists of experts 6-10, who
provide constraints based on clustering solution Y2
and have accuracy parameters α6:10 = β6:10 =
(0.75, 0.8, 0.85, 0.9, 0.95).

We compare the performance of our MCVC and meta spec-
tral clustering (MetaClust) in recovering the ground-truth
expert views as the number of constraints, ncon, is var-
ied from 200 to a large number that makes the perfor-
mances of both approaches become stable. We repeat the
constraints generation process ten times to avoid the ran-
domness of a single run. As a result, we obtain ten con-
straint sets for a ﬁxed number of constraints. Given one
constraint set, we run MCVC and MetaClust to generate
two possibly different ways to group experts, which are de-
noted as LMCVC and LMetaClust respectively. We measure
performance based on the normalized mutual information
(NMI) (Strehl & Ghosh, 2002) between LMCVC, LMetaClust

−1012345Feature1−101234Feature2−1012345Feature3−0.50.00.51.01.52.02.53.03.54.0Feature4−4−3−2−101234Feature5−4−3−2−1012345Feature6Multiple Clustering Views from Multiple Uncertain Experts

and LTrue, the ground-truth expert views. NMI measures
the similarity between two partitions. In our case, higher
NMI values indicate better performance. For a ﬁxed num-
ber of constraints, one constraint set, and one approach, we
obtain ten NMI values. We plot the mean and standard de-
viation for every set of ten NMI values of each approach as
we vary the number of constraints as shown in Figure 3.

tions. We measure performance based on NMI between the
resulting clustering solutions and the ground-truth solution
Y1. For a ﬁxed number of constraints, one constraint set,
and one approach, we obtain 10 NMI values. We plot the
mean and standard deviation for every set of 10 NMI values
for each approach as we vary the number of constraints as
shown in Figure 4. To compare the performance of differ-
ent approaches, we apply the Kruskal-Wallis test (Kruskal
& Wallis, 1952), which can be used to test whether two
groups of samples are drawn from the same distribution,
on their corresponding groups of NMI values.

(a) Synthetic

(b) WebKB

(c) Face

Figure 3. Compare our MCVC against meta clustering (Meta-
Clust) in assigning multiple experts to different views on (a) syn-
thetic, (b) WebKB and (c) Face datasets.

We have the following observations: 1) On the synthetic
dataset, our MCVC can consistently recover the ground-
truth expert views; 2) On WebKB and Face, the perfor-
mance of MCVC improves as the number of constraints
increases and can recover the ground-truth expert views
when the number of constraints becomes large enough; 3)
On WebKB and Face, when the number of constraints is too
small, as is shown in the left part of each ﬁgure, MCVC will
be dominated by the priors and therefore cannot perfectly
recover the expert views. 4) On all three datasets, meta
clustering fails to recover the ground-truth expert views.

4.2.2. TASK 2: DISCOVER CLUSTERING SOLUTION IN

AN EXPERT VIEW

In this subsection, we test the performance of our MCVC
against competing methods in learning the clustering struc-
ture given constraints provided by multiple experts from
one view. We simulate noisy constraints provided by mul-
tiple expert based on one ground-truth view, Y1. We
consider two different settings for their accuracy parame-
ters: 1) experts have unequal accuracies α1:5 = β1:5 =
(0.95, 0.9, 0.85, 0.8, 0.75); 2) experts have equal and high
accuracies α1:5 = β1:5 = (0.95, 0.95, 0.95, 0.95, 0.95).

Our objective is to show that through learning different ac-
curacies of multiple uncertain experts, our MCVC can gen-
erate better clustering results compared to competing alter-
natives (SemiCrowd, ITML, MPCKMeans and CSPA).

We vary the total number of ML/CL constraints provided
by each expert from 200 to 2000 (as described in the previ-
ous subsection). For each ﬁxed number of constraints, we
randomly generate 10 constraint sets. For each constraint
set, we run all approaches and obtain their clustering solu-

(a) Synthetic: unequal

(b) Synthetic: equal

(c) WebKB: unequal

(d) WebKB: equal

(e) Face: unequal

(f) Face: equal

ITML,
Figure 4. Compare our MCVC against SemiCrowd,
MPCKMeans, CSPA in generating better clustering solutions on
(a,b) synthetic, (c,d) WebKB and (e,f) Face datasets: in the left
ﬁgures (a,c,e), the accuracy parameters are set to be unequal:
α1:5 = β1:5 = (0.95, 0.9, 0.85, 0.8, 0.75); in the right ﬁgures
(b,d,f), the accuracy parameters are set to be equal and have high
values: α1:5 = β1:5 = (0.95, 0.95, 0.95, 0.95, 0.95).

From the left ﬁgures, where the accuracy parameters are
set to be unequal, we have the following observations: I)
Our MCVC consistently outperforms all competing alter-
natives.
II) The performances of semi-supervised clus-
tering approaches, including ITML and MPCKMeans, do
not consistently improve as the number of constraints in-
creases. III) The performance of SemiCrowd increases as
the number of constraints increases. This means it can ef-

200400600800100012001400160018002000NumberofConstraints0.00.20.40.60.81.0NormalizedMutualInformationMCVCMetaClust200400600800100012001400160018002000NumberofConstraints0.00.20.40.60.81.0NormalizedMutualInformationMCVCMetaClust200400600800100012001400160018002000NumberofConstraints0.00.20.40.60.81.0NormalizedMutualInformationMCVCMetaClust200400600800100012001400160018002000NumberofConstraints0.00.20.40.60.81.0NormalizedMutualInformationMCVCSemiCrowdITMLMPCKMeansCSPA200400600800100012001400160018002000NumberofConstraints0.00.20.40.60.81.0NormalizedMutualInformationMCVCSemiCrowdITMLMPCKMeansCSPA200400600800100012001400160018002000NumberofConstraints0.00.20.40.60.81.0NormalizedMutualInformationMCVCSemiCrowdITMLMPCKMeansCSPA200400600800100012001400160018002000NumberofConstraints0.00.20.40.60.81.0NormalizedMutualInformationMCVCSemiCrowdITMLMPCKMeansCSPA200400600800100012001400160018002000NumberofConstraints0.00.20.40.60.81.0NormalizedMutualInformationMCVCSemiCrowdITMLMPCKMeansCSPA200400600800100012001400160018002000NumberofConstraints0.00.20.40.60.81.0NormalizedMutualInformationMCVCSemiCrowdITMLMPCKMeansCSPAMultiple Clustering Views from Multiple Uncertain Experts

fectively reduce the noise in the constraints. However, it
does not work well when the number of constraints is too
small. IV) consensus clustering (CSPA) fails because the
number of constraints is too small to be used to construct
accurate sample similarity matrix.

From the right ﬁgures, where the accuracy parameters are
set to be equal and have high values, we have the follow-
ing observations: V) Our MCVC consistently outperforms
SemiCrowd, ITML and CSPA but does not consistently
outperform MPCKMeans.

By comparing the right against the left ﬁgures, we have
the following observations: VI) MPCKMeans works well
only when all the experts have high accuracies; it fails when
not all experts have high accuaracies (as shown on the left
ﬁgures). VII) Both ITML and SemiCrowd do not beneﬁt
much from higher percentage of correct constraints; VIII)
Our MCVC perfoms well in both settings.

Explanation: Our MCVC has good performance in the un-
equal accuracies case because it can learn the accuracy pa-
rameters of different experts and assign higher weights to
more accurate experts and lower weights to uncertain ex-
perts respectively. On the synthetic dataset, the posterior
distributions of accuracy parameters α1:5, β1:5 computed
from MCVC are shown in Figure 5.

MCVC, we vary K from 2 to 8 and run MCVC on the syn-
thetic dataset using two expert views constructed from the
procedures described in subsection 4.2.1. The number of
constraints is ﬁxed to be 2000 and the constraints genera-
tion process is repeated 10 times. First, for any value of K,
MCVC can correctly assign experts to two views and also
generate two clustering solutions. Second, to evaluate how
the clustering performances are affected by K, we com-
pute the NMI between the two output clustering solutions
and Y1, Y2 respectively.

≥

The errorbar plot is shown in Figure 6 (a). As we can
see, our MCVC is very robust to the setting of K as long
K ∗, where K ∗ is the maximal number of clus-
as K
ters among all clustering views and K ∗ = 3 for our syn-
thetic data. In problems where K ∗ is unknown, we can set
K to be some large value to increase the possibility that
K ∗. However, in practice, we also observe that more
K
constraints are needed to effectively train the model when
K becomes large because there will be a larger number of
parameters.

≥

(a)

(b)

Figure 5. On the synthetic dataset, the posterior distributions of
sensitivities α1:5 (a) and those of speciﬁcities β1:5 (b) when
experts have unequal accuracy parameters α1:5 = β1:5 =
(0.95, 0.9, 0.85, 0.8, 0.75).

αmβm

In our MCVC,

As we can see, the modes of their distributions are very
close to their true values.
the con-
straints from the m-th expert are assigned weight ωm =
(1−αm)(1−βm) when combining the constraints from M
log
experts (we put the derivation details in the supplementary
materials). Therefore, higher accuracies (αm, βm) natu-
rally lead to higher weights. Thus, our MCVC becomes
robust to noisy constraints in the unequal accuracies case.

4.2.3. SENSITIVITY ANALYSIS: TO THE NUMBER OF

CLUSTERS AND TO IRRELEVANT EXPERTS

(a)

(b)

(c)

Figure 6. (a) shows the NMI between output clustering solutions
and Y1, Y2 as K increases in the experiment studying the setting
of the number of clusters; (b) and (c) show the posterior distri-
butions of sensitivities α1:15 and speciﬁcities β1:15 in the exper-
iment studying the existence of irrelevant experts: green means
experts 1-5, blue means experts 6-10, red means experts 11-15.

Irrelevant Experts: We deﬁne irrelevant experts as those
who provide constraints based on a notion of similar-
ity that is not supported by any feature in the data. To
demonstrate how the existence of irrelevant experts af-
fect the performance of our MCVC, we simulate three ex-
pert views using the synthetic data: 1) the ﬁrst two views
are the same as those described in subsection 4.2.1; and
2) the third view consists of ﬁve irrelevant experts who
provide constraints based on a random clustering solu-
tion Y3 and have accuracy parameters α11:15 = β11:15 =
(0.95, 0.9, 0.85, 0.8, 0.75). We generate 2000 constraints
from each expert. First, the ﬁrst two expert views can still
be perfectly recovered by our MCVC. Second, the irrele-
vant experts (experts 11-15) are either assigned to the ﬁrst
two expert views or new expert views.

Number of Clusters: To investigate how the setting of
K, the number of clusters, affects the performance of our

We plot the posterior distributions of accuracy parameters
for all 15 experts in Figure 6 (b,c). As we can see, the

0.30.40.50.60.70.80.9012345678ProbabilityDensityFunctionq(α1)q(α2)q(α3)q(α4)q(α5)0.30.40.50.60.70.80.901234567ProbabilityDensityFunctionq(β1)q(β2)q(β3)q(β4)q(β5)2345678NumberofClusters(K)0.500.550.600.650.700.750.800.850.90NormalizedMutualInformationNMIwithY1NMIwithY20.00.10.20.30.40.50.60.70.80.901234567ProbabilityDensityFunction0.00.10.20.30.40.50.60.70.80.901234567ProbabilityDensityFunctionMultiple Clustering Views from Multiple Uncertain Experts

densities of irrelevant experts’ accuracy parameters (red
curves) concentrate around 0.5, which indicates the con-
straints from those experts are treated as random guesses
and assigned near zero weights by MCVC. In practice,
we can identify irrelevant experts by checking whether the
modes of their accuracy parameters’ posteriors are close to
0.5. Therefore, our MCVC is robust to irrelevant experts.

4.3. COPD Subtyping Experiment

Chronic Obstructive Pulmonary Disease (COPD) is a com-
plex lung disease characterized by increasing breathless-
ness. Although being called one disease, doctors believe
there exist different disease subtypes. The identiﬁcation
of different disease subtypes (clusters) can lead to tailored
medical care for each patient.

Dataset: We collected 39 features from 987 COPD pa-
including clinical measurements, demographics,
tients,
lung function and measures from CT chest imaging.

Experts’ Constraints: We also collected constraints pro-
vided by 29 experts, including clinicians and radiologists.
We need to utilize experts’ constraints to guide the cluster-
ing algorithm. However, the key challenge is that different
experts disagree on whether to put a pair of patients in the
same cluster. We suspect there exist different expert views
and experts in each view provide constraints based on a
shared way to cluster the data. The discovery of these ex-
pert views and their corresponding clustering solutions can
provide more options for further investigation.

Evaluation: Since ground truth is not known, we can no
longer use NMI to compare the performances of competing
approaches. However, there are some key genetic variables
that are known to be related to COPD, including copdScore
(Busch et al., 2017), HHIP (Pillai et al., 2009), MMP12
(Cho et al., 2014). A clustering solution is considered as
useful/relevant if patients in different clusters show signiﬁ-
cant differences on these genetic variables.

We randomly split the dataset into half training set and half
testing set. All approaches are learned using the training
set and the constraints from multiple experts. The learned
models can be used to cluster test samples and generate
clustering solutions. To evaluate each solution, we compute
its associated p-values on these genetic variables by apply-
ing Kruskal-Wallis test on copdScore (continuous) and χ2
test on HHIP and MMP12 (discrete). We use P < 0.05 to
identify signiﬁcant differences in these genetic variables.

Methods and Results: We ﬁrst apply our MCVC and
obtain 12 expert views. After removing irrelevant experts
and views containing only one expert, there are 5 expert
views left. Our physician collaborators identify 2 inter-
esting expert views by analyzing the cluster characteris-
tics of their associated clustering solutions, which are de-

noted as MCVC-A and MCVC-B respectively: 1) Solu-
tion MCVC-A contains emphysema-dominant and airway-
dominant clusters, where emphysema cluster means the de-
struction of lung tissue and airway cluster means the in-
crease of airway wall thickness. 2) Solution MCVC-B con-
tains clusters of different levels of disease severity.

For competing approaches, we ﬁrst run meta clustering and
all 29 experts were lumped into one view. Then we apply
SemiCrowd, ITML and MPCKMeans to combine the data
matrix and constraints from all experts.

Table 1. p-values on three key COPD-related genetic variables.

Solutions
MCVC-A
MCVC-B
SemiCrowd
ITML
MPCKMeans

copdScore HHIP
3.47e-2
3.49e-5
1.30e-1
4.67e-5
5.13e-4

3.29e-3
6.47e-3
2.80e-1
6.68e-3
1.46e-2

MMP12
4.41e-2
3.72e-3
1.47e-1
6.42e-2
2.66e-2

The p-values of solutions provided by our MCVC and com-
peting approaches are shown in Table 1. As we can see,
solutions provided by MCVC and MPCKMeans contain
different clusters that show signiﬁcant differences on all
three COPD-related genetic variables.
In contrast, both
ITML and SemiCrowd are not signiﬁcantly correlated with
all three genetic variables. There’s some overlap between
solution MPCKMeans and solution MCVC-B (with NMI
value 0.39). However, solution MCVC-A can only be dis-
covered by our approach. This way of clustering COPD
patients is consistent with some COPD investigators’ latest
discovery of COPD subtypes (Castaldi et al., 2014).

5. Conclusions

In this paper, we build a probabilistic model to discover
multiple ways to cluster the data given potentially diverse
inputs from multiple uncertain experts. This is achieved by
automatically assigning multiple experts to different views
and learning the clustering structure associated with each
expert view. The quality of clustering solution in each ex-
pert view are improved by assigning higher weights to ex-
perts of higher accuracies. Experimental results on syn-
thetic data, benchmark datasets and a real-world disease
subtyping problem demonstrate that our MCVC outper-
forms its competing alternatives, including meta clustering,
semi-supervised clustering, semi-crowdsourced clustering
and consensus clustering.

6. Acknowledgements

We would like to acknowledge support for this project
from the NIH grant NIH/NHLBI RO1HL089856,
RO1HL089857 and NSF/IIS-1546428.

Multiple Clustering Views from Multiple Uncertain Experts

References

Webkb dataset, 1998. URL http://www.cs.cmu.
edu/afs/cs/project/theo-20/www/data/.

Basu, Sugato, Davidson, Ian, and Wagstaff, Kiri. Con-
strained clustering: Advances in algorithms, theory, and
applications. CRC Press, 2008.

Bickel, Steffen and Scheffer, Tobias. Multi-view cluster-
ing. In IEEE International Conference on Data Mining,
volume 4, pp. 19–26, 2004.

Bilenko, Mikhail, Basu, Sugato, and Mooney, Raymond J.
Integrating constraints and metric learning in semi-
supervised clustering. In Proceedings of the Twenty-ﬁrst
International Conference on Machine Learning, pp. 11,
2004.

Blei, David M, Jordan, Michael I, et al. Variational infer-
ence for dirichlet process mixtures. Bayesian Analysis,
1:121–143, 2006.

Busch, Robert, Hobbs, Brian D, Zhou, Jin, Castaldi,
Peter J, McGeachie, Michael J, Hardin, Megan E,
Hawrylkiewicz, Iwona, Sliwinski, Pawel, Yim, Jae-Joon,
Kim, Woo Jin, et al. Genetic association and risk scores
in a copd meta-analysis of 16,707 subjects. Ameri-
can Journal of Respiratory Cell and Molecular Biology,
2017.

Caruana, Rich, Elhawary, Mohamed, Nguyen, Nam, and
Smith, Casey. Meta clustering. In IEEE International
Conference on Data Mining, pp. 107–118, 2006.

Castaldi, Peter J, Dy, Jennifer, Ross, James, Chang, Yale,
Washko, George R, Curran-Everett, Douglas, Williams,
Andre, Lynch, David A, Make, Barry J, Crapo, James D,
et al. Cluster analysis in the copdgene study identiﬁes
subtypes of smokers with distinct patterns of airway dis-
ease and emphysema. Thorax, 2014.

Cho, Michael H, McDonald, Merry-Lynn N, Zhou, Xiaobo,
Mattheisen, Manuel, Castaldi, Peter J, Hersh, Craig P,
DeMeo, Dawn L, Sylvia, Jody S, Ziniti, John, Laird,
Nan M, et al. Risk loci for chronic obstructive pul-
monary disease: a genome-wide association study and
meta-analysis. The Lancet Respiratory Medicine, 2(3):
214–225, 2014.

Cui, Ying, Fern, Xiaoli Z, and Dy, Jennifer G. Non-
redundant multi-view clustering via orthogonalization.
In IEEE International Conference on Data Mining, pp.
133–142, 2007.

Ferguson, Thomas S. A bayesian analysis of some non-
parametric problems. The Annals of Statistics, pp. 209–
230, 1973.

Fern, Xiaoli Zhang and Brodley, Carla E. Solving cluster
In
ensemble problems by bipartite graph partitioning.
Proceedings of the Twenty-ﬁrst International Conference
on Machine learning, pp. 36, 2004.

Ghosh, Joydeep and Acharya, Ayan. Cluster ensem-
bles. Wiley Interdisciplinary Reviews: Data Mining and
Knowledge Discovery, 1(4):305–315, 2011.

Gomes, Ryan G, Krause, Andreas, and Perona, Pietro. Dis-
criminative clustering by regularized information maxi-
mization. In Advances in Neural Information Processing
Systems, pp. 775–783, 2010.

Howe, Jeff. Crowdsourcing: How the power of the crowd
is driving the future of business. Random House, 2008.

Jain, Anil K, Murty, M Narasimha, and Flynn, Patrick J.
Data clustering: a review. ACM Computing Surveys, 31
(3):264–323, 1999.

Jain, Prateek, Meka, Raghu, and Dhillon, Inderjit S. Si-
multaneous unsupervised learning of disparate cluster-
ings. Statistical Analysis and Data Mining, 1(3):195–
210, 2008.

Kajino, Hiroshi, Tsuboi, Yuta, and Kashima, Hisashi. Clus-
tering crowds. In AAAI Conference on Artiﬁcial Intelli-
gence, 2013.

Kruskal, William H and Wallis, W Allen. Use of ranks in
one-criterion variance analysis. Journal of the American
Statistical Association, 47(260):583–621, 1952.

Lichman, M. UCI machine learning repository, 2013. URL

http://archive.ics.uci.edu/ml.

Maclaurin, D, Duvenaud, D, Johnson, M, and Adams,
RP. Autograd: Reverse-mode differentiation of native
python. http://github. com/HIPS/autograd, 2015.

Moreno, Pablo G, Art´es-Rodr´ıguez, Antonio, Teh,
Yee Whye, and Perez-Cruz, Fernando. Bayesian non-
parametric crowdsourcing. Journal of Machine Learning
Research, 16:1607–1627, 2015.

Murphy, Sherry L, Xu, Jiaquan, and Kochanek, Kenneth D.
Deaths: ﬁnal data for 2010. National vital statistics re-
ports: from the Centers for Disease Control and Pre-
vention, National Center for Health Statistics, National
Vital Statistics System, 61(4):1–117, 2013.

Davis, Jason V, Kulis, Brian, Jain, Prateek, Sra, Suvrit, and
Dhillon, Inderjit S. Information-theoretic metric learn-
ing. In Proceedings of the Twenty-Fourth International
Conference on Machine Learning, pp. 209–216, 2007.

Ng, Andrew Y, Jordan, Michael I, Weiss, Yair, et al. On
spectral clustering: Analysis and an algorithm. In Ad-
vances in Neural Information Processing Systems, vol-
ume 14, pp. 849–856, 2001.

Multiple Clustering Views from Multiple Uncertain Experts

Zhang, Junjun, Baran, Joachim, Cros, Anthony, Guber-
man, Jonathan M, Haider, Syed, Hsu, Jack, Liang, Yong,
Rivkin, Elena, Wang, Jianxin, Whitty, Brett, et al.
In-
ternational cancer genome consortium data portala one-
stop shop for cancer genomics data. Database, 2011,
2011.

Niu, Donglin, Dy, Jennifer G, and Jordan, Michael I. Multi-
ple non-redundant spectral clustering views. In Proceed-
ings of the Twenty-seventh International Conference on
Machine Learning, pp. 831–838, 2010.

Niu, Donglin, Dy, Jennifer G, and Ghahramani, Zoubin.
A nonparametric bayesian model for multiple clustering
In Proceedings of the
with overlapping feature views.
Fifteenth International Conference on Artiﬁcial Intelli-
gence and Statistics, pp. 814–822, 2012.

Pillai, Sreekumar G, Ge, Dongliang, Zhu, Guohua, Kong,
Xiangyang, Shianna, Kevin V, Need, Anna C, Feng,
Sheng, Hersh, Craig P, Bakke, Per, Gulsvik, Amund,
et al. A genome-wide association study in chronic ob-
structive pulmonary disease (copd): identiﬁcation of two
major susceptibility loci. PLoS Genetics, 5(3), 2009.

Rand, William M. Objective criteria for the evaluation of
clustering methods. Journal of the American Statistical
Association, 66(336):846–850, 1971.

Schmidt, Mark, Berg, Ewout, Friedlander, Michael, and
Murphy, Kevin. Optimizing costly functions with simple
constraints: A limited-memory projected quasi-newton
algorithm. In Proceedings of the Twelfth International
Conference on Artiﬁcial Intelligence and Statistics, pp.
456–463, 2009.

Strehl, Alexander and Ghosh,

Cluster
ensembles—a knowledge reuse framework for combin-
ing multiple partitions. Journal of Machine Learning
Research, 3(12):583–617, 2002.

Joydeep.

Tian, Yuandong and Zhu, Jun. Learning from crowds in
the presence of schools of thought. In Proceedings of the
Eighteenth ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 226–234,
2012.

Topchy, Alexander, Jain, Anil K, and Punch, William.
Clustering ensembles: Models of consensus and weak
partitions. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 27(12):1866–1881, 2005.

Von Luxburg, Ulrike. A tutorial on spectral clustering.

Statistics and Computing, 17(4):395–416, 2007.

Wagstaff, Kiri and Cardie, Claire. Clustering with instance-
level constraints. AAAI Conference on Artiﬁcial Intelli-
gence, 1097, 2000.

Yi, Jinfeng, Jin, Rong, Jain, Shaili, Yang, Tianbao, and
Jain, Anil K. Semi-crowdsourced clustering: General-
izing crowd labeling by robust distance metric learning.
In Advances in Neural Information Processing Systems,
pp. 1772–1780, 2012.

