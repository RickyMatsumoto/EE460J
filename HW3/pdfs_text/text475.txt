Stochastic Bouncy Particle Sampler

Supplementary Material

A. Proof Sketch of Invariance under Noisy Gradients

In this section we start with a simple reformulation of the proof in (Bouchard-Cˆot´e et al., 2015) that the BPS Markov
process leaves invariant the distribution p(w, v) = p(w)p(v) where

p(w) ∝ e−U (w) ,
p(v) = Unif[SD−1] ,

w ∈ RD ,

(A.1)

(A.2)

where SD−1 is the D-dimensional one-sphere. This will set the stage for the noisy case considered next. For a more formal
and detailed treatment of the BPS algorithm, including ergodicity, see (Bouchard-Cˆot´e et al., 2015). For simplicity, we do
not include here the velocity refreshments, which do not change the proof.

The proof sketches below are presented using a discrete-time approach followed by letting ∆t → 0. We have found this
approach more accessible for a machine learning audience. After submitting a preliminary version of this work to the
arXiv, the preprint (Fearnhead et al., 2016) was submitted to the arXiv, which presents similar proofs of invariance by ﬁrst
deriving a general Fokker-Planck equation and then showing that the equation is satisﬁed both in noiseless and noisy cases.

A.1. Exact Gradient

To understand why the algorithm is correct, consider ﬁrst the transition rule

(w, v)t+∆t =

(cid:26) (w + v∆t, v) with probability 1 − ∆t[G]+
(w + v∆t, vr) with probability ∆t[G]+

where

and

[x]+ = max(x, 0) ,
G = v · ∇U (w) ,

vr = v − 2

(v · ∇U (w))∇U (w)
||∇U (w)||2

.

This rule acts on the probability density p(w, v) as,

pt+∆t(w, v) = [pt+∆t(w, v)]d + [pt+∆t(w, v)]r .

The two terms in (A.7) correspond to the two ways to reach (w, v) at time t + ∆t. First, we can start at (w − v∆t, v) at
time t and move a distance v∆t without bouncing. This occurs with probability 1 − ∆t[v · ∇U ]+, so we have

[pt+∆t(w, v)]d = (1 − ∆t[v · ∇U ]+)pt(v)pt(w − v∆t) ,

= (1 − ∆t[v · ∇U ]+)pt(v)(pt(w) − ∆tv · ∇pt(w) + O(∆t2)) ,
= pt(v)pt(w) [1 + ∆tv · ∇U − ∆t[v · ∇U ]+] + O(∆t2) ,

where in (A.9) we did a Taylor expansion and in (A.10) we used (A.1).

The second term in (A.7) corresponds to being at (w − vr∆t, vr) at time t, moving vr∆t and bouncing. This occurs with
probability ∆t[vr · ∇U ]+ = ∆t[−v · ∇U ]+, so we have

[pt+∆t(w, v)]r = ∆t[−v · ∇U ]+pt(w − vr∆t, vr) ,

= ∆t[−v · ∇U ]+pt(w, vr) + O(∆t2) ,

(A.3)

(A.4)

(A.5)

(A.6)

(A.7)

(A.8)

(A.9)

(A.10)

(A.11)

(A.12)

where again we did a Taylor expansion in (A.11). Adding (A.10) and (A.12), and using

equation (A.7) becomes

[v · ∇U ]+ − [−v · ∇U ]+ = v · ∇U ,

pt+∆t(w, v) = pt(w, v) + O(∆t2) ,

which implies that the distribution is stationary, dpt(w,v)

= 0.

dt

A.2. Noisy Gradient

Consider now a noisy gradient represented as

∇ ˜U (w) = ∇U (w) + nw ,

nw ∼ p(nw|w) ,

nw ∈ RD ,

(A.15)

where we assume that p(nw|w) has zero mean.
First note that the requirement that nw and n(cid:48)
w are conditionally independent given w and w(cid:48), with w (cid:54)= w(cid:48), is needed to
preserve under the noise the Markov property of the sampler, which requires the bounce point process intensity to depend
only on w, and not the past history of the w trajectory.

Next we decompose the random vector nw into two orthogonal components,

nw = yv + nv ,

with y = v · nw, and nv · v = 0. This induces a corresponding decomposition in the probability density as

dnwp(nw|w) = dydnvp(y|w)p(nv|y, w, v) ,

and note that from the assumption that p(nw|w) has zero mean it follows that p(y|w) has zero mean. The noisy projected
gradient becomes

v · ∇U (w) + y ,

y ∼ p(y|w) .

To study the invariance of p(w, v) under the noisy BPS, let us consider again the decomposition (A.7) into straight and
bounced inﬁnitesimal trajectories. The probability that the particle is at (w − v∆t, v) at time t and moves a distance v∆t
without bouncing is the average of 1 − ∆t[v · ∇U (w) + y]+ over all the possible realizations of y, and is therefore given
by

1 − ∆tPv ≡ 1 − ∆t

[v · ∇U (w) + y]+p(y|w)dy ,

= 1 − ∆t

(v · ∇U (w) + y)p(y|w)dy ,

(cid:90) +∞

−∞
(cid:90) +∞

−v·∇U (w)

where the above expression deﬁnes Pv. The ﬁrst term of (A.7) is therefore

[pt+∆t(w, v)]d = (1 − ∆tPv)p(w − v∆t, v) ,

= pt(w, v) − ∆tv · ∇pt(w)pt(v) − ∆tPvpt(w)pt(v) + O(∆t2) ,
= pt(w)pt(v)[1 + ∆tv · ∇U (w) − ∆tPv] + O(∆t2) ,

similarly to (A.8)-(A.10).

The second term in (A.7) now has contributions from all those values (w − ˜vr∆t, ˜vr) at time t, such that a reﬂection of
˜vr with respect to a noisy ∇ ˜U (w) gives v. Such a ˜vr exists for every value of the noise vector nw, and is given by

˜vr = v − 2

(v · ∇ ˜U (w))∇ ˜U (w)
||∇ ˜U (w)||2

,

(A.13)

(A.14)

(A.16)

(A.17)

(A.18)

(A.19)

(A.20)

(A.21)

(A.22)

(A.23)

Therefore the second term in (A.7) contains contributions from all the possible realizations of nw and is

[pt+∆t(w, v)]r = ∆t

dnw[˜vr · ∇ ˜U (w)]+p(nw|w)pt(w − ˜vr∆t, ˜vr) ,

(A.24)

= ∆tpt(w, ˜vr)

dy p(y|w)[−v · ∇U (w) − y]+ , ×

dnvp(nv|y, w, v) + O(∆t2) ,

(cid:90)

(cid:90)

RD

(cid:90) +∞

−∞

(A.25)
where we used ˜vr · ∇ ˜U (w) = −v · ∇U (w) − y, the measure decomposition (A.17), (cid:82)dnvp(nv|y, w, v) = 1 and deﬁned

= ∆tPvr pt(w, ˜vr) + O(∆t2) ,

(cid:90) −v·∇U (w)

Pvr =

−∞

dy (−v · ∇U (w) − y)p(y|w) .

Adding now (A.22) and (A.25), using p(˜vr) = p(v) (since p(v) is uniform) and

which follows from (A.20) and (A.26), and the fact that p(y|w) has zero mean, we get again the stationarity condition

Pv − Pvr = v · ∇U (w) ,

pt+∆t(w, v) = pt(w, v) + O(∆t2) .

B. Biased Approximation

B.1. Biased bouncing rate

In the noiseless case, the velocity bounce is an event in a Poisson process with intensity λ(w) = [v · ∇U (w)]+ while in
the noisy case, the average Poisson intensity is λn(w) = Ey[λn(w, y)] where

When a thinning upper bound for [v·∇U +y]+ is unknown and the distribution of y is Gaussian with predicted variance ρ2,
our algorithm makes a bounce proposal from a Poisson process with intensity

λn(w, y) = [v · ∇U (w) + y]+ .

λρ(w) = ˆG + kρ(w) ,

where ˆG is our estimate of v · ∇U (w). At the proposed bounce point w, we evaluate λn(w, y), and accept with probability
min(λn(w, y)/λρ(w), 1). The evaluation of λn(w, y) also provides an estimate σ2(w) of the variance of y. Assuming y
is Gaussian, the probability of the bound violation event 1 < λn/λρ, is

where Φ is the standard normal CDF. For a given y, the intensity is therefore,

q(w) = 1 − Φ((λρ(w) − v · ∇U (w))/σ(w)) ,

λb(w, y) = I[ λn

<1]λn(w, y) + I[ λn

>1]λρ(w)

λρ

λρ

where I[·] is the indicator function. Averaging over y we get

λb(w) = Ey[λb(w, y)]

= (1 − q(w))Eλn≤λρ [λn(w, y)] + q(w)λρ(w)

If the probability of bound violation has a universal upper bound q(w) < q, ∀w, we assume

|λb(w) − λn(w)| ≤ Kq = Cq + O(q2)

where C is a constant.

B.2. Preliminaries

We are interested bounding the distance between the equilibrium distribution of the biased, noisy BPS process with mean
intensity λb(w), and the exact, noisy process with mean intensity λn(w). We start with some preliminary results.

(A.26)

(A.27)

(A.28)

(B.29)

(B.30)

(B.31)

(B.32)

(B.33)

(B.34)

(B.35)

Wasserstein Distance and Kantorovich Duality

We will consider the Wasserstein distance, deﬁned as

dW (p1, p2) = sup
f ∈CL

|Ep1[f ] − Ep2[f ]| ,

where CL is the set of 1-Lipshitz continuous functions,

CL = {f : Rd → R : |f (y) − f (x)| ≤ |y − x|} .

Given random variables z1 ∼ p1, z2 ∼ p2, a coupling is a joint distribution (z1, z2) ∼ p12 with marginals p1 and p2. The
Kantorovich duality (Villani, 2008) asserts that

dW (p1, p2) = inf
p12

Ep12 [|z1 − z2|] .

To simplify the notation, let us deﬁne z = (w, v), zr = (w, ˜vr). The inﬁnitesimal generator of a stochastic process is
deﬁned as

Generators

and note that it satisﬁes

Lf (z) = lim
δt→0

E[f (zt+δt)|zt = z] − f (z)
δt

,

E[Lf ] = lim
δt→0

= lim
δt→0

= 0,

(cid:82) dzt+δtdzp(zt+δt|z)p(z)f (zt+δt) − E[f (z)]
δt

,

(cid:82) dzt+δtp(zt+δt)f (zt+δt) − E[f (z)]
δt

,

where the expectation is with respect to the distribution p(z) invariant under the stochastic process, and we used
(cid:82) dzp(zt+δt|z)p(z) = p(zt+δt). In our case, the generator of a BPS process with intensity λn(w, y) is (Davis, 1984;
Fearnhead et al., 2016)

Lλn f (z) = v · ∇wf (z) + Ey[λn(w, y)(f (zr) − f (z))]

(B.43)

where the expectation is with respect to the distribution of the stochastic process with intensity λ at time t and with a given
initial condition. This expression satisﬁes the backward Kolmogorov equation

and similarly for λb(w).

Let us deﬁne

and also (Jacod & Shiryaev, 1987)

fλ(z, t) = Eλ[f (zt)|z0 = z] ,

∂fλ(z, t)
∂t

= Lλfλ(z, t) ,

lim
t→∞

fλ(z, t) = Eλ[f ] ,

where the expectation Eλ[·] is with respect to the distribution invariant under the stochastic process with intensity λ.

(B.36)

(B.37)

(B.38)

(B.39)

(B.40)

(B.41)

(B.42)

(B.44)

(B.45)

(B.46)

Ergodicity

We assume that the random process deﬁned by SBPS is polynomial ergodic (although see the recent (Deligiannidis et al.,
2017)). In particular, we assume that two distributions started at reﬂected velocities pλn,t,z = pλn (zt|z0 = z), pλn,t,zr =
pλn (zt|z0 = zr) converge as

dW (pλn,t,z, pλn,t,zr ) ≤

CA
(α + t)β

where α, β, CA are constants.1

Poisson Equation

Given a function f (z), we will consider below the Poisson equation

We assume the existence of the solution

Lλuf (z) = f (z) − Eλ[f ] .

uf (z) =

ds(Eλ[f ] − fλ(z, s)) ,

(cid:90) ∞

0

where fλ(z, s) was deﬁned in (B.44). The fact that this expression solves (B.48) can be easily veriﬁed using (B.45), (B.46)
and fλ(z, 0) = f (z). For f ∈ CL (see (B.37) ), this solution satisﬁes

|uf (z) − uf (zr)| =

ds(fλ(z, s) − fλ(zr, s))

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:90) ∞

(cid:12)
(cid:12)
(cid:12)
(cid:12)
0
(cid:90) ∞

0
(cid:90) ∞

0

≤

≤

≤

dsEλ[zs − zr,s|] ,

using the Lipshitz property

ds dW (pλ,s,z, pλ,s,zr ) ,

using (B.38)

CA
(β + 1)αβ+1 ,

using the ergodicity assumption (B.47) .

B.3. Distance Bound from Stein’s Method

We now prove a bound on the distance between the exact and biased distributions, using Stein’s method (Barbour, 1990;
Ross, 2011; Stein et al., 1972), which was recently used for the related Zig-Zag process (Huggins & Zou, 2017).

dW (pλn, pλb ) = sup
f ∈CL
= sup
f ∈CL
= sup
f ∈CL
≤ sup
f ∈CL

|Eλn [f ] − Eλb [f ]| ,

|Eλn [Lλb uf ]| ,

using (B.48)

|Eλn [Lλb uf ] − Eλn [Lλn uf ]| ,

using (B.42)

Eλn [|(Lλb − Lλn)uf |] .

Note that this last expression involves an integral over just one distribution, unlike the ﬁrst expression (B.54). Inside the
expectation we have, using (B.43),

(Lλn − Lλb )uf (z) ≤ |λn(w) − λb(w)|Ey[|uf (zr) − uf (z)|] ,

(B.58)

1This assumed property follows usually from the existence of small sets (Lemma 3 in (Bouchard-Cˆot´e et al., 2015)) along with an

appropriate Lyapunov function (Roberts et al., 2004).

(B.47)

(B.48)

(B.49)

(B.50)

(B.51)

(B.52)

(B.53)

(B.54)

(B.55)

(B.56)

(B.57)

where the expectation over y is because zr = (w, vr) depends on the noise y (see (A.23)). Using (B.35) and (B.53), we
get ﬁnally

dW (pλn, pλb ) ≤

KqCA
(β + 1)αβ+1 .

(B.59)

Interestingly, this bound depends on the mixing speed of the process generated by Lλn (see (B.47)), even though the
distance is between two equilibrium distributions.

C. SBPS algorithm

Algorithm 1 provides a description of the SBPS algorithm with a linear regression based thinning proposal intensity. We
have omitted velocity refreshments for the sake of clarity. ∆t in the code below is the resolution of the piecewise linear
proposal intensity, which should be smaller than the typical time between bounces. In all experiments a value of ∆t = .01
was used.

Algorithm 1 Stochastic Bouncy Particle Sampler

SBPS:
Initialize particle position w ∈ RD, velocity v ∈ SD−1, t ← 0, regression coefﬁcients ˆβ0, ˆβ1, ρ(t)
while desired do

t, λ(t) = Sample Proposal Time( ˆβ0, ˆβ1, ρ(t))
w ← w + v ∗ t
Store w, t
Observe ∇ ˜U (w), Var [v · ∇ log p(xri|w)]
(optional: Update preconditioner and apply it to gradient - see ??)
Calculate ˜G(t), c(t)
v = Accept/Reject Proposal( ˜G(t), λ(t), v)
ˆβ0, ˆβ1, ρ(t) = Update Local Regression Coefﬁcients( ˜G(t), c(t), t)

end while
Return piecewise linear trajectory of w

Sample Proposal Time( ˆβ0, ˆβ1, ρ(t)):
tnext proposal ← 0
Initialize set of interpolation points p = {[ ˆβ1tnext proposal + ˆβ0 + kρ(tnext proposal)]+}
Initialize piecewise linear proposal intensity λ(t) = Inter(p)*
Sample u ∼ Unif[0, 1]
while −log(u) > (cid:82) tnext proposal

0

λ(t)dt do
tnext proposal ← tnext proposal + min(∆t, −log(u) − (cid:82) tnext proposal
p ← p ∪ [ ˆβ1tnext proposal + ˆβ0 + kρ(tnext proposal)]+
λ = Inter(p)

0

λ(t)dt)

end while
Return tnext proposal, λ(tnext proposal)
* Inter(p) is a linear interpolation of the points in p and their respective times since the last proposal
Accept/Reject Proposal( ˜G(t), λ(t), v):
Draw u ∼ Unif[0, 1]
if u > ˜G(w)/λ(t) then

Proposed bounce time accepted:
Initialize { ˜G(ti), c(ti)} and regression coefﬁcients ˆβ0, ˆβ1, ρ(t) using ˜G(t), c(t)
Return v − 2 (v·∇ ˜U (w))∇ ˜U (w)

||∇ ˜U (w)||2

else

end if

Proposed bounce time rejected, maintain current trajectory:
Return v

Update Local Regression Coefﬁcients( ˜G(t), c(t), t):
Add ˜G(t), c(t) to { ˜G(ti), c(ti)}
(optional: Perform hyperparameter learning step on regression priors)
Update regression coefﬁcients ˆβ0, ˆβ1, ρ(t(cid:48)) using standard Bayesian regression formula
(optional: If ˆβ1 < 0 set ˆβ1 to non-negative value, update ˆβ0 accordingly)
Return ˆβ0, ˆβ1, ρ(t)

Figure 1: Sample traces of SBPS, SGLD and mSGNHT sampling a highly non-Gaussian posterior. SBPS appears to explore the
posterior more fully and avoids regions of low density as opposed to the large step size SGLD, leading to less bias.

D. A Highly non-Gaussian Example

We explored a case of sampling from a Bayesian posterior where the Laplace approximations is not accurate. Figure 1
shows results for a highly non-log-concave 2D hyperboloid posterior, with data generated according to yi ∼ N (w∗
1, σ).
After introducing a weak Gaussian prior, the resulting log posterior takes the form

0w∗

L(w0, w1|{yi}, σ) =

N
(cid:88)

i=1

−

(yi − w0w1)2
2σ2

−

||w||2
2 .

c
2

(D.60)

This posterior was approximated by observing mini-batches of data as in the previous examples. The scaling symmetry
that is manifest in the invariance of the likelihood with respect to w0, w1 → λw0, w1
λ leads to the highly non-Gaussian
hyperboloid form. Similar symmetries are encountered in posteriors of deep neural networks with ReLU activation (Dinh
et al., 2017). The parameters used were N = 1000, n = 100, k = 3, c = .0001, w∗
1 = 0, σ = 1. σ was not learned.

0 = w∗

Figure 1 shows comparisons with SGLD and mSGNHT, while Local BPS and SS-ZZ cannot be applied since there seems
to be no simple exact upper bound for thinning in this case. Note that for the step sizes shown, both SGLD and mSGNHT
deviate into low density regions while not mixing as well as SBPS. The smaller SGLD step size used does not deviate as
much but exhibits even slower mixing.

E. Sampling from Multimodal Targets

Our simple linear model for G(t) (the projected gradient of the log posterior), appears to be sufﬁciently accurate even when
the Laplace approximation is violated (as shown in the previous examples), but in some highly multimodal cases we have
found this approximation to be insufﬁcient.

In this section we present a slight modiﬁcation of SBPS to sample from such targets as well. The potential troubles arise
because in a multimodal target one may encounter situations where the measured G(t) drop quickly between successive ob-
servations, leading to strong negative regression slopes. In our regression model, we get an interpolation (cf. equation (13))
leading to an upper bound of the form

ˆβ1t + ˆβ0 + kρ(t)

(E.61)

with ˆβ1 < 0. Since the leading order t dependence in ρ(t) is linear, if k is too small the linear term in (E.61) may be
negative. This will lead the sampler to propose long times between samples and thus enter low target density regions of the
space.

−3−2−10123−3−2−10123-2.00e+03-2.00e+03-2.00e+03-2.00e+03-1.50e+03-1.50e+03-1.50e+03-1.50e+03-1.00e+03-1.00e+03-1.00e+03-1.00e+03100 iterations−3−2−10123−3−2−10123-2.00e+03-2.00e+03-2.00e+03-2.00e+03-1.50e+03-1.50e+03-1.50e+03-1.50e+03-1.00e+03-1.00e+03-1.00e+03-1.00e+031000 iterations−3−2−10123−3−2−10123-2.00e+03-2.00e+03-2.00e+03-2.00e+03-1.50e+03-1.50e+03-1.50e+03-1.50e+03-1.00e+03-1.00e+03-1.00e+03-1.00e+0310000 iterationsSBPSSGLD 0.1SGLD 1mSGNHT 0.2Figure 2: SBPS sampling from a highly multimodal target. As can be seen from the sample histogram on the right, SBPS manages to
accurately capture the multimodal target. The results are from 1000 epochs of sampling from a dataset of size N = 1000

In such cases, we propose to make additional auxiliary observations at times {taux} along the current linear trajectory
of the particle and update the linear bound accordingly before making the next proposal. On a large enough scale this
procedure will make auxiliary observations ˜G > 0 leading to a positive slope in (E.61). This in turn will prevent the
particle from entering low target density regions.

Note that these auxiliary observations can be performed with the same minibatch of data from the last bounce proposal. In
principle, such strong negative slopes can occur even for a unimodal target if the subsampling noise is highly non-Gaussian,
and this mechanism can also be used in those situations.

We illustrate this mechanism in a simple distribution deﬁned as

where w ∈ RD and

L(w) =

Li(wk) + const.

N
(cid:88)

D
(cid:88)

i=1

k=1

Li(wk) = log

(cid:34)

−

e

(wk −1−µi
2σ2
L

k )2

+ e

−

(wk +1−µi
D+k )2
2σ2
L

(cid:35)

(E.62)

(E.63)

and each µi
k is drawn from N (0, σµ). This is a highly multimodal toy distribution. Although it does not come from
a posterior distribution, it allows us to illustrate the proposed mechanism in a clean setting. Figure 2 shows results for
D = 2, N = 1000, σL = .25, σµ = .01 and mini-batch size n = 10. We used {taux} = {10pt, p ∈ N} where t is the
mean proposal time of all past proposals during the sampling process. While one can add multiple auxiliary points in this
way, in practice we have found that one auxiliary point (p = 1) is sufﬁcient. Figure 2 shows that SBPS is able to correctly
sample from the target while avoiding the issues posed by the multimodality of the distribution. We note that this modiﬁed
mechanism does not affect the rest of the examples presented in this paper.

F. SGLD Step Size Scan

In the logistic regression example of Section 6.1, we compare SBPS with Stochastic Gradient Langevin Dynamics
(SGLD) (Welling & Teh, 2011) with ﬁxed step size. A natural question is how to choose an appropriate step size that
ensures the fastest possible mixing without introducing an unacceptable amount of bias. Our criterion was to pick the
biggest possible (i.e., fastest-mixing) step size such that the resulting variance of the per-data-point Negative Log Like-
lihood (NLL) coincides with that of the Laplace approximation. The latter gives a per-data-point NLL distribution of
1
2N χ2(d) + N LL ˆw/N where ˆw is the MAP estimator (Bickel & Doksum, 2015). The results of this parameter scan are
shown in Figure 3 and suggest a step size of 0.1.

−3−2−10123−3−2−10123Ground Truth−3−2−10123−3−2−10123SBPS samplesFigure 3: Per-data-point variance of the NLL in the logistic regression example of Section 7.1, using SGLD samples with step sizes of
10−i/2, i = 0...9. The samplers were initialized at the MAP. We select the biggest step size whose empirical variance is below that from
the Laplace approximation,

d
2N 2 .

G. The effect of the SBPS hyperparameters

In this section we explore, in the logistic regression example of Section 6.1, the effect of two hyperparameters that control
the behavior of SBPS: the mini-batch size n, and the width k of the upper conﬁdence band. A third hyperparameter is the
rate of velocity refreshments, shown in (Bouchard-Cˆot´e et al., 2015) to be necessary in general to prove ergodicity. But, as
mentioned in Section 3, in the examples we considered the mini-batch noise was enough to sufﬁciently randomize possible
non-mixing trajectories, so we could safely set this parameter to a very low value.

G.1. Mini-batch size n
Figure 4 shows an exploration of different values of the mini-batch size n. Low values for n lead to high noise for ˜G.
This in turn yields higher values for the proposal intensity γ(t), which leads to shorter linear trajectories between bounce
proposals. This is consistent with the results of Figure 4 that show a linear relation between n (i.e. computational cost
per bounce proposal) and the average travel time between bounces. The autocorrelation functions (ACFs) were computed
from discrete samples obtained by running SBPS with different n’s such that the total data cost was the same for all cases,
and then discretizing the continuous paths into equal numbers of uniformly spaced samples. As shown, these cost adjusted
ACFs are quite similar. On the other hand, the upper-left panel, shows that lower values of n have faster convergence
to equilibrium, suggesting that low n should be preferred. But this should be contrasted with the fact that shorter linear
trajectories increase the variance of expectations over rapidly changing functions, as discussed in Section 6.3.

G.2. Upper-band width k

Figure 5 shows an exploration of different values of k, the height of the proposal intensity above the estimator mean, in
units of predictive standard deviation (see in Eq.(12) in main text). It therefore controls the trade-off between a regime, at
low k, of faster mixing and high bias from violations of the thinning upper bound ([ ˜G(t)]+/λ(t) > 1), and another regime,
high k, of low bias and high variance from slower mixing. As expected, the probability of bound violation decreases
monotonically with k, as seen in the bottom left panel of Figure 5.

10-510-410-310-210-1100101102SGLD step size10-610-510-410-310-210-1NLL per data point varianceSGLD samples12Nχ2(d) varianceFigure 4: Effect of mini-batch sizes n in the logistic regression example of Section 6.1. Mini-batch sizes were 50, 100, 200, 500, 900.
Top Left: Average per-data-point NLL over 5 runs. Note that smaller n lead to faster convergence to a region of low NLL. Lower Left:
Estimated average time between particle bounces. Center/Right: ACF and trajectories from a single run, in the directions of smallest
and biggest covariance. The x axis was chosen differently for the trajectory plots for clarity.

Figure 5: Effect of upper band size k in the logistic regression example of Section 6.1, run with mini-batch size n = 100. Bottom Left:
Rate of upper bound violations as a function of k; the same colors are used in the other plots. Top Left: NLL per data point for samples of
SBPS with different k values. Center/Right: ACF and trajectories in the directions of smallest and biggest covariance. Note that smaller
k leads to faster convergence and mixing but increased bias, as visible in the coordinate trace in the direction of biggest covariance. The
x axis was chosen differently for the trajectory plots for clarity.

H. Upper Bounds for Logistic Regression

In the case of logistic regression with data (yi, xi) the estimator of ∇wU (w) from a mini-batch of size n is

∇w ˜U (w) =

xi(σ(w · xi) − yi) .

(H.64)

N
n

n
(cid:88)

i=1

104105106data p ints  bserved10-1100NLL per data p int (l g scale)NLL ̂w/NLaplace appr (̂104105106lag−0.20.00.20.40.60.81.0ACFdirection  f largest c variance103104105106lag−0.4−0.20.00.20.40.60.81.0directi n  f smallest c variance02004006008001000mini-batch size n−0.10.00.10.20.30.40.50.60.70.8average time between b unces01234data p ints  bserved1e6−22−20−18−16−14−12−10c  rdinate trace0.00.51.01.52.0data p ints  bserved1e5−0.4−0.20.00.20.40.6103104105106data points observed10-10.080.090.200.300.40NLL per data point (log scale)NLL ̂wLaplace approx.102103104105106lag−0.20.00.20.40.60.81.0ACFdirection of largest covariance102103104105106lag0.00.20.40.60.81.0direction of smallest covariance0123456confidence interval multiple k0.000.050.100.150.20bound violation probability012345data points observed1e551015202530coordinate trace012345data points observed1e4−0.6−0.4−0.20.00.20.40.60.81.0A simple bound on ˜G(t) is therefore given by

˜G(t) ≤

(v · xi)(σ(w · xi) − yi)| ,

||v||2||(σ(w · xi) − yi)xi||2 ,

n
(cid:88)

|

i=1
n
(cid:88)

i=1
n
(cid:88)

i=1

N
n

N
n

N
n
√

≤

≤

||xi||2 ,

≤

dN max

|xij| .

i,j

(H.65)

(H.66)

(H.67)

(H.68)

This is a particular case of a bound derived in (Bierkens et al., 2017). Compared to the bound proposed in (Bouchard-Cˆot´e
et al., 2015), this bound is more conservative but cheaper to compute and does not require non-negative covariates. It
similarly scales like N and when the data used in the experiments was modiﬁed so that the covariates were non-negative
the bounds differed by a factor lower than 2.

References

1990.

CRC Press, 2015.

Barbour, Andrew D. Stein’s method for diffusion approximations. Probability theory and related ﬁelds, 84(3):297–322,

Bickel, Peter J and Doksum, Kjell A. Mathematical Statistics: Basic Ideas and Selected Topics, volume I, volume 117.

Bierkens, Joris, Bouchard-Cˆot´e, Alexandre, Doucet, Arnaud, Duncan, Andrew B, Fearnhead, Paul, Roberts, Gareth, and
Vollmer, Sebastian J. Piecewise Deterministic Markov Processes for Scalable Monte Carlo on Restricted Domains.
arXiv preprint arXiv:1701.04244, 2017.

Bouchard-Cˆot´e, Alexandre, Vollmer, Sebastian J, and Doucet, Arnaud. The Bouncy Particle Sampler: A Non-Reversible

Rejection-Free Markov Chain Monte Carlo Method. arXiv:1510.02451, 2015.

Davis, Mark HA. Piecewise-deterministic Markov processes: A general class of non-diffusion stochastic models. J. Royal

Stat. Soc., Series B (Methodological), pp. 353–388, 1984.

Deligiannidis, George, Bouchard-Cˆot´e, Alexandre, and Doucet, Arnaud. Exponential Ergodicity of the Bouncy Particle

Sampler. arXiv preprint arXiv:1705.04579, 2017.

Dinh, Laurent, Pascanu, Razvan, Bengio, Samy, and Bengio, Yoshua. Sharp minima can generalize for deep nets. arXiv

preprint arXiv:1703.04933, 2017.

Fearnhead, Paul, Bierkens, Joris, Pollock, Murray, and Roberts, Gareth O. Piecewise Deterministic Markov Processes for

Continuous-Time Monte Carlo. arXiv preprint arXiv:1611.07873, 2016.

Huggins, Jonathan H and Zou, James. Quantifying the accuracy of approximate diffusions and Markov chains. In AISTATS,

2017.

Jacod, J. and Shiryaev, A.N. Limit Theorems for Stochastic Processes. Grundlehren der mathematischen Wissenschaften

in Einzeldarstellungen. Springer-Verlag, 1987. ISBN 9783540178828.

Roberts, Gareth O, Rosenthal, Jeffrey S, et al. General state space markov chains and mcmc algorithms. Probability

Surveys, 1:20–71, 2004.

Ross, Nathan. Fundamentals of Stein’s method. Probab. Surv, 8:210–293, 2011.

Stein, Charles et al. A bound for the error in the normal approximation to the distribution of a sum of dependent random
In Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability, Volume 2:

variables.
Probability Theory. The Regents of the University of California, 1972.

Villani, C´edric. Optimal transport: old and new, volume 338. Springer Science & Business Media, 2008.

Welling, Max and Teh, Yee W. Bayesian learning via stochastic gradient Langevin dynamics. In ICML, pp. 681–688, 2011.

