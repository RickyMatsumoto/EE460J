Ordinal Graphical Models: A Tale of Two Approaches

Arun Sai Suggala 1 Eunho Yang 2 3 Pradeep Ravikumar 1

Abstract
Undirected graphical models or Markov random
ﬁelds (MRFs) are widely used for modeling mul-
tivariate probability distributions. Much of the
work on MRFs has focused on continuous vari-
ables, and nominal variables (that is, unordered
categorical variables). However, data from many
real world applications involve ordered categor-
ical variables also known as ordinal variables,
e.g., movie ratings on Netﬂix which can be or-
dered from 1 to 5 stars. With respect to uni-
variate ordinal distributions, as we detail in the
paper, there are two main categories of distri-
butions; while there have been efforts to extend
these to multivariate ordinal distributions, the re-
sulting distributions are typically very complex,
with either a large number of parameters, or with
non-convex likelihoods. While there have been
some work on tractable approximations, these do
not come with strong statistical guarantees, and
moreover are relatively computationally expen-
sive. In this paper, we theoretically investigate
two classes of graphical models for ordinal data,
corresponding to the two main categories of uni-
variate ordinal distributions. In contrast to pre-
vious work, our theoretical developments allow
us to provide correspondingly two classes of esti-
mators that are not only computationally efﬁcient
but also have strong statistical guarantees.

1. Introduction

Undirected graphical models, also know as Markov ran-
dom ﬁelds (MRF), are very popular for modeling multi-
variate random variables. They use undirected graphs to
model the conditional independence structure among the

*Equal contribution 1Carnegie Mellon University, Pittsburgh,
USA 2School of Computing, KAIST, Daejeon, South Korea
3AITrics, Seoul, South Korea.
Correspondence to: Arun
Sai Suggala <asuggala@andrew.cmu.edu>, Eunho Yang <eun-
hoy@kaist.ac.kr>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

variables. This conditional independence structure pro-
vides us with useful insights about how different variables
interact with each other. As a result MRFs are extensively
used in a variety of ﬁelds, including Natural Language Pro-
cessing (Manning & Sch¨utze, 1999), Biology (Friedman,
2004) and Medicine (Allen & Liu, 2012).

Popular parametric families in the general class of MRFs
are Gaussian graphical models (Speed & Kiiveri, 1986;
Rue & Held, 2005) for continuous (and bell-shaped) data,
Ising and discrete graphical models (Ising, 1925; Jalali
et al., 2011) for nominal data, and mixed cases of these two
instances (Lauritzen & Wermuth, 1989; Yang et al., 2014).
However, variables that occur in many real world appli-
cations have ordered categorical scales. For example, in
medical data, diseases are graded from mild to fatal, sever-
ity of an injury is rated from mild injury to death, stages of
a disease is rated from I to III. Ordinal variables also occur
very commonly in data collected from surveys. For exam-
ple, each subject taking a survey could be asked to respond
to a question using categories such as strongly disagree,
disagree, undecided, agree, strongly agree. These exam-
ples clearly show that ordinal data is pervasive in many real
world applications.

It will be instructive at this juncture to review univariate
distributions for ordinal data, which fall into two main cat-
egories. The ﬁrst category of distributions consists of pa-
rameterizing various odds ratios involving the ordinal vari-
able, and include the cumulative ratio, continuation ratio,
and consecutive ratio logit models (Armstrong & Sloan,
1989; Agresti, 2010). In practice, cumulative ratio and con-
tinuation ratio models are know to work better than the con-
secutive ratio model (McCullagh, 1984), and as a conse-
quence, the consecutive ratio model is relatively less well
considered among these three models. Some generaliza-
tions of the above models have been considered in liter-
ature (e.g., Partial Proportional Odds model (Peterson &
Harrell Jr., 1990)), which fall in between the simpler class
of models listed earlier and the multinomial logistic regres-
sion model in terms of their parametric complexity, but are
nonetheless not as popular as the simpler class of models.
The second category of univariate ordinal distributions are
based on the natural generative assumption that the ordi-
nal variable is a quantization of a real-valued latent vari-
able. Common distributions imposed on the latent variable

Ordinal Graphical Models: A Tale of Two Approaches

include the logistic distribution, in which case it reduces
to the classical cumulative ratio model (Agresti, 2010), as
well as the more popular standard normal distribution, in
which case it is called the ordered probit model (Becker &
Kennedy, 1992).

There has been some effort to construct multivariate ordi-
nal distributions, and they again fall into two categories,
namely the multivariate extensions of the corresponding
In the
two categories of univariate ordinal distributions.
ﬁrst category, there has been a line of work (see Bar-
tolucci et al., 2007, and references therein) on designing
parametrized odds ratio based models. Bartolucci et al.
(2007) provide a general framework for designing multi-
variate ordinal models by parameterizing marginal distri-
butions using various odds ratios. However, the parametric
form of these models are complex, and have a large num-
ber of parameters, and so do not necessarily scale to high-
dimensional settings. Moreover, these models cannot be
readily expressed as graphical model distributions.

In the second category of multivariate ordinal distributions,
the ordinal random vector is modeled as a quantization of
a real-valued latent random vector. Here, the efforts have
focused on the use of the multivariate normal distribution
for the latent random vector, due plausibly to its more con-
venient mathematical nature; the resulting model is also
known as the multivariate probit model (Ashford & Sow-
den, 1970; Amemiya, 1974). But even with this modeling
assumption, the likelihood of the observed ordinal random
vector is not available in closed-form, is considerably com-
plex due to the presence a multi-dimensional integral, and
in particular is non-convex, so that learning the model given
just the ordinal observations is typically computationally
intractable. Consequently Expectation Maximization (EM)
and approximate EM based approaches (Chib & Green-
berg, 1998; Guo et al., 2015) have been proposed to com-
pute the Maximum Likelihood Estimate (MLE). A caveat
with these is that they do not come with statistical guar-
antees, and moreover, as our experiments show, are still
computationally expensive. Because of the computational
intractability of the MLE, alternative approaches have been
proposed which maximize the pairwise, composite likeli-
hood of the data, which involve only the univariate and bi-
variate marginals (Lindsay, 1988; De Leon, 2005; Han &
Pan, 2012). Another class of methods have been proposed
which estimate the model parameters in multiple stages
(Muth´en, 1984; J¨oreskog, 1994), unlike the previous ap-
proaches which estimate all the parameters using a single
estimating equation. Although these approaches are com-
putationally very efﬁcient they do not provide consistent
estimates in high dimensional settings.

tivariate ordinal distributions to model such data, particu-
larly in high-dimensional settings, with a large number of
ordinal variables.

In this paper, we develop multivariate ordinal graphical
model distributions, for which the estimators are compu-
tationally tractable. Following the development of classi-
cal univariate ordinal distributions, our investigations fall
into two categories.
In the ﬁrst category, we investigate
multivariate extensions of the log-odds parameterized uni-
variate ordinal distributions. Towards this, we leverage the
line of work in Yang et al. (2012), which provides a mech-
anism to extend a univariate distribution to a multivariate
graphical model distribution, by using the univariate dis-
tributions to specify node-conditional distributions. Their
theoretical treatment requires the univariate distributions to
belong to exponential families, while as we show, the log-
odds based univariate ordinal distributions, namely cumu-
lative and continuation ratio models (Agresti, 2010), do not
belong to exponential families. Could perhaps the frame-
work of Yang et al. (2012) be nonetheless be extended to
this case? We provide a deﬁnitive answer in the negative,
and show that using these univariate ordinal distributions as
node-conditional distributions cannot lead to a consistent
joint distribution. Whereas, the consecutive ratio model
(Agresti, 2010) does belong to the exponential family, and
can be extended to a multivariate graphical model distri-
bution. However, as we will demonstrate in our experi-
ments, this resulting novel class of consecutive ratio MRFs
has mixed empirical results.

In the second category, we investigate the multivariate ex-
tensions of latent variable quantization based univariate or-
dinal distributions. We focus on the case where the latent
random vector is multivariate Gaussian. Here, we leverage
the structure of the ordinal data, and provide a very sim-
ple multistage estimator along the lines of Muth´en (1984);
J¨oreskog (1994), that ﬁnesses computing the likelihood,
and accordingly is computationally tractable, but interest-
ingly, also comes with strong statistical guarantees. We
corroborate our ﬁndings on both simulated and real data.

2. Multivariate Odds Ratio based Models

In the ﬁrst part of the paper, we investigate the approach
of Yang et al. (2012) i.e., specifying node-conditional
distributions via classical univariate ordinal distributions,
and then exploring the corresponding joint distribution via
Hammersley-Clifford-esque analyses.

2.1. MRFs via Univariate Latent Quantized Ordinal

Models

Thus, in spite of the ubiquity of multivariate ordinal data,
there have been limited popular applications of these mul-

The most popular class of univariate ordinal distributions
rely on a generative model that quantizes a latent variable.

Ordinal Graphical Models: A Tale of Two Approaches



z] = g(z

Suppose we have a real-valued latent random variable Z
2
R with CDF denoted by P[Z
µ), where µ
is a location parameter of the distribution. Suppose that the
ordinal random variable Y
can be written
2{
as a discretized version of the real-valued variable Z, as
1,✓ j], for some location (or cut-
iff Z
Y = j,
,✓ M =
1, and with ✓
point) parameters
. It then follows that the probability mass function of the

(✓j
2
 
M
✓j}
j=
{

0, . . . , M

 1

1 =

 

}

 

 

1
ordinal variable Y can be written as
P[Y = j] = g(✓j  

µ)

 

g(✓j

1  

 

µ).

(1)

A popular distribution for the latent real-valued variable
Z is the univariate logistic distribution, where Z
⇠
) above is the logistic
logistic(µ, 1), so that the function g(
·
function, g(t) =  (t) = 1/(1 + exp(
t)). In this case, the
 
distribution above can also be expressed in a more compact
form in terms of log-odds ratios as: log
µ.
Accordingly, this class of ordinal distributions are also
called cumulative ratio models. We now consider the gen-
eral framework of Yang et al. (2012), of using univariate
ordinal distribution in (1) to specify node-conditional dis-
tributions, and deriving a consistent joint distribution.

= ✓j 

P(Y
j)

P(Y >j)

⇣

⌘

Let Y = (Y1, . . . , Yp) be a p-dimensional ordinal random
vector. To simplify the notation, in the sequel we assume
p
that the domains of all the random variables
s=1 are
{
. Let G = (V, E) be a
same and equal to
graph with nodes corresponding to each of the random vari-
ables

0, 1, . . . , M
{

V , we have

Ys}

}

Ys}
{
Y
P[Ys = j
|

p
s=1. Suppose that for each s
s] = g(✓s;j  

µs(Y

s))

 

\

\

2
g(✓s;j

µs(Y

1  

 

s)),
\
(2)

\

where the location parameter µs(Y
s) is an arbitrary func-
tion of the rest of the variables and g is the logistic func-
tion. We now present the following theorem which shows
that these node-conditional distributions do not lead to a
consistent joint distribution.
Theorem 1. Consider a p-dimensional random vector
p. And let
Y = (Y1, . . . , Yp) with domain
}
G = (V, E) be a graph with nodes corresponding to each
p
Ys}
of the random variables
s=1. Suppose that all node-
conditional distributions of this random vector follow the
univariate cumulative ratio model in (2), where for each
s
s) is an arbitrary
function of the rest of the variables.

V , the location parameter µs(Y

0, 1, . . . , M

2

{

{

\

V,j

 

Then, for M
1, there exist real valued parameters
✓s;j}s
[M ] for which the speciﬁed node-conditional
{
distributions are not consistent with any joint distribution
over Y that is Markov with respect to the graph G with
factors of size at most 2.

2

2

The proof of the above theorem can be found in Appendix
A and follows the Hammersley Clifford type analysis of
Besag (1974).

2.2. MRFs via Continuation Ratio Models

One modiﬁcation to the cumulative ratio model that has
been considered in the literature is that of a closely re-
P(Y =j)
lated log-odds ratio: log
µ. This class
P(Y >j)
of univariate ordinal distributions are also called continua-
tion ratio models. From the log-odds ratio above, denoting
µ, the Probability Mass Function (PMF) of the
⌘j := ✓j  
random variable Y can be derived as

= ✓j  

⇣

⌘

P[Y = j] :=

exp(⌘j)
1 + exp(⌘i)

,

j
i=0

(3)

for j = 0, . . . , M
is ﬁxed as: 1

 

Q

 

1. Then, the probability P(Y = M )
 
1
M
i=0 P (Y = i) =
, so
 

1

1
1+exp(⌘i)

M
 
i=0

 

that the summation of the PMF equals 1.

P

Q

 

 

As in the previous section, given this univariate ordinal dis-
tribution, we ask if we could employ the strategy of Yang
et al. (2012), of using these to specify node-conditional
distributions, and deriving a consistent joint distribution?
Speciﬁcally, suppose that for each node s

V we have

P[Ys = j

Y

s] =

|

\

2
exp(⌘s;j(Y
s))
1 + exp(⌘s;j(Y

\

j
i=0

,

(4)

s))

\

 
µs(Y

Q
s)) and the location pa-
s) = ✓s;j  
where ⌘s;j(Y
\
rameter µs(Y
s) is an arbitrary function of the rest of the
variables. The following theorem shows that these node
conditional distributions do not lead to a consistent joint
distribution. The proof of this theorem is provided in Ap-
pendix B.

 

\

\

{

0, 1, . . . , M

Theorem 2. Consider a p-dimensional random vector
p. And let
Y = (Y1, . . . , Yp) with domain
}
G = (V, E) be a graph with nodes corresponding to each
p
Ys}
of the random variables
s=1. Suppose that all node-
conditional distributions of this random vector follow the
univariate continuation ratio model in (4), where for each
s) is an arbitrary
s
function of the rest of the variables.

V , the location parameter µs(Y

2

{

\

 

[p],j

1, there exist real valued parameters
Then, for M
✓s;j}s
[M ] for which the speciﬁed node-conditional
{
distributions are not consistent with any joint distribution
over Y that is Markov with respect to the undirected graph
G.

2

2

2.3. MRFs via a Consecutive Ratio model

A key caveat with the univariate cumulative and contin-
uation ratio models is that they do not belong to expo-
nential families, and in particular do not possess the reg-
ularities that allow for existence of consistent joint given
node-conditionals belonging to these distributions. We
now consider the third class of univariate ordinal distribu-

Ordinal Graphical Models: A Tale of Two Approaches

tions called consecutive ratio model which is deﬁned as:
log

µ, for j = 0, . . . , M

1.

P(Y =j)
P(Y =j+1)

= ✓j  

 

⇣

⌘

2{

0, . . . , M

As we show below, this ordinal distribution belongs to an
exponential family, unlike ordinal distributions in earlier
sections.
Proposition 1. The consecutive ratio model for an ordi-
nal random variable Y
belongs to an ex-
}
1
M
ponential family with sufﬁcient statistics
j=0 :
 
}
1
j=0 ⌘j I
, where as be-
µ, for j
2{

P[Y ] = exp
fore, ⌘j := ✓j  
⇣ P
We now consider the counterpart of our key question in
the earlier sections. Suppose we use the univariate ordinal
distribution above to specify node-conditional distributions
for an ordinal random vector Y = (Y1, . . . Yp). Speciﬁ-
cally, suppose that for each node s

 
0, . . . , M

V , we have

{I
A(⌘)

1
.
⌘
}

[Y

[Y





 

j]

j]

M

 

2

M

1

 

P[Ys|

Y

\

s]

/

exp

⌘s;j(Y

s)

\

[Ys 

I

j]

(5)

\

 

⇣
µs(Y

j=0
X
s), for j = 0, . . . , M

⌘
1, where
where ⌘s;j = ✓s;j  
the location parameter µs(Y
s) is an arbitrary function of
\
the rest of the variables. Since these node-conditional dis-
tributions belong to a univariate exponential family, an ap-
plication of Proposition 1 of Yang et al. (2012) yields the
following theorem:
Theorem 3. The node-conditional distributions in (5)
are consistent with a joint distribution that is Markov
to an undirected graph G = (V, E),
with respect
which in the pairwise case with factors of size at-
most two necessarily has the following form: P(Y)
exp

j]

/
1]

(s,t)

E

2

j,k

[M

2

 

s

V,j

[M

2

2

 

⇣ P
[Ys 

I

j]

[Yt 

✓st I
The distribution in Theorem 3 can be rewritten in the fol-
lowing equivalent form

P

P

⌘

[Ys 

1] ✓s;j I
k]
.

P(Y)

exp

/

✓s;j I

[Ys 

j] +

1]

⇣ Xs
[M
V,j
 
2
2
M
Ys
M

✓st

 

X(s,t)
2

E

 

  

Yt

.

 

 ⌘

Note that the pairwise interaction terms in the above distri-
bution utilize the ordinality of Y through the term
Ys

M

M

Yt

 

.

 

 

  

To estimate the parameters of the consecutive ratio model
(6), we solve the following regularized node conditional
[p]
log likelihood maximization problem at each node s

 

2

arg min

¯✓s  

log P(yi;s|

yi;

s) +  n

\

,

✓st|

|

V
Xt
\
2

s

n

i=1
X

V

 

s.

and

n
i=1
1] [{

are
✓st}t

yi}
{
[M
2

training samples

where
✓s;j}j
{
We brieﬂy note that existing results on statistical guaran-
tees for estimators of exponential family graphical mod-
els (Yang et al., 2015; Tansey et al., 2015) carry over to the
consecutive ratio model.

=

2

\

¯✓s

Contrast with Discrete/Nominal Graphical models: We
now contrast the consecutive ratio model in (6) with the
classical discrete nominal graphical model which treats the
random variables at each node as nominal variables. Con-
sider the following discrete graphical model over the ran-
dom vector Y:

P(Y)

exp

/

✓s;j I

[Ys = j]

+

X(s,t)
2

[M
E Xj,k
 
2

1]

1]

⇣ Xs
[M
V,j
2
2
 
[Ys = j]
✓st;jk I

I

[Yt = k]

.

(7)

⌘

Unlike the consecutive ratio model,
the above model
doesn’t have a common edge parameter ✓st for different
values of Ys, Yt. Each edge in the categorical model is
parametrized using M 2 variables. As a result this model
does not utilize the ordinality of Y and is also more com-
plex compared to the consecutive ratio model. While
this parameterization does encompass the consecutive ra-
tio model parameterization, the key disadvantage is that the
nominal graphical model has a larger number of parameters
and hence greater sample complexity.

3. Multivariate Latent Quantized Models

In the previous section we considered using the mechanism
of Yang et al. (2012) to directly construct multivariate ordi-
nal graphical models from univariate ordinal distributions.
In this section we revisit the classical and most popular
class of univariate ordinal distributions based on the quan-
tization of a real-valued latent variable. A natural class of
multivariate distributions can be obtained by taking a mul-
tivariate latent random vector, and quantizing this to obtain
a multivariate ordinal random vector.

(6)

3.1. Probit Graphical Model

The most popular instance of such multivariate quantized
ordinal distributions is the case where the multivariate la-
tent random vector is multivariate Gaussian, which is also
known as the multivariate probit model (Ashford & Sow-
den, 1970; Amemiya, 1974). Thus the dependencies are all
represented in the latent random vector via the underlying
Gaussian distribution.

the ordinal random vector Y =
In the probit model,
(Y1, . . . Yp) is assumed to be generated from a latent multi-
variate Gaussian random vector Z = (Z1, . . . , Zp), where

Ordinal Graphical Models: A Tale of Two Approaches

p
✓(j)
k

n

i=1
X

i

(0, 1)

(0, ⌃) and Zi ⇠N
[1, p]. Each Yi
Z
⇠N
is obtained through discretization of Zi as follows: Yi =
[✓(i)
k ), where
k,
iff Zi 2
1 is the set of
k
{
 
thresholds, ✓(i)
, ✓(i)
M =
1 =
. Then the density func-
1
 
tion of Y, P(Y;⌃ , ⇥), is given by

8
✓(i)
k }

1,✓ (i)

 1

M
k=

2

 

P(✓(1)
Y1 

1 

=

C(Y,⇥)

Zz

2

Z1 <✓ (1)
Y1
1
(2⇡)p

, . . . ,✓ (p)
Yp 

Zp <✓ (p)
Yp

;⌃)

exp

z⌃ 

1zT

dz

(8)

⌃

|

|

 

✓

◆

1 
1
2

{

Yp

).

2

and

: j

[1, p], k

1,✓ (p)

1, M ]
)

[
 
1,✓ (1)

where ⇥=
2
C(Y, ⇥) is the hypercube deﬁned by [✓(1)
Y1 
[✓(p)
Yp 
n
Let Yn =
i=1 be n i.i.d realizations of the random vec-
tor Y, drawn from probit model with parameters ⇥⇤, ⌃⇤.
Then the `1-regularized Maximum Likelihood (ML) esti-
mator to learn the parameters ⌃, ⇥ from Yn takes the form

}
. . .
⇥

yi}
{

⇥

Y1

minimize

⌃,⇥  

log P(yi;⌃ , ⇥) +  nk

1

⌃ 

k1,off

(9)

k·k1,off is the element-wise `1 norm excluding diago-
where
nal entries. It can be seen that the objective is non-convex,
and intractable to optimize in general. Accordingly, ap-
proximate EM based approaches (Chib & Greenberg, 1998;
Guo et al., 2015) have been proposed for learning the model
parameters, but these are still relatively computationally
demanding, and also do not come with the strong statistical
guarantees of the actual regularized MLE solutions.

3.2. A Direct Estimation Method

In the second contribution of the paper, we propose an alter-
native procedure for the estimation of the unknown param-
eters ⇥, ⌃ in the probit graphical model distribution in (8).
This is a two stage procedure where in the ﬁrst stage we es-
timate the thresholds, ⇥, from the univariate marginals and
in the second stage we estimate the polychoric correlations,
⌃, from bivariate marginal distributions.

3.2.1. ESTIMATION OF THRESHOLDS

We deﬁne

⇥, our estimator of ⇥ as follows

b
 1
  

1( 1
n

✓(j)
k = 8
><

b

1

>:

P

n
i=1 I

(yi,j 

k))

1

if k =
 
if k = 0, . . . , M
if k = M

1

,

 

where  (.) is the CDF of standard normal distribution,
(.)
is the indicator function, yi,j is the jth coordinate of vector
yi. It can be seen that

⇥ consistently estimates ⇥⇤.

I

b

M

M

a=0
X
M

Xb=0
M

nab
n

nab
n

a=0
X

Xb=0
n
i=1 I

3.2.2. ESTIMATION OF POLYCHORIC CORRELATIONS

AND LATENT GRAPH STRUCTURE

We present a two step approach for estimation of ⌃.
In
⌃ from the bi-
the ﬁrst step, we compute a raw estimate
variate marginal likelihoods. In the next step we plugin the
⌃ into the graphical lasso es-
estimated covariance matrix
e
timator (Friedman et al., 2008) to estimate the sparse latent
graph structure and a smoothed estimate
e
Step 1: To estimate each entry of ⌃ we solve an indepen-
dent optimization problem. Lets suppose we want to es-
timate ⌃jk, for j
= k. The joint distribution of (Yj, Yk)
is multinomial with probabilities P(Yj, Yk;⇥ , ⌃jk) =
P(✓(j)
;⌃ jk), where
Yj  
the joint distribution of random variables Zj, Zk is bivari-

,✓ (k)
Yk 

Zk 

Zj 

✓(k)
Yk

✓(j)
Yj

1 

1 

⌃.

b

ate normal with mean [0, 0] and covariance

 
If ⇥⇤ is known, then one could estimate the unknown pa-
rameter ⌃jk by maximizing the bivariate marginal log like-
lihood function, which has the following form



1⌃
⌃jk

jk
1

.

`jk( ;⇥ ⇤, Yn) =

log P(Yj = a, Yk = b;⇥ ⇤,  )

=

log  ab;jk( ;⇥ ⇤),

(10)

where nab =

(yi,j = a, yi,k = b) and
 ab;jk( ;⇥) = P(Yj = a, Yk = b;⇥ ,  ). However, the
thresholds ⇥⇤ are unknown. So to estimate ⌃jk, we re-
place ⇥⇤ with its estimator
⇥ and maximize the following
log likelihood

P

b
⌃jk = arg max

`jk( ;

⇥, Yn).

 

2M

e

M

b
is the domain of  , which is (
 

1, 1) unless no ad-
where
ditional constraint on covariance is placed. Note that this
is a one-dimensional optimization problem which, under
certain regularity conditions such as smoothness of the ob-
jective, allow us to solve to within error ✏ in time O(1/✏)
,
by simply evaluating the objective over a ﬁne grid in
and selecting the optimal grid point.

M

e

⌃ into a parametric Gaus-
Step 2: In this step we plug-in
sian graphical model estimator to obtain the graph struc-
ture and the ﬁnal covariance matrix. While any consistent
parametric Gaussian estimator (e.g., graphical lasso esti-
mator (Friedman et al., 2008), CLIME (Cai et al., 2011),
graphical Dantzig selector (Yuan, 2010)) can be used to es-
timate the latent graph structure, in this work we focus on
the graphical lasso estimator (glasso), which involves solv-
ing the following optimization problem

⌃ = arg min
⌃ 

1

0 hh

 

b
where

hh

ii

⌃ 

1,

⌃

log det

1

⌃ 

1

⌃ 

+  nk

k1,off,
(11)

 

 

ii  

e

A, B

denotes the trace inner product of A and B.

6
Ordinal Graphical Models: A Tale of Two Approaches

3.3. Theoretical Properties

Speciﬁcally, we provide an `

In this section, we show that the direct estimation method
we proposed in Section 3.2 is not just simple but has strong
statistical guarantees.
1
1, and show
bound for the inverse covariance estimator
its sparsistency with respect to graphical model structure
recovery. For simplicity, we assume that ⇥⇤ is given. How-
ever, extension to the case where ⇥⇤ is unknown should be
fairly straightforward.

⌃ 

b

⌦

 

log det(A) evaluated at (⌃⇤) 

We begin with introducing some notation. Let  ⇤ := ⌃⇤
⌦
⌃⇤, where
denotes the Kronecker matrix product, denote
1. Let S be
the Hessian of
the set of indices corresponding to all nonzero entries in
1, and Sc be the complement of S. We also deﬁne
(⌃⇤) 
K⌃⇤ :=
for notational
|||1
|||
simplicity where
denotes the maximum absolute row
sum of matrix. Let d be the maximum node-degree in the
latent graph. Finally, let ¯`jk( ;⇥ ⇤) = E[`jk( ;⇥ ⇤)] be the
population version of the sample loss deﬁned in Equation
(10). We now state our assumptions.

, and K ⇤ :=

( ⇤SS) 

||| · |||1

|||1

⌃⇤

|||

1

|

1

1

1

8

9

 

 

 

2

 ,

 

 

 

 

8|

8|

|

|

|

(0, 1]

|||1 

such that

some ↵
↵.
1

⌃⇤jk|
the likelihood function
 > 0
 , i.e.,

(C-1) There exists
 ⇤ScS( ⇤SS) 
|||
 
(C-2) There is a constant  > 0 such that
1
j < k. Moreover,
 ab;jk( ;⇥ ⇤), is strictly positive
 ,  ab;jk( ;⇥ ⇤)
such that
(C-3) The absolute value of the 1st, 2nd and 3rd-order
derivatives of  ab;jk( ;⇥ ⇤) w.r.t.   are upper-bounded
 . Furthermore,
respectively by L1, L2, L3,
8|
the mild regularity property that ¯`jk( ;⇥ ⇤) not have de-
generate critical points in [

1
 
1/ .

 
(C-1) is the standard incoherence assumption that is made
for the guarantees of glasso estimator (Ravikumar et al.,
2011). (C-2) is a mild condition which ensures that no two
latent variables are perfectly collinear and all the categories
of the ordinal variables have non zero probabilities.
Theorem 4. Consider our estimator (11) for solving a la-
tent Gaussian model with true parameter ⌃⇤. And suppose
conditions (C-1)-(C-3) are satisﬁed. Then there exist some
known quantities c1, c2 and c3 depending on L1, L2, L3,
M , ↵,  ,  , K⌃⇤ and K ⇤ such that if  n = c1
log p0/n
c2d2 log p0 where p0 =
and n is lower bounded as n
p
max
⌃ satisﬁes the fol-
n, p
}
{
lowing bound

, then the inverse of estimate

 ] holds.

1 +  , 1

 

 

1

⌃ 

(⌃⇤) 

1

 

1 

c3

r

b
log p0
n

(12)

 
 
and, moreover, the graph structure of latent Gaussian en-
 b
 
1, as long
1 is consistently recovered by
coded in (⌃⇤) 
log p0

⌃ 

as  min := minij
bility at least 1

1]ij
[(⌃⇤) 
1.

c3

 

q

n , with proba-

b

1/p
 
 

 

!

 
 

c3

log p0

⌃⇤jk|

Proof Sketch: The proof of the theorem involves two
main steps. In the ﬁrst step we show that our estimate ˜⌃
˜⌃jk  
from step 1 satisﬁes: supj,k |
n , with
high probability. Next, we utilize the consistency proper-
ties of glasso (Ravikumar et al., 2008) to show that our
⌃ from step 2 satisﬁes Equation (12) with high
estimate
˜⌃jk  
probability. To bound supj,k |
, we utilize re-
cent results of Mei et al. (2017), who study the properties
of the stationary points of non-convex empirical risk min-
imization problems. See Appendix C for the proof of the
Theorem.

⌃⇤jk|

q

b

4. Experiments

In this section we present the performance of Consecutive
Ratio model (Consec model), and our estimator for probit
model (ProbitDirect) on various synthetic and real world
datasets.

4.1. Synthetic Experiments

Baselines: In the synthetic experiments we compare our
estimators with the following estimators:

a) ProbitEM: EM+MCMC based estimator for probit
model described in Guo et al. (2015). This uses MCMC
sampling to approximate the E-step.
b) ProbitEMApprox: Approximate EM based estimator for
probit model proposed by Guo et al. (2015). This approach
uses mean ﬁeld approximation in the E-step to speed up the
EM procedure.
c) Discrete model: This model ignores the order in the cat-
egories and treats each ordinal variable as a nominal vari-
able. Here we restrict ourselves to a pairwise model. To
learn this model we use the pseudo-likelihood based esti-
mator of Jalali et al. (2011).
d) Oracle: When the data is generated from a probit model,
we also compare with an oracle estimator which has access
to the latent variables of the model. Here we run glasso on
the latent variables to estimate the graph structure.

Model Selection: The best tuning parameter for all the es-
timators described above is selected using 5 fold cross val-
idation. For ProbitEMApprox we use the cross validation
technique proposed in (Guo et al., 2015). For ProbitEM,
Discrete model, Consec model and Oracle we use the stan-
dard cross validation technique where we pick the best tun-
ing parameter based on log likelihood on validation set. For
ProbitDirect we use the following k-fold cross validation
technique. We partition the data set into k subsets. Let
i
 
be the covariance matrix output by Step 2 of ProbitDirect,
when trained using all the subsets except ith subset. And
let ˜⌃i be the raw estimate obtained from Step 1 of Probit-
Direct, using ith subset. We pick a   which maximizes the
following score:

k
i=1 log det(

1
i )

⌃

b

1

.

⌃ 
 

i , ˜⌃iii

  hh

⌃ 
 

P

b

b

Ordinal Graphical Models: A Tale of Two Approaches

Figure 1. Comparison of various estimators when the data is generated from a probit model with chain graph structure. Top and bottom
rows correspond to ! =
0.9 respectively. The left two columns show ROC curves for n = 50, 100. The right three
columns show performance on test log likelihood, frobenius and entropy losses.

0.3 and ! =

 

 

n =  50

n =  100

0.1

0.2

0.3

0.4

0.5

0.1

0.2

0.3

0.4

0.5

100

300

400

100

300

400

0

100

300

400

FPR
n =  100

R
P
T

R
P
T

1

0.8

0.6

0.4

0.2

0

0

1

0.8

0.6

0.4

0.2

0

0

R
P
T

R
P
T

1

0.8

0.6

0.4

0.2

0

0

1

0.8

0.6

0.4

0.2

0

0

ProbitEMApprox
ProbitEM
ProbitDirect
Oracle
Consec Model
Discrete Model

FPR
n =  50

ProbitEMApprox
ProbitEM
ProbitDirect
Oracle
Consec Model
Discrete Model

-55

0

-50

-51

-52

-53

-54

d
o
o
h

 

i
l
e
k
i
L
g
o
L
 
t
s
e
T

-30

-31

-32

-33

-34

-35

d
o
o
h

 

i
l
e
k
i
L
g
o
L
 
t
s
e
T

-36

0

200
n

200
n

0.7

0.6

0.5

0.4

0.3

0.2

0.7

0.6

0.5

0.4

0.3

s
s
o
L
 
s
u
n
e
b
o
r
F

i

s
s
o
L
 
s
u
n
e
b
o
r
F

i

0.1

0

0.2

0

200
n

200
n

14

12

10

8

6

4

2

0

35

30

25

20

15

10

s
s
o
L
 
y
p
o
r
t
n
E

s
s
o
L
 
y
p
o
r
t
n
E

5

0

0

200
n

200
n

0.1

0.2

0.3

0.4

0.5

0.1

0.2

0.3

0.4

0.5

100

300

400

100

300

400

100

300

400

FPR

FPR

n =  50

n =  100

Evaluation Metrics: We compare the performance of our
estimators against baselines, on graph structure recovery,
using ROC curves computed by varying the regulariza-
tion parameter. When the data is generated from a probit
model, we compare the parameter estimation performance
of Oracle, ProbitEM, ProbitEMApprox and ProbitDirect
using Frobenius Loss and Entropy Loss which are deﬁned
⌃⇤ 
, Entropy Loss =
as: Frobenius Loss = k

⌃ 
1
kF
b
p, where ⌃⇤ is the true
 
hh
ii  
⌃ is the estimated covariance ma-
covariance matrix and
trix. Finally, we also compare ProbitEM, ProbitEMAp-
prox, ProbitDirect on log likelihood computed on 500 test
samples (we do not compare with Discrete model, Consec
model because computation of likelihood for these models
is infeasible). For comparison on these three metrics, we
select the best tuning parameter for each of the methods
using cross validation.

 
⌃⇤ 
k
1)
⌃ 

log det(⌃⇤

⌃⇤,

⌃ 

kF

b

b

b

1

1

1

Experimental Settings: In all our experiments we ﬁx the
number of nodes in the graph to 50 and set number of cat-
egories for each ordinal variable to 5. To reduce the vari-
ance, we average results over 10 repetitions.

4.1.1. DATA FROM PROBIT MODEL

In our ﬁrst experiment we generate ordinal data from a pro-
bit model. We simulate data from a chain graph. The in-
verse covariance matrix of the latent variables is chosen as
follows:

⌃ 

1
j,k =

j

k

 

|

!|
0

(

j

k
if
 
otherwise

|

|

1

.

(13)

We pick an !

(
 
the thresholds (✓) at node j as :
10,

in our experiments
✓(j) =
and set
[
0.7, 0.7, 10, Inf]. Finally we scale the covari-
Inf,
 
ance matrix so that all the variances are equal to 1. Fig-

1, 1)

 

 

2

R
P
T

R
P
T

0

0

1

0.8

0.6

0.4

0.2

1

0.8

0.6

0.4

0.2

0

0

R
P
T

R
P
T

0

0

1

0.8

0.6

0.4

0.2

1

0.8

0.6

0.4

0.2

0

0

 

0.1

0.2

0.3

0.4

0.5

0.1

0.2

0.3

0.4

0.5

FPR

n =  200

FPR

n =  400

ProbitEMApprox
ProbitEM
ProbitDirect
Consec Model
Discrete Model

0.1

0.2

0.3

0.4

0.5

0.1

0.2

0.3

0.4

0.5

FPR

FPR

Figure 2. Data sampled from a Consec model with 2D grid struc-
5 grid). Node speciﬁc parameters (✓s) are uniformly
ture (10
sampled from [
1, 1]. Pairwise interaction terms (✓st) are set to
 
0.1 for all horizontal edges and to

0.1 for all vertical edges.

⇥

 

 

0.3,

ure 1 shows the results obtained using ! =
0.9.
More results for large n and grid and random graphs can be
found in Appendix D. We can seen that ProbitDirect and
ProbitEM have similar performance. However, ProbitDi-
rect is 1-2 orders of magnitude faster than ProbitEM. Pro-
bitEMApprox has very poor performance, especially in low
sample complexity setting. This could be because of the
mean ﬁeld approximation that is made by Guo et al. (2015),
where in the E-step they approximate E[ZjZk|
⌃] as
⌃]. This decouples the inter-
Y ;
E[Zj|
E[Zk|
actions between any two random variables. Also note that
5 times faster than ProbitEMApprox (See
ProbitDirect is
b
b
Table 1 in Appendix).

Y ;

Y ;

⇥,

⇥,

⇥,

⌃]

⇡

⇥

b

b

b

b

Ordinal Graphical Models: A Tale of Two Approaches

n =  50

n =  100

R
P
T

R
P
T

0

0

1

0.8

0.6

0.4

0.2

1

0.8

0.6

0.4

0.2

0

0

0.1

0.2

0.3

0.4

0.5

0.1

0.2

0.3

0.4

0.5

FPR

n =  200

FPR

n =  400

ProbitEMApprox
ProbitEM
ProbitDirect
Consec Model
Discrete Model

0.1

0.2

0.3

0.4

0.5

0.1

0.2

0.3

0.4

0.5

FPR

FPR

Figure 3. Data sampled from a Consec model with 2D grid struc-
5 grid). Node speciﬁc parameters (✓s) are uniformly
ture (10
sampled from [
1, 1]. Pairwise interaction terms (✓st) are set to
 
0.3 for all horizontal edges and to

0.3 for all vertical edges.

⇥

R
P
T

R
P
T

0

0

1

0.8

0.6

0.4

0.2

1

0.8

0.6

0.4

0.2

0

0

 

Figure 4. The estimated latent graph structure corresponding to
SmokeNow and sociodemographic indicators. The graph is gen-
erated from the marginal distribution of the corresponding vari-
ables. Green and red edges represent positive and negative partial
correlations respectively. Edge thickness is proportional to the
magnitude of the partial correlation.

4.1.2. DATA FROM CONSECUTIVE RATIO MODEL

In this experiment we sample data from Consec model. Fig-
ures 2, 3 present the results on a grid graph along with
the details of exact parameters used. When the interaction
between variables is low, Consec model has similar per-
formance as other estimators (Figure 2). However, when
the interactions are high (Figure 3), its performance de-
grades. We noticed similar poor performance of Consec
model on other graphs. This could suggest that either the
node conditional likelihood based estimator for Consecu-
tive Ratio model is not efﬁcient or latent graphical models
such as Probit model are better models than Consecutive
Ratio model.

4.2. Health Information National Trends Survey study

The Health Information National Trends Survey (HINTS)
is a nationally representative survey conducted by the Na-
tional Cancer Institute (NCI) every few years. In this work
we analyze HINTS-FDA data which is a special data col-

⇡

lected by NCI in partnership with the Food and Drug Ad-
ministration (FDA) and is made publicly available by NCI.
This survey collected detailed information on the follow-
ing topics: Tobacco Product Use, Beliefs about Tobacco
Products, Beliefs About Cancer, How people access Health
Information?, Socio Demographic Indicators. The survey
350 questions. Almost all the
has 3738 respondents on
questions in the survey have either ordinal or categorical
responses. Refer to Appendix D for summary statistics of
the data and details about preprocessing performed on the
data. We treat each question in the survey as a node in the
graph and responses of individuals to these questions as
samples drawn from the graph. We selected 114 questions
from the dataset, that are relevant for our analysis. We ﬁt
the probit model using ProbitDirect on the selected ques-
tions. To choose the best tuning parameter we use 10 fold
cross validation. We obtain 95% conﬁdence intervals for
the edge strengths of the latent graph through jackknife re-
sampling technique. We place an edge in the graph only if
its conﬁdence interval doesn’t intersect with [

0.1, 0.1].

 

Figure 4 shows how various variables related to sociode-
mographic indicators are associated with smoking behav-
ior of a person. In particular, it shows that SmokeNow has
a very signiﬁcant association with Education. This indi-
cates that if a person is well educated then conditioned on
all the other variables, there is lower chance that the per-
son smokes. In Appendix D, we provide an additional Fig-
ure 9, which shows how the perceptions of smoking risks
vary with smoking behavior. It shows that SmokeNow and
FewCigarettesHarmHealth have a positive partial correla-
tion, indicating that conditioned on the rest of the variables,
people who smoke, perceive smoking as less harmful than
people who don’t smoke. Table 2 in Appendix D describes
some highly relevant nodes in the learned graphs, from
which several other insights can be obtained. We believe
these insights can be helpful in designing efﬁcient strate-
gies for communicating smoking related health information
to the public.

5. Acknowledgments

and MSIP/IITP (Institute

E.Y. acknowledges
the support of MSIP/NRF (Na-
tional Research Foundation of Korea) via NRF-
2016R1A5A1012966
for
Information & Communications Technology Promo-
tion of Korea) via ICT R&D program 2016-0-00563,
A.S., P.R. acknowledge the support
2017-0-00537.
of ARO via W911NF-12-1-0390 and NSF via IIS-
1149803, IIS-1447574, DMS-1264033, and NIH via R01
GM117594-01.

Ordinal Graphical Models: A Tale of Two Approaches

References

Agresti, A. Analysis of ordinal categorical data, volume

656. John Wiley & Sons, 2010.

Allen, G. I. and Liu, Z. A log-linear graphical model for in-
ferring genetic networks from high-throughput sequenc-
In Bioinformatics and Biomedicine (BIBM),
ing data.
2012 IEEE International Conference on, pp. 1–6, 2012.

Amemiya, T. Bivariate probit analysis: Minimum chi-
square methods. Journal of the American Statistical As-
sociation, 69(348):940–944, 1974.

Armstrong, B. and Sloan, M. Ordinal regression models for
epidemiologic data. American Journal of Epidemiology,
129(1):191–204, 1989.

Ashford, J. R. and Sowden, R. R. Multi-variate probit anal-

ysis. Biometrics, 26(3):535–546, 1970.

Bartolucci, F., Colombi, R., and Forcina, A. An extended
class of marginal link functions for modelling contin-
gency tables by equality and inequality constraints. Sta-
tistica Sinica, pp. 691–711, 2007.

Becker, W. E. and Kennedy, P. E. A graphical exposition of
the ordered probit. Econometric theory, 8(01):127–131,
1992.

Besag, J. Spatial interaction and the statistical analysis of
lattice systems. J. Roy. Stat. Soc. Series B, 36:192–236,
1974.

Cai, T., Liu, W., and Luo, X. A constrained l1 minimization
approach to sparse precision matrix estimation. Journal
of the American Statistical Association, 106(494):594–
607, 2011.

Chib, S. and Greenberg, E. Analysis of multivariate probit

models. Biometrika, pp. 347–361, 1998.

De Leon, A. R. Pairwise likelihood approach to grouped
continuous model and its extension. Statistics & proba-
bility letters, 75(1):49–57, 2005.

Friedman, J., Hastie, T., and Tibshirani, R. Sparse inverse
covariance estimation with the graphical lasso. Biostatis-
tics, 9(3):432–441, 2008.

Friedman, N.

Inferring cellular networks using proba-
bilistic graphical models. Science, 303(5659):799–805,
2004.

Guo, J., Levina, E., Michailidis, G., and Zhu, J. Graphical
models for ordinal data. Journal of Computational and
Graphical Statistics, 24(1):183–204, 2015.

Han, F. and Pan, W. A composite likelihood approach to
latent multivariate gaussian modeling of snp data with
application to genetic association testing. Biometrics, 68
(1):307–315, 2012.

Ising, E.

Beitrag zur theorie der ferromagnetismus.

Zeitschrift f¨ur Physik, 31:253–258, 1925.

Jalali, A., Ravikumar, P., Vasuki, V., and Sanghavi, S. On
learning discrete graphical models using group-sparse
regularization. In Inter. Conf. on AI and Statistics (AIS-
TATS), 14, 2011.

J¨oreskog, K. G. On the estimation of polychoric correla-
tions and their asymptotic covariance matrix. Psychome-
trika, 59(3):381–389, 1994.

Lauritzen, S. L. and Wermuth, N. Graphical models for
associations between variables, some of which are qual-
itative and some quantitative. The Annals of Statistics,
pp. 31–57, 1989.

Lindsay, Bruce G. Composite likelihood methods. Statisti-
cal Inference from Stochastic Processes Contemporary
Mathematics, pp. 221239, 1988. doi: 10.1090/conm/
080/999014.

Liu, H., Han, F., Yuan, M., Lafferty, J., and Wasserman, L.
The nonparanormal skeptic. In International Conference
on Machine learning (ICML), 2012.

Manning, C. D. and Sch¨utze, H. Foundations of statistical
natural language processing, volume 999. MIT Press,
1999.

McCullagh, P. Generalized linear models. European Jour-
nal of Operational Research, 16(3):285–292, 1984.

Mei, S., Bai, Y., and Montanari, A. The landscape of
empirical risk for non-convex losses. Arxiv preprint
arXiv:1607.06534, 2017.

Muth´en, B. A general structural equation model with
dichotomous, ordered categorical, and continuous la-
tent variable indicators. Psychometrika, 49(1):115–132,
1984.

Peterson, B. and Harrell Jr., F. E. Partial proportional odds
models for ordinal response variables. Applied statistics,
pp. 205–217, 1990.

Ravikumar, P., Wainwright, M. J., Raskutti, G., and Yu,
B. High-dimensional covariance estimation by minimiz-
ing `1-penalized log-determinant divergence. Techni-
cal Report 767, Department of Statistics, UC Berkeley,
September 2008.

Ordinal Graphical Models: A Tale of Two Approaches

Ravikumar, P., Wainwright, M. J., Raskutti, G., and Yu,
B. High-dimensional covariance estimation by minimiz-
ing `1-penalized log-determinant divergence. Electronic
Journal of Statistics, 5:935–980, 2011.

Rue, H. and Held, L. Gaussian Markov Random Fields:
Theory and Applications. Chapman and Hall/CRC,
2005.

Speed, T. P. and Kiiveri, H. T. Gaussian Markov distri-
butions over ﬁnite graphs. Annals of Statistics, 14(1):
138–150, March 1986.

Tansey, W., Padilla, O. H. M., Suggala, A. S., and Raviku-
mar, P. Vector-space markov random ﬁelds via exponen-
tial families. In ICML, pp. 684–692, 2015.

Yang, E., Ravikumar, P., Allen, G. I., and Liu, Z. Graphi-
cal models via generalized linear models. In Neur. Info.
Proc. Sys. (NIPS), 25, 2012.

Yang, E., Baker, Y., Ravikumar, P., Allen, G. I., and Liu,
Z. Mixed graphical models via exponential families. In
Inter. Conf. on AI and Statistics (AISTATS), 17, 2014.

Yang, E., Ravikumar, P., Allen, G. I., and Liu, Z. Graphical
models via univariate exponential family distributions.
Journal of Machine Learning Research, 16:3813–3847,
2015.

Yuan, M. High dimensional inverse covariance matrix es-
timation via linear programming. Journal of Machine
Learning Research, 11(Aug):2261–2286, 2010.

