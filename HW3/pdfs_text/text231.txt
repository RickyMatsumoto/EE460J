OnCalibrationofModernNeuralNetworksChuanGuo*1GeoffPleiss*1YuSun*1KilianQ.Weinberger1AbstractConﬁdencecalibration–theproblemofpredict-ingprobabilityestimatesrepresentativeofthetruecorrectnesslikelihood–isimportantforclassiﬁcationmodelsinmanyapplications.Wediscoverthatmodernneuralnetworks,unlikethosefromadecadeago,arepoorlycalibrated.Throughextensiveexperiments,weobservethatdepth,width,weightdecay,andBatchNormal-izationareimportantfactorsinﬂuencingcalibra-tion.Weevaluatetheperformanceofvariouspost-processingcalibrationmethodsonstate-of-the-artarchitectureswithimageanddocumentclassiﬁcationdatasets.Ouranalysisandexper-imentsnotonlyofferinsightsintoneuralnet-worklearning,butalsoprovideasimpleandstraightforwardrecipeforpracticalsettings:onmostdatasets,temperaturescaling–asingle-parametervariantofPlattScaling–issurpris-inglyeffectiveatcalibratingpredictions.1.IntroductionRecentadvancesindeeplearninghavedramaticallyim-provedneuralnetworkaccuracy(Simonyan&Zisserman,2015;Srivastavaetal.,2015;Heetal.,2016;Huangetal.,2016;2017).Asaresult,neuralnetworksarenowentrustedwithmakingcomplexdecisionsinapplications,suchasob-jectdetection(Girshick,2015),speechrecognition(Han-nunetal.,2014),andmedicaldiagnosis(Caruanaetal.,2015).Inthesesettings,neuralnetworksareanessentialcomponentoflargerdecisionmakingpipelines.Inreal-worlddecisionmakingsystems,classiﬁcationnet-worksmustnotonlybeaccurate,butalsoshouldindicatewhentheyarelikelytobeincorrect.Asanexample,con-sideraself-drivingcarthatusesaneuralnetworktodetectpedestriansandotherobstructions(Bojarskietal.,2016).*Equalcontribution,alphabeticalorder.1CornellUniversity.Correspondenceto:ChuanGuo<cg563@cornell.edu>,GeoffPleiss<geoff@cs.cornell.edu>,YuSun<ys646@cornell.edu>.Proceedingsofthe34thInternationalConferenceonMachineLearning,Sydney,Australia,PMLR70,2017.Copyright2017bytheauthor(s).0.00.20.40.60.81.00.00.20.40.60.81.0%ofSamplesAvg.conﬁdenceAccuracyLeNet(1998)CIFAR-1000.00.20.40.60.81.0Avg.conﬁdenceAccuracyResNet(2016)CIFAR-1000.00.20.40.60.81.00.00.20.40.60.81.0AccuracyError=44.9OutputsGap0.00.20.40.60.81.0Error=30.6OutputsGapConﬁdenceFigure1.Conﬁdencehistograms(top)andreliabilitydiagrams(bottom)fora5-layerLeNet(left)anda110-layerResNet(right)onCIFAR-100.Refertothetextbelowfordetailedillustration.Ifthedetectionnetworkisnotabletoconﬁdentlypredictthepresenceorabsenceofimmediateobstructions,thecarshouldrelymoreontheoutputofothersensorsforbraking.Alternatively,inautomatedhealthcare,controlshouldbepassedontohumandoctorswhentheconﬁdenceofadis-easediagnosisnetworkislow(Jiangetal.,2012).Specif-ically,anetworkshouldprovideacalibratedconﬁdencemeasureinadditiontoitsprediction.Inotherwords,theprobabilityassociatedwiththepredictedclasslabelshouldreﬂectitsgroundtruthcorrectnesslikelihood.Calibratedconﬁdenceestimatesarealsoimportantformodelinterpretability.Humanshaveanaturalcognitivein-tuitionforprobabilities(Cosmides&Tooby,1996).Goodconﬁdenceestimatesprovideavaluableextrabitofinfor-mationtoestablishtrustworthinesswiththeuser–espe-ciallyforneuralnetworks,whoseclassiﬁcationdecisionsareoftendifﬁculttointerpret.Further,goodprobabilityestimatescanbeusedtoincorporateneuralnetworksintootherprobabilisticmodels.Forexample,onecanimproveperformancebycombiningnetworkoutputswithalan-guagemodelinspeechrecognition(Hannunetal.,2014;Xiongetal.,2016),orwithcamerainformationforobjectdetection(Kendall&Cipolla,2016).In2005,Niculescu-Mizil&Caruana(2005)showedthatneuralnetworkstypicallyproducewell-calibratedproba-bilitiesonbinaryclassiﬁcationtasks.Whileneuralnet-workstodayareundoubtedlymoreaccuratethantheywereadecadeago,wediscoverwithgreatsurprisethatmod-ernneuralnetworksarenolongerwell-calibrated.ThisisvisualizedinFigure1,whichcomparesa5-layerLeNet(left)(LeCunetal.,1998)witha110-layerResNet(right)(Heetal.,2016)ontheCIFAR-100dataset.Thetoprowshowsthedistributionofpredictionconﬁdence(i.e.prob-abilitiesassociatedwiththepredictedlabel)ashistograms.TheaverageconﬁdenceofLeNetcloselymatchesitsaccu-racy,whiletheaverageconﬁdenceoftheResNetissubstan-tiallyhigherthanitsaccuracy.Thisisfurtherillustratedinthebottomrowreliabilitydiagrams(DeGroot&Fienberg,1983;Niculescu-Mizil&Caruana,2005),whichshowac-curacyasafunctionofconﬁdence.WeseethatLeNetiswell-calibrated,asconﬁdencecloselyapproximatestheex-pectedaccuracy(i.e.thebarsalignroughlyalongthediag-onal).Ontheotherhand,theResNet’saccuracyisbetter,butdoesnotmatchitsconﬁdence.Ourgoalisnotonlytounderstandwhyneuralnetworkshavebecomemiscalibrated,butalsotoidentifywhatmeth-odscanalleviatethisproblem.Inthispaper,wedemon-strateonseveralcomputervisionandNLPtasksthatneu-ralnetworksproduceconﬁdencesthatcannotrepresenttrueprobabilities.Additionally,weofferinsightandintuitionintonetworktrainingandarchitecturaltrendsthatmaycausemiscalibration.Finally,wecomparevariouspost-processingcalibrationmethodsonstate-of-the-artneuralnetworks,andintroduceseveralextensionsofourown.Surprisingly,weﬁndthatasingle-parametervariantofPlattscaling(Plattetal.,1999)–whichwerefertoastemper-aturescaling–isoftenthemosteffectivemethodatob-tainingcalibratedprobabilities.Becausethismethodisstraightforwardtoimplementwithexistingdeeplearningframeworks,itcanbeeasilyadoptedinpracticalsettings.2.DeﬁnitionsTheproblemweaddressinthispaperissupervisedmulti-classclassiﬁcationwithneuralnetworks.TheinputX∈XandlabelY∈Y={1,...,K}arerandomvariablesthatfollowagroundtruthjointdistributionπ(X,Y)=π(Y|X)π(X).Lethbeaneuralnetworkwithh(X)=(ˆY,ˆP),whereˆYisaclasspredictionandˆPisitsassoci-atedconﬁdence,i.e.probabilityofcorrectness.WewouldliketheconﬁdenceestimateˆPtobecalibrated,whichin-tuitivelymeansthatˆPrepresentsatrueprobability.Forexample,given100predictions,eachwithconﬁdenceof0.8,weexpectthat80shouldbecorrectlyclassiﬁed.Moreformally,wedeﬁneperfectcalibrationasP(cid:16)ˆY=Y|ˆP=p(cid:17)=p,∀p∈[0,1](1)wheretheprobabilityisoverthejointdistribution.Inallpracticalsettings,achievingperfectcalibrationisimpos-sible.Additionally,theprobabilityin(1)cannotbecom-putedusingﬁnitelymanysamplessinceˆPisacontinuousrandomvariable.Thismotivatestheneedforempiricalap-proximationsthatcapturetheessenceof(1).ReliabilityDiagrams(e.g.Figure1bottom)areavisualrepresentationofmodelcalibration(DeGroot&Fienberg,1983;Niculescu-Mizil&Caruana,2005).Thesediagramsplotexpectedsampleaccuracyasafunctionofconﬁdence.Ifthemodelisperfectlycalibrated–i.e.if(1)holds–thenthediagramshouldplottheidentityfunction.Anydevia-tionfromaperfectdiagonalrepresentsmiscalibration.Toestimatetheexpectedaccuracyfromﬁnitesamples,wegrouppredictionsintoMintervalbins(eachofsize1/M)andcalculatetheaccuracyofeachbin.LetBmbethesetofindicesofsampleswhosepredictionconﬁdencefallsintotheintervalIm=(m−1M,mM].TheaccuracyofBmisacc(Bm)=1|Bm|Xi∈Bm1(ˆyi=yi),whereˆyiandyiarethepredictedandtrueclasslabelsforsamplei.Basicprobabilitytellsusthatacc(Bm)isanun-biasedandconsistentestimatorofP(ˆY=Y|ˆP∈Im).WedeﬁnetheaverageconﬁdencewithinbinBmasconf(Bm)=1|Bm|Xi∈Bmˆpi,whereˆpiistheconﬁdenceforsamplei.acc(Bm)andconf(Bm)approximatetheleft-handandright-handsidesof(1)respectivelyforbinBm.Therefore,aperfectlycal-ibratedmodelwillhaveacc(Bm)=conf(Bm)forallm∈{1,...,M}.Notethatreliabilitydiagramsdonotdis-playtheproportionofsamplesinagivenbin,andthuscan-notbeusedtoestimatehowmanysamplesarecalibrated.ExpectedCalibrationError(ECE).Whilereliabilitydiagramsareusefulvisualtools,itismoreconvenienttohaveascalarsummarystatisticofcalibration.Sincestatis-ticscomparingtwodistributionscannotbecomprehensive,previousworkshaveproposedvariants,eachwithauniqueemphasis.Onenotionofmiscalibrationisthedifferenceinexpectationbetweenconﬁdenceandaccuracy,i.e.EˆPh(cid:12)(cid:12)(cid:12)P(cid:16)ˆY=Y|ˆP=p(cid:17)−p(cid:12)(cid:12)(cid:12)i(2)ExpectedCalibrationError(Naeinietal.,2015)–orECE–approximates(2)bypartitioningpredictionsintoMequally-spacedbins(similartothereliabilitydiagrams)and020406080100120Depth0.00.10.20.30.40.50.60.7Error/ECEVaryingDepthResNet-CIFAR-100ErrorECE050100150200250300FiltersperlayerVaryingWidthResNet-14-CIFAR-100ErrorECEWithoutWithBatchNormalizationUsingNormalizationConvNet-CIFAR-100ErrorECE10−510−410−310−2WeightdecayVaryingWeightDecayResNet-110-CIFAR-100ErrorECEFigure2.Theeffectofnetworkdepth(farleft),width(middleleft),BatchNormalization(middleright),andweightdecay(farright)onmiscalibration,asmeasuredbyECE(lowerisbetter).takingaweightedaverageofthebins’accuracy/conﬁdencedifference.Moreprecisely,ECE=MXm=1|Bm|n(cid:12)(cid:12)(cid:12)(cid:12)acc(Bm)−conf(Bm)(cid:12)(cid:12)(cid:12)(cid:12),(3)wherenisthenumberofsamples.Thedifferencebetweenaccandconfforagivenbinrepresentsthecalibrationgap(redbarsinreliabilitydiagrams–e.g.Figure1).WeuseECEastheprimaryempiricalmetrictomeasurecalibra-tion.SeeSectionS1formoreanalysisofthismetric.MaximumCalibrationError(MCE).Inhigh-riskap-plicationswherereliableconﬁdencemeasuresareabso-lutelynecessary,wemaywishtominimizetheworst-casedeviationbetweenconﬁdenceandaccuracy:maxp∈[0,1](cid:12)(cid:12)(cid:12)P(cid:16)ˆY=Y|ˆP=p(cid:17)−p(cid:12)(cid:12)(cid:12).(4)TheMaximumCalibrationError(Naeinietal.,2015)–orMCE–estimatesanupperboundofthisdeviation.Simi-larlytoECE,thisapproximationinvolvesbinning:MCE=maxm∈{1,...,M}|acc(Bm)−conf(Bm)|.(5)Inreliabilitydiagrams,MCEmeasuresthelargestcalibra-tiongap(redbars)acrossallbins,whereasECEmeasuresaweightedaverageofallgaps.Forperfectlycalibratedclas-siﬁers,MCEandECEbothequal0.Negativeloglikelihoodisastandardmeasureofaprob-abilisticmodel’squality(Friedmanetal.,2001).Itisalsoreferredtoasthecrossentropylossinthecontextofdeeplearning(Bengioetal.,2015).Givenaprobabilisticmodelˆπ(Y|X)andnsamples,NLLisdeﬁnedas:L=−nXi=1log(ˆπ(yi|xi))(6)Itisastandardresult(Friedmanetal.,2001)that,inexpec-tation,NLLisminimizedifandonlyifˆπ(Y|X)recoversthegroundtruthconditionaldistributionπ(Y|X).3.ObservingMiscalibrationThearchitectureandtrainingproceduresofneuralnet-workshaverapidlyevolvedinrecentyears.Inthissec-tionweidentifysomerecentchangesthatareresponsibleforthemiscalibrationphenomenonobservedinFigure1.Thoughwecannotclaimcausality,weﬁndthatmodelcapacityandlackofregularizationarecloselyrelatedtomodel(mis)calibration.Modelcapacity.Themodelcapacityofneuralnetworkshasincreasedatadramaticpaceoverthepastfewyears.Itisnowcommontoseenetworkswithhundreds,ifnotthousandsoflayers(Heetal.,2016;Huangetal.,2016)andhundredsofconvolutionalﬁltersperlayer(Zagoruyko&Komodakis,2016).Recentworkshowsthatverydeeporwidemodelsareabletogeneralizebetterthansmallerones,whileexhibitingthecapacitytoeasilyﬁtthetrainingset(Zhangetal.,2017).Althoughincreasingdepthandwidthmayreduceclassi-ﬁcationerror,weobservethattheseincreasesnegativelyaffectmodelcalibration.Figure2displayserrorandECEasafunctionofdepthandwidthonaResNettrainedonCIFAR-100.Thefarleftﬁgurevariesdepthforanetworkwith64convolutionalﬁltersperlayer,whilethemiddleleftﬁgureﬁxesthedepthat14layersandvariesthenumberofconvolutionalﬁltersperlayer.Thougheventhesmall-estmodelsinthegraphexhibitsomedegreeofmiscalibra-tion,theECEmetricgrowssubstantiallywithmodelca-pacity.Duringtraining,afterthemodelisabletocorrectlyclassify(almost)alltrainingsamples,NLLcanbefurtherminimizedbyincreasingtheconﬁdenceofpredictions.In-creasedmodelcapacitywilllowertrainingNLL,andthusthemodelwillbemore(over)conﬁdentonaverage.BatchNormalization(Ioffe&Szegedy,2015)improvestheoptimizationofneuralnetworksbyminimizingdistri-butionshiftsinactivationswithintheneuralnetwork’shid-0100200300400500202530354045EpochError (%) / NLL (scaled)NLL Overfitting on CIFAR−100  Test errorTest NLLFigure3.TesterrorandNLLofa110-layerResNetwithstochas-ticdepthonCIFAR-100duringtraining.NLLisscaledbyacon-stanttoﬁtintheﬁgure.Learningratedropsby10xatepochs250and375.Theshadedareamarksbetweenepochsatwhichthebestvalidationlossandbestvalidationerrorareproduced.denlayers.Recentresearchsuggeststhatthesenormal-izationtechniqueshaveenabledthedevelopmentofverydeeparchitectures,suchasResNets(Heetal.,2016)andDenseNets(Huangetal.,2017).IthasbeenshownthatBatchNormalizationimprovestrainingtime,reducestheneedforadditionalregularization,andcaninsomecasesimprovetheaccuracyofnetworks.WhileitisdifﬁculttopinpointexactlyhowBatchNormal-izationaffectstheﬁnalpredictionsofamodel,wedoob-servethatmodelstrainedwithBatchNormalizationtendtobemoremiscalibrated.InthemiddlerightplotofFigure2,weseethata6-layerConvNetobtainsworsecalibrationwhenBatchNormalizationisapplied,eventhoughclassi-ﬁcationaccuracyimprovesslightly.WeﬁndthatthisresultholdsregardlessofthehyperparametersusedontheBatchNormalizationmodel(i.e.loworhighlearningrate,etc.).Weightdecay,whichusedtobethepredominantregu-larizationmechanismforneuralnetworks,isdecreasinglyutilizedwhentrainingmodernneuralnetworks.Learningtheorysuggeststhatregularizationisnecessarytopreventoverﬁtting,especiallyasmodelcapacityincreases(Vapnik,1998).However,duetotheapparentregularizationeffectsofBatchNormalization,recentresearchseemstosuggestthatmodelswithlessL2regularizationtendtogeneralizebetter(Ioffe&Szegedy,2015).Asaresult,itisnowcom-montotrainmodelswithlittleweightdecay,ifanyatall.ThetopperformingImageNetmodelsof2015alluseanor-derofmagnitudelessweightdecaythanmodelsofpreviousyears(Heetal.,2016;Simonyan&Zisserman,2015).Weﬁndthattrainingwithlessweightdecayhasanegativeimpactoncalibration.ThefarrightplotinFigure2dis-playstrainingerrorandECEfora110-layerResNetwithvaryingamountsofweightdecay.TheonlyotherformsofregularizationaredataaugmentationandBatchNormal-ization.Weobservethatcalibrationandaccuracyarenotoptimizedbythesameparametersetting.Whilethemodelexhibitsbothover-regularizationandunder-regularizationwithrespecttoclassiﬁcationerror,itdoesnotappearthatcalibrationisnegativelyimpactedbyhavingtoomuchweightdecay.Modelcalibrationcontinuestoimprovewhenmoreregularizationisadded,wellafterthepointofachievingoptimalaccuracy.Theslightuptickattheendofthegraphmaybeanartifactofusingaweightdecayfactorthatimpedesoptimization.NLLcanbeusedtoindirectlymeasuremodelcalibra-tion.Inpractice,weobserveadisconnectbetweenNLLandaccuracy,whichmayexplainthemiscalibrationinFig-ure2.ThisdisconnectoccursbecauseneuralnetworkscanoverﬁttoNLLwithoutoverﬁttingtothe0/1loss.Weob-servethistrendinthetrainingcurvesofsomemiscalibratedmodels.Figure3showstesterrorandNLL(rescaledtomatcherror)onCIFAR-100astrainingprogresses.BotherrorandNLLimmediatelydropatepoch250,whenthelearningrateisdropped;however,NLLoverﬁtsduringtheremainderoftraining.Surprisingly,overﬁttingtoNLLisbeneﬁcialtoclassiﬁcationaccuracy.OnCIFAR-100,testerrordropsfrom29%to27%intheregionwhereNLLoverﬁts.Thisphenomenonrendersaconcreteexplanationofmiscalibration:thenetworklearnsbetterclassiﬁcationaccuracyattheexpenseofwell-modeledprobabilities.Wecanconnectthisﬁndingtorecentworkexaminingthegeneralizationoflargeneuralnetworks.Zhangetal.(2017)observethatdeepneuralnetworksseeminglyviolatethecommonunderstandingoflearningtheorythatlargemod-elswithlittleregularizationwillnotgeneralizewell.TheobserveddisconnectbetweenNLLand0/1losssuggeststhatthesehighcapacitymodelsarenotnecessarilyimmunefromoverﬁtting,butrather,overﬁttingmanifestsinproba-bilisticerrorratherthanclassiﬁcationerror.4.CalibrationMethodsInthissection,weﬁrstreviewexistingcalibrationmeth-ods,andintroducenewvariantsofourown.Allmethodsarepost-processingstepsthatproduce(calibrated)proba-bilities.Eachmethodrequiresahold-outvalidationset,whichinpracticecanbethesamesetusedforhyperparam-etertuning.Weassumethatthetraining,validation,andtestsetsaredrawnfromthesamedistribution.4.1.CalibratingBinaryModelsWeﬁrstintroducecalibrationinthebinarysetting,i.e.Y={0,1}.Forsimplicity,throughoutthissubsection,weassumethemodeloutputsonlytheconﬁdenceforthepositiveclass.1Givenasamplexi,wehaveaccesstoˆpi–thenetwork’spredictedprobabilityofyi=1,aswellaszi∈R–whichisthenetwork’snon-probabilisticoutput,orlogit.Thepredictedprobabilityˆpiisderivedfromzius-ingasigmoidfunctionσ;i.e.ˆpi=σ(zi).Ourgoalistoproduceacalibratedprobabilityˆqibasedonyi,ˆpi,andzi.Histogrambinning(Zadrozny&Elkan,2001)isasim-plenon-parametriccalibrationmethod.Inanutshell,alluncalibratedpredictionsˆpiaredividedintomutuallyex-clusivebinsB1,...,BM.Eachbinisassignedacalibratedscoreθm;i.e.ifˆpiisassignedtobinBm,thenˆqi=θm.Attesttime,ifpredictionˆptefallsintobinBm,thenthecali-bratedpredictionˆqteisθm.Moreprecisely,forasuitablychosenM(usuallysmall),weﬁrstdeﬁnebinboundaries0=a1≤a2≤...≤aM+1=1,wherethebinBmisdeﬁnedbytheinterval(am,am+1].Typicallythebinboundariesareeitherchosentobeequallengthintervalsortoequalizethenumberofsamplesineachbin.Thepredic-tionsθiarechosentominimizethebin-wisesquaredloss:minθ1,...,θMMXm=1nXi=11(am≤ˆpi<am+1)(θm−yi)2,(7)where1istheindicatorfunction.Givenﬁxedbinsbound-aries,thesolutionto(7)resultsinθmthatcorrespondtotheaveragenumberofpositive-classsamplesinbinBm.Isotonicregression(Zadrozny&Elkan,2002),arguablythemostcommonnon-parametriccalibrationmethod,learnsapiecewiseconstantfunctionftotransformun-calibratedoutputs;i.e.ˆqi=f(ˆpi).Speciﬁcally,iso-tonicregressionproducesftominimizethesquarelossPni=1(f(ˆpi)−yi)2.Becausefisconstrainedtobepiece-wiseconstant,wecanwritetheoptimizationproblemas:minMθ1,...,θMa1,...,aM+1MXm=1nXi=11(am≤ˆpi<am+1)(θm−yi)2subjectto0=a1≤a2≤...≤aM+1=1,θ1≤θ2≤...≤θM.whereMisthenumberofintervals;a1,...,aM+1aretheintervalboundaries;andθ1,...,θMarethefunctionval-ues.Underthisparameterization,isotonicregressionisastrictgeneralizationofhistogrambinninginwhichthebinboundariesandbinpredictionsarejointlyoptimized.BayesianBinningintoQuantiles(BBQ)(Naeinietal.,2015)isaextensionofhistogrambinningusingBayesian1ThisisincontrastwiththesettinginSection2,inwhichthemodelproducesbothaclasspredictionandconﬁdence.modelaveraging.Essentially,BBQmarginalizesoutallpossiblebinningschemestoproduceˆqi.Moreformally,abinningschemesisapair(M,I)whereMisthenumberofbins,andIisacorrespondingpartitioningof[0,1]intodisjointintervals(0=a1≤a2≤...≤aM+1=1).Theparametersofabinningschemeareθ1,...,θM.Underthisframework,histogrambinningandisotonicregressionbothproduceasinglebinningscheme,whereasBBQconsidersaspaceSofallpossiblebinningschemesforthevalida-tiondatasetD.BBQperformsBayesianaveragingoftheprobabilitiesproducedbyeachscheme:2P(ˆqte|ˆpte,D)=Xs∈SP(ˆqte,S=s|ˆpte,D)=Xs∈SP(ˆqte|ˆpte,S=s,D)P(S=s|D).whereP(ˆqte|ˆpte,S=s,D)isthecalibratedprobabilityusingbinningschemes.Usingauniformprior,theweightP(S=s|D)canbederivedusingBayes’rule:P(S=s|D)=P(D|S=s)Ps0∈SP(D|S=s0).Theparametersθ1,...,θMcanbeviewedasparametersofMindependentbinomialdistributions.Hence,byplacingaBetaprioronθ1,...,θM,wecanobtainaclosedformexpressionforthemarginallikelihoodP(D|S=s).ThisallowsustocomputeP(ˆqte|ˆpte,D)foranytestinput.Plattscaling(Plattetal.,1999)isaparametricapproachtocalibration,unliketheotherapproaches.Thenon-probabilisticpredictionsofaclassiﬁerareusedasfeaturesforalogisticregressionmodel,whichistrainedontheval-idationsettoreturnprobabilities.Morespeciﬁcally,inthecontextofneuralnetworks(Niculescu-Mizil&Caruana,2005),Plattscalinglearnsscalarparametersa,b∈Randoutputsˆqi=σ(azi+b)asthecalibratedprobability.Pa-rametersaandbcanbeoptimizedusingtheNLLlossoverthevalidationset.Itisimportanttonotethattheneuralnetwork’sparametersareﬁxedduringthisstage.4.2.ExtensiontoMulticlassModelsForclassiﬁcationproblemsinvolvingK>2classes,wereturntotheoriginalproblemformulation.Thenetworkoutputsaclasspredictionˆyiandconﬁdencescoreˆpiforeachinputxi.Inthiscase,thenetworklogitsziarevectors,whereˆyi=argmaxkz(k)i,andˆpiistypicallyderivedusingthesoftmaxfunctionσSM:σSM(zi)(k)=exp(z(k)i)PKj=1exp(z(j)i),ˆpi=maxkσSM(zi)(k).Thegoalistoproduceacalibratedconﬁdenceˆqiand(pos-siblynew)classpredictionˆy0ibasedonyi,ˆyi,ˆpi,andzi.2Becausethevalidationdatasetisﬁnite,Sisaswell.DatasetModelUncalibratedHist.BinningIsotonicBBQTemp.ScalingVectorScalingMatrixScalingBirdsResNet509.19%4.34%5.22%4.12%1.85%3.0%21.13%CarsResNet504.3%1.74%4.29%1.84%2.35%2.37%10.5%CIFAR-10ResNet1104.6%0.58%0.81%0.54%0.83%0.88%1.0%CIFAR-10ResNet110(SD)4.12%0.67%1.11%0.9%0.6%0.64%0.72%CIFAR-10WideResNet324.52%0.72%1.08%0.74%0.54%0.6%0.72%CIFAR-10DenseNet403.28%0.44%0.61%0.81%0.33%0.41%0.41%CIFAR-10LeNet53.02%1.56%1.85%1.59%0.93%1.15%1.16%CIFAR-100ResNet11016.53%2.66%4.99%5.46%1.26%1.32%25.49%CIFAR-100ResNet110(SD)12.67%2.46%4.16%3.58%0.96%0.9%20.09%CIFAR-100WideResNet3215.0%3.01%5.85%5.77%2.32%2.57%24.44%CIFAR-100DenseNet4010.37%2.68%4.51%3.59%1.18%1.09%21.87%CIFAR-100LeNet54.85%6.48%2.35%3.77%2.02%2.09%13.24%ImageNetDenseNet1616.28%4.52%5.18%3.51%1.99%2.24%-ImageNetResNet1525.48%4.36%4.77%3.56%1.86%2.23%-SVHNResNet152(SD)0.44%0.14%0.28%0.22%0.17%0.27%0.17%20NewsDAN38.02%3.6%5.52%4.98%4.11%4.61%9.1%ReutersDAN30.85%1.75%1.15%0.97%0.91%0.66%1.58%SSTBinaryTreeLSTM6.63%1.93%1.65%2.27%1.84%1.84%1.84%SSTFineGrainedTreeLSTM6.71%2.09%1.65%2.61%2.56%2.98%2.39%Table1.ECE(%)(withM=15bins)onstandardvisionandNLPdatasetsbeforecalibrationandwithvariouscalibrationmethods.Thenumberfollowingamodel’snamedenotesthenetworkdepth.Extensionofbinningmethods.Onecommonwayofex-tendingbinarycalibrationmethodstothemulticlasssettingisbytreatingtheproblemasKone-versus-allproblems(Zadrozny&Elkan,2002).Fork=1,...,K,weformabinarycalibrationproblemwherethelabelis1(yi=k)andthepredictedprobabilityisσSM(zi)(k).ThisgivesusKcalibrationmodels,eachforaparticularclass.Attesttime,weobtainanunnormalizedprobabilityvector[ˆq(1)i,...,ˆq(K)i],whereˆq(k)iisthecalibratedprobabilityforclassk.Thenewclasspredictionˆy0iistheargmaxofthevector,andthenewconﬁdenceˆq0iisthemaxofthevectornormalizedbyPKk=1ˆq(k)i.Thisextensioncanbeappliedtohistogrambinning,isotonicregression,andBBQ.Matrixandvectorscalingaretwomulti-classexten-sionsofPlattscaling.Letzibethelogitsvectorproducedbeforethesoftmaxlayerforinputxi.Matrixscalingap-pliesalineartransformationWzi+btothelogits:ˆqi=maxkσSM(Wzi+b)(k),ˆy0i=argmaxk(Wzi+b)(k).(8)TheparametersWandbareoptimizedwithrespecttoNLLonthevalidationset.AsthenumberofparametersformatrixscalinggrowsquadraticallywiththenumberofclassesK,wedeﬁnevectorscalingasavariantwhereWisrestrictedtobeadiagonalmatrix.Temperaturescaling,thesimplestextensionofPlattscaling,usesasinglescalarparameterT>0forallclasses.Giventhelogitvectorzi,thenewconﬁdencepredictionisˆqi=maxkσSM(zi/T)(k).(9)Tiscalledthetemperature,andit“softens”thesoftmax(i.e.raisestheoutputentropy)withT>1.AsT→∞,theprobabilityˆqiapproaches1/K,whichrepresentsmax-imumuncertainty.WithT=1,werecovertheoriginalprobabilityˆpi.AsT→0,theprobabilitycollapsestoapointmass(i.e.ˆqi=1).TisoptimizedwithrespecttoNLLonthevalidationset.BecausetheparameterTdoesnotchangethemaximumofthesoftmaxfunction,theclasspredictionˆy0iremainsunchanged.Inotherwords,temper-aturescalingdoesnotaffectthemodel’saccuracy.Temperaturescalingiscommonlyusedinsettingssuchasknowledgedistillation(Hintonetal.,2015)andstatisticalmechanics(Jaynes,1957).Tothebestofourknowledge,wearenotawareofanyprioruseinthecontextofcalibrat-ingprobabilisticmodels.3Themodelisequivalenttomax-imizingtheentropyoftheoutputprobabilitydistributionsubjecttocertainconstraintsonthelogits(seeSectionS2).4.3.OtherRelatedWorksCalibrationandconﬁdencescoreshavebeenstudiedinvar-iouscontextsinrecentyears.Kuleshov&Ermon(2016)studytheproblemofcalibrationintheonlinesetting,wheretheinputscancomefromapotentiallyadversarialsource.Kuleshov&Liang(2015)investigatehowtoproducecal-ibratedprobabilitieswhentheoutputspaceisastructuredobject.Lakshminarayananetal.(2016)useensemblesofnetworkstoobtainuncertaintyestimates.Pereyraetal.(2017)penalizeoverconﬁdentpredictionsasaformofreg-ularization.Hendrycks&Gimpel(2017)useconﬁdence3Tohighlighttheconnectionwithpriorworkswedeﬁnetem-peraturescalingintermsof1Tinsteadofamultiplicativescalar.scorestodetermineifsamplesareout-of-distribution.Bayesianneuralnetworks(Denker&Lecun,1990;MacKay,1992)returnaprobabilitydistributionoverout-putsasanalternativewaytorepresentmodeluncertainty.Gal&Ghahramani(2016)drawaconnectionbetweenDropout(Srivastavaetal.,2014)andmodeluncertainty,claimingthatsamplingmodelswithdroppednodesisawaytoestimatetheprobabilitydistributionoverallpos-siblemodelsforagivensample.Kendall&Gal(2017)combinethisapproachwithamodelthatoutputsapredic-tivemeanandvarianceforeachdatapoint.Thisnotionofuncertaintyisnotrestrictedtoclassiﬁcationproblems.Incontrast,ourframework,whichdoesnotrequiremodelsampling,returnsaconﬁdenceforagivenoutputratherthanreturningadistributionofpossibleoutputs.5.ResultsWeapplythecalibrationmethodsinSection4toimageclassiﬁcationanddocumentclassiﬁcationneuralnetworks.Forimageclassiﬁcationweuse6datasets:1.Caltech-UCSDBirds(Welinderetal.,2010):200birdspecies.5994/2897/2897imagesfortrain/validation/testsets.2.StanfordCars(Krauseetal.,2013):196classesofcarsbymake,model,andyear.8041/4020/4020im-agesfortrain/validation/test.3.ImageNet2012(Dengetal.,2009):Naturalsceneim-agesfrom1000classes.1.3million/25,000/25,000imagesfortrain/validation/test.4.CIFAR-10/CIFAR-100(Krizhevsky&Hinton,2009):Colorimages(32×32)from10/100classes.45,000/5,000/10,000imagesfortrain/validation/test.5.StreetViewHouseNumbers(SVHN)(Netzeretal.,2011):32×32coloredimagesofcroppedouthousenumbersfromGoogleStreetView.604,388/6,000/26,032imagesfortrain/validation/test.Wetrainstate-of-the-artconvolutionalnetworks:ResNets(Heetal.,2016),ResNetswithstochasticdepth(SD)(Huangetal.,2016),WideResNets(Zagoruyko&Ko-modakis,2016),andDenseNets(Huangetal.,2017).Weusethedatapreprocessing,trainingprocedures,andhyper-parametersasdescribedineachpaper.ForBirdsandCars,weﬁne-tunenetworkspretrainedonImageNet.Fordocumentclassiﬁcationweexperimentwith4datasets:1.20News:Newsarticles,partitionedinto20cate-goriesbycontent.9034/2259/7528documentsfortrain/validation/test.2.Reuters:Newsarticles,partitionedinto8cate-goriesbytopic.4388/1097/2189documentsfortrain/validation/test.3.StanfordSentimentTreebank(SST)(Socheretal.,2013):Moviereviews,representedassentenceparsetreesthatareannotatedbysentiment.Eachsamplein-cludesacoarsebinarylabelandaﬁnegrained5-classlabel.Asdescribedin(Taietal.,2015),thetrain-ing/validation/testsetscontain6920/872/1821docu-mentsforbinary,and544/1101/2210forﬁne-grained.On20NewsandReuters,wetrainDeepAveragingNet-works(DANs)(Iyyeretal.,2015)with3feed-forwardlayersandBatchNormalization.Thesenetworksobtaincompetitiveaccuracyusingtheoptimizationhyperparam-eterssuggestedbytheoriginalpaper.OnSST,wetrainTreeLSTMs(LongShortTermMemory)(Taietal.,2015)usingthedefaultsettingsintheauthors’code.CalibrationResults.Table1displaysmodelcalibration,asmeasuredbyECE(withM=15bins),beforeandaf-terapplyingthevariousmethods(seeSectionS3forMCE,NLL,anderrortables).Itisworthnotingthatmostdatasetsandmodelsexperiencesomedegreeofmiscalibration,withECEtypicallybetween4to10%.Thisisnotarchitecturespeciﬁc:weobservemiscalibrationonconvolutionalnet-works(withandwithoutskipconnections),recurrentnet-works,anddeepaveragingnetworks.Thetwonotableex-ceptionsareSVHNandReuters,bothofwhichexperienceECEvaluesbelow1%.Bothofthesedatasetshaveverylowerror(1.98%and2.97%,respectively);andthereforetheratioofECEtoerroriscomparabletootherdatasets.Ourmostimportantdiscoveryisthesurprisingeffective-nessoftemperaturescalingdespiteitsremarkablesimplic-ity.Temperaturescalingoutperformsallothermethodsonthevisiontasks,andperformscomparablytoothermethodsontheNLPdatasets.Whatisperhapsevenmoresurpris-ingisthattemperaturescalingoutperformsthevectorandmatrixPlattscalingvariants,whicharestrictlymoregen-eralmethods.Infact,vectorscalingrecoversessentiallythesamesolutionastemperaturescaling–thelearnedvec-torhasnearlyconstantentries,andthereforeisnodifferentthanascalartransformation.Inotherwords,networkmis-calibrationisintrinsicallylowdimensional.TheonlydatasetthattemperaturescalingdoesnotcalibrateistheReutersdataset.Inthisinstance,onlyoneoftheabovemethodsisabletoimprovecalibration.Becausethisdatasetiswell-calibratedtobeginwith(ECE≤1%),thereisnotmuchroomforimprovementwithanymethod,andpost-processingmaynotevenbenecessarytobeginwith.Itisalsopossiblethatourmeasurementsareaffectedbydatasetsplitorbytheparticularbinningscheme.Matrixscalingperformspoorlyondatasetswithhundredsofclasses(i.e.Birds,Cars,andCIFAR-100),andfailstoconvergeonthe1000-classImageNetdataset.Thisisexpected,sincethenumberofparametersscalesquadrat-0.00.20.40.60.81.00.00.20.40.60.81.0AccuracyECE=12.67Uncal.-CIFAR-100ResNet-110(SD)OutputsGap0.00.20.40.60.81.0ECE=0.96Temp.Scale-CIFAR-100ResNet-110(SD)OutputsGap0.00.20.40.60.81.0ECE=2.46Hist.Bin.-CIFAR-100ResNet-110(SD)OutputsGap0.00.20.40.60.81.0ECE=4.16Iso.Reg.-CIFAR-100ResNet-110(SD)OutputsGapConﬁdenceFigure4.ReliabilitydiagramsforCIFAR-100before(farleft)andaftercalibration(middleleft,middleright,farright).icallywiththenumberofclasses.Anycalibrationmodelwithtensofthousands(ormore)parameterswilloverﬁttoasmallvalidationset,evenwhenapplyingregularization.Binningmethodsimprovecalibrationonmostdatasets,butdonotoutperformtemperaturescaling.Additionally,bin-ningmethodstendtochangeclasspredictionswhichhurtsaccuracy(seeSectionS3).Histogrambinning,thesimplestbinningmethod,typicallyoutperformsisotonicregressionandBBQ,despitethefactthatbothmethodsarestrictlymoregeneral.Thisfurthersupportsourﬁndingthatcali-brationisbestcorrectedbysimplemodels.Reliabilitydiagrams.Figure4containsreliabilitydia-gramsfor110-layerResNetsonCIFAR-100beforeandaf-tercalibration.Fromthefarleftdiagram,weseethattheuncalibratedResNettendstobeoverconﬁdentinitspre-dictions.Wethencanobservetheeffectsoftemperaturescaling(middleleft),histogrambinning(middleright),andisotonicregression(farright)oncalibration.Allthreedis-playedmethodsproducemuchbetterconﬁdenceestimates.Ofthethreemethods,temperaturescalingmostcloselyre-coversthedesireddiagonalfunction.Eachofthebinsarewellcalibrated,whichisremarkablegiventhatalltheprob-abilitiesweremodiﬁedbyonlyasingleparameter.Wein-cludereliabilitydiagramsforotherdatasetsinSectionS4.Computationtime.Allmethodsscalelinearlywiththenumberofvalidationsetsamples.Temperaturescalingisbyfarthefastestmethod,asitamountstoaone-dimensionalconvexoptimizationproblem.Usingaconju-gategradientsolver,theoptimaltemperaturecanbefoundin10iterations,orafractionofasecondonmostmodernhardware.Infact,evenanaiveline-searchfortheoptimaltemperatureisfasterthananyoftheothermethods.Thecomputationalcomplexityofvectorandmatrixscalingarelinearandquadraticrespectivelyinthenumberofclasses,reﬂectingthenumberofparametersineachmethod.ForCIFAR-100(K=100),ﬁndinganear-optimalvectorscal-ingsolutionwithconjugategradientdescentrequiresatleast2ordersofmagnitudemoretime.Histogrambinningandisotonicregressiontakeanorderofmagnitudelongerthantemperaturescaling,andBBQtakesroughly3ordersofmagnitudemoretime.Easeofimplementation.BBQisarguablythemostdif-ﬁculttoimplement,asitrequiresimplementingamodelaveragingscheme.Whileallothermethodsarerelativelyeasytoimplement,temperaturescalingmayarguablybethemoststraightforwardtoincorporateintoaneuralnet-workpipeline.InTorch7(Collobertetal.,2011),forex-ample,weimplementtemperaturescalingbyinsertingann.MulConstantbetweenthelogitsandthesoftmax,whoseparameteris1/T.WesetT=1duringtraining,andsubsequentlyﬁnditsoptimalvalueonthevalidationset.6.ConclusionModernneuralnetworksexhibitastrangephenomenon:probabilisticerrorandmiscalibrationworsenevenasclas-siﬁcationerrorisreduced.Wehavedemonstratedthatrecentadvancesinneuralnetworkarchitectureandtrain-ing–modelcapacity,normalization,andregularization–havestrongeffectsonnetworkcalibration.Itremainsfutureworktounderstandwhythesetrendsaffectcali-brationwhileimprovingaccuracy.Nevertheless,simpletechniquescaneffectivelyremedythemiscalibrationphe-nomenoninneuralnetworks.Temperaturescalingisthesimplest,fastest,andmoststraightforwardofthemethods,andsurprisinglyisoftenthemosteffective.AcknowledgmentsTheauthorsaresupportedinpartbytheIII-1618134,III-1526012,andIIS-1149882grantsfromtheNationalSci-enceFoundation,aswellastheBillandMelindaGatesFoundationandtheOfﬁceofNavalResearch.ReferencesBengio,Yoshua,Goodfellow,IanJ,andCourville,Aaron.Deeplearning.Nature,521:436–444,2015.Bojarski,Mariusz,DelTesta,Davide,Dworakowski,Daniel,Firner,Bernhard,Flepp,Beat,Goyal,Prasoon,Jackel,LawrenceD,Monfort,Mathew,Muller,Urs,Zhang,Jiakai,etal.Endtoendlearningforself-drivingcars.arXivpreprintarXiv:1604.07316,2016.Caruana,Rich,Lou,Yin,Gehrke,Johannes,Koch,Paul,Sturm,Marc,andElhadad,Noemie.Intelligiblemodelsforhealthcare:Predictingpneumoniariskandhospital30-dayreadmission.InKDD,2015.Collobert,Ronan,Kavukcuoglu,Koray,andFarabet,Cl´ement.Torch7:Amatlab-likeenvironmentforma-chinelearning.InBigLearnWorkshop,NIPS,2011.Cosmides,LedaandTooby,John.Arehumansgoodintu-itivestatisticiansafterall?rethinkingsomeconclusionsfromtheliteratureonjudgmentunderuncertainty.cog-nition,58(1):1–73,1996.DeGroot,MorrisHandFienberg,StephenE.Thecompar-isonandevaluationofforecasters.Thestatistician,pp.12–22,1983.Deng,Jia,Dong,Wei,Socher,Richard,Li,Li-Jia,Li,Kai,andFei-Fei,Li.Imagenet:Alarge-scalehierarchicalimagedatabase.InCVPR,pp.248–255,2009.Denker,JohnSandLecun,Yann.Transformingneural-netoutputlevelstoprobabilitydistributions.InNIPS,pp.853–859,1990.Friedman,Jerome,Hastie,Trevor,andTibshirani,Robert.Theelementsofstatisticallearning,volume1.SpringerseriesinstatisticsSpringer,Berlin,2001.Gal,YarinandGhahramani,Zoubin.Dropoutasabayesianapproximation:Representingmodeluncertaintyindeeplearning.InICML,2016.Girshick,Ross.Fastr-cnn.InICCV,pp.1440–1448,2015.Hannun,Awni,Case,Carl,Casper,Jared,Catanzaro,Bryan,Diamos,Greg,Elsen,Erich,Prenger,Ryan,Satheesh,Sanjeev,Sengupta,Shubho,Coates,Adam,etal.Deepspeech:Scalingupend-to-endspeechrecog-nition.arXivpreprintarXiv:1412.5567,2014.He,Kaiming,Zhang,Xiangyu,Ren,Shaoqing,andSun,Jian.Deepresiduallearningforimagerecognition.InCVPR,pp.770–778,2016.Hendrycks,DanandGimpel,Kevin.Abaselineforde-tectingmisclassiﬁedandout-of-distributionexamplesinneuralnetworks.InICLR,2017.Hinton,Geoffrey,Vinyals,Oriol,andDean,Jeff.Distillingtheknowledgeinaneuralnetwork.2015.Huang,Gao,Sun,Yu,Liu,Zhuang,Sedra,Daniel,andWeinberger,Kilian.Deepnetworkswithstochasticdepth.InECCV,2016.Huang,Gao,Liu,Zhuang,Weinberger,KilianQ,andvanderMaaten,Laurens.Denselyconnectedconvolu-tionalnetworks.InCVPR,2017.Ioffe,SergeyandSzegedy,Christian.Batchnormalization:Acceleratingdeepnetworktrainingbyreducinginternalcovariateshift.2015.Iyyer,Mohit,Manjunatha,Varun,Boyd-Graber,Jordan,andDaum´eIII,Hal.Deepunorderedcompositionrivalssyntacticmethodsfortextclassiﬁcation.InACL,2015.Jaynes,EdwinT.Informationtheoryandstatisticalme-chanics.Physicalreview,106(4):620,1957.Jiang,Xiaoqian,Osl,Melanie,Kim,Jihoon,andOhno-Machado,Lucila.Calibratingpredictivemodelestimatestosupportpersonalizedmedicine.JournaloftheAmer-icanMedicalInformaticsAssociation,19(2):263–274,2012.Kendall,AlexandCipolla,Roberto.Modellinguncertaintyindeeplearningforcamerarelocalization.2016.Kendall,AlexandGal,Yarin.Whatuncertaintiesdoweneedinbayesiandeeplearningforcomputervision?arXivpreprintarXiv:1703.04977,2017.Krause,Jonathan,Stark,Michael,Deng,Jia,andFei-Fei,Li.3dobjectrepresentationsforﬁne-grainedcatego-rization.InIEEEWorkshopon3DRepresentationandRecognition(3dRR),Sydney,Australia,2013.Krizhevsky,AlexandHinton,Geoffrey.Learningmultiplelayersoffeaturesfromtinyimages,2009.Kuleshov,VolodymyrandErmon,Stefano.Reliablecon-ﬁdenceestimationviaonlinelearning.arXivpreprintarXiv:1607.03594,2016.Kuleshov,VolodymyrandLiang,Percy.Calibratedstruc-turedprediction.InNIPS,pp.3474–3482,2015.Lakshminarayanan,Balaji,Pritzel,Alexander,andBlun-dell,Charles.Simpleandscalablepredictiveuncer-taintyestimationusingdeepensembles.arXivpreprintarXiv:1612.01474,2016.LeCun,Yann,Bottou,L´eon,Bengio,Yoshua,andHaffner,Patrick.Gradient-basedlearningappliedtodocumentrecognition.ProceedingsoftheIEEE,86(11):2278–2324,1998.SupplementaryMaterials:OnCalibrationofModernNeuralNetworksMacKay,DavidJC.Apracticalbayesianframeworkforbackpropagationnetworks.Neuralcomputation,4(3):448–472,1992.Naeini,MahdiPakdaman,Cooper,GregoryF,andHauskrecht,Milos.Obtainingwellcalibratedprobabili-tiesusingbayesianbinning.InAAAI,pp.2901,2015.Netzer,Yuval,Wang,Tao,Coates,Adam,Bissacco,Alessandro,Wu,Bo,andNg,AndrewY.Readingdig-itsinnaturalimageswithunsupervisedfeaturelearning.InDeepLearningandUnsupervisedFeatureLearningWorkshop,NIPS,2011.Niculescu-Mizil,AlexandruandCaruana,Rich.Predictinggoodprobabilitieswithsupervisedlearning.InICML,pp.625–632,2005.Pereyra,Gabriel,Tucker,George,Chorowski,Jan,Kaiser,Łukasz,andHinton,Geoffrey.Regularizingneuralnetworksbypenalizingconﬁdentoutputdistributions.arXivpreprintarXiv:1701.06548,2017.Platt,Johnetal.Probabilisticoutputsforsupportvec-tormachinesandcomparisonstoregularizedlikelihoodmethods.Advancesinlargemarginclassiﬁers,10(3):61–74,1999.Simonyan,KarenandZisserman,Andrew.Verydeepcon-volutionalnetworksforlarge-scaleimagerecognition.InICLR,2015.Socher,Richard,Perelygin,Alex,Wu,Jean,Chuang,Ja-son,Manning,ChristopherD.,Ng,Andrew,andPotts,Christopher.Recursivedeepmodelsforsemanticcom-positionalityoverasentimenttreebank.InEMNLP,pp.1631–1642,2013.Srivastava,Nitish,Hinton,Geoffrey,Krizhevsky,Alex,Sutskever,Ilya,andSalakhutdinov,Ruslan.Dropout:Asimplewaytopreventneuralnetworksfromoverﬁtting.JournalofMachineLearningResearch,15:1929–1958,2014.Srivastava,RupeshKumar,Greff,Klaus,andSchmid-huber,J¨urgen.Highwaynetworks.arXivpreprintarXiv:1505.00387,2015.Tai,KaiSheng,Socher,Richard,andManning,Christo-pherD.Improvedsemanticrepresentationsfromtree-structuredlongshort-termmemorynetworks.2015.Vapnik,VladimirN.StatisticalLearningTheory.Wiley-Interscience,1998.Welinder,P.,Branson,S.,Mita,T.,Wah,C.,Schroff,F.,Belongie,S.,andPerona,P.Caltech-UCSDBirds200.TechnicalReportCNS-TR-2010-001,CaliforniaInsti-tuteofTechnology,2010.Xiong,Wayne,Droppo,Jasha,Huang,Xuedong,Seide,Frank,Seltzer,Mike,Stolcke,Andreas,Yu,Dong,andZweig,Geoffrey.Achievinghumanparityinconversationalspeechrecognition.arXivpreprintarXiv:1610.05256,2016.Zadrozny,BiancaandElkan,Charles.Obtainingcal-ibratedprobabilityestimatesfromdecisiontreesandnaivebayesianclassiﬁers.InICML,pp.609–616,2001.Zadrozny,BiancaandElkan,Charles.Transformingclassi-ﬁerscoresintoaccuratemulticlassprobabilityestimates.InKDD,pp.694–699,2002.Zagoruyko,SergeyandKomodakis,Nikos.Wideresidualnetworks.InBMVC,2016.Zhang,Chiyuan,Bengio,Samy,Hardt,Moritz,Recht,Ben-jamin,andVinyals,Oriol.Understandingdeeplearningrequiresrethinkinggeneralization.InICLR,2017.