Bidirectional Learning for Time-series Models with Hidden Units

Takayuki Osogami 1 Hiroshi Kajino 1 Taro Sekiyama 1

Abstract

Hidden units can play essential roles in modeling
time-series having long-term dependency or non-
linearity but make it difﬁcult to learn associated
parameters. Here we propose a way to learn such
a time-series model by training a backward model
for the time-reversed time-series, where the back-
ward model has a common set of parameters as
the original (forward) model. Our key observation
is that only a subset of the parameters is hard to
learn, and that subset is complementary between
the forward model and the backward model. By
training both of the two models, we can effec-
tively learn the values of the parameters that are
hard to learn if only either of the two models is
trained. We apply bidirectional learning to a dy-
namic Boltzmann machine extended with hidden
units. Numerical experiments with synthetic and
real datasets clearly demonstrate advantages of
bidirectional learning.

1. Introduction

Learning from time-series data is of paramount importance
for prediction, anomaly detection, classiﬁcation, and other
critical tasks that appear in business and society. Various
models of time-series have been studied in the literature to
better learn from time-series data. These include vector auto-
regressive (VAR) models (L¨utkepohl, 2005), hidden Markov
models (HMM) (Baum & Petrie, 1966), and recurrent neural
networks (RNN) (Rumelhart et al., 1986), including long
short term memory (LSTM) (Hochreiter & Schmidhuber,
1997) and echo state networks (ESN) (Jaeger & Haas, 2004).
With these models of time-series, one seeks to learn the
relation between past values and future values.

In some of these models of time-series, hidden units (or
latent variables) play essential roles in taking into account
long term dependency or non-linearity in time-series. Hid-

1IBM Research - Tokyo, Tokyo, Japan. Correspondence to:

Takayuki Osogami <osogami@jp.ibm.com>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by
the author(s).

den units, however, make it difﬁcult to learn the parameters
of those models. For example, the Baum-Welch algorithm
(Baum & Petrie, 1966) learns the parameters of an HMM
by iteration of expectation and maximization (i.e., an EM
algorithm). An RNN, including LSTM, is trained via back
propagation through time (Rumelhart et al., 1986). These
algorithms are time-consuming and do not necessarily ﬁnd
optimal values of the parameters.

This difﬁculty in learning a model with hidden units partly
stems from the fact that the values of hidden units can only
be reliably estimated after observing future values of target
time-series. It then requires iteration or back propagation to
learn the relation between the hidden values and preceding
values. An ESN, on the other hand, gives up learning the
hard-to-learn parameters between hidden values and pre-
ceding (visible or hidden) values and set those parameters
randomly. The ESN only learns the relation between visible
values and preceding (hidden) values (Jaeger & Haas, 2004).

We study a model of time-series whose parameters can be
represented as a matrix M or a set of such matrices. An
element Mi,j of the matrix may, for example, represent the
weight between a past value of a unit i and a future value of
a unit j. In a VAR model, each matrix corresponds to the
coefﬁcients for a particular lag. In an RNN, a matrix corre-
sponds to the weight between hidden units. We consider a
situation where it is hard to estimate an appropriate value
of Mi,j for some of the units j ∈ H (in particular, H may
denote the set of hidden units).

We propose a method of training a time-series model with
hidden units in a bidirectional manner, one from the past
and the other from the future. From a time-series model
with parameter M, we construct a backward model, whose
parameters are represented by the transposed matrix M(cid:62)
or a set of such transposed matrices. The (i, j)-th element
of M(cid:62) is Mj,i, which represents the weight between a
preceding value of a unit j and a succeeding value of a
unit i. Our key idea is to let the preceding value represent a
future value and the succeeding value represent a past value
in the backward model. Then an intuitive meaning of Mj,i
in the backward model matches that in the original (forward)
model. We use a common matrix M both in the forward
model and in the backward model. Namely, the parameters
are shared between the two models.

Bidirectional Learning for Time-series Models with Hidden Units

The two models have an identical structure and trained in an
identical manner with a stochastic gradient method (Bottou,
2009) except that we train the forward model using time-
series in a standard (forward) manner and the backward
model using the time-series from the future to the past. We
alternately train the forward model to learn M and the back-
ward model to learn M(cid:62). An advantage of our bidirectional
training is that the elements of M that are hard to estimate
differ between when we train the forward model and when
we train the backward model. For the forward model, it
is hard to estimate Mi,j for j ∈ H (i.e., M:,H). For the
backward model, it is hard to estimate Mj,i for j ∈ H (i.e.,
MH,: = (M(cid:62)):,H). Although MH,H is hard to estimate
for both models, the other elements of M can be reliably
estimated in either of the two models. This idea of bidirec-
tional training for learning time-series models with hidden
units constitutes our ﬁrst contribution.

Here, we extend a Dynamic Boltzmann Machine (DyBM)
to incorporate hidden units and apply bidirectional training
to learn its parameters. The DyBM has been proposed by
Osogami & Otsuka (2015a;b) and subsequently studied by
Dasgupta et al. (2016); Dasgupta & Osogami (2017); Ka-
jino (2017). The prior work on the DyBM does not consider
hidden units but instead uses various features of past values
to capture the long term dependency in time-series. For
example, Dasgupta & Osogami (2017) use an ESN to cre-
ate nonlinear features of past values. In our context, these
features are fed into visible units of a DyBM. In partic-
ular, what features of past values are used is determined
randomly without learning. Our analysis of the DyBM with
hidden units illuminates the difﬁculty of learning some of
its parameters. With bidirectional learning, we seek to learn
the weight from the past visible values to the future hidden
values, which corresponds to learning what features of past
values are effective for prediction. The DyBM with hidden
units and its analysis constitute our second contribution.

We validate the effectiveness of bidirectional training and
the hidden units in DyBMs through numerical experiments
using synthetic and real time-series. We will show that the
DyBM with hidden units can be trained more effectively
with bidirectional training and reduces the predictive error
by up to 90 %.

1.1. Related Work

Our bidirectional training is related to but different from
bidirectional recurrent neural networks (BRNN) (Schuster
& Paliwal, 1997; Baldi et al., 1999), including bidirectional
LSTM (Graves & Schmidhuber, 2005; Chen & Chaudhari,
2005). Similar to our bidirectional training, a BRNN trains
both a forward model and a backward model. These two
models, however, do not share parameters, contrary to our
bidirectional training. In fact, motivation and purpose of the

BRNN are quite different from ours. The BRNN uses both
the sequence from the past and the sequence from the future
to better estimate missing values. The BRNN thus needs
both of the two sequences for learning and for prediction.
On the other hand, our bidirectional training uses both a
forward sequence and a backward sequence at the time
of learning, but the trained model uses only the sequence
from the past to predict future unseen values. Namely, our
bidirectional training is used to learn a model for predicting
future values from past values, while the BRNN is used for
estimating missing values from past and future values.

Our bidirectional training is also related to but different
from Forward Backward Lasso Granger (FBLG) by Cheng
et al. (2014). In FBLG, forward and backward VAR models
are estimated with Lasso, and an averaged model is used
to infer the Granger causality. The VAR models in FBLG
do not have hidden units, while our bidirectional training is
motivated by the need for training time-series models with
hidden units. Winkler et al. (2016) also study a backward
VAR in the context of the Granger causality but do not
consider hidden units.

Another related work is structure learning of a VAR model
(Bahadori et al., 2013) or a simpler linear dynamical sys-
tem (Jalali & Sanghavi, 2012) that takes into account the
existence of unobserved (or latent) variables. However,
their goal is to reliably estimate the structure of the relation
between observable variables by taking into account the un-
observed variables. This is in contrast to the purpose of our
bidirectional training, which aims at learning the relation
between visible units and hidden units.

2. DyBM with Hidden Units

We study a particularly structured Boltzmann machine for
time-series (see Figure 1). Corresponding to a segment
of a time-series of length T + 1, the Boltzmann machine
in Figure 1 has T + 1 layers in the horizontal (temporal)
direction. Each layer corresponds to a time t−δ for 0 ≤ δ ≤
T . Each layer has two parts, hidden and visible. The visible
part x[t−δ] at the δ-th layer represents the values of the time-
series at time t − δ. The hidden part h[t−δ] represents the
values of hidden units at time t − δ. Here, units within
each layer do not have connections to each other. We let
x[<t] ≡ (x[s])t−T ≤s<t and deﬁne h[<t] analogously.

The Boltzmann machine in Figure 1 has bias parameter b
and weight parameter (U, V, W, Z). Let θ ≡ (V, W, b)
be the parameters connected to visible units x[t] (from the
units in the past, x[s] or h[s] for s < t) and φ ≡ (U, Z).
The energy of this Boltzmann machine is given as follows:

Eθ,φ(x[t], h[t]|x[<t], h[<t])
= Eθ(x[t]|x[<t], h[<t]) + Eφ(h[t]|x[<t], h[<t]),

(1)

Bidirectional Learning for Time-series Models with Hidden Units

Figure 1. A (forward) DyBM with hidden units.

Figure 2. A backward DyBM.

where we deﬁne

Eθ(x[t]|x[<t], h[<t])

T
(cid:88)

δ=1

= −b(cid:62)x[t] −

(x[t−δ])(cid:62)W[δ] x[t] −

(h[t−δ])(cid:62)V[δ] x[t]

T
(cid:88)

δ=1

(2)

for any binary vector x[t], where Z is the normalization
factor for the probabilities to sum up to one. Due to the
structure in Figure 1, the values in x[t] = (x[t]
i )i=1,2,... are
conditionally independent of each other given x[<t] and
h[<t], so that we can represent

and deﬁne Eφ(h[t]|x[<t], h[<t]) from (2) by letting W ←
U, V ← Z, b ← 0, and x[t] ← h[h].

Similar to the DyBM in Osogami & Otsuka (2015a), we
study the case where W ≡ (W[δ])1≤δ≤T and other matri-
ces have the following parametric forms for δ ≥ d:

W[δ] = λδ−d W[d], V[δ] = λδ−d V[d],
Z[δ] = λδ−d Z[d], U[δ] = λδ−d U[d],

(3)

(4)

where λ is a decay rate satisfying 0 ≤ λ < 1. Then, in the
limit of T → ∞, the energy in (2) can be represented as
follows (and Eφ(h[t]|x[<t], h[<t]) has an analogous limit
shown in (37) of the supplementary material):

Eθ(x[t]|x[<t], h[<t])

d−1
(cid:88)

δ=1

= −b(cid:62)x[t] −

(x[t−δ])(cid:62)W[δ] x[t] −

(h[t−δ])(cid:62)V[δ] x[t]

d−1
(cid:88)

δ=1

∞
(cid:88)

δ=d

− (α[t−1])(cid:62)W[d] x[t] − (β[t−1])(cid:62)V[d] x[t],

(5)

where α[t−1] is referred to as an eligibility trace in Osogami
& Otsuka (2015a) and deﬁned as follows (here, we deﬁne
an eligibility trace β[t−1] for the hidden part analogously):

α[t−1] ≡

λδ−d x[t−δ], β[t−1] ≡

λδ−d h[t−δ].

(6)

∞
(cid:88)

δ=d

The energy in (5) gives the conditional probability distri-
bution over x[t] given x[<t] and h[<t]. For binary-valued
time-series, we have

pθ(x[t]|x[<t], h[<t]) =

exp(−Eθ(x[t]|x[<t], h[<t])) (7)

1
Z

pθ(x[t]|x[<t], h[<t]) =

pθ,i(x[t]

i |x[<t], h[<t]), (8)

(cid:89)

i=1,2,...

where the conditional probability pi(x[t]
i |x[<t], h[<t]) is de-
ﬁned with the energy associated with unit i (see Osogami &
Otsuka (2015a)). For real-valued time-series, one can deﬁne
the conditional density pi(x[t]
i |x[<t], h[<t]) with a Gaussian
distribution whose mean is given from the energy associated
with unit i (Dasgupta & Osogami, 2017; Osogami, 2016).
Conditional distributions can be deﬁned analogously for h[t]
(see (40)–(42) and (51) in the supplementary material).

3. Training a DyBM with Hidden Units

Here, we derive a learning rule for θ. We will also see that
φ cannot be trained in an analogous manner.

Our DyBM with binary hidden units gives the probability
of a time-series, x ≡ (x[t])t=(cid:96),...,u, by

pθ,φ(x) =

pφ(˜h|x)

pθ(x[t]|x[<t], ˜h[<t])

(9)

(cid:88)

˜h

u
(cid:89)

t=(cid:96)

where (cid:80)
values of hidden units from time t = (cid:96) to t = u, and

˜h denotes the summation over all of the possible

pφ(˜h|x) ≡

pφ(˜h[s]|x[<s], ˜h[<s]),

(10)

u
(cid:89)

s=(cid:96)

where pφ(˜h[s]|x[<s], ˜h[<s]) is deﬁned analogously to (7)–
(8) and provided in (36) of the supplementary material, and
we arbitrarily deﬁne x[s] = 0 and ˜h[s] = 0 for s < (cid:96).

𝐡𝑡−𝑇𝐱𝑡−𝑇𝐙1𝐡𝑡𝐱𝑡𝐡𝑡−1𝐱𝑡−1𝐡𝑡−𝛿𝐱𝑡−𝛿𝐕1𝐔1𝐖1𝐙𝛿𝐕𝛿𝐖𝛿𝐔𝛿𝐛𝐡𝑡+1𝐱𝑡+1𝐙1𝐡𝑡𝐱𝑡𝐡𝑡+𝑇𝐱𝑡+𝑇𝐡𝑡+𝛿𝐱𝑡+𝛿𝐕1𝐔1𝐖1𝐙𝛿𝐕𝛿𝐖𝛿𝐔𝛿𝐛(11)

(12)

(13)

(14)

(16)

∇φLθ,φ(x)
u
(cid:88)

(cid:88)

=

t=(cid:96)

˜h[<t]

where

t−1
(cid:89)

s=(cid:96)

=

t−1
(cid:88)

s=(cid:96)

∇φpφ(˜h[<t]|x[<t−1])

Bidirectional Learning for Time-series Models with Hidden Units

We seek to maximize the log likelihood of a given x by
maximizing a lower bound given by Jensen’s inequality:

Now we take the gradient of Lθ,φ(x) with respect to φ:

∇φpφ(˜h[<t]|x[<t−1]) log pθ(x[t]|x[<t], ˜h[<t]),

(23)

(cid:16) (cid:88)

= log

pφ(˜h|x)

(cid:17)
pθ(x[t]|x[<t], ˜h[<t])

(cid:88)

≥

pφ(˜h|x) log

pθ(x[t]|x[<t], ˜h[<t])

(cid:17)

u
(cid:89)

t=(cid:96)
(cid:16) u
(cid:89)

t=(cid:96)

u
(cid:88)

t=(cid:96)

log pθ,φ(x)

˜h

˜h

(cid:88)

˜h
u
(cid:88)

=

=

t=(cid:96)

˜h[<t]
≡ Lθ,φ(x),

pφ(˜h|x)

log pθ(x[t]|x[<t], ˜h[<t])

= ∇φ

pφ(˜h[s]|x[<s], ˜h[<s])

(24)

(cid:88)

pφ(˜h[<t]|x[<t−1]) log pθ(x[t]|x[<t], ˜h[<t])

∇φ log pφ(˜h[s]|x[<s], ˜h[<s])

pφ(˜h[s(cid:48)]|x[<s(cid:48)], ˜h[<s(cid:48)])

t−1
(cid:89)

s(cid:48)=(cid:96)

t−1
(cid:88)

s=(cid:96)

= pφ(˜h[<t]|x[<t−1])

∇φ log pφ(˜h[s]|x[<s], ˜h[<s]). (25)

Plugging (25) into the right-hand side of (23), we obtain

pφ(˜h[<t]|x[<t−1]) log pθ(x[t]|x[<t], ˜h[<t])

∇φ log pφ(˜h[s]|x[<s], ˜h[<s]).

(26)

Similar to (16), the expression of (26) suggests a method
of stochastic gradient: at each time t, we sample h[t−1]
according to pφ(h[t−1]|x[<t−1], h[<t−1]) and update φ on
the basis of the following stochastic gradient:

log pθ(x[t]|x[<t], h[<t]) Gt−1,

(27)

where the summation with respect to ˜h[<t] is over all of the
possible values of ˜h[s] for s ≤ t − 1, and

pφ(˜h[<t]|x[<t−1]) ≡

pφ(˜h[s]|x[<s], ˜h[<s]).

(15)

t−1
(cid:89)

s=(cid:96)

The gradient of the lower bound with respect to θ is:

∇φLθ,φ(x)
u
(cid:88)

(cid:88)

=

t=(cid:96)

˜h[<t]

∇θLθ,φ(x)
u
(cid:88)

(cid:88)

=

t=(cid:96)

˜h[<t]

pφ(˜h[<t]|x[<t−1])∇θ log pθ(x[t]|x[<t], ˜h[<t]).

The right-hand side of (16) is a summation of expected
gradients, which suggests a method of stochastic gradi-
ent. Namely, at each step t, we sample h[t−1] according to
pφ(h[t−1]|x[<t−1], h[<t−1]) and update θ on the basis of

∇θ log pθ(x[t]|x[<t], h[<t]).

(17)

where

This learning rule is equivalent to the one for the model
where all of the units are visible, except that the values for
the hidden units are given by sampled values.

Therefore, the learning rule for θ follows directly from Os-
ogami & Otsuka (2015a):

b ← b + η (x[t] − (cid:104)X[t](cid:105)θ)

W[d] ← W[d] + η α[t−1] (x[t] − (cid:104)X[t](cid:105)θ)(cid:62)
V[d] ← V[d] + η β[t−1] (x[t] − (cid:104)X[t](cid:105)θ)(cid:62)
W[δ] ← W[δ] + η x[t−δ] (x[t] − (cid:104)X[t](cid:105)θ)(cid:62)
V[δ] ← V[δ] + η h[t−δ] (x[t] − (cid:104)X[t](cid:105)θ)(cid:62)

(18)

(19)

(20)

(21)

(22)

for 1 ≤ δ < d, where (cid:104)X[t](cid:105)θ denotes the expected values
of x[t] with respect to pθ in (7).

Gt−1 ≡

∇φ log pφ(h[s]|x[<s], h[<s]).

(28)

Computation of (26) involves mainly two interrelated inef-
ﬁciencies. First, although (26) can be approximately com-
puted using sampled hidden values ˜h[<t] in the same way as
(16), the samples cannot be reused after updating φ because
it was sampled from the distribution with the previous pa-
rameter. Second, since each summand of Gt−1 is dependent
on φ, Gt−1 also has to be recomputed after each update.
Thus, the computational complexity of (27) grows linearly
with respect to the length of the time-series (i.e., t − (cid:96)), in
contrast to (17), whose complexity is independent of that
length. One could approximately compute (28) recursively:

Gt ← γ Gt−1 + (1 − γ)∇φ log pφ(h[t]|x[<t], h[<t]),

(29)

t−1
(cid:88)

s=(cid:96)

t−1
(cid:88)

s=(cid:96)

Bidirectional Learning for Time-series Models with Hidden Units

where γ ∈ [0, 1) is a discount factor. The recursive update
rule with γ < 1 puts exponentially small weight γt−s on
∇φ log pφ(h[s]|x[<s], h[<s]) computed with an old value of
φ (i.e., s (cid:28) t). This recursively computed Gt is related to
the momentum in gradient descent (Qian, 1999). See the
supplementary material for speciﬁc learning rules suggested
by (27)–(29).

s

t.

Observe in (26) that ∇φLθ,φ(x) consists of the products
of log pθ(x[t]|x[<t], h[<t]) and ∇φ log pφ(h[s]|x[<s], h[<s])
<
the dependency on
for
Without
log pθ(x[t]|x[<t], h[<t]),
the parameter φ is updated
in a way that h[s] is more likely to be generated (i.e.,
the learning rule would be equivalent to that for visible
units). Such an update rule is undesirable, because h[s]
has been sampled and is not necessarily what we want to
sample again. The dependency on log pθ(x[t]|x[<t], h[<t])
suggests that φ is updated by a large amount if the sampled
h[s] happens to make the future values, x[t] for t > s,
Intuitively, weighting ∇φ log pφ(h[s]|x[<s], h[<s])
likely.
by log pθ(x[t]|x[<t], h[<t]) for t > s is inevitable, because
whether the particular values of hidden units are good for
the purpose of predicting future values will only be known
after seeing future values.

4. Learning with Reversed Time-series

Because the stochastic gradient for φ requires approxima-
tions that are not needed for θ, we might not be able to
learn appropriate values of φ as effectively as θ. This moti-
vates us to consider a backward DyBM in Figure 2, which
has a common set of parameters, (θ, φ), as the forward
DyBM in Figure 1 but deﬁnes the conditional distribution
for time-series from the future. Speciﬁcally, the energy of
the backward DyBM is represented analogously to (1) with
the superscript [< t] replaced by [> t], where we deﬁne

Eθ(x[t]|x[>t], h[>t]) = −b(cid:62)x[t] −

(x[t+δ])(cid:62)(W[δ])(cid:62)x[t]

T
(cid:88)

δ=1

−

(x[t+δ])(cid:62)(U[δ])(cid:62)h[t]

(30)

T
(cid:88)

δ=1

and Eφ(h[t]|x[>t], h[>t]) is deﬁned from (30) by letting
W ← V, U ← Z, b ← 0, and x[t] ← h[t]. Similar
to the forward DyBM, we assume that the weight has the
parametric form of (4) and let T → ∞.

Namely, the backward DyBM is obtained from the forward
DyBM by the following changes: W ← W(cid:62), Z ← Z(cid:62),
U ← V(cid:62), and V ← U(cid:62). The other difference between (2)
and (30) is the sign of δ, but this is because the backward
DyBM deals with time-series from the future.

Because the backward DyBM has the structure that is equiv-
alent to that of the forward DyBM, it can be trained in

the same manner as the forward DyBM but using time-
series from the future. Speciﬁcally, θ(cid:48) ≡ (U(cid:62), W(cid:62), b) in
the backward DyBM is optimized analogously to θ in the
forward DyBM. Likewise, φ(cid:48) ≡ (V(cid:62), Z(cid:62)) is optimized
analogously to φ. Recall that φ and φ(cid:48) are relatively hard to
optimize, and θ and θ(cid:48) are relatively easy to optimize.

Our key observation is that the parameter U, which is in
φ and is relatively hard to optimize in the forward DyBM,
is in θ(cid:48) and is relatively easy to optimize in the backward
DyBM. By training both the forward DyBM and the back-
ward DyBM, we expect to effectively ﬁnd appropriate values
of θ and θ(cid:48).

Consider a stochastic process X(t) whose distribution is
given by a forward DyBM. We remark that the distribution
of the stochastic process X(−t) that is deﬁned by reversing
X(t) is generally different from what the corresponding
backward DyBM gives unless the DyBMs have no hidden
units. The exact distribution of X(−t) needs to be given by
marginalizing out the past values (i.e., succeeding values
for the backward process). Despite this discrepancy, we
expect that bidirectional training is effective because of
intuitive correspondence between the forward DyBM and
the backward DyBM. In particular, W [δ]
i,j in both DyBMs
represent the strength of the correlation between the past
value of unit i and the future value of unit j, where the
time is separated by δ. A recommendation is, however, to
perform backward training more moderately than forward
training. We will show an example of a speciﬁc procedure
in the next section.

5. Numerical Experiments

We now demonstrate the effectiveness of bidirectional train-
ing through numerical experiments in two settings. The
purpose of the ﬁrst setting is to study whether bidirectional
learning of the DyBM with hidden units can indeed learn to
predict what cannot be done without bidirectional learning
or hidden units. We use a synthetic dataset that is designed
speciﬁcally for this purpose. In the second setting, we study
the effectiveness of bidirectional learning and hidden units
on real datasets. We use the two datasets that have been
used in Dasgupta & Osogami (2017) as well as a 391 di-
mensional time-series, which is substantially larger than the
eight or lower dimensional time-series that are used in the
other experiments. The experiments are carried out with a
Python implementation on workstations having 48-64 GB
memory and 2.6-4.0 GHz CPU.

5.1. Speciﬁc Learning Algorithms to Evaluate

For each dataset, we train a DyBM with or without hidden
units. Because all of the datasets are real valued, visible
units are Gaussian and give predictions by (5) with x[t] omit-

Bidirectional Learning for Time-series Models with Hidden Units

Algorithm 1 Speciﬁc steps of bidirectional learning evalu-
ated in experiments

5.2. Synthetic Data

T : The total number of iterations
T0: The number of iterations of bidirectional learning
F : The relative frequency of forward learning
for t = 1 to T do

if t < T0 and t mod F + 1 = 0 then

Backward learning to update (U, W, b)

Forward learning to update (V, W, b)

else

end if
end for

ted (see (52) in the supplementary material). To reduce the
variability in the experiments, we use the expected value
for the output of a hidden unit instead of sampling a binary
value. By the law of large numbers, the use of expected
value corresponds to having an inﬁnitely many binary hid-
den units that are conditionally independent and identically
distributed (i.i.d.) given the internal state of the DyBM. See
also (Sutskever et al., 2008; Sutskever & Hinton, 2007) for
the related use of the expected values for hidden units.

A DyBM with hidden unit is trained bidirectionally or only
with forward learning. A DyBM without hidden units is
trained only with forward learning. While bidirectional
learning has several design choices, here we evaluate the
speciﬁc algorithm shown in Algorithm 1. In particular, we
perform bidirectional learning for the ﬁrst T0 iterations,
where the backward training is apply every F + 1 steps. For
the rest of T − T0 iterations, we perform forward learning
only. Throughout we set F = 2. Note that Z is ﬁxed with
its initial values throughout learning. Here we do not update
U in forward learning and V in backward learning. This is
partly because the learning rule of (27)-(28) has no effect
when we use the expected values in hidden units.

Before applying Algorithm 1, the bias b is initialized to
zero, and the weight (U, V, W, Z) is initialized with i.i.d.
normal random variable with mean 0 and standard deviation
of 0.01 (Hinton, 2012) except the following two changes.
First, we set the mean of W[1] as an identity matrix for real
datasets, because using the previous value for prediction
is clearly beneﬁcial for these datasets. Second, we use the
small standard deviation of 0.001 for the large dataset of
391 dimensions for faster convergence. The learning rate is
adjusted according to AdaGrad (Duchi et al., 2011), where
the the initial learning rate is optimized as we discuss in the
following.

Throughout the experiments, we set the decay rate of the
eligibility traces in (6) to zero: α[t−1] = x[t−d] and
β[t−1] = h[t−d]. The delay d and the number of hidden
units are varied for each dataset.

We ﬁrst demonstrate the effectiveness of our bidirectional
training in a synthetic setting of learning a one-dimensional
noisy sawtooth wave, which is generated according to

x[t] =

t
C

−

(cid:107)

(cid:106) t
C

+ εt, for t = 0, 1, . . .

(31)

where C is the period of the noisy sawtooth wave, and εt is
an i.i.d. normal random variable, whose mean is ﬁxed at 0
and standard deviation at 0.01. The noisy sawtooth wave has
large discontinuity at the end of each period, which makes
hidden units essential for learning.

Here we train a DyBM with one hidden unit or no hidden
units. Throughout, the delay is set d = 4, and the learn-
ing rate is initialized to η = 1.0. Bidirectional learning
is continued for T0 = T /2 iterations, where T is varied
depending on C. In each iteration, we use one period of
the noisy sawtooth wave and update the parameters with
stochastic gradients.

Figure 3(a) and (c) show how learning progresses over itera-
tions. The period of the noisy sawtooth wave is C = 6 in
(a) and C = 8 in (c). Training is continued for T = 1, 000
iterations for C = 6 and T = 30, 000 iterations for C = 8.
In every F + 1 iterations, we let the DyBM predict the
one-step-ahead value for each of the C steps of one period
during forward learning. We evaluate the root mean squared
error (RMSE) of one-step-ahead predictions against true
values. For clarity, the RMSE curves are smoothed with a
Gaussian ﬁlter with window size of 50.

In the ﬁgure, the solid curves show the results with the bidi-
rectionally trained DyBMs (Bidirectional). As a baseline,
we also train the DyBM only with forward training and
show the results with dashed curves (Baseline). The dotted
curves show the results with the DyBM with no hidden units
(No hidden). The comparison suggests that Bidirectional
can substantially (by a factor of 10) improve the predictive
accuracy over Baseline. Notice also that the hidden unit can
hurt the predictive accuracy without bidirectional training.
No hidden often exhibits lower RMSE than Baseline.

In Figure 3(c), the reduction of the RMSE accelerates at
T0 iterations, after which bidirectional learning is no longer
performed. This suggests that, after learning appropriate
values of U (namely, what features should be used for pre-
diction) via bidirectional learning, it is better to optimally
learn (V, W, b) given the learned values of U. Namely,
although bidirectional learning help learn appropriate values
of U, it does not necessarily optimize all of the parameters
of the DyBM. Recall also the discussion at the end of Sec-
tion 4 that the backward DyBM is not exactly the same as
the time-reversed DyBM.

Figure 3(b) and (d) show the values predicted by bidirection-

Bidirectional Learning for Time-series Models with Hidden Units

(a) RMSE (C = 6)

(b) Prediction (C = 6)

(c) RMSE (C = 8)

(d) Prediction (C = 8)

Figure 3. Experimental results with noisy sawtooth waves. Bidirectional is a bidirectionally trained DyBM with one hidden unit, Baseline
is a DyBM with hidden units trained only with forward learning, and No hidden is a bidirectionally trained DyBM without hidden units.
In (a) and (c), the RMSE of one-step-ahead prediction with respect to training data is plotted against the number of iterations of training.
In (b) and (d), the predicted values after training is plotted for two periods together with corresponding target values (red curves).

ally trained DyBMs (black curves) and the corresponding
target values (red curves). For clarity, we use a noiseless
sawtooth wave as the target by letting εt = 0 in (31). Ob-
serve that the bidirectionally trained DyBM well predicts
the next value of the sawtooth wave, substantially better
than the baseline (or the DyBM with no hidden unit). In par-
ticular, the bidirectionally trained DyBM can well predict
the sharp drop at the end of each period. This is in contrast
to the baseline, whose prediction is rather smoothed out
over the period.

5.3. Real Data

Next, we demonstrate the effectiveness of bidirectional train-
ing on three real datasets, including the two datasets used
in Dasgupta & Osogami (2017). The ﬁrst dataset is the
monthly sunspot number1, which we will refer to as Sunspot.
This time-series has one dimension and 2,820 steps (cor-
responding to January 1749 to December 1983). The sec-
ond dataset is the weekly retail gasoline and diesel prices2,
which we will refer to as Price. This time-series has eight
dimensions (corresponding to eight locations in the US) and
1,223 steps (corresponding to April 5th, 1993 to September
5th, 2016). Following Dasgupta & Osogami (2017), the
ﬁrst 67 % of each time-series is used for training, and the
remaining 33 % is used for test. See Dasgupta & Osogami
(2017) for further details about the ﬁrst two datasets. The
third dataset is the NOAA Global Surface Temperature3,
which consists of a real valued time-series of 1,635 steps
(t = 1, . . . , 1635) with 391 dimensions. We use the ﬁrst
80 % of the time-series for training and the remaining 20 %
for test.

We normalize the values of each dataset in a way that the

1https://datamarket.com/data/set/22t4/
2https://www.eia.gov/dnav/pet/pet_pri_

gnd_a_epm0_pte_dpgal_w.htm
3V4.00 of Air Temperature

from
https://www.esrl.noaa.gov/psd/data/gridded/
data.noaaglobaltemp.html

(air.mon.anom.nc)

values in a training data are in [0,1] for each dimension.
Notice that this normalization differs from that in (Dasgupta
& Osogami, 2017), where the values in training or test data
are in [0,1] for each dimension. However, the use of test
data for normalization is less appropriate. This difference
in normalization has no effect on the Price dataset, but the
results on the Sunspot dataset need to be renormalized to be
compared against those in (Dasgupta & Osogami, 2017).

Here we train a DyBM with four hidden units or no hidden
units. In each iteration, we use the whole training data (ex-
cept the ﬁrst d steps for forward learning and the last d steps
for backward learning, which are used only to update the
internal state of the DyBM) once and update the parameters
with stochastic gradients.

We ﬁnd that the speed of convergence is sensitive to the
initial learning rate. Here, we choose the initial learning
rate from {20, 2−1, 2−2, . . .}. Speciﬁcally, we choose 2−k
with the smallest k such that the training RMSE after the
initial T /100 iterations is smaller than that with 2−(k+1).
Because the training RMSE tends to decrease with k up to
a point and then increases with k, we usually choose the
initial learning rate that minimizes the training RMSE after
those initial iterations.

Figure 4 shows the RMSE of one-step-ahead prediction with
respect to the test data after every F + 1 iterations of train-
ing. We show the results where the delay is set d = 30 for
Sunspot, d = 3 for Price, and d = 2 for Temperature. How-
ever, we have also run experiments with d ∈ {20, 40} for
Sunspot and d ∈ {2, 4} for Price and have found that these
do not improve the accuracy for any of the three methods.
For the large dataset of Temperature, we have been able
to perform limited experiments due to its relatively heavy
computational requirements. Again, we compare Bidirec-
tional against Baseline and No hidden. However, we now
vary T0 ∈ {T /4, T /2, T }, so that each ﬁgure has three solid
curves. The range of the vertical axis is chosen in a way
that the upper limit corresponds to the RMSE with a na¨ıve

02004006008001000Number of iterations0.00.10.20.30.40.5Training RMSEBidirectionalNo hiddenBaseline0246810Steps0.00.20.40.60.81.0Target or predicted valueBidirectionalNo hiddenTargetBaseline050001000015000200002500030000Number of iterations0.00.10.20.30.40.5Training RMSEBidirectionalNo hiddenBaseline02468101214Steps0.00.20.40.60.81.0Target or predicted valueBidirectionalNo hiddenTargetBaselineBidirectional Learning for Time-series Models with Hidden Units

(a) Sunspot dataset (d = 30)

(b) Price dataset (d = 3)

(c) Temperature dataset (d = 2)

Figure 4. Experimental results with real datasets. Bidirectional is a bidirectionally trained DyBM with four hidden units, Baseline is
a DyBM with four hidden units trained only with forward learning, and No hidden is a DyBM with no hidden units trained only with
forward learning. The RMSE of one-step-ahead prediction with respect to test data is plotted against the number of iterations of training.

prediction of using the preceding values as prediction.

avoiding overﬁt to training data.

For the Sunspot dataset (a), we ﬁnd that Bidirectional does
not improve upon Baseline, although having hidden units
(Bidirectional and Baseline) can make the RMSE lower than
No hidden. This means that the randomly set values of U
is effective, and bidirectional learning does not ﬁnd better
values of U. After 1,000 iterations, however, Bidirectional
with T0 = T /4 or T0 = T /2 achieves the RMSE that is
essentially indistinguishable from that with Baseline. The
best RMSE achieved by the Baseline is 0.0698, which corre-
sponds to 0.0657 when the dataset is normalized in the way
of (Dasgupta & Osogami, 2017) and is lower than 0.0734
reported in (Dasgupta & Osogami, 2017).

For Price (b) and Temperature (c), Bidirectional improves
upon Baseline particularly when the bidirectional learning
is stopped after T0 < T iterations. Bidirectional reduces the
RMSE more slowly than Baseline or No hidden but eventu-
ally outperforms the others, and the reduction of the RMSE
can be accelerated by stopping the bidirectional training af-
ter T0 < T iterations. In particular, the best RMSE achieved
by Bidirectional with T0 = T /4 is 0.0399, which is lower
than 0.0564 reported in (Dasgupta & Osogami, 2017). In
addition, while Baseline and No hidden (namely, forward
learning only) starts overﬁtting to training data and increases
the RMSE with respect to the test data after some iterations,
bidirectional training appears to avoid such overﬁt.

6. Conclusion

We have proposed bidirectional training for time-series mod-
els with hidden units. Namely, we consider two models
that have a common set of parameters, where one model is
trained with forward time-series and the other with back-
ward time-series. Our key idea is that some of the parame-
ters that are difﬁcult to learn in one model can be effectively
learned in the other model. Numerical experiments sug-
gest that bidirectional training has the additional effect of

The DyBM with hidden units analyzed in Sections 2–4 is
new, and its analysis has two highlights, which have led
to proposing bidirectional training. The ﬁrst highlight is
that the learning rule for V (hidden-to-visible weight) in
(20)–(22) becomes equivalent to those for W (visible-to-
visible weight) in (20)–(22) when the lower bound (14) is
maximized. The second highlight is that we cannot learn
the weight to hidden units (φ = (U, Z)) in the same way as
the weight to visible units (θ = (V, W, b)) due to the form
of the gradient in (27).

Although we have demonstrated the effectiveness of bidirec-
tional training in speciﬁc cases, its capabilities are not fully
explored. Bidirectional training has many design choices
that need further study. For example, one might want to use
the gradients in (27)-(28), possibly with the approximation
in (29), to update (U, Z) in forward learning and (V, Z)
in backward learning. It would also be interesting to apply
bidirectional training to other time-series models having
parameters that represent the dependency between hidden
values at one time and visible values at another time. In
addition to DyBM and VAR with hidden units, these include
Spiking Boltzmann Machine (Hinton & Brown, 1999) and
Conditional Restricted Boltzmann Machine (Taylor et al.,
2007). Because bidirectional training is largely complemen-
tary to other techniques for learning time-series, it would
be interesting to investigate how bidirectional training im-
proves performance when it is combined with these other
techniques. We expect that this work opens up a line of re-
search on more effective methods of bidirectional training.

Acknowledgments

This work was supported by JST CREST Grant Number
JPMJCR1304, Japan.

02004006008001000Number of iterations0.0690.0700.0710.0720.0730.0740.0750.0760.077Test RMSENo hiddenBaselineBidirectional0200040006000800010000Number of iterations0.0400.0420.0440.0460.048Test RMSENo hiddenBaselineBidirectional02004006008001000Number of iterations2.202.252.302.352.402.452.50Test RMSENo hiddenBaselineBidirectionalBidirectional Learning for Time-series Models with Hidden Units

References

Bahadori, M. T., Liu, Y., and Xing, E. P. Fast structure learn-
ing in generalized stochastic processes with latent factors.
In Proceedings of the 19th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining,
pp. 284–292, 2013.

Baldi, P., Brunak, S., Frasconi, P., Soda, G., and Pollastri,
G. Exploiting the past and the future in protein secondary
structure prediction. Bioinformatics, 15(11):937–946,
1999.

Baum, L. E. and Petrie, T. Statistical inference for prob-
abilistic functions of ﬁnite state Markov chains. The
Annals of Mathematical Statistics, 37:1554–1563, 1966.

Bottou, L. Online learning and stochastic approximations.
In Saad, D. (ed.), On-Line Learning in Neural Networks,
chapter 2, pp. 9–42. Cambridge University Press, 2009.

Chen, J. and Chaudhari, N. Protein secondary structure
prediction with bidirectional LSTM networks. In Inter-
national Joint Conference on Neural Networks: Post-
conference Workshop on Computational Intelligence Ap-
proaches for the Analysis of Bio-data (CI-BIO), August
2005.

Cheng, D., Bahadori, M. T., and Liu, Y. FBLG: A simple
and effective approach for temporal dependence discov-
ery from time series data. In Proceedings of the 20th
ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 382–391, 2014.

Dasgupta, S. and Osogami, T. Nonlinear dynamic Boltz-
mann machines for time-series prediction. In The 31st
AAAI Conference on Artiﬁcial Intelligence (AAAI-17), pp.
1833–1839, January 2017.

Dasgupta, S., Yoshizumi, T., and Osogami, T. Regular-
ized dynamic Boltzmann machine with delay pruning for
unsupervised learning of temporal sequences. In Pro-
ceedings of the 23rd International Conference on Pattern
Recognition, 2016.

Duchi, J., Hazan, E., and Singer, Y. Adaptive subgradient
methods for online learning and stochastic optimization.
Journal of Machine Learning Research, 12:2121–2159,
2011.

Graves, A. and Schmidhuber, J. Framewise phoneme clas-
siﬁcation with bidirectional LSTM networks and other
neural network architectures. Neural Networks, 18(5-6):
602–610, 2005.

Hinton, G. E. A practical guide to training restricted Boltz-
mann machines. In Montavon, G., Orr, G. B., and M¨uller,

K.-R. (eds.), Neural Networks: Tricks of the Trade, chap-
ter 24, pp. 599–619. Springer-Verlag Berlin Heidelberg,
2012.

Hinton, G. E. and Brown, A. D. Spiking Boltzmann ma-
chines. In Advances in Neural Information Processing
Systems 12, pp. 122–128. November 1999.

Hochreiter, S. and Schmidhuber, J. Long short-term memory.

Neural Computation, 9(8):17351780, 1997.

Jaeger, H. and Haas, H. Harnessing nonlinearity: Predicting
chaotic systems and saving energy in wireless communi-
cation. Science, 304(5667):7880, 2004.

Jalali, A. and Sanghavi, S. Learning the dependence graph
of time series with latent factors. In Proceedings of the
29th International Conference on Machine Learning, pp.
473–480, 2012.

Kajino, H. A functional dynamic Boltzmann machine. In
Proceedings of the 26th International Joint Conference
on Artiﬁcial Intelligence, August 2017.

L¨utkepohl, H. New Introduction to Multiple Time Series

Analysis. Springer-Verlag Berlin Heidelberg, 2005.

Osogami, T.

Learning binary or real-valued time-
series via spike-timing dependent plasticity. CoRR,
abs/1612.04897, 2016. URL http://arxiv.org/
abs/1612.04897.

Osogami, T. and Otsuka, M. Seven neurons memorizing
sequences of alphabetical images via spike-timing depen-
dent plasticity. Scientiﬁc Reports, 5:14149, 2015a.

Osogami, T. and Otsuka, M. Learning dynamic Boltzmann
machines with spike-timing dependent plasticity. Techni-
cal Report RT0967, IBM Research, 2015b.

Qian, N. On the momentum term in gradient descent learn-
ing algorithms. Neural Networks: The Ofﬁcial Journal of
the International Neural Network Society, 12(1):145–151,
1999.

Rumelhart, D. E., Hinton, G. E., and Williams, R. J. Learn-
In
ing internal representations by error propagation.
Rumelhart, D. E., McClelland, J. L., and PDP Research
Group (eds.), Parallel Distributed Processing: Explo-
rations in the Microstructure of Cognition, vol. 1: Foun-
dations, chapter 8. MIT Press, 1986.

Schuster, M. and Paliwal, K. K. Bidirectional recurrent neu-
ral networks. IEEE Transactions on Signal Processing,
45(11):2673–2681, 1997.

Sutskever, I. and Hinton, G. E. Learning multilevel dis-
tributed representations for high-dimensional sequences.
In Proceedings of the Eleventh International Conference

Bidirectional Learning for Time-series Models with Hidden Units

on Artiﬁcial Intelligence and Statistics (AISTATS-07), vol-
ume 2, pp. 548–555. Journal of Machine Learning Re-
search - Proceedings Track, 2007.

Sutskever, I., Hinton, G. E., and Taylor, G. W. The recurrent
In Advances
temporal restricted Boltzmann machine.
in Neural Information Processing Systems 21, pp. 1601–
1608. December 2008.

Taylor, G. W., Hinton, G. E., and Roweis, S. T. Modeling
human motion using binary latent variables. In Advances
in Neural Information Processing Systems 19, pp. 1345–
1352. 2007.

Winkler, I., Panknin, D., Bartz, D., M¨uller, K.-R., and Haufe,
S. Validity of time reversal for testing granger causality.
IEEE Transactions on Signal Processing, 64(11):2746–
2760, 2016.

