Supplementary Material for
“Efﬁcient Regret Minimization in Non-Convex Games”

Elad Hazan 1 Karan Singh 1 Cyril Zhang 1

A. Proof of Theorem 4.4

Now, applying E [·|xt] on both sides, it follows that

Since each ft is β-smooth, it follows that each Ft is β-
smooth. Deﬁne (cid:100)∇ft = xt−xt+1
. Note that since the it-
η
erates (xt : t ∈ [T ]) depend on the gradient estimates,
the iterates are stochastic variables, as are (cid:100)∇ft. By β-
smoothness of Ft, we have

Ft,w(xt+1) − Ft,w(xt)

≤ (cid:104)∇Ft,w(xt), xt+1 − xt(cid:105) +

(cid:107)xt+1 − xt(cid:107)2

(cid:68)

= − η

∇Ft,w(xt), (cid:100)∇ft

(cid:107)(cid:100)∇ft(cid:107)2

β
2
+ η2 β
2
(cid:68)

(cid:69)

= − η(cid:107)∇Ft,w(xt)(cid:107)2 − η

∇Ft,w(xt), (cid:100)∇ft − ∇Ft,w(xt)

(cid:69)

∇Ft,w(xt), (cid:100)∇ft − ∇Ft,w(xt)

(cid:69)(cid:17)

+ η2 β
2
+ η2 β
2
+ η2 β
2
(cid:18)

(cid:0)(cid:107)∇Ft,w(xt)(cid:107)2(cid:1)
(cid:16)

(cid:68)

(cid:16)

2
(cid:107)(cid:100)∇ft − ∇Ft,w(xt)(cid:107)2(cid:17)
β
2

(cid:107)∇Ft,w(xt)(cid:107)2

η2

(cid:19)

= −

η −

∇Ft,w(xt), (cid:100)∇ft − ∇Ft,w(xt)

(cid:69)

(cid:68)

− (η − βη2)
+ η2 β
2

(cid:107)(cid:100)∇ft − ∇f (xt)(cid:107)2.

Additionally, we each observe that (cid:100)∇ft is an average of
w independently sampled unbiased gradient estimates of
variance σ2 each. It follows as a consequence that

E(cid:2)

(cid:12)
(cid:12)xt

(cid:100)∇ft

(cid:3) = ∇Ft,w(xt)
E(cid:2)(cid:107)(cid:100)∇ft − ∇Ft,w(xt)(cid:107)2(cid:12)

(cid:3) ≤

(cid:12)xt

σ2
w

1Computer Science,
to:

spondence
Karan
<cyril.zhang@princeton.edu>.

Princeton University.

Corre-
Elad Hazan <ehazan@princeton.edu>,
Zhang

Cyril

Singh <karans@princeton.edu>,

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

(cid:18)

(cid:19)

η −

η2

· E(cid:107)∇Ft,w(xt)(cid:107)2

β
2

≤ E [Ft,w(xt) − Ft,w(xt+1)] + η2 β
2

σ2
w

.

Also, we note that

Ft+1,w(xt+1) − Ft,w(xt+1)

ft+1−i(xt+1) −

ft−i(xt+1)

w−1
(cid:88)

i=0

w−2
(cid:88)

1
w

1
w

=

=

=

ft−i(xt+1) −

ft−i(xt+1)

i=−1

i=0
ft+1(xt+1) − ft−w+1(xt+1)
w

≤

2M
w

1
w

w−1
(cid:88)

i=0

w−1
(cid:88)

1
w

Adding the last two inequalities, we proceed to sum the
above inequality over all time steps:

(cid:35)

(cid:107)∇Ft,w(xt)(cid:107)2

≤

(cid:34) T

(cid:88)

E

t=1

2M + 2M T

2w σ2

w + T βη2
η − βη2
2

.

Setting η = 1/β yields the claim from the theorem.

Finally, note that for each round the number of stochastic
gradient oracle calls required is w. Therefore, across all T
rounds, the number of noisy oracle calls is T w.

B. Proof of Theorem 5.1 (ii)

Following the technique from Theorem 3.1, for 2 ≤ t ≤ T ,
let τt be the number of iterations of the inner loop during
the execution of Algorithm 3 during round t − 1 (in order
to generate the iterate xt). Then, we have the following
lemma:

Lemma B.1. For any 2 ≤ t ≤ T ,

Ft−1(xt) − Ft−1(xt−1) ≤ −τt ·

δ3
2βw3 .

Proof. This follows by summing the inequality Lemma 5.3
for across all pairs of consecutive iterates of the inner loop

Efﬁcient Regret Minimization in Non-Convex Games

within the same epoch, and noting that each term Φ(z) is
at least δ3
w3 before the inner loop has terminated.

Ft−1(xt) − Ft−1(xt−1) + ft(xt) − ft−w(xt)

Finally, we write (understanding F0(x0) := 0):

FT (xT ) =

Ft(xt) − Ft−1(xt−1)

T
(cid:88)

t=1

=

≤

T
(cid:88)

t=1

T
(cid:88)

t=2

whence

[Ft−1(xt) − Ft−1(xt−1)] +

2M T
w

.

Using Lemma B.1, we have

FT (xT ) ≤

2M T
w

−

δ3
2βw3 ·

T
(cid:88)

t=1

τt,

τ =

τt ≤

T
(cid:88)

t=1

2βw3
δ3

(cid:18) 2M T
w

·

(cid:19)

− FT (xT )

· (cid:0)2T w2 + w3(cid:1)

≤

≤

2βM
δ3
6M
β2 · T w2,

as claimed (recalling that we chose δ = β for this analysis).

C. Proof of Theorem 6.2

Summing up the deﬁnitions of w-regret bounds achieved
by each A, and truncating the ﬁrst w − 1 terms, we get

k
(cid:88)

T
(cid:88)

i=1

t=w

(cid:107)∇K,ηF i

t (xi

t)(cid:107)2 ≤

Rw,Ai(T ).

k
(cid:88)

i=1

Thus, for some t between w and T inclusive, it holds that

k
(cid:88)

i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

∇K,η

(cid:34) (cid:80)w−1
j=0

˜fi,t−j
w

(cid:35)

(cid:13)
2
(cid:13)
(xi
(cid:13)
t)
(cid:13)
(cid:13)

=

k
(cid:88)

i=1

(cid:107)∇K,ηF i

t (xi

t)(cid:107)2

≤

k
(cid:88)

i=1

Rw,Ai(T )
T − w

.

Thus, for the same t we have

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

max
i∈[k]

∇K,η

(cid:34) (cid:80)w−1
j=0

˜fi,t−j
w

(cid:35)

(cid:13)
(cid:13)
(xi
(cid:13)
t)
(cid:13)
(cid:13)

(cid:118)
(cid:117)
(cid:117)
(cid:116)

≤

k
(cid:88)

i=1

Rw,Ai(T )
T − w

,

as claimed.

