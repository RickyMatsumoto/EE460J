Supplemental Materials for:
Estimating individual treatment effect: generalization bounds and algorithms

Uri Shalit * 1 Fredrik D. Johansson * 2 David Sontag 2 3

A. Proofs

A.1. Deﬁnitions, assumptions, and auxiliary lemmas

We ﬁrst deﬁne the necessary distributions and prove some
simple results about them. We assume a joint distribu-
tion function p(x, t, Y0, Y1), such that (Y1, Y0) ⊥⊥ t|x, and
0 < p(t = 1|x) < 1 for all x. Recall that we assume Con-
sistency, that is we assume that we observe y = Y1|(t = 1)
and y = Y0|(t = 0).
Deﬁnition A1. The treatment effect for unit x is:

τ (x) := E [Y1 − Y0|x] .

We ﬁrst show that under consistency and strong ignorabil-
ity, the ITE function τ (x) is identiﬁable:

Lemma A1. We have:

E [Y1 − Y0|x] =
E [Y1|x] − E [Y0|x] =
E [Y1|x, t = 1] − E [Y0|x, t = 0] =
E [y|x, t = 1] − E [y|x, t = 0] .

(1)

(2)

Equality (1) is because we assume that Yt and t are inde-
pendent conditioned on x. Equality (2) follows from the
consistency assumption. Finally, the last equation is com-
posed entirely of observable quantities and can be esti-
mated from data since we assume 0 < p(t = 1|x) < 1
for all x.
Deﬁnition A2. Let pt=1(x)
:= p(x|t = 1), and
pt=0(x) := p(x|t = 0) denote respectively the treatment
and control distributions.

Let Φ : X → R be a representation function. We will
assume that Φ is differentiable.

*Equal contribution

1CIMS, New York University, New
York, NY 10003 2IMES, MIT, Cambridge, MA 02142
3CSAIL, MIT, Cambridge, MA 02139.
Correspondence
to: Uri Shalit <shalit@cs.nyu.edu>, Fredrik D. Johansson
<fredrikj@mit.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

Assumption A1. The representation function Φ is one-to-
one. Without loss of generality we will assume that R is
the image of X under Φ, and deﬁne Ψ : R → X to be the
inverse of Φ, such that Ψ(Φ(x)) = x for all x ∈ X .
Deﬁnition A3. For a representation function Φ : X → R,
and for a distribution p deﬁned over X , let pΦ be the distri-
bution induced by Φ over R. Deﬁne pt=1
Φ (r) := pΦ(r|t =
1), pt=0
Φ (r) := pΦ(r|t = 0), to be the treatment and control
distributions induced over R.

For a one-to-one Φ, the distribution pΦ over R × {0, 1} can
be obtained by the standard change of variables formula,
using the determinant of the Jacobian of Ψ(r). See (Ben-
Israel, 1999) for the case of a mapping Φ between spaces
of different dimensions.
Lemma A2. For all r ∈ R, t ∈ {0, 1}:

pΦ(t|r) = p(t|Ψ(r))
p(Yt|r) = p(Yt|Ψ(r)).

Proof. Let JΨ(r) be the absolute of the determinant of the
Jacobian of Ψ(r).

pΦ(t, r)
pΦ(r)

(a)
=

p(t, Ψ(r))JΨ(r)
p(Ψ(r))JΨ(r)

=

pΦ(t|r) =

p(t, Ψ(r))
p(Ψ(r))

= p(t|Ψ(r)),

where equality (a) is by the change of variable formula.
The proof is identical for p(Yt|r).

Let L : Y × Y → R+ be a loss function, e.g. the absolute
loss or squared loss.
Deﬁnition A4. Let Φ : X → R be a representation func-
tion. Let h : R×{0, 1} → Y be an hypothesis deﬁned over
the representation space R. The expected loss for the unit
and treatment pair (x, t) is:

(cid:96)h,Φ(x, t) =

L(Yt, h(Φ(x), t))p(Yt|x)dYt

Deﬁnition A5. The expected factual loss and counterfac-
tual losses of h and Φ are, respectively:

(cid:90)

Y

(cid:90)

(cid:15)F (h, Φ) =

(cid:96)h,Φ(x, t) p(x, t) dxdt

X ×{0,1}

Estimating individual treatment effect: generalization bounds and algorithms

Notation:
p(x, t): distribution on X × {0, 1}
u = p(t = 1): the marginal probability of treatment.
pt=1(x) = p(x|t = 1): treated distribution. pt=0(x) = p(x|t = 0): control distribution.
Φ: representation function mapping from X to R.
Ψ: the inverse function of Φ, mapping from R to X .
pΦ(r, t): the distribution induced by Φ on R × {0, 1}.
pt=1
Φ (r), pt=0
L(·, ·): loss function, from Y × Y to R+.
(cid:96)h,Φ(x, t): the expected loss of h(Φ(x), t) for the unit x and treatment t.
(cid:15)F (h, Φ), (cid:15)CF (h, Φ): expected factual and counterfactual loss of h(Φ(x), t).
τ (x) := E [Y1 − Y0|x], the expected treatment effect for unit x.
(cid:15)PEHE(f ): expected error in estimating the individual treatment effect of a function f (x, t).
IPMG(p, q): the integral probability metric distance induced by function family G between distributions p and q.

Φ (r): treated and control distributions induced by Φ on R.

(cid:15)CF (h, Φ) =

(cid:96)h,Φ(x, t) p(x, 1 − t) dxdt.

(cid:90)

X ×{0,1}

When it is clear from the context, we will sometimes use
(cid:15)F (f ) and (cid:15)CF (f ) for the expected factual and counterfac-
tual losses of an arbitrary function f : X × {0, 1} → Y.

Deﬁnition A6. The expected treated and control losses
are:

(cid:90)

(cid:90)

(cid:90)

(cid:90)

(cid:15)t=1
F (h, Φ) =

(cid:96)h,Φ(x, 1) pt=1(x) dx
X

(cid:15)t=0
F (h, Φ) =

(cid:96)h,Φ(x, 0) pt=0(x) dx
X

(cid:15)t=1
CF (h, Φ) =

(cid:96)h,Φ(x, 1) pt=0(x) dx
X

(cid:15)t=0
CF (h, Φ) =

(cid:96)h,Φ(x, 0) pt=1(x) dx.
X

The four losses above are simply the loss conditioned on
either the control or treated set. Let u := p(t = 1) be the
proportion of treated in the population. We then have the
immediate result:

Lemma A3.

(cid:15)F (h, Φ) = u · (cid:15)t=1

F (h, Φ) + (1 − u) · (cid:15)t=0

F (h, Φ)

(cid:15)CF (h, Φ) = (1 − u) · (cid:15)t=1

CF (h, Φ) + u · (cid:15)t=0

CF (h, Φ).

The proof is immediate, noting that p(x, t) = u · pt=1(x) +
(1 − u) · (¸x), and from the Deﬁnitions A4 and A6 of the
losses.

Deﬁnition A7. Let G be a function family consisting of
functions g : S → R. For a pair of distributions p1, p2
over S, deﬁne the Integral Probability Metric:

IPMG(p1, p2) = sup
g∈G

(cid:90)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

S

(cid:12)
(cid:12)
g(s) (p1(s) − p2(s)) ds
(cid:12)
(cid:12)

IPMG(·, ·) deﬁnes a pseudo-metric on the space of proba-
bility functions over S, and for sufﬁciently large function
families, IPMG(·, ·) is a proper metric (M¨uller, 1997). Ex-
amples of sufﬁciently large functions families includes the
set of bounded continuous functions, the set of 1-Lipschitz
functions, and the set of unit norm functions in a univer-
sal Reproducing Norm Hilbert Space. The latter two give
rise to the Wasserstein and Maximum Mean Discrepancy
metrics, respectively (Gretton et al., 2012; Sriperumbudur
et al., 2012). We note that for function families G such as
the three mentioned above, for which g ∈ G =⇒ −g ∈
G, the absolute value can be omitted from deﬁnition A7.

A.2. General IPM bound

We now state and prove the most important technical
lemma of this section.
Lemma A4 (Lemma 1, main text). Let Φ : X → R be an
Φ , pt=0
invertible representation with Ψ its inverse. Let pt=1
be deﬁned as in Deﬁnition A3. Let u = p(t = 1). Let
G be a family of functions g : R → R, and denote by
IPMG(·, ·) the integral probability metric induced by G.
Let h : R×{0, 1} → Y be an hypothesis. Assume there ex-
ists a constant BΦ > 0, such that for t = 0, 1, the function
gΦ,h(r, t) := 1
BΦ

· (cid:96)h,Φ(Ψ(r), t) ∈ G. Then we have:

Φ

(cid:15)CF (h, Φ) ≤
(1 − u)(cid:15)t=1

BΦ · IPMG

F (h, Φ) + u(cid:15)t=0
F (h, Φ)+
(cid:1) .
Φ , pt=0

(cid:0)pt=1

Φ

Proof.
(cid:15)CF (h, Φ) − (cid:2)(1 − u) · (cid:15)t=1
(cid:2)(1 − u) · (cid:15)t=1
(cid:2)(1 − u) · (cid:15)t=1
(1 − u) · (cid:2)(cid:15)t=1
u · (cid:2)(cid:15)t=0

CF (h, Φ) + u · (cid:15)t=0
F (h, Φ) + u · (cid:15)t=0
CF (h, Φ) − (cid:15)t=1

CF (h, Φ) − (cid:15)t=0

F (h, Φ)(cid:3) =

F (h, Φ) + u · (cid:15)t=0
CF (h, Φ)(cid:3) −
F (h, Φ)(cid:3) =

F (h, Φ)(cid:3) +

F (h, Φ)(cid:3) =

(3)

(4)

Estimating individual treatment effect: generalization bounds and algorithms

(cid:96)h,Φ(Ψ(r), 1) (cid:0)pt=0

Φ (r) − pt=1

Φ (r)(cid:1) dr+

Deﬁnition A10. The expected Precision in Estimation of
Heterogeneous Effect (PEHE) loss of g is:

(1 − u)

(cid:96)h,Φ(x, 1) (cid:0)pt=0(x) − pt=1(x)(cid:1) dx+

(cid:96)h,Φ(x, 0) (cid:0)pt=1(x) − pt=0(x)(cid:1) dx =

(5)

(1 − u)

(cid:96)h,Φ(Ψ(r), 1) (cid:0)pt=0

Φ (r) − pt=1

Φ (r)(cid:1) dr+

(cid:90)

X

(cid:90)

R

(cid:90)

u

X

(cid:90)

u

Φ (r) − pt=0

Φ (r)(cid:1) dr =

(cid:96)h,Φ(Ψ(r), 0) (cid:0)pt=1
(cid:90)

R

1
BΦ

R

BΦ · (1 − u)

BΦ · u

(cid:90)

1
BΦ

R

(cid:90)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

R

BΦ · (1 − u) sup
g∈G
(cid:90)

BΦ · u sup
g∈G
R
Φ , pt=1
BΦ · IPMG(pt=0

Φ ).

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:96)h,Φ(Ψ(r), 0) (cid:0)pt=1

Φ (r) − pt=0

Φ (r)(cid:1) dr ≤

g(r) (cid:0)pt=0

Φ (r) − pt=1

g(r) (cid:0)pt=1

Φ (r) − pt=0

Φ (r)(cid:1) dr

(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

Φ (r)(cid:1) dr
(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

(6)

(7)

(8)

Equality (4) is by Deﬁnition A6 of the treated and control
loss, equality (5) is by the change of variables formula and
Deﬁnition A3 of pt=1
and pt=0
Φ , inequality (6) is by the
premise that 1
· (cid:96)h,Φ(Ψ(r), t) ∈ G for t = 0, 1, and (7) is
BΦ
by Deﬁnition A7 of an IPM.

Φ

We deﬁne:

Φ

The essential point in the proof of Lemma A4 is inequal-
ity 6. Note that on the l.h.s. of the inequality, we need to
evaluate the expectations of (cid:96)h,Φ(Ψ(r), 0) over pt=1
and
(cid:96)h,Φ(Ψ(r), 1) over pt=0
Φ . Both of these expectations are in
general unavailable, since they require us to evaluate treat-
ment outcomes on the control, and control outcomes on
the treated. We therefore upper bound these unknowable
quantities by taking a supremum over a function family
which includes (cid:96)h,Φ(Ψ(r), 0) and (cid:96)h,Φ(Ψ(r), 1). The up-
per bound ignores most of the details of the outcome, and
amounts to measuring a distance between two distributions
we have samples from: the control and treated distribution.
Note that for a randomized trial (i.e. when t ⊥⊥ x) with we
have that IPM(pt=1
Φ ) = 0. Indeed, it is straightfor-
ward to show that in that case we actually have an equality:
(cid:15)CF (h, Φ) = (1 − u) · (cid:15)t=1

F (h, Φ) + u · (cid:15)t=0

F (h, Φ).

Φ , pt=0

The crucial condition in Lemma A4 is that the function
gΦ,h(r) := 1
(cid:96)h,Φ(Ψ(r), t) is in G. In subsections A.3
BΦ
and A.4 below we look into two speciﬁc function families
G, and evaluate what does this inclusion condition entail,
and in particular we will derive speciﬁc bounds for BΦ.
Deﬁnition A8. For t = 0, 1 deﬁne:

mt(x) := E [Yt|x] .

Let f : X × {0, 1} → Y by an hypothesis, such that
f (x, t) = h(Φ(x), t) for a representation Φ and hypothesis
h deﬁned over the output of Φ.

Deﬁnition A9. The treatment effect estimate for unit x is:

ˆτf (x) = f (x, 1) − f (x, 0).

(cid:15)PEHE(f ) =

(ˆτf (x) − τ (x))2 p(x) dx.

(cid:90)

X

Deﬁnition A11. The expected variance of Yt with respect
to a distribution p(x, t):

σ2
Yt

(p(x, t)) =

(Yt − mt(x))2 p(Yt|x)p(x, t) dYtdx.

(cid:90)

X ×Y

σ2
= min{σ2
Yt
Yt
Y = min{σ2
σ2
Y0

(p(x, t)), σ2
Yt
, σ2
Y1

}.

(p(x, 1 − t))},

If Yt are deterministic functions of x, then σ2

Y = 0.

We now show that (cid:15)PEHE(f ) is upper bounded by 2(cid:15)F +
2(cid:15)CF − 2σ2
to the squared
loss. An analogous result can be obtained for the absolute
loss, using mean absolute deviation.

Y where (cid:15)F and (cid:15)CF are w.r.t.

Lemma A5. For any function f : X × {0, 1} → Y, and
distribution p(x, t) over X × {0, 1}:

(cid:90)

(cid:90)

X

X

(f (x, t) − mt(x))2 p(x, t) dxdt =

(cid:15)F (f ) − σ2
Yt

(p(x, t)),

(f (x, t) − mt(x))2 p(x, 1 − t) dxdt =

(cid:15)CF (f ) − σ2
Yt

(p(x, 1 − t)),

where (cid:15)F (f ) and (cid:15)CF (f ) are w.r.t. to the squared loss.

Obviously for the treatment effect τ (x) we have τ (x) =
m1(x) − m0(x).

Proof. For simplicity we will prove for p(x, t) and (cid:15)F (f ).

Estimating individual treatment effect: generalization bounds and algorithms

The proof for p(x, 1 − t) and (cid:15)CF is identical.

(cid:15)PEHE(f ) = (cid:15)PEHE(h, Φ) for f (x, t) = h(Φ(x), t).

(cid:15)PEHE(f ) =
(cid:90)

(cid:0)(f (x, 1) − f (x, 0)) − (m1(x) − m0(x))(cid:1)2

p(x) dx =

(cid:0)(f (x, 1) − m1(x)) + (m0(x) − f (x, 0))(cid:1)2

p(x) dx ≤

(cid:16)

(f (x, 1) − m1(x))2 + (m0(x) − f (x, 0))2(cid:17)

p(x) dx =

(11)

(12)

(10)

(f (x, 1) − m1(x))2 p(x, t = 1) dx+
X
(cid:90)

(m0(x) − f (x, 0))2 p(x, t = 0) dx+

2

(f (x, 1) − m1(x))2 p(x, t = 0) dx+

(f (x, t) − Yt)2 p(Yt|x)p(x, t) dYtdxdt =

(f (x, t) − mt(x))2 p(Yt|x)p(x, t) dYtdxdt+

(mt(x) − Yt)2 p(Yt|x)p(x, t) dYtdxdt+

(9)

(f (x, t) − mt(x)) (mt(x) − Yt) p(Yt|x)p(x, t) dYtdxdt =

(cid:15)F (f ) =
(cid:90)

X ×{0,1}×Y

X ×{0,1}×Y

X ×{0,1}×Y

X ×{0,1}×Y

(cid:90)

(cid:90)

(cid:90)

(cid:90)

(f (x, t) − mt(x))2 p(x, t) dxdt+
X ×{0,1}
σ2
Y0

(p(x, t)) + σ2
Y1

(p(x, t)) + 0,

where the equality (10) is by the Deﬁnition A11 of σ2
(p),
Yt
and because the integral in (9) evaluates to zero, since
mt(x) = (cid:82)

X Ytp(Yt|x) dx.

X

(cid:90)

X

(cid:90)

2

X

(cid:90)

2

X

(cid:90)

X

(cid:90)

2

2

2

(m0(x) − f (x, 0))2 p(x, t = 1) dx =

(cid:90)

2

X
(f (x, t) − mt(x))2 p(x, t) dxdt+
X
(cid:90)

(f (x, t) − mt(x))2 p(x, 1 − t) dxdt ≤

(13)

X
2((cid:15)F − σ2

Y ) + 2((cid:15)CF − σ2

Y ).

where (11) is because (x + y)2 ≤ 2(x2 + y2), (12) is be-
cause p(x) = p(x, t = 0) + p(x, t = 1) and (13) is by
Lemma A5 and Deﬁnition A5 of the losses (cid:15)F , (cid:15)CF and
Deﬁnition A11 of σ2
Y . Having established the ﬁrst inequal-
ity in the Theorem statement, we now show the second. We
have by Lemma A4 that:

(cid:15)CF (h, Φ) ≤
(1 − u)(cid:15)t=1

F (h, Φ) + u(cid:15)t=0

F (h, Φ) + BΦ · IPMG

(cid:0)pt=1

Φ , pt=0

Φ

(cid:1) .

We further have by Lemma A3 that:

(cid:15)F (h, Φ) = u(cid:15)t=1

F (h, Φ) + (1 − u)(cid:15)t=0

F (h, Φ).

Therefore

Φ , pt=0

Theorem 1. Let Φ : X → R be a one-to-one representa-
tion function, with inverse Ψ. Let pt=1
Φ be deﬁned as
in Deﬁnition A3. Let u = p(t = 1). Let G be a family of
functions g : R → R, and denote by IPMG(·, ·) the integral
probability metric induced by G. Let h : R × {0, 1} → Y
be an hypothesis. Let the loss L(y1, y2) = (y1 − y2)2. As-
sume there exists a constant BΦ > 0, such that for t ∈
{0, 1}, the functions gΦ,h(r, t) := 1
· (cid:96)h,Φ(Ψ(r), t) ∈ G.
BΦ
We then have:

(cid:15)PEHE(h, Φ) ≤
2(cid:0)(cid:15)CF (h, Φ) + (cid:15)F (h, Φ) − 2σ2
2(cid:0)(cid:15)t=0

(cid:1) ≤
F (h, Φ)+BΦIPMG

F (h, Φ)+(cid:15)t=1

Y

where (cid:15)F and (cid:15)CF are with respect to the squared loss.

(cid:0)pt=1

Φ , pt=0

Φ

(cid:1)−2σ2

Y

(cid:1),

(cid:15)CF (h, Φ) + (cid:15)F (h, Φ) ≤
F (h, Φ) + (cid:15)t=0
(cid:15)t=1

F (h, Φ) + BΦIPMG

(cid:0)pt=1

Φ , pt=0

Φ

(cid:1) .

Proof. We will prove the ﬁrst inequality, (cid:15)PEHE(f ) ≤
2(cid:15)CF (h, Φ) + 2(cid:15)F (h, Φ) − 2σ2
Y . The second inequality
is then immediate by Lemma A4. Recall that we denote

The upper bound is in terms of the standard generaliza-
tion error on the treated and control distributions separately.
Note that in some cases we might have very different sam-
ple sizes for treated and control, and that will show up in
the ﬁnite sample bounds of these generalization errors.

We also note that the upper bound can be easily adapted to
the case of the absolute loss PEHE |ˆτ (x) − τ (x)|. In that

Estimating individual treatment effect: generalization bounds and algorithms

case the upper bound in the Theorem will have a factor 1
instead of the 2 stated above, and the standard deviation σ2
Y
replaced by mean absolute deviation. The proof is straight-
forward where one simply applies the triangle inequality in
inequality (11).

We will now give speciﬁc upper bounds for the constant
BΦ in Theorem 1, using two function families G in the
IPM: the family of 1-Lipschitz functions, and the family of
1-norm reproducing kernel Hilbert space functions. Each
one will have different assumptions about the distribution
p(x, t, Y0, Y1) and about the representation Φ and hypoth-
esis h.

A.3. The family of 1-Lipschitz functions

For S ⊂ Rd, a function f : S → R has Lipschitz constant
K if for all x, y ∈ S, |f (x) − f (y)| ≤ K(cid:107)x − y(cid:107). If f is
differentiable, then a sufﬁcient condition for K-Lipschitz
constant is if (cid:107) ∂f

∂s (cid:107) ≤ K for all s ∈ S.

For simplicity’s sake we assume throughout this subsection
that the true labeling functions the densities p(Yt|x) and the
loss L are differentiable. However, this assumption could
be relaxed to a mere Lipschitzness assumption.
Assumption A2. There exists a constant K > 0 such that
for all x ∈ X , t ∈ {0, 1}, (cid:107) p(Yt|x)

∂x (cid:107) ≤ K.

Assumption A2 entails that each of the potential outcomes
change smoothly as a function of the covariates (context)
x.
Assumption A3. The loss function L is differentiable, and
(cid:12)
(cid:12)
there exists a constant KL > 0 such that
(cid:12) ≤ KL
for i = 1, 2. Additionally, there exists a constant M such
that for all y2 ∈ Y, M ≥ (cid:82)

dL(y1,y2)
dyi

Y L(y1, y2) dy1.

(cid:12)
(cid:12)
(cid:12)

Assuming Y is compact, loss functions which obey As-
sumption A3 include the log-loss, hinge-loss, absolute loss,
and the squared loss.

When we let G in Deﬁnition A7 be the family of 1-
Lipschitz functions, we obtain the so-called 1-Wasserstein
distance between distributions, which we denote Wass(·, ·).
It is well known that Wass(·, ·) is indeed a metric between
distributions (Villani, 2008).
Deﬁnition A12. Let ∂Φ(x)
∂x be the Jacobian matrix of Φ at
point x, i.e. the matrix of the partial derivatives of Φ. Let
σmax(A) and σmin(A) denote respectively the largest and
smallest singular values of a matrix A. Deﬁne ρ(Φ) =
supx∈X σmax

(cid:16) ∂Φ(x)
∂x

(cid:16) ∂Φ(x)
∂x

/σmin

(cid:17)

(cid:17)

.

It is an immediate result that ρ(Φ) ≥ 1.
Deﬁnition A13. We will call a representation function Φ :
X → R Jacobian-normalized if supx∈X σmax
=
1.

(cid:16) ∂Φ(x)
∂x

(cid:17)

Note that any non-constant representation function Φ can
be Jacobian-normalized by a simple scalar multiplication.

Lemma A6. Assume that Φ is a Jacobian-normalized rep-
resentation, and let Ψ be its inverse. For t = 0, 1, the Lips-
chitz constant of p(Yt|Ψ(r)) is bounded by ρ(Φ)K, where
K is from Assumption A2, and ρ(Φ) as in Deﬁnition A12.

Proof. Let Ψ : R → X be the inverse of Φ, which exists
by the assumption that Φ is one-to-one. Let ∂Φ(x)
be the
∂x
Jacobian matrix of Φ evaluated at x, and similarly let ∂Ψ(r)
∂r
be the Jacobian matrix of Ψ evaluated at r. Note that ∂Ψ(r)
·
∂Φ(x)
∂x = I for r = Φ(x), since Ψ◦Φ is the identity function

∂r

on X . Therefore for any r ∈ R and x = Ψ(r):

σmax

(cid:19)

(cid:18) ∂Ψ(r)
∂r

=

1
(cid:16) ∂Φ(x)
∂x

(cid:17) ,

σmin

(14)

where σmax(A) and σmin(A) are respectively the largest
and smallest singular values of the matrix A, i.e. σmax(A)
is the spectral norm of A.

For x = Ψ(r) and t ∈ {0, 1}, we have by the chain rule:

(cid:107) = (cid:107)

∂p(Yt|Ψ(r))
∂Ψ(r)

∂Ψ(r)
∂r

(cid:107) ≤

(15)

(cid:107)

(cid:107)

∂p(Yt|Ψ(r))
∂r
∂Ψ(r)
∂r

(cid:107)(cid:107)

1
(cid:16) ∂Φ(x)
∂x

K
(cid:16) ∂Φ(x)
∂x

σmin

σmin

∂p(Yt|Ψ(r))
∂Ψ(r)

(cid:107) =

(cid:17) (cid:107)

∂p(Yt|x)
∂x

(cid:107) ≤

(cid:17) ≤ ρ(Φ)K,

(16)

(17)

(18)

where inequality (15) is by the matrix norm inequality,
equality (16) is by (14), inequality (17) is by assumption
A2 on the norms of the gradient of p(Yt|x) w.r.t x , and
inequality (18) is by Deﬁnition A12 of ρ(Φ), the assump-
tion that Φ is Jacobian-normalized, and noting that singular
values are necessarily non-negative.

Lemma A7. Under the conditions of Lemma A4, further
assume that for t = 0, 1, p(Yt|x) has gradients bounded
by K as in A2, that h has bounded gradient norm bK,
that the loss L has bounded gradient norm KL, and that
Φ is Jacobian-normalized. Then the Lipschitz constant of
(cid:96)h,Φ(Ψ(r), t) is upper bounded by KL · K (M ρ(Φ) + b)
for t = 0, 1.

Estimating individual treatment effect: generalization bounds and algorithms

Proof. Using the chain rule, we have that:

∂(cid:96)h,Φ(Ψ(r), t)
∂r

(cid:90)

∂
∂r

Y

(cid:107) = (cid:107)

L(Yt, h(r, t))p(Yt|r)dYt(cid:107) =

[L(Yt, h(r, t))p(Yt|r)] dYt(cid:107) =

p(Yt|r)

L(Yt, h(r, t))+L(Yt, h(r, t))

p(Yt|r)dYt(cid:107) ≤

∂
∂r

∂
∂r

(cid:107)

(cid:107)

(cid:107)

(cid:90)

Y

(cid:90)

Y

(cid:90)

Y

(cid:90)

Y

(cid:90)

Y

(cid:90)

Y

(cid:90)

Y

∂
∂r
∂
∂r

p(Yt|r)(cid:107)

L(Yt, h(r, t))(cid:107) dYt+

L(Yt, h(r, t))

p(Yt|r) dYt ≤

∂
∂r
∂L(Yt, h(r, t))
∂h(r, t)

p(Yt|r)(cid:107)

∂h(r, t)
∂r

(cid:107) dYt+

L(Yt, h(r, t))

p(Yt|r) dYt ≤

∂
∂r

p(Yt|r)KL · b · K + M · ρ(Φ) · K,

(19)

(20)

(21)

where inequality 19 is due to Assumption A3 and inequal-
ity 20 is due to Lemma A6.

Lemma A8. Let u = p(t = 1) be the marginal probability
of treatment, and assume 0 < u < 1. Let Φ : X → R be a
one-to-one, Jacobian-normalized representation function.
Let K be the Lipschitz constant of the functions p(Yt|x) on
X . Let KL be the Lipschitz constant of the loss function L,
and M be as in Assumption A3. Let h : R × {0, 1} → R
be an hypothesis with Lipschitz constant bK. Then:

our control and measures an aspect of the complexity of
the true underlying functions we wish to approximate. The
terms KL and M depend on our choice of loss function and
the size of the space Y. The term b comes from our assump-
tion that the hypothesis h has norm bK. Note that smaller
b, while reducing the bound, might force the factual loss
term (cid:15)F (h, Φ) to be larger since a small b implies a less
ﬂexible h. Finally, consider the term ρ(Φ). The assump-
tion that Φ is normalized is rather natural, as we do not
expect a certain scale from a representation. Furthermore,
below we show that in fact the Wasserstein distance is pos-
itively homogeneous with respect to the representation Φ.
Therefore, in Lemma A8, we can indeed assume that Φ is
normalized. The speciﬁc choice of Jacobian-normalized
scaling yields what is in our opinion a more interpretable
result in terms of the inverse condition number ρ(Φ). For
twice-differentiable Φ, ρ(Φ) is minimized if and only if Φ
is a linear orthogonal transformation (mat).

Lemma A9. The Wasserstein distance is positive homoge-
neous for scalar transformations of the underlying space.
Let p, q be probability density functions deﬁned over X .
For α > 0 and the mapping Φ(x) = αx, let pα and qα be
the distributions on αX induced by Φ. Then:

Wass (pα, qα) = αWass (p, q) .

Proof. Following (Villani, 2008; Kuang & Tabak, 2016),
we use another characterization of the Wasserstein dis-
tance. Let Mp,q be the set of mass preserving maps from
X to itself which map the distribution p to the distribu-
tion q. That is, Mp,q = {M : X → X s.t. q(M (S)) =
p(S) for all measurable bounded S ⊂ X }. We then have
that:

(cid:15)CF (h, Φ) ≤
(1 − u)(cid:15)t=1
F (h, Φ) + u(cid:15)t=0
2 (M ρ(Φ) + b) · K · KL · Wass(pt=1

F (h, Φ)+

Φ , pt=0

Φ ).

(22)

Wass(p, q) = inf

(cid:107)M (x) − x(cid:107)p(x) dx.

(23)

(cid:90)

M ∈Mp,q

X

Proof. We will apply Lemma A4 with G = {g
:
R → R s.t. f is 1-Lipschitz}. By Lemma A7, we have
that for BΦ = (M ρ(Φ) + b) · K · KL,
the function
1
(cid:96)h,Φ(Ψ(r), t) ∈ G. Inequality (22) then holds as a spe-
BΦ
cial case of Lemma A4.

Theorem 2. Under the assumptions of Lemma A8, using
the squared loss for (cid:15)F , we have:

(cid:15)PEHE(h, Φ) ≤
2(cid:15)t=0
Y +
Φ , pt=0
2 (M ρ(Φ) + b) · K · KL · Wass(pt=1

F (h, Φ) + 2(cid:15)t=1

F (h, Φ) − 4σ2

Φ ).

Proof. Plug in the upper bound of Lemma A8 into the up-
per bound of Theorem 1.

We examine the constant (M ρ(Φ) + b)·K ·KL in Theorem
A8. K, the Lipschitz constant of m0 and m1, is not under

α : αX → αX , by M ∗

It is known that the inﬁmum in (23) is actually achievable
(Villani, 2008, Theorem 5.2). Denote by M ∗ : X → X
the map achieving the inﬁmum for Wass(p, q) . Deﬁne
M ∗
α ), where
x(cid:48) = αx. M ∗
α(x(cid:48)) −
x(cid:48)(cid:107) = α(cid:107)M ∗(x)−x(cid:107). Therefore M ∗
α achieves the inﬁmum
for the pair (pα, qα), and we have that Wass (pα, qα) =
αWass (p, q).

α maps pα to qα, and we have that (cid:107)M ∗

α(x(cid:48)) = αM ∗( x(cid:48)

A.4. Functions in the unit ball of a RKHS

Let Hx, Hr be a reproducing kernel Hilbert space, with
corresponding kernels kx(·, ·), kr(·, ·). We have for all
x ∈ X that kx(·, x) is its Hilbert space mapping, and simi-
larly kr(·, r) for all r ∈ R.

Recall that the major condition in Lemma A4 is that
1
(cid:96)h,Φ(Ψ(r), t) ∈ G. The function space G we use here
BΦ
is G = {g ∈ Hr s.t. (cid:107)g(cid:107)Hr ≤ 1}.

Estimating individual treatment effect: generalization bounds and algorithms

We will focus on the case where L is the squared loss, and
we will make the following two assumptions:
Assumption A4. There exist f Y
0 , f Y
1 ∈ Hx such that
mt(x) = (cid:10)f Y
the mean potential out-
, i.e.
come functions m0, m1 are in Hx. Further assume that
(cid:107)f Y

t , kx(x, ·)(cid:11)

t (cid:107)Hx ≤ K.

Hx

Deﬁnition
(cid:113)(cid:82)

A14.

Deﬁne

ηYt(x)

:=

Y (Yt − mt(x))2 p(Yt|x).

ηYt(x) is the standard

t (cid:107)Hx ≤ M .

t , kx(x, ·)(cid:105)Hx

deviation of Yt|x.
0 , f η
Assumption A5. There exists f η
1 ∈ Hx such that
ηYt(x) = (cid:104)f η
the conditional standard
, i.e.
deviation functions of Yt|x are in Hx. Further assume that
(cid:107)f η
Assumption A6. Let Φ : X → Y be an invertible rep-
resentation function, and let Ψ be its inverse. We assume
there exists a bounded linear operator ΓΦ : Hr → Hx such
that (cid:10)f Y
= (cid:10)f Y
. We fur-
ther assume that the Hilbert-Schmidt norm (operator norm)
(cid:107)ΓΦ(cid:107)HS of ΓΦ is bounded by KΦ.

t , kx(Ψ(r), ·)(cid:11)

t , ΓΦkr(r, ·)(cid:11)

Hx

Hx

Hr

Hr

recall

Φf Y

Φf Y

the Hilbert

t , kr(r, ·)(cid:11)

where equality (24) is by Deﬁnition A14 of η, and because
(cid:82)
Y (Yt − mt(x)) p(Yt|x) dYt = 0 by deﬁnition of mt(x).
that r = Φ(x), x = Ψ(r).
Moving to R,
space, we have that
By linearity of
t , kr(r, ·)(cid:11)
(cid:10)Γ∗
Φf Y
−
=
mt(Ψ(r)) − h(r, t)
Hr
t , kr(r, ·)(cid:11)
= (cid:10)Γ∗
(cid:10)f h
t − f h
. By a well
known result (Steinwart & Christmann, 2008, Theorem
7.25), the product (Yt(Ψ(r))−h(r, t))·(Yt(Ψ(r))−h(r, t))
lies in the tensor product space Hr ⊗ Hr, and is equal to
(cid:10)(Γ∗
Φf Y
Hr⊗Hr
The norm of this function in Hr ⊗ Hr is (cid:107)Γ∗
t (cid:107)2
.
Hr
This is the general Hilbert space version of the fact that for
a vector w ∈ Rd one has that (cid:107)ww(cid:62)(cid:107)F = (cid:107)w(cid:107)2
2, where
(cid:107) · (cid:107)F is the matrix Frobenius norm, and (cid:107) · (cid:107)2
2 is the
square of the standard Euclidean norm. We therefore have
a similar result for η2
(x) =
Yt
Φf η
t ⊗ Γ∗
(Ψ(r)) = (cid:104)Γ∗
η2
t , kr(r, ·) ⊗ kr(r, ·)(cid:105)Hr⊗Hr
.
Yt
t (cid:107)2
The norm of this function in Hr ⊗ Hr is (cid:107)Γ∗
.
Hr
Overall this leads us to conclude, using Equation (25) that
(cid:96)h,Φ(Ψ(r), t) ∈ Hr ⊗ Hr. Now we have, using (25):

t ), kr(r, ·) ⊗ kr(r, ·)(cid:11)
t − f h

, using Assumption A5: η2
Yt

t ) ⊗ (Γ∗

t − f h

t − f h

Φf η

Φf η

Φf Y

.

The two assumptions above amount to assuming that Φ can
be represented as one-to-one linear map between the two
Hilbert spaces Hx and Hr.

(cid:107)(cid:96)h,Φ(Ψ(r), t)(cid:107)Hr⊗Hr =
Φf Y
(cid:107)(Γ∗

t ) ⊗ (Γ∗

t − f h

Φf Y

t − f h

t ) + Γ∗

Φf η

t ⊗ Γ∗

Φf η

t (cid:107)Hr⊗Hr ≤

Hr

, where Γ∗

t , kr(r, ·)(cid:11)

Under Assumptions A4 and A6 about m0, m1, and Φ, we
have that mt(Ψ(r)) = (cid:10)Γ∗
Φf Y
Φ is
the adjoint operator of ΓΦ (Grunewalder et al., 2013).
Lemma A10. Let h : R × {0, 1} → R be an hypothesis,
and assume that there exist f h
t ∈ Hr such that h(r, t) =
(cid:10)f h
t (cid:107)Hr ≤ b. Under As-
sumption A4 about m0, m1, we have that (cid:96)h,Φ(Ψ(r), t) =
(cid:82)
Y (Yt − h(r, t))2 p(Yt|r)dYt is in the tensor Hilbert space
Hr ⊗ Hr. Moreover, the norm of (cid:96)h,Φ(Ψ(r), t) in Hr ⊗ Hr
ΦK 2 + b2(cid:1).
is upper bounded by 4 (cid:0)K 2

, and such that (cid:107)f h

t , kr(r, ·)(cid:11)

Hr

Proof. We ﬁrst decompose (cid:82)
into a noise and mean ﬁtting term, using r = Φ(x):

Y (Yt − h(r, t))2 p(Yt|x)dYt

(Yt − mt(x) + mt(x) − h(Φ(x), t))2 p(Yt|x) dYt =

(cid:96)h,Φ(Ψ(r), t) =
(cid:90)

(Yt − h(r, t))2 p(Yt|r) dYt =

Y

(cid:90)

Y

(cid:90)

(Yt − mt(x))2 p(Yt|x) dYt+

Y
(mt(x) − h(Φ(x), t))2 +
(cid:90)

2

(Yt − mt(x)) (mt(x) − h(Φ(x), t)) p(Yt|x)dYt =

Y

η2
Yt

(x) + (mt(x) − h(Φ(x), t))2 + 0,

(24)

(25)

Φf η

t (cid:107)2
Hr
+ 2(cid:107)f h
t (cid:107)2
t (cid:107)2

(cid:107)Γ∗
t − f h
Φf Y
2(cid:107)Γ∗
Φf Y
t (cid:107)2
Hr
(cid:0)2(cid:107)f Y
(cid:107)Γ∗
Φ(cid:107)2
(cid:0)2(cid:107)f Y
(cid:107)ΓΦ(cid:107)2
2K 2
Φ(K 2 + M 2) + 2b2.

+ (cid:107)Γ∗
t (cid:107)2
Hr
+ (cid:107)f η
+ (cid:107)f η

HS

HS

Hx

Hx

t (cid:107)2
Hr
+ (cid:107)Γ∗
t (cid:107)2
t (cid:107)2

≤
Φf η
t (cid:107)2
≤
Hr
(cid:1) + 2(cid:107)f h
t (cid:107)2
Hr
(cid:1) + 2(cid:107)f h
t (cid:107)2
Hr

Hx

Hx

=

≤

(26)

(27)

(28)

(29)

(30)

H + 2(cid:107)b(cid:107)2

H ≤ 2(cid:107)a(cid:107)2

Inequality (26) is by the norms given above and the triangle
inequality. Inequality (27) is because for any Hilbert space
H, (cid:107)a − b(cid:107)2
H. Inequality (28) is by the
deﬁnition of the operator norm. Equality (29) is because
the norm of the adjoint operator is equal to the norm of
the original operator, where we abused the notation (cid:107) · (cid:107)HS
to mean both the norm of operators from Hx to Hr and
vice-versa. Finally, inequality (30) is by Assumptions A4,
A5 and A6, and by the Lemma’s premise on the norm of
f h
T .

Lemma A11. Let u = p(t = 1) be the marginal proba-
bility of treatment, and assume 0 < u < 1. Assume the
distribution of Yt conditioned on x follows Assumptions
A5 with constant M . Let Φ : X → R be a one-to-one
representation function which obeys Assumption A6 with
corresponding operator ΓΦ with operator norm KΦ. Let
the functions Y0, Y1 obey Assumption A4, with bounded
Hilbert space norm K . Let h : R × {0, 1} → R be an
hypothesis, and assume that there exist f h
t ∈ Hr such that
h(r, t) = (cid:10)f h
t (cid:107)Hr ≤ b. Assume
that (cid:15)F and (cid:15)CF are deﬁned with respect to L being the

t , kr(r, ·)(cid:11)

, such that (cid:107)f h

Hr

Estimating individual treatment effect: generalization bounds and algorithms

squared loss. Then:

(cid:15)CF (h, Φ) ≤
(1 − u)(cid:15)t=1
2 (cid:0)K 2

F (h, Φ) + u(cid:15)t=0

F (h, Φ)+

Φ(K 2 + M 2) + b2(cid:1) · MMD(pt=1

Φ , pt=0

Φ ),

(31)

where (cid:15)CF and (cid:15)F use the squared loss.

apply Lemma A4 with G

Proof. We will
f ∈ Hr ⊗ Hr s.t. (cid:107)f (cid:107)Hr⊗Hr ≤ 1.
we have that for BΦ = 2 (cid:0)K 2
being the squared loss,
(31) then holds as a special case of Lemma A4.

=
By Lemma A10,
Φ(K 2 + M 2) + b2(cid:1) and L
(cid:96)h,Φ(Ψ(r), t) ∈ G. Inequality

1
BΦ

Theorem 3. Under the assumptions of Lemma A11, using
the squared loss for (cid:15)F , we have:

(cid:15)PEHE(h, Φ) ≤
2(cid:15)t=0
4 (cid:0)K 2

F (h, Φ) + 2(cid:15)t=1

F (h, Φ) − 4σ2

Y +

Φ(K 2 + M 2) + b2(cid:1) · MMD(pt=1

Φ , pt=0

Φ ).

Proof. Plug in the upper bound of Lemma A11 into the
upper bound of Theorem 1.

B. Algorithmic details

We give details about the algorithms used in our frame-
work.

B.1. Minimizing the Wasserstein distance

In general, computing (and minimizing) the Wasserstein
distance involves solving a linear program, which may
be prohibitively expensive for many practical applications.
Cuturi (2013) showed that an approximation based on en-
tropic regularization can be obtained through the Sinkhorn-
Knopp matrix scaling algorithm, at orders of magnitude
faster speed. Dubbed Sinkhorn distances, the approxima-
tion is computed using a ﬁxed-point iteration involving re-
peated multiplication with a kernel matrix K. We can use
the algorithm of Cuturi (2013) in our framework. See Al-
gorithm 1 for an overview of how to compute the gradient
g1 in Algorithm ??. When computing g1, disregarding the
gradient ∇WT ∗ amounts to minimizing an upper bound on
the Sinkhorn transport. More advanced ideas for stochas-
tic optimization of this distance have recently proposed by
Aude et al. (2016), and might be used in future work.

While our framework is agnostic to the parameterization of
Φ, our experiments focus on the case where Φ is a neural
network. For convenience of implementation, we may rep-
resent the ﬁxed-point iterations of the Sinkhorn algorithm

Let

Algorithm 1 Computing the stochastic gradient of the
Wasserstein distance
1: Input: Factual (x1, t1, y1), . . . , (xn, tn, yn), represen-

tation network ΦW with current weights by W

2: Randomly sample a mini-batch with m treated and m(cid:48)

control units (xi1, 0, yi1 ), . . . ,
(xim, 0, yim ), (xim+1, 1, yim+1), . . . , (xi2m , 1, yi2m )
3: Calculate the m × m pairwise distance matrix between

all treatment and control pairs M (ΦW):
Mkl(Φ) = (cid:107)ΦW(xik ) − ΦW(xim+l )(cid:107)

4: Calculate the approximate optimal transport matrix T ∗
using Algorithm 3 of Cuturi & Doucet (2014), with
input M (ΦW)

5: Calculate the gradient:

g1 = ∇W (cid:104)T ∗, M (ΦW)(cid:105)

as a recurrent neural network, where the states ut evolve
according to

ut+1 = nt./(ncK(1./(u(cid:62)

t K)(cid:62))) .

Here, K is a kernel matrix corresponding to a metric such
as the euclidean distance, Kij = e−λ(cid:107)Φ(xi)−Φ(xj )(cid:107)2 , and
nc, nt are the sizes of the control and treatment groups. In
this way, we can minimize our entire objective with most
of the frameworks commonly used for training neural net-
works, out of the box.

B.2. Minimizing the maximum mean discrepancy

The MMD of treatment populations in the representation
Φ, for a kernel k(·, ·) can be written as,

MMDk({ΦW(xij )}m
m
(cid:88)

m
(cid:88)

1
m(m − 1)

j=1, {ΦW(xik )}m(cid:48)

k=m+1) = (32)

k(ΦW(xij ), ΦW(xik )) (33)

+

2
mm(cid:48)

j=1

k=1,k(cid:54)=j

m
(cid:88)

m+m(cid:48)
(cid:88)

j=1

k=m

m
(cid:88)

m(cid:48)
(cid:88)

j=1

k=m,k(cid:54)=j

+

1
m(cid:48)(1 − m(cid:48))

k(ΦW(xij ), ΦW(xik )) (34)

k(ΦW(xij ), ΦW(xik )) (35)

The linear maximum-mean discrepancy can be written as a
distance between means. In the notation of Algorithm ??,

MMD = 2

ΦW(xij ) −

ΦW(xik )

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
m

m
(cid:88)

j=1

1
m

m
(cid:88)

j=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)2

1
m(cid:48)

m(cid:48)
(cid:88)

k=m+1

1
m(cid:48)

m+m(cid:48)
(cid:88)

k=m+1

f (W) =

ΦW(xij ) −

ΦW(xik )

Estimating individual treatment effect: generalization bounds and algorithms

References
MathOverﬂow: functions with orthogonal Jacobian. https:

//mathoverflow.net/questions/228964/
functions-with-orthogonal-jacobian.
cessed: 2016-05-05.

Ac-

Aude, Genevay, Cuturi, Marco, Peyr´e, Gabriel, and Bach, Francis.
Stochastic optimization for large-scale optimal transport. arXiv
preprint arXiv:1605.08527, 2016.

Ben-Israel, Adi. The change-of-variables formula using matrix
volume. SIAM Journal on Matrix Analysis and Applications,
21(1):300–312, 1999.

Cuturi, Marco. Sinkhorn distances: Lightspeed computation of
optimal transport. In Advances in Neural Information Process-
ing Systems, pp. 2292–2300, 2013.

Cuturi, Marco and Doucet, Arnaud. Fast computation of Wasser-
In Proceedings of The 31st International

stein barycenters.
Conference on Machine Learning, pp. 685–693, 2014.

Gretton, Arthur, Borgwardt, Karsten M., Rasch, Malte J.,
Sch¨olkopf, Bernhard, and Smola, Alexander. A kernel two-
sample test. J. Mach. Learn. Res., 13:723–773, March 2012.
ISSN 1532-4435.

Grunewalder, Steffen, Arthur, Gretton, and Shawe-Taylor, John.
In Proceedings of the 30th International
Smooth operators.
Conference on Machine Learning (ICML-13), pp. 1184–1192,
2013.

Kuang, Max and Tabak, Esteban. Preconditioning of optimal

M¨uller, Alfred. Integral probability metrics and their generating
classes of functions. Advances in Applied Probability, pp. 429–
443, 1997.

Sriperumbudur, Bharath K, Fukumizu, Kenji, Gretton, Arthur,
Sch¨olkopf, Bernhard, Lanckriet, Gert RG, et al. On the em-
pirical estimation of integral probability metrics. Electronic
Journal of Statistics, 6:1550–1599, 2012.

Steinwart, Ingo and Christmann, Andreas. Support vector ma-

chines. Springer Science & Business Media, 2008.

Villani, C´edric. Optimal transport: old and new, volume 338.

Springer Science & Business Media, 2008.

Table 1. Hyperparameters and ranges.

Parameter
Imbalance parameter, α
Num. representation layers
Num. hypothesis layers
Dim. representation layers
Dim. hypothesis layers
Batch size
Normalization
Weight decay (hypothesis)

k=−10

Range
{10k/2}6
{1, 2, 3}
{1, 2, 3}
{20, 50, 100, 200}
{20, 50, 100, 200}
{100, 200, 500, 700}
{projection, batch norm}
{10−4, 10−3, 10−2}

Then the gradient of the MMD with respect to W is,

g1 = 2

df (W)
dW

f (W)
(cid:107)f (W)(cid:107)2

.

C. Experimental details

Our implementations of CFR and TARNet are based on
Python and TensorFlow and are available at https://
github.com/clinicalml/cfrnet. Both models
were trained using stochastic gradient descent with Adam.

Standard methods for hyperparameter selection, such as
cross-validation, are not generally applicable for estimat-
ing the PEHE loss since only one potential outcome is
observed (unless the outcome is simulated). For real-
world data, we may use the observed outcome yj(i)
of the nearest neighbor j(i) to i in the opposite treat-
ment group, tj(i) = 1 − ti as surrogate for the coun-
terfactual outcome. We use this to deﬁne a nearest-
neighbor approximation of the PEHE loss, (cid:15)PEHEnn(f ) =
(cid:0)(1 − 2ti)(yj(i) − yi) − (f (xi, 1) − f (xi, 0))(cid:1)2
1
.
n
On IHDP, we use the objective value on the validation set
for early stopping in CFR, and (cid:15)PEHEnn(f ) for hyperparam-
eter selection. On the Jobs dataset, we use the policy risk
on the validation set.

(cid:80)n

i=1

See Table 1 for a description of hyperparameters and search
ranges.

C.2. Learned representations

Figure 1 show the representations learned by our CFR al-
gorithm.

C.3. Absolute error for increasingly imbalanced data

Figure 2 shows the results of the same experiment as Figure
2 of the main paper, but in absolute terms.

C.1. Hyperparameter selection

transport. Preprint, 2016.

Estimating individual treatment effect: generalization bounds and algorithms

(a) Original data

(b) Linear MMD

(c) Wasserstein

Figure 1. t-SNE visualizations of the balanced representations of IHDP learned by our algorithms CFR, CFR MMD and CFR Wass. We
note that the nearest-neighbor like quality of the Wasserstein distance results in a strip-like representation, whereas the linear MMD
results in a ball-like shape in regions where overlap is small.

Figure 2. Out-of-sample error in estimated ITE, as a function of
IPM regularization parameter for CFR Wass, on 500 realizations
of IHDP, with high (q = 1), medium and low (artiﬁcial) imbal-
ance between control and treated.

010-510-410-310-210-1100101102Imbalancepenalty;®1.01.52.02.53.03.54.04.5²PEHEq=0:0q=0:5q=1:0