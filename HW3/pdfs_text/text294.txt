From Patches to Images: A Nonparametric Generative Model

Geng Ji 1 Michael C. Hughes 2 Erik B. Sudderth 1 3

Abstract
We propose a hierarchical generative model that
captures the self-similar structure of image re-
gions as well as how this structure is shared
across image collections. Our model is based on
a novel, variational interpretation of the popular
expected patch log-likelihood (EPLL) method as
a model for randomly positioned grids of image
patches. While previous EPLL methods modeled
image patches with ﬁnite Gaussian mixtures, we
use nonparametric Dirichlet process (DP) mix-
tures to create models whose complexity grows
as additional images are observed. An exten-
sion based on the hierarchical DP then captures
repetitive and self-similar structure via image-
speciﬁc variations in cluster frequencies. We de-
rive a structured variational inference algorithm
that adaptively creates new patch clusters to more
accurately model novel image textures. Our de-
noising performance on standard benchmarks is
superior to EPLL and comparable to the state-of-
the-art, and we provide novel statistical justiﬁ-
cations for common image processing heuristics.
We also show accurate image inpainting results.

1. Introduction

Models of the statistical structure of natural images play a
key role in computer vision and image processing (Srivas-
tava et al., 2003). Due to the high dimensionality of the im-
ages captured by modern cameras, a rich research literature
instead models the statistics of small image patches. For
example, the K-SVD method (Elad & Aharon, 2006) gen-
eralizes K-means clustering to learn a dictionary for sparse
coding of image patches. The state-of-the-art learned si-
multaneous sparse coding (LSSC, Mairal et al. (2009))
and block matching and 3D ﬁltering (BM3D, Dabov et al.
(2008)) methods integrate clustering, dictionary learning,

1Brown University, Providence, RI, USA. 2Harvard Univer-
sity, Cambridge, MA, USA. 3University of California, Irvine, CA,
USA. Correspondence to: Geng Ji <gji@cs.brown.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

and denoising to extract information directly from a single
corrupted image. Alternatively, the accurate expected patch
log-likelihood (EPLL, Zoran & Weiss (2011)) method
maximizes the log-likelihood of overlapping image patches
under a ﬁnite Gaussian mixture model learned from uncor-
rupted natural images.

We show that with minor modiﬁcations, the objective func-
tion underlying EPLL is equivalent to a variational log-
likelihood bound for a novel generative model of whole
images. Our model coherently captures overlapping image
patches via a randomly positioned spatial grid. By deriv-
ing a rigorous variational bound, we then develop improved
nonparametric models of natural image statistics using the
hierarchical Dirichlet process (HDP, Teh et al. (2006)). In
particular, DP mixtures allow an appropriate model com-
plexity to be inferred from data, while the hierarchical DP
captures the patch self-similarities and repetitions that are
ubiquitous in natural images (J´egou et al., 2009). Unlike
previous whole-image generative models such as ﬁelds of
experts (FoE, Roth & Black (2005)), which uses a single
set of Markov random ﬁeld parameters to model all images,
our HDP model learns image-speciﬁc clusters to accurately
model distinctive textures. Coupled with a scalable struc-
tured variational inference algorithm, we improve on the
excellent denoising accuracy of the LSSC and BM3D al-
gorithms, while providing a Bayesian nonparametric model
with a broader range of potential applications.

2. Expected Patch Log-likelihood

Our approach is derived from models of small (8
8 pixel)
patches of a large natural image x. Let Pi be a binary indi-
RG in
cator matrix that extracts the G = 82 pixels Pix
patch i. To reduce sensitivity to lighting variations, a con-
trast normalizing transform is applied to remove the mean
(or “DC component”) of the pixel intensities in each patch:

×

∈

vi = Pix

−

1

G 1T Pix = BPix,

(1)

for a “zero-centering” matrix B. Zoran & Weiss (2012)
show that a ﬁnite mixture of K zero-mean Gaussians,

p(vi) = (cid:80)K

k=1 πkNorm(vi |
is superior to many classic image models in terms of pre-
dictive likelihood and patch denoising performance.

k ),

(2)

0, Λ−1

From Patches to Images: A Nonparametric Generative Model

The widely-used EPLL image restoration framework mea-
sures the quality of a reconstruction by the expected patch
log-likelihood, “assuming a patch location in the image
is chosen uniformly at random” (Zoran & Weiss, 2011).
Given a corrupted image y, EPLL estimates a clean image
x by minimizing the objective:

min
x

λ
2 (cid:107)

x

2

y

(cid:80)

i log p(BPix).

(3)

(cid:107)

−

−
Here, the sum ranges over all overlapping, completely vis-
ible (uncropped) image patches. The constant λ is deter-
mined by the noise level of the corrupted image y.

Direct optimization of Eq. (3) is challenging, so inspired by
half quadratic splitting (Geman & Yang, 1995), the EPLL
objective can be reformulated as follows:

min
x,¯v

λ
2 (cid:107)

x

y

2 +

−

(cid:107)

(cid:88)

i

κ
2 (cid:107)

Pix

2

¯vi(cid:107)

−

−

log p(B¯vi). (4)

Each patch i is allocated an auxiliary variable ¯vi, which
(unlike the vi variable in Eq. (1)) includes an estimate of
the mean patch intensity. This augmented objective leads
to closed-form coordinate descent updates.
Gating. Assign each patch i to some cluster zi:

zi = arg max

k

πk Norm(cid:0)BPix

0, Λ−1

k + κI(cid:1).

(5)

|

Filtering. Given an approximate clean image x and clus-
ter assignments z, denoise patches via least squares:

(cid:16)

¯vi =

I + κ−1BT Λzi B

Pix.

(cid:17)−1

(6)

Mixing. Given a ﬁxed set of auxiliary patches ¯v and the
noisy image y, a denoised image x is estimated as

(cid:16)

x =

λI + κ

P T

i Pi

(cid:17)−1(cid:16)

λy + κ

(cid:88)

(cid:17)
.

P T

i ¯vi

(7)

(cid:88)

i

i

→ ∞

Annealing. Optimal solutions of Eq. (4) approach those
. EPLL denois-
of the EPLL objective in Eq. (3) as κ
ing algorithms slowly increase κ via an annealing schedule
that must be tuned for best performance.
Justiﬁcation? Empirically, the intuitive EPLL objective
is much more effective than baselines which use only a sub-
set of non-overlapping patches, or average independently
denoised patches (Zoran & Weiss, 2011). But why should
we optimize the expected log-likelihood, instead of the ex-
pected likelihood or another function of patch-speciﬁc like-
lihoods? And how can the EPLL heuristic be generalized
to capture more complex statistics of natural images? This
paper answers these questions by linking EPLL to a rigor-
ous, nonparametric generative model of whole images.

3. Mixture Models for Grids of Image Patches

We now develop the HDP-Grid generative model summa-
rized in Fig. 1, which uses randomly placed patch grids
to formalize the EPLL objective, and hierarchical DP mix-
tures to capture image patch self-similarity.

Figure 1. Directed graphical model for our HDP-Grid model of
M natural images. Clean image xm is generated via a randomly
placed grid wm of patches vm generated by a hierarchical Gaus-
sian mixture model. We observe corrupted images ym.

3.1. Hierarchical Dirichlet Process Mixtures

The hierarchical Dirichlet process (HDP, Teh et al. (2006))
is a Bayesian nonparametric prior used to cluster groups of
related data; we model natural images as groups of patches.
The HDP shares visual structure, such as patches of grass
or bricks, by sharing a common set of clusters (called topics
in applications to text data) across images. In addition, the
HDP models image-speciﬁc variability by allowing each
image to use this shared set of clusters with unique fre-
quencies; grass might be abundant in one image but absent
in another. Via the HDP, we can learn the proper number
of hidden clusters from data, and discover new clusters as
we collect new images with novel visual textures.

The HDP uses a stick-breaking construction to generate a
corpus-wide vector π0 = [π01, π02, . . . , π0k, . . .] of fre-
quencies for a countably inﬁnite set of visual clusters:

(cid:81)k−1

−

β(cid:96)).

(cid:96)=1 (1

βk ∼

Beta(1, γ), π0k(β) (cid:44) βk

(8)
The HDP allocates each image m its own cluster frequen-
cies πm, where the vector π0 determines the mean of a DP
prior on the frequencies of shared clusters:
DP(απ0),

(9)
When the concentration parameter α < 1, we capture
the “burstiness” and self-similarity of natural image re-
gions (J´egou et al., 2009) by placing most probability mass
in πm on a sparse subset of global clusters.

E[πmk] = π0k.

πm ∼

3.2. Image Generation via Random Grids

We sample pixels in image m via a randomly placed grid of
patches. When each patch has G pixels, Fig. 2 shows there
are exactly G grid alignments for an image of arbitrary size.
The alignment wm ∈ {
wm ∼

(10)
Modeling multiple overlapping grids is crucial to capture
real image statistics. As the true grid alignment for each
image is uncertain, posterior inference will favor images

1, . . . , G
}
Cat(1/G, . . . , 1/G).

has a uniform prior:

Λkβkπmwmxmymumgnzmgnvmgngridsg∈1...Gpatchesn∈1...Nmgclustersclustersk∈1...∞imagesm∈1...MFrom Patches to Images: A Nonparametric Generative Model

independent of the HDP mixture model parameters.

3.4. From Patches to Corrupted Images

,

(cid:17)

(cid:16)

(13)

Norm

xm |

mgn¯vmgn, δ2I
P T

Given patches vmg with offsets umg generated via grid
wm = g, we sample a whole “clean image” xm as
(cid:88)Nmg
n=1
where ¯vmgn (cid:44) Cmgnvmgn +umgn. Binary indicator matri-
ces Pmgn, as in Sec. 2, stitch together patches in the chosen
grid g. Image xm is then generated by adding independent
Gaussian noise with small variance δ2. Most patches in the
chosen grid will be fully observed in xm, but as illustrated
in Fig. 2, some may be clipped by the image boundary. In-
dicator matrices Cmgn are deﬁned so Cmgnvmgn + umgn
is a vector containing the observed pixels from patch n.

For image restoration tasks, the observed image ym is a
corrupted version of some clean image xm that we would
like to estimate. Models of natural image statistics are com-
monly validated on the problem of image denoising, where
xm is polluted by additive white Gaussian noise:
xm, σ2I).

(14)
p(ym |
The variance σ2
δ2 indicates the noise level. We
also validate our model on image inpainting prob-
lems (Bertalmio et al., 2000), where some pixels are ob-
served without noise but others are completely missing. By
replacing Eq. (14) with other linear likelihood models, our
novel generative model for natural images may be easily
applied to other tasks including image deblurring (Zoran
& Weiss, 2011), image super resolution (Yang & Huang,
2010), and color image demosaicing (Mairal et al., 2009).

xm) = Norm(ym |
(cid:29)

Figure 2. Generation of a complete image via a randomly posi-
tioned grid of non-overlapping patches. Top left: A 5 × 5 pixel
image, where each pixel is identiﬁed by a distinct colored sym-
bol. Top right: An inﬁnite 2D grid of pixels, divided into 2 × 2
patches. Bottom: The four possible ways a 5 × 5 image may be
generated from 2 × 2 patches. Shaded pixels are clipped by the
image boundary (see Sec. 3.4).

that are likely under all possible wm. Models based on a
single, ﬁxed grid produce severe artifacts at patch bound-
aries, as shown in Fig. 2 of Zoran & Weiss (2011).

3.3. Patch Generation via Gaussian Mixtures

4. Variational Inference

Gaussian mixtures provide excellent density models for
natural image patches (Zoran & Weiss, 2012). We as-
sociate clusters with zero-mean, full-covariance Gaussian
distributions on patches with G pixels. We parameterize
cluster k by a precision (inverse covariance) matrix Λk ∼
Wish(ν, W ), whose conjugate Wishart prior has ν degrees
of freedom and scale matrix W . Given that wm = g, each
of the Nmg patches vmgn in grid g is sampled from an inﬁ-
nite mixture with image-speciﬁc cluster frequencies:

∞
(cid:88)

0, Λ−1

k=1

wm = g) =

πmkNorm(vmgn|
p(vmgn|
Cat(πm) denote the cluster that
Let zmgn |
generates patch n. To account for the contrast normaliza-
tion of Eq. (1), the intensities in patch n are shifted by an
independent, scalar “DC offset” umgn:

wm = g

k ).

(11)

∼

(12)
wm = g) = Norm(umgn |
p(umgn |
= g so that grid g is unobserved, we sam-
Finally, if wm (cid:54)
ple (zmgn, vmgn, umgn) from some reference distribution

r, s2).

We now develop scalable learning algorithms for our non-
parametric, grid-based image model. We ﬁrst examine a
baseline DP Grid model in which the same cluster frequen-
cies π0 are shared by all images. Our full HDP Grid model
then learns image-speciﬁc cluster frequencies πm, and in-
stantiates new clusters to model unique visual textures.

4.1. DP Grid: Variational Inference

Our goal is to infer the DP Grid model parameters that
best explain observed images which may be clean (xm)
or corrupted by noise (ym). The DP Grid model uses
the same cluster probabilities π0, generated from stick-
breaking weights β as in Eq. (8), for all images.

Learning from clean images. Given a training set
of
uncorrupted images x1, . . . xM , we estimate the posterior
distribution p(β, Λ, w, Ψpatch
x) for our global mixture
|
model parameters β and Λ, grid assignment indicators wm,
and patch-level latent variables Ψpatch

m =

D

.
um, vm, zm}

{

n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u n ✚ ★ ¢ u !(cid:1)✚(cid:1)(cid:2)(cid:1)"(cid:1)#(cid:1)!(cid:1)✚(cid:1)(cid:2)(cid:1)"(cid:1)#(cid:1)!(cid:1)✚(cid:1)(cid:2)(cid:1)"(cid:1)#(cid:1)!(cid:1)✚(cid:1)(cid:2)(cid:1)"(cid:1)#(cid:1)!(cid:1)✚(cid:1)(cid:2)(cid:1)"(cid:1)#(cid:1)From Patches to Images: A Nonparametric Generative Model

Exact posterior inference is intractable, so we instead ﬁnd
) = q(β, Λ, w, Ψpatch) mini-
an approximate posterior q(
·
mizing the KL divergence (Wainwright & Jordan, 2008)
from the true posterior p(
x). Equivalently, our variational
method maximizes the following objective

·|

:

max
q∈Q L

(q, x) = max
q∈Q

L

(cid:20)

Eq

log

(cid:21)

)

p(x,
·
)
q(
·

≤

log p(x).

(15)

We constrain the solution of our optimization to come from
a tractable family of structured mean-ﬁeld distributions
,
Q
parameterized by free parameters. Unlike na¨ıve mean-ﬁeld
methods which assume complete posterior independence,
our structured mean-ﬁeld approximation is more accurate
and includes dependencies between some latent variables:

) =
q(
·

∞
(cid:89)

k=1

q(Λk)q(βk)

q(wm)q(Ψpatch
m |

wm).

M
(cid:89)

·

m=1

As in Hughes & Sudderth (2013), this approximate poste-
rior family contains inﬁnitely many clusters, just like the
true posterior. Rather than applying a ﬁxed truncation to
the stick-breaking prior (Blei & Jordan, 2006), we dynam-
ically truncate the patch assignment distributions q(z) to
only use the ﬁrst K clusters to explain the M observed im-
ages. Clusters with indices k > K then have factors q(Λk)
set to the prior, and need not be explicitly represented.

Global mixture model. The global cluster weights β
and precision matrices Λ have standard exponential fam-
ily forms (free parameters are marked by hats):
(cid:1), q(βk) = Beta(cid:0)ˆρk ˆωk, (1
q(Λk) = Wish(cid:0)ˆνk, ˆWk
ˆρk)ˆωk
Here ˆρk = Eq[βk], and ˆωk controls the variance of q(βk).

−

(cid:1).

Image-speciﬁc alignment. For natural images, all grid
alignments are typically of similar quality, so we ﬁx a uni-
(cid:1). This
form alignment posterior q(wm) = Cat(cid:0) 1
simpliﬁes many updates while still avoiding artifacts that
would arise from a single, non-overlapping patch grid.

G , . . . , 1

G

Patch-speciﬁc
factors. The patch-speciﬁc variables
Ψpatch have structured posteriors, conditioned on the value
of the grid indicator wm for the current image:
q(zmgn |
q(umgn |
q(vmgn |
Below, we let Eq[
] denote the conditional expectation with
·
respect to the variational distribution q, given wm.

wm = g) = Categorical(cid:0)ˆrmgn1, ..., ˆrmgnK
wm = g) = Norm(cid:0)ˆumgn, ˆφu
wm = g,zmgn = k) = Norm(cid:0)ˆvmgnk, ˆφv

mgnk

mgn

(cid:1).

(cid:1),

(cid:1),

Learning. Given clean images x, we perform coodinate
, alternatively updating one factor
ascent on the objective
among q(β)q(Λ)q(w)q(Ψpatch). Most updates have closed
forms due to the exponential families deﬁning
(see sup-
plement). As one intuitive example, consider the update for

Q

L

the cluster precision matrix posterior q(Λk|
Nmg
(cid:88)

M
(cid:88)

G
(cid:88)

ˆνk = ν +

Nk, Nk =

ˆνk, ˆWk):

ˆrmgnk,

(16)

1
G

1
G

m=1

g=1

n=1

M
(cid:88)

G
(cid:88)

Nmg
(cid:88)

g=1

n=1

m=1
(cid:124)

(cid:123)(cid:122)
Sk

ˆWk = W +

Eq

(cid:2)1k(zmgn)vmgnvT

mgn

(cid:3) .

(cid:125)

Statistic Nk(ˆr) counts patches assigned to cluster k, while
Sk(ˆr, ˆv, ˆφv) aggregates second moments. These updates
follow the standard form of prior parameter plus expected
sufﬁcient statistic, except the statistics are averaged (not
simply added) across the G grid alignments.

4.2. Image Denoising and Connections to EPLL

Given a corrupted image ym, we seek to compute the pos-
), where we condition on the training
terior p(xm |
set
. Our variational posterior family Q now includes an
additional factor for the unobserved, “clean” image xm:

ym,

D

D

(cid:1).
ˆxm, ˆφx
m
The variational inference objective becomes

q(xm) = Norm(cid:0)xm |

(cid:21)

(cid:20)

D

p(

)
·

log

Eq

max
q∈Q

, ym, xm,
q(xm,
D
and the coordinate ascent update for q(xm) equals
hm
δ2

δ2σ2
δ2 + σ2 I.

(cid:16) ym
σ2 +

ˆxm = ˆφx
m

log p(ym,

ˆφx
m =

)
·

≤

(cid:17)

,

(17)

),

(18)

(19)

The updated covariance is diagonal, improving computa-
tional efﬁciency. The mean depends on the average image
vector across all patches in all grids, denoted by hm:

hm (cid:44) 1
G

G
(cid:88)

Nmg
(cid:88)

g=1

n=1

mgn(CmgnEq[vmgn] + ˆumgn).
P T

(20)

Note that the update for ˆxm in Eq. (19) is similar to the
EPLL update in Eq. (7), except that some terms involving
projection matrices become constants because we account
for partially observed patches. Modeling partial patches is
necessary to produce a valid likelihood bound in Eq. (18).

In fact, as we show below all three terms in the EPLL ob-
jective in Eq. (4) are very similar to our proposed mini-
mization objective function
, up to a scale factor of G.
−L
Of course, a key difference is that our objective seeks full
posteriors rather than point estimates, and enables the HDP
model of multiple images detailed in Sec. 4.3.
EPLL Term 1. When we set λ (cid:44) G
EPLL objective in Eq. (4) becomes
y)T (x

σ2 , the ﬁrst term of the

−
Similarly, suppressing the subscript m denoting the image
for simplicity, Eq[
log p(y
−
2σ2 Eq[(x
1

x)] in our
|
y)T (x

simpliﬁes as

1
2σ2 (x

−L
y)].

(21)

(22)

y).

G

−

·

−

−

From Patches to Images: A Nonparametric Generative Model

EPLL Term 2. Taking the second term in Eq. (4) and
substituting κ = 1/δ2, we have:
1
2δ2
−
The corresponding term Eq[
jective

¯vi)T (Pix
log p(x
can be written similarly up to a scaling by G:

(23)
−
w, u, v)] in our ob-
|

i(Pix

¯vi).

(cid:80)

−

−L
G
(cid:88)

Ng
(cid:88)

g=1

n=1

1
G

1
2δ2

(cid:104)

Eq

(Pgnx

¯vgn)T (Pgnx

−

−

(cid:105)
¯vgn)

.

(24)

−

(cid:80)

π0, Λ).

EPLL Term 3. The third EPLL term assumes zero-
centered patches B¯vi are drawn from Gaussian mixtures:
i log p(B¯vi |

(25)
Similarly, in our minimization objective
we draw vgn
from a DP mixture model. Explicitly including the cluster
assignment zgn, Eq[
−
Ng
(cid:88)

|
Eq[log p(vgn, zgn |
EPLL is similar, but maximizes assignments (Eq. (5))
rather than computing posterior assignment probabilities.

w)] equals

log p(v, z

π0, Λ)].

G
(cid:88)

1
G

(26)

−L

n=1

g=1

−

4.3. HDP Grid: Variational Inference

Image-speciﬁc frequencies. The DP model above, and
the parametric EPLL objective it generalizes, assume the
same cluster frequency vector π0 for each image m. Our
HDP Grid model allows image-speciﬁc frequencies πm to
be learned from data, via the hierarchical regularization of
the HDP prior (Teh et al., 2006). Our approximate posterior
family

now has the following HDP-speciﬁc factors:
ˆρk)ˆωk) ,

Q
q(β) = (cid:81)∞

ˆρk ˆωk, (1

(27)

k=1 Beta (βk |

q([πm1 . . .πmK πm>K]) = Dir(ˆθm1 . . . ˆθmK, ˆθm>K).
This approximate posterior represents inﬁnitely many clus-
ters via a ﬁnite partition of πm into K + 1 terms: one for
each of the K active clusters, and a remainder term at index
>K that aggregates the mass of all inactive clusters. The
free parameter ˆθm is also a vector of size K + 1 whose last
entry represents all inactive clusters. We follow Hughes
et al. (2015) to obtain a closed-form update for ˆθm, and
gradient-based updates for ˆρ, ˆω; see the supplement for de-
tails. We highlight that the ˆθm update naturally includes
a 1
G rescaling of count sufﬁcient statistics as in Eq. (16).
Other factors remain unchanged from the DP Grid model.

−

Image-speciﬁc clusters. Due to the heavy-tailed distri-
bution of natural images (Ruderman, 1997), even with large
training sets, test images may still contain unique textural
patterns like the striped scarf in the Barbara image in Fig. 3.
Fortunately, our Bayesian nonparametric HDP Grid model
provides a coherent way to capture such patterns by ap-
pending K (cid:48) novel, image-speciﬁc clusters to the original
K clusters learned from training images. These novel clus-
ters lead to more accurate posterior approximations q
that better optimize our objective

∈ Q

.
L

We initialize inference by creating K (cid:48) = 100 image-
speciﬁc clusters with the k-means++ algorithm (Arthur
& Vassilvitskii, 2007), which minimizes the cost function

i

J

k),

(cid:80)K(cid:48)
k=1

1k(z(cid:48)

(z(cid:48), Λ(cid:48)) = (cid:80)

i , Λ(cid:48)

i)D(˜vi˜vT

(28)
where the ﬁrst sum is over the set of fully-observed patches
within the image. The function D is the Bregman di-
vergence associated with our zero-mean Gaussian likeli-
hood (Banerjee et al., 2005), and ˜vi = BPiy is a zero-
centered patch. We initialize the algorithm by sampling K (cid:48)
diverse patches in a distance-biased fashion, and reﬁne with
50 iterations of coordinate descent updates of z(cid:48) and Λ(cid:48).

Then we expand the variational posterior q(Λ) into K + K (cid:48)
clusters. The ﬁrst K indices are kept the same as training,
and the last K (cid:48) indices are set via Eq. (16) using sufﬁcient
statistics N (cid:48), S(cid:48) derived from hard assignments z(cid:48):

N (cid:48)
k(cid:48)

(cid:88)

←

i

1k(cid:48)(z(cid:48)

i), S(cid:48)
k(cid:48)

(cid:20) (cid:88)

←

i

1k(cid:48)(z(cid:48)

i)˜vi˜vT

Nk(cid:48)σ2I

i −

(cid:21)

.
+

Here, following Portilla et al. (2003) and Kivinen et al.
(2007), S(cid:48)
k(cid:48) estimates the clean data statistic Sk(cid:48) by sub-
tracting the expected noise covariance. The [
]+ operator
·
thresholds any negative eigenvalues to zero.

Similarly, the other global variational factor q(β) is also
expanded to K + K (cid:48) clusters via sufﬁcient statistics N (cid:48)
and counts of cluster usage from training data. Given
, each factor in q may then be updated in turn
β, Λ
{
(see supplement).
to maximize the variational objective

K+K(cid:48)
k=1
}

Finally, while we initialize K (cid:48) to a large number to avoid
local optima, this may lead to extraneous clusters. We thus
delete new clusters that our sparsity-biased variational up-
dates do not assign to any patch. In the Barbara image in
Fig. 3, this leaves 9 image-speciﬁc clusters. Deletion im-
proves model interpretability and algorithm speed, because
costs scale linearly with the number of instantiated clusters.

L

5. Experiments
Following EPLL, we train our HDP-Grid model using 400
clean training and validation images from the Berkeley seg-
mentation dataset (BSDS, Martin et al. (2001)). We ﬁx
δ = 0.5/255 to account for the quantization of image in-
tensities to 8-bit integers. Observed DC offsets u provide
maximum likelihood estimates of the mean r and variance
s2 in Eq. (12). Similarly, we compute empirical covari-
ance matrices for patches in the same image segments to
estimate hyperparameters W and ν in Eq. (16). Using vari-
ational learning algorithms that adapt the number of clus-
ters to the observed data (Hughes & Sudderth, 2013), we
discover K = 449 clusters for the DP-Grid model, which
we use to initialize our HDP model. We set our annealing
schedule for κ to match that used by the public EPLL code.

Image denoising methods are often divided into two
external methods (like
types (Zontak & Irani, 2011):

From Patches to Images: A Nonparametric Generative Model

Noisy: 20.19 dB

iDP: 29.41 dB

eDP: 32.47 dB

HDP: 32.65 dB

Figure 4. By capturing self-similar patches in the “house” image,
our HDP model reduces artifacts in smooth regions such as the
sky, roof, and walls. Input noise level σ = 25 (20.21 dB).

EPLL: 28.65 dB

eDP: 29.01 dB

HDP: 30.15 dB

HDP: new clusters

Figure 3. For an image with noise level σ = 25, the HDP im-
proves denoising performance by leveraging both internal clusters
(e.g., scarf and tablecloth) and external clusters (e.g., ﬂoor and ta-
ble legs). The bottom right image colors the pixels assigned to
each of 9 internal HDP clusters. Best viewed electronically.

EPLL) that learn all parameters from a training database
of clean images, and internal methods that denoise patches
using other patches of the single noisy image. For example,
the K-SVD (Elad & Aharon, 2006) has an external variant
that uses a dictionary learned from clean images, and an
internal variant that learns its dictionary from the noisy im-
age. A major contribution of our paper is to show that the
hierarchical DP leads to a principled hybrid of internal and
external methods, in which cues from clean and noisy im-
ages are automatically combined in an adaptive way.

5.1. Image Denoising

We test our algorithm on 12 “classic” images used in many
previous denoising papers (Mairal et al., 2009; Zoran &
Weiss, 2011), as well as the 68 BSDS test images used by
(Roth & Black, 2005; Zoran & Weiss, 2011). We evaluate

Figure 5. Denoising performance of grid-based models on the
Barbara image of Fig. 3 (left) and the house image of Fig. 4
(right), as a function of the noise standard deviation. For both
images and all noise levels, the HDP model is superior to base-
lines that solely use external (eDP) or internal (iDP) training, in
terms of PSNR improvement relative to the noisy input image.
When the image is extremely noisy (σ = 100), internal clusters
are of poor quality, and the HDP and eDP models are comparable.

the denoising performance by the peak signal-to-noise ra-
tio (PSNR), a logarithmic transform of the mean squared
error (MSE) between images with normalized intensities,

PSNR (cid:44)

20 log10 MSE.

−

(29)

We also evaluate the structural similarity index (SSIM,
Wang et al. (2004)), which quantiﬁes image quality degra-
dation via changes in structure, luminance, and contrast.

Internal vs. external clusters.
In result ﬁgures, we use
eDP to refer to our DP-Grid model trained solely on exter-
nal clean images and HDP to refer to the HDP-Grid model
that also learns novel image-speciﬁc clusters. We also
train an internal DP-Grid model, referred to as iDP, using
only information from the noisy test image. The ﬁrst four
columns of Table 1 compare their average denoising per-
formance, where EPLL can be viewed as a simpliﬁcation
of eDP. For all noise levels and datasets, the HDP model
has superior performance. As shown in Fig. 6, HDP is more
accurate than EPLL and eDP for every single classic-12 im-
age. Also, the consistent gain in performance from EPLL
to eDP demonstrates the beneﬁts of Bayesian nonparamet-
ric learning of an appropriate model complexity (for EPLL,
the number of clusters was arbitrarily ﬁxed at K = 200).

Fig. 3 further illustrates the complementary role of internal

050100noise level51015PSNRiDPEPLLeDPHDP050100noise level5101520PSNRiDPEPLLeDPHDPFrom Patches to Images: A Nonparametric Generative Model

Table 1. Average PSNR and SSIM values on benchmark datasets (larger values indicate better denoising). Methods are highlighted if
they are indistinguishable with 95% conﬁdence, according to a Wilcoxon signed-rank test on the fraction of images where one method
outperforms another. For all noise levels the patch size of BM3D is ﬁxed to 8 × 8 and LSSC is ﬁxed to 9 × 9.

metric

dataset

iDP

EPLL

eDP

FoE

eKSVD iKSVD BM3D LSSC

PSNR

SSIM

classic-12

BSDS-68

classic-12

BSDS-68

σ

10
25
50
10
25
50

10
25
50
10
25
50

33.66
29.02
25.44
33.10
28.33
25.10

0.9118
0.8189
0.6962
0.9119
0.7964
0.6636

33.68
29.39
26.22
33.37
28.72
25.72

0.9136
0.8286
0.7301
0.9219
0.8090
0.6870

33.77
29.47
26.28
33.42
28.76
25.75

0.9143
0.8299
0.7316
0.9224
0.8103
0.6880

HDP

33.99
29.68
26.42
33.47
28.82
25.83

0.9169
0.8337
0.7366
0.9230
0.8131
0.6962

33.11
28.32
24.69
32.69
27.76
24.48

0.8962
0.8018
0.6885
0.8971
0.7804
0.6585

33.45
28.89
25.44
33.06
28.28
25.17

0.9084
0.8082
0.6926
0.9128
0.7859
0.6544

33.62
29.11
25.64
33.08
28.28
25.17

0.9111
0.8131
0.6975
0.9135
0.7879
0.6539

33.98
29.73
26.55
33.26
28.55
25.59

0.9168
0.8357
0.7425
0.9157
0.8010
0.6840

34.05
29.74
26.43
33.45
28.70
25.50

0.9185
0.8359
0.7390
0.9206
0.8109
0.6885

Figure 6. Clean-image evidence lower bound (ELBO) versus out-
put PSNR (σ = 25) for 12 “classic” images. The horizontal axis
plots log p(xtest|xtrain) ≈ L(xtest, xtrain) − L(xtrain), divided by the
number of pixels. Our HDP is uniformly superior to the eDP.

and external clusters for a single test image (“Barbara”).
The internal iDP perfectly captures some unique textures
like the striped clothing, but produces artifacts in smooth
background regions. The external EPLL and eDP better
represent smooth surfaces and contours, which are com-
mon in training data, but poorly recover striped textures.

As shown in Fig. 5, while the relative accuracy of the eDP
and iDP models varies depending on image statistics, the
HDP model adaptively combines external and internal clus-
ters for superior performance at all noise levels. By captur-
ing the expected self-similarity of image patches, the HDP
model also reduces artifacts in large regions with regular
textures, such as the smoothly shaded areas of Fig. 4.
Computational speed. To denoise a 512
512 pixel im-
age on a modern laptop, our Python code for eDP infer-
ence with K = 449 clusters takes about 12 min. The
public EPLL Matlab code (Zoran & Weiss, 2011) with
K = 200 clusters takes about 5 min. With equal num-
bers of clusters, the two methods have comparable run-
times. Our open-source Python code is available online at

×

Original

FoE

EPLL

HDP

Figure 7. A qualitative comparison of image inpainting algo-
rithms. As illustrated in the three close-up views, the HDP ex-
ploits patch self-similarity to better recover ﬁne details.

github.com/bnpy/hdp-grid-image-restoration.

Learning image-speciﬁc clusters for the HDP model is
more expensive: our non-optimized Python denoising code
currently requires about 30 min. per image. Nearly all
of the extra time is spent on the k-means++ initialization
of Eq. (28). We expect this can be sped up signiﬁcantly
by coding core routines in C, parallelizing some sub-steps
(possibly via GPUs), using fewer internal clusters (100 is
often too many), or using faster initialization heuristics.

11.52ELBO/pixel26283032PSNReDPHDPFrom Patches to Images: A Nonparametric Generative Model

Noisy

BM3D

LSSC

HDP

28.15 dB

30.40 dB

30.95 dB

31.05 dB

20.19 dB

25.58 dB

25.88 dB

28.95 dB

20.19 dB

23.35 dB

23.79 dB

23.87 dB

20.19 dB

36.84 dB

35.60 dB

37.85 dB

Figure 8. Comparison of image denoising methods on BSDS-68. Unlike our HDP model, the BM3D and LSSC methods learn solely
from the noisy image and do not accurately capture some textures such as the sandy ground in Row 1, fallen leaves and tiger tail in Row
2, trees and grass in Row 3, and sky and clouds in Row 4. Noise level σ = 10 in Row 1, σ = 25 elsewhere. Best viewed electronically.

Performance. We compare our HDP model to other
patch-based denoising methods in Table 1. On classic-12,
where many top methods have been hand-tuned to perform
well, our model is statistically indistinguishable from the
best baselines. On the larger BSDS-68, our performance
is superior to the state-of-the-art, showing the value of
nonparametric learning from large image collections. See
Fig. 8 for examples. At higher noise levels (σ = 50), LSSC
has modestly improved performance (0.2 dB in PSNR)
when modeling 12
12 patches (Mairal et al., 2009). HDP
models of larger patches are a promising research area.

×

5.2. Image Inpainting

While many image processing systems are designed for
just one problem, our generative model is useful for many
tasks. For example, we can “inpaint” occluded image re-
gions (like the red pixels in Fig. 7) by modifying Eq. (14) to

→ ∞

let σ2
for only those regions and setting σ2 = 0 else-
where. To process color images, we follow the approach of
FoE and EPLL and convert to the YCbCr color space be-
fore independently inpainting each channel. While ground
truth is unavailable for the classic image in Fig. 7, our grid-
based HDP produces fewer visual artifacts than baselines.

6. Conclusion
We have developed a coherent Bayesian nonparamet-
ric model that, via randomly positioned grids of image
patches, provides a novel statistical foundation for the pop-
ular EPLL method. We show that HDP mixture models of
visual textures can grow in complexity as additional im-
ages are observed and capture the self-similarity of natural
images. Our HDP-grid image denoising and inpainting al-
gorithms are competitive with the state-of-the-art, and our
model is applicable to many other computer vision tasks.

From Patches to Images: A Nonparametric Generative Model

Acknowledgements

This research supported in part by NSF CAREER Award
No. IIS-1349774. MCH supported in part by Oracle Labs.

References

Arthur, D. and Vassilvitskii, S. k-means++: The advan-
tages of careful seeding. In ACM-SIAM Symposium on
Discrete Algorithms, 2007.

Banerjee, A., Merugu, S., Dhillon, I. S., and Ghosh, J.
Clustering with Bregman divergences. Journal of Ma-
chine Learning Research, 6:1705–1749, 2005.

Bertalmio, M., Sapiro, G., Caselles, V., and Ballester, C.
Image inpainting. In Computer Graphics and Interactive
Techniques, pp. 417–424, 2000.

Blei, D. M. and Jordan, M. I. Variational inference for
Dirichlet process mixtures. Bayesian Analysis, 1(1):
121–143, 2006.

Martin, D., Fowlkes, C., Tal, D., and Malik, J. A database
of human segmented natural images and its applica-
tion to evaluating segmentation algorithms and measur-
ing ecological statistics. In International Conference on
Computer Vision, 2001.

Portilla, J., Strela, V., Wainwright, M. J., and Simoncelli,
E. P. Image denoising using scale mixtures of Gaussians
in the wavelet domain. IEEE Transactions on Image Pro-
cessing, 12(11):1338–1351, 2003.

Roth, S. and Black, M. J. Fields of experts: A framework
for learning image priors. In IEEE Conf. on Computer
Vision and Pattern Recognition, volume 2, pp. 860–867,
2005.

Ruderman, D. L. Origins of scaling in natural images. Vi-

sion Research, 37(23):3385–3398, 1997.

Srivastava, A., Lee, A. B., Simoncelli, E. P., and Zhu, S.
On advances in statistical modeling of natural images.
Journal of Mathematical Imaging and Vision, 18(1):17–
33, 2003.

Dabov, K., Foi, A., Katkovnik, V., and Egiazarian, K. Im-
age restoration by sparse 3d transform-domain collabo-
rative ﬁltering. In Electronic Imaging, 2008.

Teh, Y. W., Jordan, M. I., Beal, M. J., and Blei, D. M. Hi-
erarchical Dirichlet processes. Journal of the American
Statistical Association, 101(476):1566–1581, 2006.

Elad, M. and Aharon, M.

Image denoising via sparse
and redundant representations over learned dictionaries.
IEEE Transactions on Image Processing, 15(12):3736–
3745, 2006.

Geman, D. and Yang, C. Nonlinear image recovery with
half-quadratic regularization. IEEE Transactions on Im-
age Processing, 4(7):932–946, 1995.

Hughes, M. C. and Sudderth, E. B. Memoized online vari-
ational inference for Dirichlet process mixture models.
In Neural Information Processing Systems, 2013.

Hughes, M. C., Kim, D. I., and Sudderth, E. B. Reliable
and scalable variational inference for the hierarchical
In Artiﬁcial Intelligence and Statis-
Dirichlet process.
tics, 2015.

J´egou, H., Douze, M., and Schmid, C. On the burstiness of
visual elements. In IEEE Conf. on Computer Vision and
Pattern Recognition, pp. 1169–1176, 2009.

Kivinen, J. J., Sudderth, E. B., and Jordan, M. I.

Image
denoising with nonparametric hidden Markov trees. In
International Conference on Image Processing, 2007.

Mairal, J., Bach, F., Ponce, J., Sapiro, G., and Zisserman,
A. Non-local sparse models for image restoration.
In
International Conference on Computer Vision, 2009.

Wainwright, M. J. and Jordan, M. I. Graphical models,
exponential families, and variational inference. Founda-
tions and Trends in Machine Learning, 1:1–305, 2008.

Wang, Z., Bovik, A. C., Sheikh, H. R., and Simoncelli, E. P.
Image quality assessment: From error visibility to struc-
tural similarity. IEEE Transactions on Image Processing,
13(4):600–612, 2004.

Yang, J. and Huang, T. Image super-resolution: Historical
overview and future challenges. Super-resolution imag-
ing, pp. 20–34, 2010.

Zontak, M. and Irani, M. Internal statistics of a single nat-
ural image. In IEEE Conf. on Computer Vision and Pat-
tern Recognition, pp. 977–984, 2011.

Zoran, D. and Weiss, Y. From learning models of natural
In Interna-

image patches to whole image restoration.
tional Conference on Computer Vision, 2011.

Zoran, D. and Weiss, Y. Natural images, Gaussian mix-
tures and dead leaves. In Neural Information Processing
Systems, 2012.

