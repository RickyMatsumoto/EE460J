Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to
Non-smooth Concave Maximization
Supplementary File

A. Technical Proofs

A.1. Proof of Theorem 1

Proof. “⇐”: If the pair ( ¯w, ¯α) is a sparse saddle point for L, then from the deﬁnition of conjugate convexity and inequali-
ty (3) we have

On the other hand, we know that for any (cid:107)w(cid:107)0 ≤ k and α ∈ F N

P ( ¯w) = max
α∈F N

L( ¯w, α) ≤ L( ¯w, ¯α) ≤ min

L(w, ¯α).

(cid:107)w(cid:107)0≤k

By combining the preceding two inequalities we obtain

L(w, α) ≤ max
α(cid:48)∈F N

L(w, α(cid:48)) = P (w).

P ( ¯w) ≤ min

L(w, ¯α) ≤ min

P (w) ≤ P ( ¯w).

(cid:107)w(cid:107)0≤k

(cid:107)w(cid:107)0≤k

Therefore P ( ¯w) = min(cid:107)w(cid:107)0≤k P (w), i.e., ¯w solves the problem in (1), which proves the necessary condition (a). Moreover,
the above arguments lead to

P ( ¯w) = max
α∈F N

L( ¯w, α) = L( ¯w, ¯α).

Then from the maximizing argument property of convex conjugate we know that ¯αi ∈ ∂li( ¯w(cid:62)xi). Thus the necessary
condition (b) holds. Note that

where C is a quantity not dependent on w. Let ¯F = supp( ¯w). Since the above analysis implies L( ¯w, ¯α) =
min(cid:107)w(cid:107)0≤k L(w, ¯α), it must hold that

L(w, ¯α) =

w +

¯αixi

−

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

λ
2

1
N λ

N
(cid:88)

i=1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
N

N
(cid:88)

i=1

l∗
i (¯αi) + C,

¯w = H ¯F

(cid:32)

−

1
N λ

N
(cid:88)

i=1

(cid:33)

(cid:32)

¯αixi

= Hk

−

(cid:33)

¯αixi

.

1
N λ

N
(cid:88)

i=1

This validates the necessary condition (c).

“⇒”: Conversely, let us assume that ¯w is a k-sparse solution to the problem (1) (i.e., conditio(a)) and let ¯αi ∈ ∂li( ¯w(cid:62)xi)
(i.e., condition (b)). Again from the maximizing argument property of convex conjugate we know that li( ¯w(cid:62)xi) =
¯αi ¯w(cid:62)xi − l∗

i ( ¯αi). This leads to

L( ¯w, α) ≤ P ( ¯w) = max
α∈F N

L( ¯w, α) = L( ¯w, ¯α).

The sufﬁcient condition (c) guarantees that ¯F contains the top k (in absolute value) entries of − 1
N λ
on the expression in (11) we can see that the following holds for any k-sparse vector w

(cid:80)N

i=1 ¯αixi. Then based

By combining the inequalities (12) and (13) we get that for any (cid:107)w(cid:107)0 ≤ k and α ∈ F N ,

L( ¯w, ¯α) ≤ L(w, ¯α).

L( ¯w, α) ≤ L( ¯w, ¯α) ≤ L(w, ¯α).

This shows that ( ¯w, ¯α) is a sparse saddle point of the Lagrangian L.

(11)

(12)

(13)

Proof. “⇒”: Let ( ¯w, ¯α) be a saddle point for L. On one hand, note that the following holds for any k-sparse w(cid:48) and
α(cid:48) ∈ F N

Dual Iterative Hard Thresholding

A.2. Proof of Theorem 2

which implies

min
(cid:107)w(cid:107)0≤k

L(w, α(cid:48)) ≤ L(w(cid:48), α(cid:48)) ≤ max
α∈F N

L(w(cid:48), α),

max
α∈F N

min
(cid:107)w(cid:107)0≤k

L(w, α) ≤ min

(cid:107)w(cid:107)0≤k

max
α∈F N

L(w, α).

On the other hand, since ( ¯w, ¯α) is a saddle point for L, the following is true:

min
(cid:107)w(cid:107)0≤k

max
α∈F N

L(w, α) ≤ max
α∈F N

L( ¯w, α)

(14)

(15)

≤ L( ¯w, ¯α) ≤ min

L(w, ¯α)

(cid:107)w(cid:107)0≤k

≤ max
α∈F N

min
(cid:107)w(cid:107)0≤k

L(w, α).

By combining (14) and (15) we prove the equality in (4).

“⇐”: Assume that the equality in (4) holds. Let us deﬁne ¯w and ¯α such that

max
α∈F N

L( ¯w, α) = min

(cid:107)w(cid:107)0≤k

max
α∈F N

L(w, α)

min
(cid:107)w(cid:107)0≤k

L(w, ¯α) = max
α∈F N

min
(cid:107)w(cid:107)0≤k

L(w, α)

.

Then we can see that for any α ∈ F N ,

L( ¯w, ¯α) ≥ min

(cid:107)w(cid:107)0≤k

L(w, ¯α) = max
α(cid:48)∈F N

L( ¯w, α(cid:48)) ≥ L( ¯w, α),

where the “=” is due to (4). In the meantime, for any (cid:107)w(cid:107)0 ≤ k,

L( ¯w, ¯α) ≤ max
α∈F N

L( ¯w, α) = min

L(w(cid:48), ¯α) ≤ L(w, ¯α).

(cid:107)w(cid:48)(cid:107)0≤k

This shows that ( ¯w, ¯α) is a sparse saddle point for L.

A.3. Proof of Lemma 1

Thus we have

w(α) = arg min
(cid:107)w(cid:107)0≤k

L(w, α) = Hk

−

(cid:32)

(cid:33)

αixi

.

1
N λ

N
(cid:88)

i=1

D(α) = min

L(w, α) = L(w(α), α)

(cid:107)w(cid:107)0≤k

1
N

1
N

N
(cid:88)

i=1

N
(cid:88)

i=1

=

ζ1=

(cid:0)αiw(α)(cid:62)xi − l∗

i (αi)(cid:1) +

(cid:107)w(α)(cid:107)2

λ
2

−l∗

i (αi) −

(cid:107)w(α)(cid:107)2,

λ
2

Proof. For any ﬁxed α ∈ F N , then it is easy to verify that the k-sparse minimum of L(w, α) with respect to w is attained
at the following point:

where “ζ1” follows from the above deﬁnition of w(α).
Now let us consider two arbitrary dual variables α(cid:48), α(cid:48)(cid:48) ∈ F N and any g(α(cid:48)(cid:48)) ∈ 1
∂l∗
that

1 ), ..., w(α(cid:48)(cid:48))(cid:62)xN −
N )]. From the deﬁnition of D(α) and the fact that L(w, α) is concave with respect to α at any ﬁxed w we can derive

N [w(α(cid:48)(cid:48))(cid:62)x1 −∂l∗

N (α(cid:48)(cid:48)

1(α(cid:48)(cid:48)

D(α(cid:48)) = L(w(α(cid:48)), α(cid:48))
≤ L(w(α(cid:48)(cid:48)), α(cid:48))
≤ L(w(α(cid:48)(cid:48)), α(cid:48)(cid:48)) + (cid:104)g(α(cid:48)(cid:48)), α(cid:48) − α(cid:48)(cid:48)(cid:105) .

Dual Iterative Hard Thresholding

This shows that D(α) is a concave function and its super-differential is as given in the theorem.

If we further assume that w(α) is unique and {l∗
∂l∗

1(α1), ..., w(α)(cid:62)xN − ∂l∗

N (αN )] becomes unique, which implies that ∂D(α) is the unique super-gradient of D(α).

i }i=1,...,N are differentiable at any α, then ∂D(α) = 1

N [w(α)(cid:62)x1 −

A.4. Proof of Theorem 3

Proof. “⇒”: Given the conditions in the theorem, it can be known from Theorem 1 that the pair ( ¯w, ¯α) forms a sparse
saddle point of L. Thus based on the deﬁnitions of sparse saddle point and dual function D(α) we can show that

D(¯α) = min

L(w, ¯α) ≥ L( ¯w, ¯α) ≥ L( ¯w, α) ≥ D(α).

(cid:107)w(cid:107)0≤k

This implies that ¯α solves the dual problem in (5). Furthermore, Theorem 2 guarantees the following

D(¯α) = max
α∈F N

min
(cid:107)w(cid:107)0≤k

L(w, α) = min

(cid:107)w(cid:107)0≤k

max
α∈F N

L(w, α) = P ( ¯w).

This indicates that the primal and dual optimal values are equal to each other.

“⇐”: Assume that ¯α solves the dual problem in (5) and D(¯α) = P ( ¯w). Since D(¯α) ≤ P (w) holds for any (cid:107)w(cid:107)0 ≤ k, ¯w
must be the sparse minimizer of P (w). It follows that

max
α∈F N

min
(cid:107)w(cid:107)0≤k

L(w, α) = D(¯α) = P ( ¯w) = min

(cid:107)w(cid:107)0≤k

max
α∈F N

L(w, α).

From the “⇐” argument in the proof of Theorem 2 and Corollary 1 we get that the conditions (a)∼(c) in Theorem 1 should
be satisﬁed for ( ¯w, ¯α).

A.5. Proof of Theorem 4

We need a series of technical lemmas to prove this theorem. The following lemmas shows that under proper conditions,
w(α) is locally smooth around ¯w = w(¯α).
Lemma 2. Let X = [x1, ..., xN ] ∈ Rd×N be the data matrix. Assume that {li}i=1,...,N are differentiable and

If (cid:107)α − ¯α(cid:107) ≤ λN ¯(cid:15)

2σmax(X) , then supp(w(α)) = supp( ¯w) and

Proof. For any α ∈ F N , let us deﬁne

¯(cid:15) := ¯wmin −

(cid:107)P (cid:48)( ¯w)(cid:107)∞ > 0.

1
λ

(cid:107)w(α) − ¯w(cid:107) ≤

(cid:107)α − ¯α(cid:107).

σmax(X, k)
N λ

˜w(α) = −

αixi.

1
N λ

N
(cid:88)

i=1

Consider ¯F = supp( ¯w). Given ¯(cid:15) > 0, it is known from Theorem 3 that ¯w = H ¯F ( ˜w(¯α)) and P (cid:48)( ¯w)
¯(cid:15) > 0 implies ¯F is unique, i.e., the top k entries of ˜w(¯α) is unique. Given that (cid:107)α − ¯α(cid:107) ≤ λN ¯(cid:15)

(cid:107) ˜w(α) − ˜w(¯α)(cid:107) =

(cid:107)X(α − ¯α)(cid:107) ≤

(cid:107)α − ¯α(cid:107) ≤

1
N λ

σmax(X)
N λ

This indicates that ¯F still contains the (unique) top k entries of ˜w(α). Therefore,

λ = H ¯F c (− ˜w(¯α)). Then
2σmax(X) , it can be shown that
¯(cid:15)
2

.

Then it must hold that

(cid:107)w(α) − w(¯α)(cid:107) = (cid:107)H ¯F ( ˜w(α)) − H ¯F ( ˜w(¯α)) (cid:107)

supp(w(α)) = ¯F = supp( ¯w).

This proves the desired bound.

(cid:107)X ¯F (α − ¯α)(cid:107)

=

≤

1
N λ
σmax(X, k)
N λ

(cid:107)α − ¯α(cid:107).

Dual Iterative Hard Thresholding

The following lemma bounds the estimation error (cid:107)α − ¯α(cid:107) = O((cid:112)(cid:104)D(cid:48)(α), ¯α − α(cid:105)) when the primal loss {li}N
smooth.
Lemma 3. Assume that the primal loss functions {li(·)}N
α, α(cid:48)(cid:48) ∈ F and g(α(cid:48)(cid:48)) ∈ ∂D(α(cid:48)(cid:48)):

i=1 are 1/µ-smooth. Then the following inequality holds for any

i=1 are

D(α(cid:48)) ≤ D(α(cid:48)(cid:48)) + (cid:104)g(α(cid:48)(cid:48)), α(cid:48) − α(cid:48)(cid:48)(cid:105) −

λN µ + σ2

min(X, k)

2λN 2

(cid:107)α(cid:48) − α(cid:48)(cid:48)(cid:107)2.

Moreover, ∀α ∈ F and g(α) ∈ ∂D(α),

Proof. Recall that

(cid:107)α − ¯α(cid:107) ≤

(cid:115)

2λN 2(cid:104)g(α), ¯α − α(cid:105)
λN µ + σ2
min(X, k)

.

D(α) =

−l∗

i (αi) −

(cid:107)w(α)(cid:107)2,

λ
2

1
N

N
(cid:88)

i=1

Now let us consider two arbitrary dual variables α(cid:48), α(cid:48)(cid:48) ∈ F. The assumption of li being 1/µ-smooth implies that its
convex conjugate function l∗

i is µ-strongly-convex. Let F (cid:48)(cid:48) = supp(w(α(cid:48)(cid:48))). Then

D(α(cid:48)) =

−l∗

i (α(cid:48)

i) −

(cid:107)w(α(cid:48))(cid:107)2

λ
2

λ
2

1
N

1
N

1
N

1
N

=

≤

≤

N
(cid:88)

i=1

N
(cid:88)

i=1

N
(cid:88)

(cid:16)

i=1

N
(cid:88)

(cid:16)

i=1
1

−l∗

i (α(cid:48)

i) −

(cid:32)

Hk

−

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
N λ

N
(cid:88)

i=1

α(cid:48)

ixi

(cid:33)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

−l∗

i (α(cid:48)(cid:48)

i ) − l∗(cid:48)

i (α(cid:48)(cid:48)

i )(α(cid:48)

i − α(cid:48)(cid:48)

i ) −

(α(cid:48)

i − α(cid:48)(cid:48)

i )2(cid:17)

−

−l∗

i (α(cid:48)(cid:48)

i ) − l∗(cid:48)

i (α(cid:48)(cid:48)

i )(α(cid:48)

i − α(cid:48)(cid:48)

i ) −

(α(cid:48)

i − α(cid:48)(cid:48)

i )2(cid:17)

−

(cid:107)w(α(cid:48)(cid:48))(cid:107)2 +

i w(α(cid:48)(cid:48))(α(cid:48)
x(cid:62)

i − α(cid:48)(cid:48)
i )

µ
2

µ
2

λ
2

λ
2

(cid:32)

HF (cid:48)(cid:48)

−

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

N
(cid:88)

α(cid:48)

ixi

1
N λ

(cid:33)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

i=1

N
(cid:88)

i=1

1
N

−

2λN 2 (α(cid:48) − α(cid:48)(cid:48))(cid:62)X (cid:62)
≤D(α(cid:48)(cid:48)) + (cid:104)g(α(cid:48)(cid:48)), α(cid:48) − α(cid:48)(cid:48)(cid:105) −

F (cid:48)(cid:48)XF (cid:48)(cid:48) (α(cid:48) − α(cid:48)(cid:48))
λN µ + σ2

min(X, k)

(cid:107)α(cid:48) − α(cid:48)(cid:48)(cid:107)2.

2λN 2

This proves the ﬁrst desirable inequality in the lemma. By invoking the above inequality and using the fact D(α) ≤ D(¯α)
we get that

D(¯α) ≤D(α) + (cid:104)g(α), ¯α − α(cid:105) −

≤D(¯α) + (cid:104)g(α), ¯α − α(cid:105) −

λN µ + σ2

min(X, k)

λN µ + σ2

min(X, k)

2λN 2

2λN 2

(cid:107)α − ¯α(cid:107)2

(cid:107)α − ¯α(cid:107)2,

which leads to the second desired bound.

The following lemma gives a simple expression of the gap for properly related primal-dual pairs.
Lemma 4. Given a dual variable α ∈ F N and the related primal variable
(cid:33)

(cid:32)

w = Hk

−

αixi

.

1
N λ

N
(cid:88)

i=1

The primal-dual gap (cid:15)P D(w, α) can be expressed as:

(cid:15)P D(w, α) =

(cid:0)li(w(cid:62)xi) + l∗

i (αi) − αiw(cid:62)xi

(cid:1) .

1
N

N
(cid:88)

i=1

Proof. It is directly to know from the deﬁnitions of P (w) and D(α) that

Dual Iterative Hard Thresholding

P (w) − D(α)

=

=

1
N

1
N

N
(cid:88)

i=1

N
(cid:88)

i=1

li(w(cid:62)xi) +

(cid:107)w(cid:107)2 −

λ
2

(cid:0)αiw(cid:62)xi − l∗

i (αi)(cid:1) +

(cid:107)w(cid:107)2

λ
2

(cid:32)

1
N

N
(cid:88)

i=1

(cid:33)

(cid:0)li(w(cid:62)xi) + l∗

i (αi) − αiw(cid:62)xi

(cid:1) .

This shows the desired expression.

Based on Lemma 4, we can derive the following lemma which establishes a bound on the primal-dual gap.
Lemma 5. Consider a primal-dual pair (w, α) satisfying

Then the following inequality holds for any g(α) ∈ ∂D(α) and β ∈ [∂l1(w(cid:62)x1), ..., ∂lN (w(cid:62)xN )]:

w = Hk

−

(cid:32)

(cid:33)

αixi

.

1
N λ

N
(cid:88)

i=1

P (w) − D(α) ≤ (cid:104)g(α), β − α(cid:105).

Proof. For any i ∈ [1, ..., N ], from the maximizing argument property of convex conjugate we have

and

By summing both sides of above two equalities we get

li(w(cid:62)xi) = w(cid:62)xil(cid:48)

i(w(cid:62)xi) − l∗

i (l(cid:48)

i(w(cid:62)xi)),

i (αi) = αil∗(cid:48)
l∗

i (αi) − li(l∗(cid:48)

i (αi)).

li(w(cid:62)xi) + l∗

i (αi)
i(w(cid:62)xi) + αil∗(cid:48)
i(w(cid:62)xi) + αil∗(cid:48)

=w(cid:62)xil(cid:48)
ζ1
≤w(cid:62)xil(cid:48)

i (αi)) + l∗

i (l(cid:48)

i(w(cid:62)xi)))

i (αi) − (li(l∗(cid:48)
i (αi) − l∗(cid:48)

i (αi)l(cid:48)

i(w(cid:62)xi),

(16)

where “ζ1” follows from Fenchel-Young inequality. Therefore

(cid:104)g(α), β − α(cid:105)

N
(cid:88)

i=1

N
(cid:88)

(cid:16)

i=1

N
(cid:88)

=

=

1
N

1
N

ζ2
≥

1
N

i=1
ζ3=P (w) − D(α),

(w(cid:62)xi − l∗(cid:48)

i (αi))(l(cid:48)

i(w(cid:62)xi) − αi)

w(cid:62)xil(cid:48)

i(w(cid:62)xi) − l∗(cid:48)

i (αi)l(cid:48)

i(w(cid:62)xi) − αiw(cid:62)xi + αil∗(cid:48)

i (αi)

(cid:17)

(li(w(cid:62)xi) + αil∗

i (αi) − w(cid:62)xi)

where “ζ2” follows from (16) and “ζ3” follows from Lemma 4. This proves the desired bound.

The following simple result is also needed in our iteration complexity analysis.
Lemma 6. For any (cid:15) > 0,

1
t

+

ln t
t

≤ (cid:15)

holds when t ≥ max (cid:8) 3

(cid:15) ln 3

(cid:15) , 1(cid:9).

Proof. Obviously, the inequality 1
t implies that 1
t ≤ (cid:15)
3 . Also, we have

t + ln t

t ≤ (cid:15) holds for (cid:15) ≥ 1. When (cid:15) < 1, it holds that ln( 3

(cid:15) ) ≥ 1. Then the condition on

Dual Iterative Hard Thresholding

ln t
t

≤

ln( 3
3

(cid:15) ln 3
(cid:15) )
(cid:15) ln 3

(cid:15)

≤

ln( 3
(cid:15) )2
(cid:15) ln 3
3

(cid:15)

=

2(cid:15)
3

,

where the ﬁrst “≤” follows the fact that ln t/t is decreasing when t ≥ 1 while the second “≤” follows ln x < x for all
x > 0. Therefore we have 1

t + ln t

t ≤ (cid:15).

We are now in the position to prove the main theorem.

of Theorem 4. Part(a): Let us consider g(t) ∈ ∂D(α(t)) with g(t)
we can verify that (cid:107)w(t)(cid:107) ≤ r/λ. Therefore we have

i = 1

N (x(cid:62)

i w(t) − l∗(cid:48)

i (α(t)

i )). From the expression of w(t)

(cid:107)g(t)(cid:107) ≤ c0 =

r + λρ
√
N
λ

.

Let h(t) = (cid:107)α(t) − ¯α(cid:107) and v(t) = (cid:104)g(t), ¯α − α(t)(cid:105). The concavity of D implies v(t) ≥ 0. From Lemma 3 we know that
h(t) ≤ (cid:112)2λN 2v(t)/(λN µ + σmin(X, k)). Then

(h(t))2 =(cid:107)PF N

(cid:16)

α(t−1) + η(t−1)g(t−1)(cid:17)
≤(cid:107)α(t−1) + η(t−1)g(t−1) − ¯α(cid:107)2
=(h(t−1))2 − 2η(t−1)v(t−1) + (η(t−1))2(cid:107)g(t−1)(cid:107)2

− ¯α(cid:107)2

≤(h(t−1))2 −

η(t−1)(λN µ + σmin(X, k))
λN 2

(h(t−1))2 + (η(t−1))2c2
0.

Let η(t) =

(λN µ+σmin(X,k))(t+1) . Then we obtain

λN 2

(h(t))2 ≤

1 −

(h(t−1))2 +

(cid:18)

(cid:19)

1
t

λ2N 4c2
0
(λN µ + σmin(X, k))2t2 .

By recursively applying the above inequality we get

(h(t))2 ≤

λ2N 4c2
0
(λN µ + σmin(X, k))2

(cid:19)

(cid:18) 1
t

+

ln t
t

= c1

+

(cid:18) 1
t

(cid:19)

.

ln t
t

This proves the desired bound in part(a).

Part(b): Let us consider (cid:15) = λN ¯(cid:15)

2σmax(X) . From part(a) and Lemma 6 we obtain

(cid:107)α(t) − ¯α(cid:107) ≤ (cid:15)

after t ≥ t0 = 3c1

(cid:15)2 ln 3c1

Let β(t) := [l(cid:48)

1((w(t))(cid:62)x1), ..., l(cid:48)

(cid:15)2 . It follows from Lemma 2 that supp(w(t)) = supp( ¯w).
N ((w(t))(cid:62)xN )]. According to Lemma 5 we have

(cid:15)(t)
P D = P (w(t)) − D(α(t))
≤ (cid:104)g(t), β(t) − α(t)(cid:105)
≤ (cid:107)g(t)(cid:107)((cid:107)β(t) − ¯α(cid:107) + (cid:107)¯α − α(t)(cid:107)).

Since ¯(cid:15) = ¯wmin − 1
from the smoothness of li and Lemma 2 we get

λ (cid:107)P (cid:48)( ¯w)(cid:107)∞ > 0, it follows from Theorem 2 that ¯α = [l(cid:48)

1( ¯w(cid:62)x1), ..., l(cid:48)

N ( ¯w(cid:62)xN )]. Given that t ≥ t0,

(cid:107)β(t) − ¯α(cid:107) ≤

(cid:107)w(t) − ¯w(cid:107) ≤

(cid:107)α(t) − ¯α(cid:107), .

1
µ

σmax(X, k)
µλN

where in the ﬁrst “≤” we have used (cid:107)xi(cid:107) ≤ 1. Therefore, the following is valid when t ≥ t0:

Dual Iterative Hard Thresholding

(cid:15)(t)
P D ≤ (cid:107)g(t)(cid:107)((cid:107)β(t) − ¯α(cid:107) + (cid:107)¯α − α(t)(cid:107))
σmax(X, k)
µλN

(cid:107)α(t) − ¯α(cid:107).

≤ c0

1 +

(cid:18)

(cid:19)

Since t ≥ t1, from part(a) and Lemma 6 we get (cid:107)α(t) − ¯α(cid:107) ≤
implies (cid:15)(t)

P D ≤ (cid:15). This proves the desired bound.

(cid:15)
c0(1+ σmax(X,k)

µλN

)

, which according to the above inequality

A.6. Proof of Theorem 5
Proof. Part(a): Let us consider g(t) with g(t)
i )). Let h(t) = (cid:107)α(t) − ¯α(cid:107) and v(t) = (cid:104)g(t), ¯α − α(t)(cid:105).
The concavity of D implies v(t) ≥ 0. From Lemma 3 we know that h(t) ≤ (cid:112)2λN 2v(t)/(λN µ + σmin(X, k)). Let
g(t)
Bi

(g(t)) and v(t)
Bi

, ¯α − α(t)(cid:105) Then

j w(t) − l∗(cid:48)

:= (cid:104)g(t)
Bi

j = 1

j (α(t)

N (x(cid:62)

:= HB(t)

i

By taking conditional expectation (with respect to uniform random block selection, conditioned on α(t−1)) on both sides
of the above inequality we get

(h(t))2 =(cid:107)PF N

α(t−1) + η(t−1)g(t−1)

− ¯α(cid:107)2

Bi

(cid:16)

(cid:17)

≤(cid:107)α(t−1) + η(t−1)g(t−1)
=(h(t−1))2 − 2η(t−1)v(t−1)

Bi

− ¯α(cid:107)2

+ (η(t−1))2(cid:107)g(t−1)

(cid:107)2.

Bi

Bi

2η(t−1)v(t−1)

+

Bi

(η(t−1))2(cid:107)g(t−1)

(cid:107)2

Bi

E[(h(t))2 | α(t−1)]
m
(cid:88)

≤(h(t−1))2 −

1
m

i=1
2η(t−1)
m

1
m

m
(cid:88)

i=1

(η(t−1))2
m

=(h(t−1))2 −

v(t−1) +

(cid:107)g(t−1)(cid:107)2

≤(h(t−1))2 −

η(t−1)(λN µ + σmin(X, k))
λmN 2

(h(t−1))2 +

(η(t−1))2
m

c2
0..

Let η(t) =

λmN 2

(λN µ+σmin(X,k))(t+1) . Then we obtain
(cid:18)

E[(h(t))2 | α(t−1)] ≤

1 −

(h(t−1))2 +

(cid:19)

1
t

λ2mN 4c2
0
(λN µ + σmin(X, k))2t2 .

By taking expectation on both sides of the above over α(t−1), we further get

E[(h(t))2] ≤

1 −

E[(h(t−1))2] +

(cid:18)

(cid:19)

1
t

λ2mN 4c2
0
(λN µ + σmin(X, k))2t2 .

This recursive inequality leads to

E[(h(t))2] ≤

λ2mN 4c2
0
(λN µ + σmin(X, k))2

(cid:19)

(cid:18) 1
t

+

ln t
t

= c2

+

(cid:18) 1
t

(cid:19)

.

ln t
t

This proves the desired bound in part(a).

Part(b): Let us consider (cid:15) = λN ¯(cid:15)

2σmax(X) . From part(a) and Lemma 6 we obtain

E[(cid:107)α(t) − ¯α(cid:107)] ≤ δ(cid:15)

δ2(cid:15)2 ln 3c2

δ2(cid:15)2 . Then from Markov inequality we know that (cid:107)α(t) − ¯α(cid:107) ≤ E[(cid:107)α(t) − ¯α(cid:107)]/δ ≤ (cid:15) holds with
after t ≥ t2 = 3c2
probability at least 1 − δ. Lemma 2 shows that (cid:107)α(t) − ¯α(cid:107) ≤ (cid:15) implies supp(w(t)) = supp( ¯w). Therefore when t ≥ t2, the
event supp(w(t)) = supp( ¯w) occurs with probability at least 1 − δ.

Similar to the proof arguments of Theorem 4(b) we can further show that when t ≥ 4t2, with probability at least 1 − δ/2

Dual Iterative Hard Thresholding

(cid:107)α(t) − ¯α(cid:107) ≤

λN ¯(cid:15)
2σmax(X)

,

(cid:18)

(cid:15)(t)
P D ≤ c0

1 +

(cid:19)

σmax(X, k)
µλN

(cid:107)α(t) − ¯α(cid:107).

which then leads to

Since t ≥ t3, from the arguments in part(a) and Lemma 6 we get that (cid:107)α(t) − ¯α(cid:107) ≤

(cid:15)
c0(1+ σmax(X,k)

µλN

)

holds with probability

at least 1 − δ/2. Let us consider the following events:

• A: the event of (cid:15)(t)

P D ≤ (cid:15);

• B: the event of (cid:107)α(t) − ¯α(cid:107) ≤ λN ¯(cid:15)

2σmax(X) ;

• C: the event of (cid:107)α(t) − ¯α(cid:107) ≤

(cid:15)
c0(1+ σmax(X,k)

µλN

)

.

When t ≥ max{4t2, t3}, we have the following holds:

This proves the desired bound.

P(A) ≥ P(A | B)P(B) ≥ P(C | B)P(B) ≥ (1 − δ/2)2 ≥ 1 − δ.

