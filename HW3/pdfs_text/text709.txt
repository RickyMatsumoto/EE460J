Collect at Once, Use Effectively:
Making Non-interactive Locally Private Learning Possible

Kai Zheng * 1 Wenlong Mou * 1 Liwei Wang 1

Abstract

Non-interactive Local Differential Privacy (LDP)
requires data analysts to collect data from users
through noisy channel at once.
In this paper,
we extend the frontiers of Non-interactive LDP
learning and estimation from several aspects. For
learning with smooth generalized linear losses,
we propose an approximate stochastic gradient
oracle estimated from non-interactive LDP chan-
nel using Chebyshev expansion, which is com-
bined with inexact gradient methods to obtain an
efﬁcient algorithm with quasi-polynomial sam-
ple complexity bound. For the high-dimensional
world, we discover that under (cid:96)2-norm assump-
tion on data points, high-dimensional sparse
linear regression and mean estimation can be
achieved with logarithmic dependence on dimen-
sion, using random projection and approximate
recovery. We also extend our methods to Ker-
nel Ridge Regression. Our work is the ﬁrst
one that makes learning and estimation possible
for a broad range of learning tasks under non-
interactive LDP model.

1. Introduction

Data privacy has become an increasingly important issue
in the age of data science. Differential Privacy (DP), pro-
posed in 2006 by Dwork et al.,(Dwork et al., 2006), provide
a solid foundation and rigorous standard for private data
analysis. Since then, there has been extensive literature
studying the fundamental trade-offs between differential
privacy and accuracy for query answering (Hardt & Roth-
blum, 2010; Hardt et al., 2012; Thaler et al., 2012; Wang

*Equal contribution 1Key Laboratory of Machine Perception,
MOE, School of EECS, Peking University, Beijing, China. Cor-
respondence to: Kai Zheng <zhengk92@pku.edu.cn>, Wen-
long Mou <mouwenlong@pku.edu.cn>, Liwei Wang <wan-
glw@cis.pku.edu.cn>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

et al., 2016), machine learning (Chaudhuri & Monteleoni,
2008; Chaudhuri et al., 2011; Rubinstein et al., 2012; Wang
et al., 2015), and statistical inference (Lei, 2011; Smith,
2011). For more details on DP results, please refer to the
excellent monograph written by Dwork and Roth (Dwork
& Roth, 2014). Intuitively, a DP algorithm uses random-
ized response to defend against adversary, so that change
of one of data points could not be detected.

Despite the prevailing success of this notion in academia,
its applicability in data science practice could be limited.
For example, if data analysts just promise to follow the
differential privacy constraints, user will not feel their pri-
vacy are preserved. The promise could not be validated;
the mechanisms are complicated; and even worse: users do
not trust the data collector at all. Unfortunately, most of
differential privacy algorithms are based on adding noise
calibrated to stability of loss function, which essentially re-
quires access to original data.

Borrowing ideas from classical wisdom on collecting sen-
sitive survey data (Warner, 1965), Local Differential Pri-
vacy (LDP) (Kasiviswanathan et al., 2008; Duchi et al.,
2013b) was proposed as a stronger notion of privacy to re-
solve this problem. LDP requires each of data points to
be passed through a noisy channel during collection. This
channel will ensure one can hardly tell anything about the
user based on what he have sent. The practical advan-
tage of LDP is obvious: users will be comfortable sending
their sensitive information through noisy channels, which
are transparent and reliable; additionally, users can choose
their own privacy parameters, making it possible to as-
sociate with economic value. Therefore, this line of re-
search has attracted lots of attention (Duchi et al., 2013a;b;
Kairouz et al., 2014; Bassily & Smith, 2015; Kairouz et al.,
2016).

Despite the analogy in deﬁnition, the way in which LDP
achieves accurate results are fundamentally different from
classical DP. Essentially, the information collected from
each user is almost completely noisy, from which one needs
to obtain accurate results. The only way to do that is to
make the independently distributed noise cancel out with
each other in some sense. With sand being washed away
by waves, golds begin to appear.

Non-interactive Local DP Learning

Two local privacy notions have been discussed in existing
literature: the interactive model allows the algorithm to col-
lect data sequentially, and decide what to ask based on in-
formation from previously asked users. The non-interactive
model, on the contrary, requires all data to be collected
at once, with no interactive queries allowed. Apparently
the non-interactive model is strictly stronger, and prohibi-
tion on interactive queries rules out most of SGD-type ap-
proaches, making the problem signiﬁcantly harder. How-
ever, non-interactive LDP is more useful in real-world ap-
plications, as opportunities of interactive queries may not
be available in most settings.

In existing literature,
learning and inference under in-
teractive and non-interactive LDP therefore are exhibit-
ing different appearances.
In the interactive world, LDP
is promised with connection to Statistical Query (SQ)
model (Kearns, 1998),
from its very beginning (Ka-
siviswanathan et al., 2011). SQ algorithms for a wide
range of convex ERM problems were proposed by (Feld-
man et al., 2017), implying good risk bounds for LDP.
(Duchi et al., 2013b) established matching upper and lower
bounds for convex risk minimization problems. On the
other hand, very few has been done in the non-interactive
setting. Existing works primarily focus on basic estima-
tion problems such as means and discrete densities (Duchi
et al., 2013a; 2016; Bassily & Smith, 2015), or some func-
tion calculations (Kairouz et al., 2015b). Most of important
modern learning and inference tasks, including estimation
in linear models and convex ERM, are still poorly under-
stood in non-interactive local DP settings.

For the high-dimensional world, where d (cid:29) n while some
low-complexity constraints are imposed, we may hope the
error induced by privacy constraints to be logarithmically
dependent upon d. In classical differential privacy litera-
ture, this has been be addressed using different techniques,
guarantee error bounds logarithmically dependent on di-
mension (Talwar et al., 2015; Smith & Thakurta, 2013).
However, lower bounds have been shown in local privacy
model even for high-dimensional 1-sparse mean estima-
tion, ruling out any good guarantees (Duchi et al., 2016).
The lower bound result illustrates fundamental difﬁculties
of local differential privacy. But if we still want to do high-
dimensional learning under local privacy, are there addi-
tional assumptions that helps?

Therefore, the starting point of this work lies on making
learning possible under the non-interactive LDP setting,
which is the hardest yet the most useful. We initiate the
ﬁrst attempt towards a broad range of learning tasks beyond
simple distribution estimation. In particular, we investigate
two important classes of problems under non-interactive
LDP: (1) High-dimensional sparse linear regression and
mean estimation; (2) Generalized linear models. Our fo-

cus is to design corresponding mechanisms and study their
convergence rates with respect to the number and dimen-
sion of data. One can also consider optimal mechanisms
in terms of privacy parameters like (Geng & Viswanath,
2014), which is of independent interests.

Our Contributions: In this paper, we propose several ef-
ﬁcient algorithms for learning and estimation problems un-
der non-interactive LDP model, with good theoretical guar-
antees. In the following we summarize our contributions.

(1) High Dimensional Estimation: One of exciting
ﬁndings in this paper is about local privacy for high-
dimensional data. Roughly speaking, convergence rate
with logarithmic dependence on the dimension can be at-
tained under LDP, if we assume data points are (cid:96)2 bounded.
This is in sharp contrast with information-theoretic lower
bounds for 1-sparse mean estimation for (cid:96)∞ bounded
data (Duchi et al., 2016). Valid algorithms are presented for
both sparse mean estimation and sparse linear regression,
respectively.
Intuitively, non-interactivity doesn’t bring
about additional difﬁculties, since the loss functions are
quadratic forms. However, if we directly add noise to each
of data points and send it to the server, the aggregated noise
will lead to linear dependence on the dimension. Thus we
adopt the random projection technique, and send the noisy
version of projected data to the server. Based on the aggre-
gated information, we can approximately recover the opti-
mal solution via linear inverse problem.

(2) Learning Smooth Generalized Linear Models: Gen-
eralized linear problems which has additional smooth prop-
erties (we call the loss with respect to it as smooth general-
ized linear loss (SGLL), see rigorous deﬁnition in section
2) include many common loss functions, such as logistic
loss, square loss, etc. Optimizing such losses are intuitively
much more difﬁcult in non-interactive LDP model, as the
loss can be an arbitrary function wT x. This even makes it
difﬁcult for us to obtain an unbiased estimator for objective
function, or its gradient. As a result, when we aggregate the
loss of noisy data together, it is even hard to ensure it con-
verge to the population loss. Approximation theory tech-
niques are introduced to tackle this problem. In particular,
we use polynomials of wT x to approximate nonlinear co-
efﬁcients of gradients. Chebyshev bases, instead of Taylor
series, are used to get faster convergence within an arbi-
trary domain. Then we are able to build inexact stochastic
gradient oracles to arbitrarily speciﬁed accuracy. SIGM al-
gorithm in (Dvurechensky & Gasnikov, 2016) is exploited
to ﬁnd the minimizer with inexact gradients.

Other Related Work:
Local privacy dates back
to (Warner, 1965), who uses random responses to protect
privacy in surveys. In recent LDP literature, both (Duchi
et al., 2013a) and (Kairouz et al., 2016) studied den-
sity estimation methods and their theoretical behaviors in

Non-interactive Local DP Learning

LDP model. Rather than statistical setting in above two
work, (Bassily & Smith, 2015) considered how to produce
frequent items and corresponding frequencies of a dataset
in local model. Besides, (Kairouz et al., 2014) investigated
optimality of LDP mechanisms based on information theo-
retical measures for statistical discrimination.

Approximation techniques are commonly used in DP lit-
erature. (Thaler et al., 2012) employed polynomials for
marginal queries. (Wang et al., 2016) leveraged trigono-
metric polynomials to answer smooth queries.
(Zhang
et al., 2012) also used polynomial approximations and get
basic convergence results in standard DP model. Besides,
the random projection and recovery has also been used in
DP learning (Kasiviswanathan & Jin, 2016) and local DP
histogram estimation (Bassily & Smith, 2015).

In standard DP model, both high-dimensional sparse es-
timation and generalized linear model have been inten-
sively studied. (Kifer et al., 2012) and (Smith & Thakurta,
2013) considered the convergence of private LASSO es-
timator under RSC and incoherence assumptions.
(Tal-
war et al., 2015) considered constrained ERM of sparse
linear regression, and obtained ˜O(log d/n2/3) rate using
private Frank-Wolfe. Above results assume (cid:96)∞-bounded
data. By stronger assumption of (cid:96)2 bounded data, (Ka-
siviswanathan & Jin, 2016) gave a general framework for
high dimensional empirical risk minimization (ERM) prob-
lem. There are several works to estimate generalized lin-
ear model under DP, with a particular emphasis on logis-
tic regression. Objective and output perturbation are used
to get low excess risks (Chaudhuri & Monteleoni, 2008;
Chaudhuri et al., 2011). Both (Bassily et al., 2014) and
(Zhang et al., 2017) considered concrete private algorithms
to solve ERM. None of these existing results extends di-
rectly to non-interactive LDP setting.

2. Preliminaries

Some notations: [p] = {1, 2, · · · , p}. Vectors are writ-
ten in bold symbol, such as x, w. x represents univari-
ate number, which has no relation with x. For a vec-
tor x = [x1, x2, · · · , xd]T , xk represents the power of
(cid:54) r}. Denote S+
each element. B2(r) = {x| (cid:107)x(cid:107)2
as the semipositive matrix space, ProjS+(·) means pro-
jecting a matrix to S+ in terms of Frobenius norm (i.e.
eliminate all negative eigenvalues). For an univariate func-
tion f (x), f (k)(x) represents its k-th derivative, and deﬁne
(cid:13)f (k)(cid:13)
(cid:13)
1−x2 dx. For the reason of limited
space, all omitted proof can be found in the supplementary.

(cid:13)T := (cid:82) 1

|f (k+1)(x)|

−1

√

2.1. Local Differential Privacy

Here we adopt the LDP deﬁnition given in (Bassily &
Smith, 2015).

Deﬁnition 1. A mechanism Q : V → Z is said to be ((cid:15), δ)-
local differential private or ((cid:15), δ)-LDP, if for any v, v(cid:48) ∈ V,
and any (measurable) subset S ⊂ Z, there is

Pr[Q(v) ∈ S] (cid:54) e(cid:15) Pr[Q(v(cid:48)) ∈ S] + δ

If V = {v ∈
(cid:54) 1}, then Q(v) = v + e is ((cid:15), δ)-LDP, where

Just the same with basic results in DP (Dwork & Roth,
2014), there are corresponding basic results for LDP:
Lemma 1 (Gaussian Mechanism).
Rd| (cid:107)v(cid:107)2
e ∈ Rd, and e ∼ N (0, σ2Id), σ = 2(cid:112)2 ln(1.25/δ)/(cid:15).
Lemma 2 (Composition Theorem1). Let Qi : V → Zi be
an ((cid:15)i, δi)-LDP mechanism for i ∈ [k]. Then if Q[k] : V →
(cid:81)k
i=1 Zi is deﬁned to be Q[k](v) = (Q1(v), . . . , Qk(v)),
then Q[k] is ((cid:80)k
i=1 δi)-LDP.

i=1 (cid:15)i, (cid:80)k

The following simple mechanism add Gaussian noise to
preserve LDP of a vector, which serves as a basic tool in
LDP learning and estimation.

Algorithm 1 Basic Private Vector mechanism
Input: A vector x ∈ Rd, privacy parameter (cid:15), δ for LDP
Output: Private vector z

√

2 ln(1.25/δ)

(cid:15)

1: Setting σ =
2: if (cid:107)x(cid:107)2 > 1 then
x = x/ (cid:107)x(cid:107)2
3:
4: end if
5: z ← x + e, where e ∼ N (0, σ2Id)

Theorem 1. Algorithm 1 preserves ((cid:15), δ)-LDP.

3. High Dimensional and Non-parametric

Learning via Random Projections

In this section we consider three learning problems under
non-interactive LDP: Mean Estimation and Linear Regres-
sion in High-dimensions, as well as Kernel Ridge Regres-
sion. Using random projection techniques, we are able to
get logarithmic dependence on d in high-dimensional set-
tings, and also to get good guarantees for Kernel version.
The ﬁrst problem is considered in statistical settings, as we
need to assume a sparse mean vector. The latter two prob-
lems are considered as ERM problems, which can easily be
translated to population risk using uniform convergence.

3.1. High-dimensional Mean Estimation

In this section, we propose a non-interactive LDP mech-
anism for high-dimensional sparse mean estimation prob-
lem. By assuming (cid:96)2 bounded data points, and (cid:96)1 bounded

1Note one can also use the advanced composition mechanism
(Kairouz et al., 2015a) with a reﬁned analysis, but the main de-
pendence over n and d will remain nearly the same.

Non-interactive Local DP Learning

population mean, we can get error rates with logarithmic
dependence on d. Our results are in sharp contrast with the
lower bound for (cid:96)2-bounded general mean estimation un-
der standard DP (Bassily et al., 2014), as well as the lower
bound for (cid:96)∞-bounded 1-sparse mean estimation under lo-
cal DP (Duchi et al., 2016). It can be easily seen that our
method extends to mean estimation problem for arbitrary
low-complexity constraint set in high dimensions. We state
our results in (cid:96)1 setting to keep the arguments clear. Our
problem adopts a statistical estimation setting as follows:

(cid:96)2-bounded sparse mean estimation Suppose there is
an unknown distribution D supported on B(0, 1), with
(cid:107)ED(x)(cid:107)1 ≤ Λ. The (cid:96)2-bounded sparse mean estimation
problem requires us to produce an estimator ˆθ that makes
(cid:107)θ − ED(x)(cid:107)2 small with high probability.

Algorithm 2 LDP (cid:96)1 Constrained Mean Estimation
Input: x1, x2, · · · , xn ∼ i.i.d.D
Output: Estimator z

√

Set p = (cid:100)Λ(cid:15)
Sample G ∼ 1√
for User i do

n(cid:101), and m = (cid:100)18 log 1
δ (cid:101)
p N (0, 1)p×d.

Collect yi = Gxi + ri,
with ri ∼ i.i.d.N (0, 2 log(1.25/δ)

Ip)

(cid:15)2

end for
for j ∈ {1, 2, · · · , m} do

(cid:110)

Sj =
Let µj = 1
|Sj |

m , 2 + (j−1)n
1 + (j−1)n
(cid:80)
yi.

i∈Sj

m , · · · , jn

m

(cid:111)
.

end for
Let M = {µ1, µ2, · · · , µm}.
for j ∈ {1, 2, · · · , m} do

Let rj = min (cid:8)r : |B(cid:96)1(µj, r) ∩ M| ≥ m

(cid:9).

2

end for
Let j∗ = arg minj rj, and u = µj∗
Solve the following convex program:

arg min

(cid:107)z(cid:107)1

z

s.t.(cid:107)Gz − u(cid:107)1 ≤

100p log(nd/δ)
(cid:15)

(cid:114) m
n

nel. This locally private estimation procedure can be
viewed as a variant of noisy compressed sensing, where
(cid:96)2 recovery rate is fundamentally controlled by the Gaus-
sian Mean Width of constraint set (Vershynin, 2015).
Though the distribution has bounded support,
the con-
centration for mean estimation is dimension-dependent,
while dimension-independent Markov Inequalities hold.
To tackle this problem, we employ Median-of-Mean esti-
mator to get exponential tails (Hsu & Sabato, 2016).

We ﬁrst give the following bound on the error in projected
space.
Lemma 3. Let x1, x2, · · · , xn ∼ i.i.d.D with µ = ED[x]
and supp(D) ⊆ B(0, 1). Let G and {yi}n
i=1 deﬁned in the
above procedure. For each of group Sj ﬁxed, we have the
following with probability 2/3:

(cid:13)
(cid:13)
(cid:13)

1
|Sj|

(cid:88)

yi∈Sj

yi − Gµ

≤ O

(cid:13)
(cid:13)
(cid:13)1

(cid:32)

(cid:33)

p log(nd)
(cid:15)(cid:112)|Sj|

(2)

The aggregation step in Algorithm 2 is a high-dimensional
generalization of Median-of-Mean estimator used in
heavy-tailed statistics. The tail properties are guaranteed
in the following lemma:

Lemma 4 (Proposition 9 in (Hsu & Sabato, 2016)).
Suppose in metric space X , a set of points M =
[θ1, θ2, · · · , θm] ∼ i.i.d.D, with P r[dX (θi, θ) ≥ (cid:15)] ≤ 2
3 .
Let ˆθ be generated from the following procedure: ri =
min (cid:8)r : |BX (θi, r) ∩ M| ≥ m
(cid:9),and ˆθ = arg minθi ri.
Then we have:

2

P r[dX ( ˆθ, θ) ≥ 3(cid:15)] ≤ e− m

18

Since the original data are i.i.d. samples from underlying
distribution, small group with ﬁxed indices should also be
i.i, d.. Therefore µ1, µ2, · · · , µk are i.i.d.. Combining
Lemma 3 and Lemma 4 we get the following result:

Corollary 1. The vector u constructed in Algorithm 2 sat-
isﬁes the following with probability 1 − δ:

(1)

(cid:107)u − Gµ(cid:107)1 ≤ O

(cid:18) p log(nd/δ)
(cid:15)

(cid:114) m
n

(cid:19)

(3)

In Algorithm 2 we describe our data collection procedure
and estimation algorithm. We are primarily using two
techniques:
random projection and recovery from low-
complexity structures; median-of-mean estimator to boost
failure probability. The privacy argument is directly impli-
cation of Theorem 1.

Intuitively, adding noise to each entry of mean vector will
result in error rate’s linear dependence on d. Thus we
adopt the random projection technique to send a com-
pressed version of data vector through the noisy chan-

Then we turn to the recovery of original mean estima-
tor. The primary tool we are using are General M ∗ bound
in (Vershynin, 2015).

Lemma 5 (Theorem 6.2 in (Vershynin, 2015), High Prob-
ability Version). For unknown vector x ∈ K ⊆ Rd, let
p N (0, 1)p×d. Noisy vector ν ∈ Rp with (cid:107)ν(cid:107)1 ≤ σ.
G ∼ 1√
Let y = Gx + ν. By solving the following optimization
problem:

arg min
x(cid:48)

(cid:107)x(cid:48)(cid:107)K s.t. (cid:107)Gx(cid:48) − y(cid:107)1 ≤ σ

(4)

Non-interactive Local DP Learning

where (cid:107)·(cid:107)K denotes the Minkowski functional of K. Then
we can get the following with probability 1 − δ

Algorithm 3 LDP (cid:96)1 Constrained Linear Regression
Input: Personal data (x, y), parameter (cid:15), δ, projection ma-

(cid:107)x − x(cid:48)(cid:107)2 ≤ O

(cid:18) w(K) + σ + log 1
δ
√

(cid:19)

p

where w(K) denotes the Gaussian width of K.

By putting these results together we get the bound on esti-
mation loss:

Theorem 2. Algorithm 2 outputs z satisfying the following
with probability 1 − δ:

(cid:107)z − µ(cid:107)2 ≤ O

log

(cid:32)

(cid:114)

log

nd
δ

(cid:18) Λ2
(cid:15)2n

1
δ

4 (cid:33)

(cid:19) 1

3.2. Sparse Linear Regression

i=1(xT

(cid:80)n
(cid:54) 1, yi ∈ [−1, 1]. 2.

In this section, we consider empirical loss of sparse linear
regression, i.e. L(w; D) = 1
i w − yi)2, where
2n
D = {(xi, yi)|i ∈ [n]}, (cid:107)xi(cid:107)2
Deﬁne w∗ = argminw∈C L(w; D), where C =
(cid:54) 1}. We want to obtain a vector wpriv ∈ C
{w| (cid:107)w(cid:107)1
within non-interactive LDP model, such that the empirical
excess risk L(wpriv; D) − L(w∗; D) has polynomial de-
pendences on log d and 1
n .

As in the case of high-dimensional mean estimation, di-
rectly manipulating in the original high dimensional fea-
ture space will introduce large noise, hence we use a sub-
Gaussian random matrix Φ ∈ Rm×d to project original data
(i.e. vectors in Rd) into the low dimensional space (i.e.
Rm) ﬁrst, then perturb each data in low dimensional space
(i.e. Basic Private Vector mechanism given in Algorithm 1)
which protects local privacy, and send it to the server.

Having obtained private synopsis, the server then recon-
struct an unbiased estimator for objective function accord-
ing to these private synopsis. We subtract a quadratic term
to ensure unbiasedness and project to PSD matrices to pre-
serve convexity. To show good approximation guarantee,
we make use of RIP bounds for random projection. As
the loss function is determined by inner products between
w and data, it could be uniformly preserved in projected
space, which guarantees the accuracy of solution estimated
with local privacy. Apparently, our methods also imply
bounds with general low-complexity constraint set that pre-
serves RIP.

Our private learning mechanism is given in Algorithm
3 and any random projection matrix can be used here.
The privacy argument directly follows from Private Vector
Mechanism and composition.

2Our methods suits to any radius of x and y.

trix Φ ∈ Rd×m

Output: Learned classiﬁer wpriv ∈ Rd
1: for Each user i = 1, . . . , n do
2:
3:
4: end for
5: Setting Z = [z1, · · · , zn]T , σ =

zi ← Basic Private Vector (ΦT xi, (cid:15)/2, δ/2)
vi ← Basic Private Vector (yi, (cid:15)/2, δ/2)

2 ln(2.5/δ)

√
2

,

(cid:15)

Q = ProjS+(Z T Z − nσ2Im), v = [v1, · · · , vn]T

6: wpriv ← argminw∈C
ˆL(w; Z, v) := 1

ˆL(w; Z, v), where
2n (ΦT w)T Q(ΦT w) − 1

n vT ZΦT w

In fact, as original data is in L2 ball, and random projection
preserves norms with high probabilty, hence steps 2-4 in
Algorithm 1 will be executed with very low probability.

Denote the true objective function in low dimensional
(cid:13) ¯XΦT w(cid:13)
(cid:13)
2
n yT ¯XΦT w,
space ¯L(w; ¯X, y)
:= 1
(cid:13)
2n
where ¯X = [x1, · · · , xn]T Φ, w ∈ C. Let ˆw∗
:=
¯L(w; ¯X, y). The following lemma gives the
argminw∈C
accuracy of private solution wpriv when reduced into low
dimensional space:

− 1

Lemma 6. Under the assumptions made in this section,
given projection matrix Φ, with high probability over the
randomness of private mechanism, we have

¯L(wpriv; ¯X, y) − ¯L( ˆw∗; ¯X, y) (cid:54) ˜O

(cid:19)

(cid:18)(cid:114) m
n(cid:15)2

(5)

Now, combined with RIP bound for random projection, we
can move on to prove the empirical excess risk of sparse
linear regression:

Theorem 3. Under the assumption in this section, set m =
Θ

, then with high probability , there is

(cid:16)(cid:112)n(cid:15)2 log d

(cid:17)

L(wpriv) − L(w∗) = ˜O

(cid:19)1/4(cid:33)

(cid:32)(cid:18) log d
n(cid:15)2

Note (Talwar et al., 2015) assume data is in L∞ ball, while
both (Kasiviswanathan & Jin, 2016) and ours assume data
is in L2 ball. However, in LDP model, (Duchi et al., 2016)
show it was impossible to obtain polynomial dependences
over log d for (cid:96)0 mean estimation problem if data is in L∞
ball.

3.3. Inﬁnite Dimension: Kernel Ridge Regression

Previous method mainly applies to data with ﬁnite dimen-
sional features. However, it is common to use kernel trick
in practice. This brings about new difﬁculties for LDP
learning, as we could not add noise in the Hilbert space.

Non-interactive Local DP Learning

In this subsection, we take kernel ridge regression as an ex-
ample to show how to use Random Fourier Features (RFF)
(Rahimi et al., 2007) to deal with such cases caused by
shift-invariant kernels (i.e. k(x, y) = k(x − y)). Note
our technique also suits to similar problems.

Fix a shift-invariant kernel k(·, ·), denote the Hilbert space
implicitly deﬁned as H, and the corresponding feature map
as Φ : Rd → H. Let the Hilbert space corresponding
to the random Fourier feature map be ˆH ⊂ Rdp , and its
feature map ˆΦ : Rd → ˆH, where dp is the RFF pro-
jection dimension. Given a subset X ⊂ Rd and data
D = {(xi, yi)|xi ∈ X , i ∈ [n]}, for any f ∈ H, g ∈ ˆH,
deﬁne loss functions in H and ˆH as follows:

LH (f ) :=

L ˆH (g) :=

C
2n

C
2n

(cid:88)

i
(cid:88)

i

(cid:13)
(cid:13)f T Φ(xi) − yi

(cid:13)
2
2 +
(cid:13)

(cid:107)f (cid:107)2
H

(cid:13)
(cid:13)gT ˆΦ(xi) − yi
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)
2

+

(cid:107)g(cid:107)2
ˆH

1
2

1
2

(6)

(7)

where C is the regularization parameter. Denote f ∗ =
argminf ∈H LH (f ), g∗ = argming∈ ˆH L ˆH (g), G as the
Lipschitz constant of square loss, which depends on the
bounded norm of features. Kernel ridge regression try to
optimize formula (6), while after using RFF, we try to solve
formula (7) in non-interactive LDP model, which can be
easily tackled with similar mechanisms like sparse linear
regression above. Borrow the key result in (Rubinstein
et al., 2012) (restated in lemma 7 below), which used RFF
to design private mechanims for SVM in DP model, it be-
comes easy to prove guarantees for kernel ridge regression
in our setting (see Corollary 2).

Lemma 7 ((Rubinstein et al., 2012)). Suppose dual
variables with respect to f ∗, g∗ are L1 norm bounded
by some r > 0, and supx1,x2∈X |Φ(x1)T Φ(x2) −
( ˆΦ(x1))T ˆΦ(x2)| (cid:54) γ, then there is supx∈X |Φ(x)T f ∗ −
( ˆΦ(x))T g∗| (cid:54) rγ + 2(cid:112)(CG + r/2)rγ.
Corollary 2. Algorithm 4 satisﬁes ((cid:15), δ)-LDP, and by set-
ting dp = ˜O

, with high probability, there is

dn(cid:15)2

(cid:16)√

(cid:17)

L ˆH ( ˆwpriv)−LH (f ∗) (cid:54) ˜O

(cid:19)1/4(cid:33)

(cid:32)(cid:18) d
n(cid:15)2

|Φ(x)T f ∗−( ˆΦ(x))T ˆwpriv| (cid:54) ˜O

sup
x∈X

(cid:19)1/8(cid:33)

(cid:32)(cid:18) d
n(cid:15)2

4. Learning Smooth Generalized Linear

Model

In this section, we consider learning smooth general-
ized linear model in non-interactive LDP setting. Non-
interactive LDP learning for this problem is essentially dif-
ﬁcult, as it is even hard to obtain an unbiased estimator of

Algorithm 4 LDP kernel mechanism
Input: Personal data (xi, yi), i ∈ [n], random feature’s
dimension dp, shift-invariant kernel k(x1, x2) =
transform f (s) =
k(x1 − x2) with Fourier
1
2π

(cid:82) e−jsT xk(x)dx, privacy parameter (cid:15), δ

Output: Private output ˆwpriv ∈ Rdp
1: Draw i.i.d. samples s1, s2, . . . , sdp ∈ Rd from f (s)
and b1, b2, . . . , bdp ∈ R from the uniform distribution
on [0, 2π]

2: for i = 1, . . . , n do
3:

1 xi + b1), . . . , cos(sT
dp

(cid:104)
cos(sT
(cid:113) 1
dp

Construct low dimensional random feature ˆΦ(xi) =
(cid:113) 1
∈
dp
ˆC :=
zi ← Basic Private Vector ( ˆΦ(xi), (cid:15)/2, δ/2)
vi ← Basic Private Vector (yi, (cid:15)/2, δ/2)

xi + bdp )

(cid:113) 1
dp

⊂ Rdp

(cid:105)dp

−

(cid:105)(cid:48)

(cid:104)

,

4:
5:
6: end for
7: Setting Z = [z1, · · · , zn]T , σ =

√
2

2 ln(2.5/δ)

,

(cid:15)

Q = ProjS+(Z T Z − nσ2Idp ), v = [v1, · · · , vn]T

8: ˆwpriv ← argmin ˆw
ˆL( ˆw; Z, v) := 1

ˆL( ˆw; Z, v), where
n vT Z ˆw

2n ˆwT Q ˆw − 1

gradient. We resolve this problem using Chebyshev poly-
nomial expansion, which requires additional smoothness
assumptions. Fortunately these assumptions are naturally
satisﬁed by a broad range of learning tasks.

We will ﬁrst deﬁne the Smooth GLM loss family with
appropriate assumptions. Our deﬁnition could be shown
with connection to exponential family GLM, which is com-
monly used in machine learning. We also illustrate our al-
gorithm and guarantees with logistic regression.

Deﬁnition 2. (Absolutely Smooth Functions) We say that
an univariate function h(x) is absolutely smooth, if for any
r > 0, f (x) := h(rx) satisﬁes the following properties:
there exist functions µ1(k; r), µ2(k; r), which are polyno-
mial on k and µ2(k; r) = O(kr), such that for any k ∈ N+,
there is:

(1) f (x), f (cid:48)(x), . . . , f (k−1)(x) are absolutely continuous

on [−1, 1];
(cid:13)f (k)(x)(cid:13)
(cid:13)T

(2) (cid:13)

(cid:54) µ1(k; r) · µ2(k; r)k.

Deﬁnition 3. (Smooth Generalized Linear Loss, SGLL) A
loss function (cid:96)(w; x, y), is called smooth generalized lin-
ear loss, if for any given data (x, y), (cid:96)(w; x, y) is convex
and β-smooth with respect to w, and there exist absolutely
smooth functions h1(x), h2(x), such that (cid:96)(w; x, y) =
−yh1(xT w) + h2(xT w).

It will be convenient to consider population risk directly.
Now, we adopt standard setting of learning problems,

Non-interactive Local DP Learning

where each data point (x, y) is drawn from some under-
(cid:54) 1. Given
lying unknown distribution D and (cid:107)x(cid:107)2
a SGLL (cid:96)(w; x, y),
the population loss is deﬁned as
L(w) := E(x,y)∼D(cid:96)(w; x, y). For simplicity, instead
of assuming w belongs to B2(r), we use the follow-
ing equivalent notation: (cid:96)(w; x, y) = −yh1(rxT w) +
h2(rxT w), and the constraint set for w is C = B2(1).
Denote G(w; x, y) = ∇(cid:96)(w; x, y) = rm(w; x, y)x,
where m(w; x, y) = h(cid:48)
1(rxT w). Suppose
E(x,y)∼D[(cid:107)G(w; x, y) − g(w)(cid:107)2
0, where g(w) =
∇L(w). This is a common assumption in stochastic opti-
mization literature, such as (Bubeck et al., 2015).

2(rxT w) − yh(cid:48)
2] (cid:54) σ2

Given any α > 0, we hope to design a noninteractive local
DP mechanism with low sample complexity, such that the
ﬁnal output point wpriv satisﬁes L(wpriv) − L(w∗) (cid:54) α.

For GLM loss functions, it is easy to see that the stochastic
gradient evaluated on w with data point xi is at the same
direction with xi. So adding isotropic noise to xi provides
”unbiased” information about direction of stochastic gra-
dient. However, the magnitude is a nonlinear function of
wT xi, making it hard for SGD even to converge to popu-
lation minimizer. This is why we seek to ﬁnd polynomial
approximation of the magnitude of gradients.

To estimate the magnitude of gradients, we use Chebyshev
polynomials to approximate nonlinear univariate function
fi(x) = h(cid:48)
i(rx), where x ∈ [−1, 1]. For brevity of
notations, we just use f (x) to represent either f1(x) or
f2(x). Denote the Chebyshev approximation with degree
2 + (cid:80)p
p as ˆfp(x) = 1
k=1 akTk(x), where Tk(x) is the k-
th Chebyshev polynomial, and ak = 2
1−x2 dx
π
is the corresponding coefﬁcient. According to existing re-
sults about Chebyshev approximations and some calcula-
tions, we have the following lemma:

f (x)Tk(x)

(cid:82) 1
−1

√

Lemma 8. Given any α > 0, by setting k =
c ln 1
α , p = (cid:100)k + eµ2(k; r)(cid:101), where c is a constant, we have
(cid:13)
ˆfp(x) − f (x)
(cid:13)
(cid:13)

(cid:54) α

(cid:13)
(cid:13)
(cid:13)∞

The Chebyshev approximations with degree p for fi(x)
(i = 1, 2) are denoted as ˆfip(x) = 1
k=1 aikTk(x) =
(cid:80)p
k=0 cikxk, where cik is the coefﬁcient of term xk. Now

2 + (cid:80)p

we approximate m(w; x, y) and G(w; x, y) as follows:

ˆm(w; x, y) := − y ˆf1p(rxT w) + ˆf2p(rxT w)

=

p
(cid:88)

k=0

(c2k − c1ky)(rxT w)k

ˆG(w; x, y) :=r ˆm(w; x, y)x

With these approximations, we state our mechanism in Al-
gorithm 5, where Basic Private Vector mechanism is given

in Algorithm 1. Note an important trick in Step 6-8 of
Algorithm 5, is that: we run basic private mechanism p
times, to obtain fresh private copies of the same vector x,
which are then used to calculate an unbiased estimation of
ˆG(w; x, y) with variance as low as possible (i.e. line 8 in
Algorithm 6).The LDP property of Algorithm 5 is given
as follows: The privacy proof directly follows from Basic

Algorithm 5 LDP SGLD Mechanism - Collection
Input: Personal data (x, y), expansion order p, privacy pa-

Output: Private synopsis b = {zyi, zj|i ∈ {0} ∪ [p], j ∈

[p(p + 1)/2]} sent to the server
4(p+1) , δy = δ

1: Setting (cid:15)y = (cid:15)

4(p+1) , (cid:15)1 = (cid:15)

p(p+1) , δ1 =

rameter (cid:15), δ

δ
p(p+1)

zyj ← Basic Private Vector(y, (cid:15)y, δy)

2: z0 ← Basic Private Vector(x, (cid:15)/4, δ/4)
3: for i = 0, 1, . . . , p do
4:
5: end for
6: for j = 1, . . . , p(p+1)
7:
8: end for

zj ← Basic Private Vector(x, (cid:15)1, δ1)

do

2

Vector Mechanism and Composition Theorem.

Theorem 4. LDP SGLD Mechanism 5 preserves ((cid:15), δ)-
LDP.

Having obtained the private synopsis sent by all uers, now
the server can construct a stochastic inexact gradient oracle
(deﬁned in Deﬁntion 4) for any point w ∈ C, as stated in
Algorithm 6.

Deﬁnition 4. (Dvurechensky & Gasnikov, 2016) For an ob-
jective function f (w), a (γ, β, σ) stochastic oracle returns
a turple (Fγ,β,σ(w; ξ), Gγ,β,σ(w; ξ)), such that:

Eξ[Fγ,β,σ(w; ξ)] = fγ,β,σ(w)
Eξ[Gγ,β,σ(w; ξ)] = gγ,β,σ(w)
Eξ[(cid:107)Gγ,β,σ(w; ξ) − gγ,β,σ(w)(cid:107)2] (cid:54) σ2

0 (cid:54) h(v, w) (cid:54) β
2

(cid:107)v − w(cid:107)2 + γ, ∀v, w ∈ C

where h(v, w) = f (v) − fγ,β,σ(w) − (cid:104)gγ,β,σ(w), v − w(cid:105).

For any (x, y) in the domain, as loss function (cid:96)(w; x, y) is
convex and β-smooth with respect to w, we can prove the
following lemma:
Lemma 9. For any γ > 0, setting k = c ln 4r
γ , p =
then Algorithm 6 outputs a (γ, β, σ)
(cid:100)k + 2µ2(k; r)(cid:101),
stochastic oracle deﬁned in Deﬁnition 4, where σ =
˜O
.

σ0 + γ + p2p+1(4r)p+1

(cid:17)

(cid:16)

(cid:15)p+2

Non-interactive Local DP Learning

Algorithm 6 LDP SGLD Mechanism - Learning
Input: Private synopsis b = {zy, zj|j ∈ {0} ∪ [p(p +
1)/2]} of each user, public coefﬁcients {c1k, c2k|k ∈
{0} ∪ [p]}, initial point w1
Output: Learned classiﬁer wpriv
1: for s = 1, . . . , n do
2:
3:

\\ Construct stochastic inexact gradient
\\ Denote the private synopsis of user s as b above
for abbreviation
Set t0 = 1
for j = 1, . . . , p do
tj = (cid:81)j(j+1)/2

i=j(j−1)/2+1(wT

s zi)

end for
˜G(ws; b) ←

(cid:32) p

(cid:88)

k=0

(c2k − c1kzyj)tkrk+1

z0

(cid:33)

\\ One update via SIGM
Run one iteration of SIGM algorithm with ˜G(ws, b)
and obtain ws+1

4:
5:
6:
7:

8:

9:
10:

11: end for
12: Set wpriv := wn+1

Based on above (γ, β, σ) stochastic oracle, and the al-
gorithm proposed in SIGM paper (Dvurechensky & Gas-
nikov, 2016) (omitted here, due to the limitation of space),
our complete learning algorithm is given in Algorithm 6.
Before proving our sample complexity, we state the basic
convergence result of SIGM algorithm:

Lemma 10 ((Dvurechensky & Gasnikov, 2016)). Assume
a function f (w) (suppose constrain set is W) is endowed
with a (γ, β, σ) stochastic oracle, then the sequence wk
(corresponds to yk in the original paper) generated by the
SIGM algorithm satisﬁes:

E[f (wk)] − f (w∗) (cid:54) O

(cid:18) σ
√
k

(cid:19)

+ γ

where expectation is over the randomness of the stochastic
oracle and w∗ = argminw∈W f (w).

The accuracy results directly follows from the quality of
inexact stochastic gradient oracle we constructed, and the
convergence result of SIGM.

Theorem 5. Consider smooth generalized linear loss. For
any setting α > 0, by setting γ = α
γ , p =
(cid:100)k + 2µ2(k; r)(cid:101) in Algorithm 5, 6, if

2 , k = c ln 4r

n > O

)4r ln ln(8r/α)

(cid:32)
(

8r
α

(cid:18) 4r
(cid:15)

(cid:19)2cr ln(8r/α)+2 (cid:18) 1

(cid:19)(cid:33)

,

α2(cid:15)2

we can achieve loss guarantee L(wpriv) − L(w∗) (cid:54) α

As we can see, learning in non-interactive LDP model is
more difﬁcult than interactive form, especially when loss is

highly nonlinear, we even can not obtain an unbiased esti-
mation either for objective function or gradients. However,
our method shows it possible to learn smooth GLM with
quasi-polynomial sample complexity.

4.1. Example: Learning Logistic Regression

(cid:17)

2 wT x(cid:1) +

Either from the view of exponential family generalized
linear model or the concrete loss function, it is not dif-
ﬁcult to see logistic loss belongs to SGLL. For example,
in logistic regression, (cid:96)(w; x, y) = log(1 + e−ywT x) =
(cid:16) 1
− (cid:0) y
2 wT x + ln(1 + e−wT x)
So we let
h1(x) = x
2 +ln(1+e−x). As we know logistic
loss is convex and β-smooth for some parameter β, and the
absolutely smooth property of linear function is obvious,
hence once we prove f (x) = ln(1 + e−x) is absolutely
smooth, then logistic loss satisﬁes the deﬁnition of SGLL.
Proposition 1. f (x) = ln(1 + e−x) is absolutely smooth
4kπ3, µ2(k; r) = rk
with µ1(k; r) = r
e

2 , h2(x) = x

√

.

Hence, we can use private mechanisms (5,6) to learn logis-
tic regression.

Theorem 6. Consider Logistic regression problem with
(cid:96)(w; x, y) = log(1 + exp(−ywT x)) For any α > 0,
by setting γ = α
γ , p = (cid:100)k + 2µ2(k; r)(cid:101),
(cid:16)
(cid:1)2cr ln(8r/α)+2 (cid:0) 1
in

if n > O
Algorithm 5, 6, we can achieve L(wpriv) − L(w∗) (cid:54) α.

2 , k = c ln 4r
α )4r ln ln(8r/α) (cid:0) 4r
( 8r

(cid:1)(cid:17)

α2(cid:15)2

(cid:15)

5. Conclusions

In this paper, we consider how to design efﬁcient algo-
rithms for common learning and estimation problems under
non-interactive LDP model. In particular, for sparse linear
regression and mean estimation problem, we propose efﬁ-
cient algorithms and prove the polynomial dependence of
excess risk or square error over log d and 1
n , which is ex-
actly to be expected in high dimensional case. We also
extend our methods to nonparametric case and show good
bounds for Kernel Ridge Regression.

For more difﬁcult smooth generalized linear loss optimiza-
tion problems, we use private Chebyshev approximations
to estimate gradients of the objective loss, combined with
existing inexact gradient descent methods to obtain ﬁnal
outputs. The sample complexity of our mechanism is
quasi-polynomial with respect to 1
α , where α is the desired
population excess risk.

An interesting open problem is whether our theoretical
guarantees are optimal. If not, how to improve them while
preserving the efﬁciency in non-interactive LDP model.
We think these problems are critical to understand LDP in
the future.

Non-interactive Local DP Learning

Acknowledgments

This work was partially supported by National Basic
Research Program of China (973 Program) (grant no.
2015CB352502), NSFC (61573026). We would like to
thank the anonymous reviewers for their valuable com-
ments on our paper.

References

Bassily, Raef and Smith, Adam. Local, private, efﬁcient
protocols for succinct histograms. In Proceedings of the
Forty-Seventh Annual ACM on Symposium on Theory of
Computing, pp. 127–135. ACM, 2015.

Bassily, Raef, Smith, Adam, and Thakurta, Abhradeep. Pri-
vate empirical risk minimization: Efﬁcient algorithms
and tight error bounds. In Foundations of Computer Sci-
ence (FOCS), 2014 IEEE 55th Annual Symposium on,
pp. 464–473. IEEE, 2014.

Bubeck, S´ebastien et al. Convex optimization: Algorithms
and complexity. Foundations and Trends R(cid:13) in Machine
Learning, 8(3-4):231–357, 2015.

Chaudhuri, K. and Monteleoni, C. Privacy-preserving lo-
gistic regression. In Conference on Neural Information
Processing Systems, British Columbia, Canada, Decem-
ber, pp. 289–296, 2008.

Chaudhuri, K., Monteleoni, C., and Sarwate, A. D. Differ-
entially private empirical risk minimization. The Journal
of Machine Learning Research, 12:1069–1109, 2011.

Duchi, John, Wainwright, Martin J, and Jordan, Michael I.
Local privacy and minimax bounds: Sharp rates for
probability estimation. In Advances in Neural Informa-
tion Processing Systems, pp. 1529–1537, 2013a.

Duchi, John, Wainwright, Martin, and Jordan, Michael.
Minimax optimal procedures for locally private estima-
tion. arXiv preprint arXiv:1604.02390, 2016.

Duchi, John C, Jordan, Michael I, and Wainwright, Mar-
tin J. Local privacy and statistical minimax rates.
In
Foundations of Computer Science (FOCS), 2013 IEEE
54th Annual Symposium on, pp. 429–438. IEEE, 2013b.

Dvurechensky, Pavel and Gasnikov, Alexander. Stochastic
intermediate gradient method for convex problems with
stochastic inexact oracle. Journal of Optimization The-
ory and Applications, 171(1):121–145, 2016.

Dwork, C., McSherry, F., Nissim, K., and Smith, A. Cal-
ibrating noise to sensitivity in private data analysis. In
Theory of cryptography, pp. 265–284. Springer, New
York, USA, 2006.

Dwork, Cynthia and Roth, Aaron.

The algorithmic
foundations of differential privacy. Foundations and
Trends R(cid:13) in Theoretical Computer Science, 9(3–4):211–
407, 2014.

Feldman, Vitaly, Guzm´an, Crist´obal, and Vempala, San-
tosh. Statistical query algorithms for mean vector esti-
mation and stochastic convex optimization. In Proceed-
ings of the Twenty-Eighth Annual ACM-SIAM Sympo-
sium on Discrete Algorithms, pp. 1265–1277. Society for
Industrial and Applied Mathematics, 2017.

Geng, Quan and Viswanath, Pramod. The optimal mech-
In Information Theory
anism in differential privacy.
(ISIT), 2014 IEEE International Symposium on, pp.
2371–2375. IEEE, 2014.

Hardt, M. and Rothblum, G. N. A multiplicative weights
In
mechanism for privacy-preserving data analysis.
IEEE Symposium on Foundations of Computer Science,
pp. 61–70, 2010.

Hardt, M., Ligett, K., and Mcsherry, F. A simple and prac-
tical algorithm for differentially private data release. In
Advances in Neural Information Processing Systems, pp.
2339–2347, 2012.

Hsu, Daniel and Sabato, Sivan. Loss minimization and pa-
rameter estimation with heavy tails. Journal of Machine
Learning Research, 17(18):1–40, 2016.

Kairouz, Peter, Oh, Sewoong, and Viswanath, Pramod.
In
Extremal mechanisms for local differential privacy.
Advances in neural information processing systems, pp.
2879–2887, 2014.

Kairouz, Peter, Oh, Sewoong, and Viswanath, Pramod. The
In Pro-
composition theorem for differential privacy.
ceedings of The 32nd International Conference on Ma-
chine Learning, pp. 1376–1385, 2015a.

Kairouz, Peter, Oh, Sewoong, and Viswanath, Pramod. Se-
In Advances in
cure multi-party differential privacy.
Neural Information Processing Systems, pp. 2008–2016,
2015b.

Kairouz, Peter, Bonawitz, Keith, and Ramage, Daniel. Dis-
crete distribution estimation under local privacy. In Pro-
ceedings of The 33rd International Conference on Ma-
chine Learning, pp. 2436–2444, 2016.

Kasiviswanathan, S. P., Lee, H. K., Nissim, K., Raskhod-
nikova, S., and Smith, A. What can we learn privately?
In IEEE Symposium on Foundations of Computer Sci-
ence, pp. 531–540, 2008.

Kasiviswanathan, Shiva Prasad and Jin, Hongxia. Efﬁcient
private empirical risk minimization for high-dimensional

Non-interactive Local DP Learning

Wang, Z., Jin, C., Fan, K., Zhang, J., Huang, J., Zhong,
Y., and Wang, L. Differentially private data releasing for
smooth queries. Journal of Machine Learning Research,
17(51):1–42, 2016.

Warner, Stanley L. Randomized response: A survey tech-
nique for eliminating evasive answer bias. Journal of the
American Statistical Association, 60(309):63–69, 1965.

Zhang, Jiaqi, Zheng, Kai, Mou, Wenlong, and Wang, Li-
wei. Efﬁcient private erm for smooth objectives. arXiv
preprint arXiv:1703.09947, 2017.

Zhang, Jun, Zhang, Zhenjie, Xiao, Xiaokui, Yang, Yin, and
Winslett, Marianne. Functional mechanism: regression
analysis under differential privacy. Proceedings of the
VLDB Endowment, 5(11):1364–1375, 2012.

learning. In Proceedings of The 33rd International Con-
ference on Machine Learning, pp. 488–497, 2016.

Kasiviswanathan, Shiva Prasad, Lee, Homin K, Nissim,
Kobbi, Raskhodnikova, Sofya, and Smith, Adam. What
can we learn privately? SIAM Journal on Computing, 40
(3):793–826, 2011.

Kearns, Michael. Efﬁcient noise-tolerant learning from sta-
tistical queries. Journal of the ACM (JACM), 45(6):983–
1006, 1998.

Kifer, Daniel, Smith, Adam, and Thakurta, Abhradeep.
Private convex empirical risk minimization and high-
dimensional regression. Journal of Machine Learning
Research, 1(41):3–1, 2012.

Lei, J. Differentially private m-estimators.

In Advances
in Neural Information Processing Systems, pp. 361–369,
2011.

Rahimi, Ali, Recht, Benjamin, et al. Random features for
large-scale kernel machines. In NIPS, volume 3, pp. 5,
2007.

Rubinstein, B., Bartlett, P. L., Huang, L., and Taft, N.
Learning in a large function space: Privacy-preserving
mechanisms for svm learning. Journal of Privacy and
Conﬁdentiality, 4(1):4, 2012.

Smith, A. Privacy-preserving statistical estimation with op-
timal convergence rates. In ACM Symposium on Theory
of Computing, STOC, pp. 813–822, 2011.

Smith, Adam and Thakurta, Abhradeep. Differentially pri-
vate model selection via stability arguments and the ro-
bustness of the lasso. J Mach Learn Res Proc Track, 30:
819–850, 2013.

Talwar, Kunal, Thakurta, Abhradeep, and Zhang, Li.
Nearly optimal private lasso. In Advances in Neural In-
formation Processing Systems, pp. 3025–3033, 2015.

Thaler, J., Ullman, J., and Vadhan, S. Faster algorithms
for privately releasing marginals. In International Collo-
quium on Automata, Languages, and Programming, vol-
ume 7391, pp. 810–821. 2012.

Vershynin, Roman. Estimation in high dimensions: a ge-
ometric perspective. In Sampling theory, a renaissance,
pp. 3–66. Springer, 2015.

Wang, Y., Fienberg, S. E., and Smola, A. J. Privacy for free:
Posterior sampling and stochastic gradient monte carlo.
In International Conference on Machine Learning, pp.
2493–2502, 2015.

