Stochastic DCA for the Large-sum of Non-convex Functions Problem and its
Application to Group Variable Selection in Classiﬁcation

Hoai An Le Thi 1 Hoai Minh Le 1 Duy Nhat Phan 1 Bach Tran 1

Abstract
In this paper, we present a stochastic version
of DCA (Difference of Convex functions Algo-
rithm) to solve a class of optimization problems
whose objective function is a large sum of non-
convex functions and a regularization term. We
consider the (cid:96)2,0 regularization to deal with the
group variables selection. By exploiting the spe-
cial structure of the problem, we propose an ef-
ﬁcient DC decomposition for which the corre-
sponding stochastic DCA scheme is very inex-
pensive: it only requires the projection of points
onto balls that is explicitly computed. As an ap-
plication, we applied our algorithm for the group
variables selection in multiclass logistic regres-
sion. Numerical experiments on several bench-
mark datasets and synthetic datasets illustrate the
efﬁciency of our algorithm and its superiority
over well-known methods, with respect to clas-
siﬁcation accuracy, sparsity of solution as well
as running time.

1. Introduction

We consider the following optimization problem
(cid:41)

(cid:40)

min

f (x) =

fi(x) + λp(x)

,

(1)

1
n

n
(cid:88)

i=1

whose objective function f is a large sum of non-convex
functions fi(x) and a regularization term p(x), where fi(x)
corresponds to a criteria to optimize and λ ≥ 0 is a trade-
off parameter between the two terms. This model covers
a very vast class of problems arising from several ﬁelds
such as machine learning, signal processing, etc. For in-
stance, least-squares regression, logistic regression prob-
lem, etc can be expressed in the form of (1).

1Laboratory of Theoretical and Applied Computer Science,
University of Lorraine, France. Correspondence to: Hoai Minh
Le <minh.le@univ-lorraine.fr>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

Nowadays, the growth of technologies leads to exponen-
tial augmentation of large-scale data where the number of
both variables and samples are huge. Thus, optimization
methods for solving the problem (1) are faced with a great
challenge that is the number of samples n can be extremely
large. Among existing methods for this problem, stochastic
programming has been proved to be suitable thanks to its
ability to exploit the advantage of the sum structure of the
problem. In (Schmidt et al., 2015), the authors considered
a special case of the large-sum problem (1) where fi are
convex and smooth functions and p corresponds to the (cid:96)2
regularization. Stochastic Average Gradient was developed
to solve the resulting problem. Reddi et al. (Reddi et al.,
2016) developed Proximal Stochastic Gradient method for
the case where fi are smooth (can be non-convex) and p
is convex, non-smooth function. Motivated by its success,
we will study stochastic programming for solving (1) in or-
der to deal with data having an extremely large number of
samples.

On the other hand, in real-world applications such as im-
age processing, microarray analysis, etc. datasets contain
a very large number of variables. In such of cases, we are
often to face with the problem of redundant and irrelevant
variables. Redundant variables contain information already
presented by other variables while irrelevant variables do
not contain useful information. Variables selection meth-
ods that consist of selecting important variables for a con-
sidered task, are a popular and efﬁcient way to deal with
redundant and irrelevant variables. In this direction, a nat-
ural idea is to formulate the variables selection problem as
a minimization of the (cid:96)0-norm (or (cid:107).(cid:107)0). The sparse opti-
mization has been extensively studied on both theoretical
and practical aspects. The readers can refer to Le Thi et al.
(Le Thi et al., 2015) for an extensive overview of existing
approaches for the minimization of (cid:96)0-norm.

Nevertheless, when the data possesses certain group struc-
tures, we are naturally interested in selecting important
groups of variables rather than individual ones.
For
instance,
in multi-factor analysis of variance, a factor
with several levels may be expressed through a group of
dummy variables. In genomic data analysis, the correla-
tions between genes sharing the biological pathway can

Stochastic DCA for the Large-sum of Non-convex Functions Problem

be high. Hence these genes should be considered as a
group. Recently, the mixed-norm regularization has been
developed for the group variable selection.
It consists
in using the (cid:96)2,0 regularization term. Assume that x =
(x1, ..., xm) ∈ Rm is partitioned into J non-overlapping
groups x(1), ..., x(J), then the (cid:96)2,0-norm of x is deﬁned by
(cid:107)x(cid:107)2,0 = | (cid:8)j ∈ {1, ..., J} : (cid:107)x(j)(cid:107)2 (cid:54)= 0(cid:9) |. Clearly, (cid:96)2,0-
norm is non-convex that makes the optimization problem
involving (cid:96)2,0 challenging. Several works have been de-
veloped to solve the problem of mixed-norm regularization
(cid:96)2,0. The ﬁrst approach, named the group Lasso ((cid:96)2,1-
norm) (Yuan & Lin, 2006), is closely connected to the
Lasso ((cid:96)1-norm) - an approximation of the (cid:96)0-norm (Tib-
shirani, 1994). This approach was widely used for select-
ing groups of variables in multi-task learning (Obozinski
et al., 2006), multiclass support vector machine (Blondel
et al., 2013), principal component analysis (Khan et al.,
2015), linear discriminant analysis (Gu et al., 2011), and
compressed sensing (Sun et al., 2009), etc. The second ap-
proach consists in replacing the (cid:96)2,0-norm by a DC (Differ-
ence of Convex functions) approximation. In (Wang et al.,
2007), the authors used the smoothly clipped absolute de-
viation (SCAD) approximation and developed a group co-
ordinate descent based algorithm for the sparse linear re-
gression. Later, Huang et al. (Huang et al., 2012) used the
minimax concave penalty (MCP) for the same problem. In
(Lee et al., 2016), the authors considered both above ap-
proximations and developed DC programming and DCA
(DC algorithm) based method for the resulting problems.
Recently, Phan et al.
(Phan et al., 2017) proposed DCA
based algorithms for bi-level variable selection using the
combination of the (cid:96)0-norm and (cid:96)q,0-norm.

Paper’s contribution: In this paper, we aim at developing
efﬁcient methods to solve the problem (1) where n is ex-
tremely large and p(x) corresponds to (cid:96)2,0 regularization
(in order to deal with the group variables selection). The
large-sum optimization (1) becomes

(cid:40)

(cid:41)

min

f (x) =

fi(x) + λ(cid:107)x(cid:107)2,0

.

(2)

1
n

n
(cid:88)

i=1

We assume that fi(x) is differentiable with L-Lipschitz
gradient. This assumption is broad enough to cover sev-
eral applications. Various important problems in machine
learning such as Multi-task feature selection, Sparse logis-
tic regression, Minimizing an expected loss in stochastic
programming, etc. can be expressed in the form of (2).
As we have mentioned above, the (cid:96)2,0-norm can be ap-
proximated by a convex (e.g. (cid:96)2,1-norm) or non-convex
function. Using a non-convex approximation will lead to a
”harder” optimization problem but it has been proved that
non-convex approximations perform better than convex ap-
proximations in terms of sparsity (Le Thi et al., 2015). The
resulting problem is then reformulated as a DC program

and DCA based algorithm will be developed to solve it.
We exploit the special structure of the problem to propose
an efﬁcient DC decomposition for which the corresponding
DCA scheme is very inexpensive: it only requires the pro-
jection of points onto balls that is explicitly computed. On
the other hand, in order to deal with data having a large
number of samples, we present stochastic version DCA.
The convergence properties of the proposed algorithm is
rigorously studied to show that the convergence is guaran-
teed with probability one.

As an application of our algorithm, we consider the group
variables selection in multiclass logistic regression. We
perform an empirical comparison of stochastic DCA with
DCA and standard methods on very large synthetic and
real-world datasets, and show that the stochastic DCA is
efﬁcient in group variable selection ability and classiﬁca-
tion accuracy as well as running time.

The remainder of the paper is organized as follows. So-
lution method based on Stochastic DCA for solving (2) is
developed in Section 2. In Section 3, we apply the proposed
algorithm to the group variables selection in multiclass lo-
gistic regression. Finally Section 4 concludes the paper.

2. Solution method via stochastic DCA

2.1. Outline of DC programming and DCA

DC programming and DCA constitute the backbone of
smooth/non-smooth non-convex programming and global
optimization (Pham Dinh & Le Thi, 1997; 1998; Le Thi &
Pham Dinh, 2005). They address the problem of minimiz-
ing a DC function on the whole space Rn or on a closed
convex set Ω ⊂ Rn. Generally speaking, a standard DC
program takes the form:

α = inf{F (x) := G(x) − H(x) | x ∈ Rn}

(Pdc),

where G, H are lower semi-continuous proper convex
functions on Rn. Such a function F is called a DC func-
tion, and G−H is a DC decomposition of F while G and H
are the DC components of F . A DC program with convex
constraint x ∈ Ω can be equivalently expressed as (Pdc) by
adding the indicator function χΩ (χΩ(x) = 0 if x ∈ Ω and
+∞ otherwise) to the ﬁrst DC component G.

The modulus of strong convexity of θ on Ω, denoted by
µ(θ, Ω) or µ(θ) if Ω = Rn, is given by

µ(θ, Ω) = sup{µ ≥ 0 : θ − (µ/2)(cid:107).(cid:107)2 is convex on Ω}

One says that θ is strongly convex on Ω if µ(θ, Ω) > 0.

For a convex function θ, the subdifferential of θ at x0 ∈
domθ := {x ∈ Rn : θ(x0) < +∞}, denoted by ∂θ(x0), is

Stochastic DCA for the Large-sum of Non-convex Functions Problem

deﬁned by

Each function fi(x) can be rewritten as

∂θ(x0) := {y ∈ Rn : θ(x) ≥ θ(x0) + (cid:104)x − x0, y(cid:105),

∀x ∈ Rn}.

fi(x) =

(cid:107)x(cid:107)2 −

ρ
2

(cid:105)
(cid:107)x(cid:107)2 − fi(x)

.

(cid:104) ρ
2

The subdifferential ∂θ(x0) generalizes the derivative in the
sense that θ is differentiable at x0 if and only if ∂θ(x0) ≡
{∇xθ(x0)}.

A point x∗ is called a critical point of G − H, or a
generalized Karush-Kuhn-Tucker point (KKT) of (Pdc)) if
∂H(x∗) ∩ ∂G(x∗) (cid:54)= ∅.

The main idea of DCA is simple: each iteration l of DCA
approximates the concave part −H by its afﬁne majoriza-
tion (that corresponds to taking vl ∈ ∂H(xl)) and then
computes xl+1 by solving the resulting convex problem.

{G(x) − (cid:104)vl, x(cid:105)}.

min
x∈Rn

The sequence {xl} generated by DCA enjoys the following
properties (Pham Dinh & Le Thi, 1997; 1998; Le Thi &
Pham Dinh, 2005):

(i) The sequence {F (xl)} is decreasing;

(ii) If F (xl+1) = F (xl), then xl is a critical point of (Pdc)

and DCA terminates at l-th iteration.

(iii) If µ(G) + µ(H) > 0 then the series {(cid:107)xk+1 − xk(cid:107)2

converges.

(iv) If the optimal value α of (Pdc) is ﬁnite and the inﬁnite
sequence {xl} is bounded then every limit point of the
sequence {xl} is a critical point of G − H.

2.2. Stochastic DCA for solving the problem (2)

In this section, we introduce a stochastic version of DCA
for solving (2) that exploits the structure of objective func-
tion f . We consider a family of DC approximations ˜p(x)
of (cid:96)2,0-norm, deﬁned by

˜p(x) =

η((cid:107)x(j)(cid:107)2),

J
(cid:88)

j=1

where η is a non-convex penalty function which includes
SCAD, MCP, Capped-(cid:96)1, exponential function, (cid:96)p+ with
0 < p < 1, (cid:96)p− with p < 0 (see (Le Thi et al., 2015) for
more details). ˜p(x) can be expressed as ˜p(x) = ˜g(x) −
˜h(x), where

˜g(x) = α

(cid:107)x(j)(cid:107)2 and ˜h(x) = α

(cid:107)x(j)(cid:107)2 − ˜p(x).

J
(cid:88)

j=1

J
(cid:88)

j=1

Hence, the approximate problem of (2) can be written as

(cid:40)

min
x∈Rm

f (x) =

1
n

n
(cid:88)

(cid:104)

i=1

fi(x) + λ˜g(x) − λ˜h(x)

.

(3)

(cid:41)
(cid:105)

Since fi(x) is differentiable with L-Lipschitz gradient,
2 (cid:107)x(cid:107)2 − fi(x)(cid:3) is strongly convex with ρ > L. Hence,
(cid:2) ρ
fi(x) is a DC function. Consequently, f (x) is a DC func-
tion with the following DC decomposition

f (x) = g(x) − h(x),

(4)

where g(x) and h(x) are convex functions deﬁned by

2 (cid:107)x(cid:107)2 + λ˜g(x),

g(x) = ρ
h(x) = 1
n

n
(cid:80)
i=1

hi(x); hi(x) = ρ

2 (cid:107)x(cid:107)2 − fi(x) + λ˜h(x).

DCA for solving (3) amounts to computing two sequences
{xl} and {vl} such that vl ∈ ∂h(xl) and xl+1 is an optimal
solution of the following convex problem

min (cid:8)g(x) − (cid:104)vl, x(cid:105)(cid:9) .

(5)

The computation of subgradients of h requires the one of
all components hi. This can be expensive when n is very
large. Hence we propose a stochastic version of DCA in
which we only compute the subgradients of a small subset
of components hi. Precisely, at each iteration l, we com-
pute vl
for i (cid:54)∈ sl,
where sl ⊂ {1, ..., n} is a randomly chosen set of index.
i ∈ ∂hi(xl) can be given as vl

The computation of vl
i =
ρxl − ∇fi(xl) + yl, where yl ∈ λ∂˜h(xl) for all i ∈ sl. The
convex problem (5) take the form

i ∈ ∂hi(xl) for i ∈ sl and keep vl

i = vl−1
i

min

λα

(cid:107)x(j)(cid:107)2 +

(cid:107)x(cid:107)2 − (cid:104)

vl
i, x(cid:105)

.

(6)

1
n

n
(cid:88)

i=1











J
(cid:88)

j=1

We observe that the objective of (6) is separable in groups
of x, then the solution to this problem can be computed by
solving J independent sub-problems of the same form:

(cid:110)

min

λα(cid:107)x(j)(cid:107)2 +

(cid:107)x(j)(cid:107)2 − (cid:104)vl

(j), x(j)(cid:105)

(cid:111)

,

(7)

where vl
tion of (7) can be explicitly computed by

(j) = 1

i=1(vl

ρn

i)(j) for j = 1, ..., J. The solu-

(cid:80)n

ρ
2

ρ
2

xl+1
(j) =

(cid:16)

(cid:107)vl

(cid:17)
(j)(cid:107)2 − λα/ρ

vl
(j)
(cid:107)vl
(j)(cid:107)2

,

+

(8)

Thus, the stochastic DCA (SDCA) for solving the problem
(3) is described in Algorithm 1.

Now we will prove that the convergence properties of
SDCA are guaranteed with probability one.

Stochastic DCA for the Large-sum of Non-convex Functions Problem

Algorithm 1 SDCA for solving the problem (3)

Initialization: Choose x0 ∈ Rm, ρ > L and s0 =
{1, ..., n}, l ← 0.
Repeat

vl−1
i

i ∈ ∂hi(xl) for i ∈ sl and keep vl

1. Compute vl
for i (cid:54)∈ sl.
2. Compute xl+1 by using (8).
3. Set l ← l+1 and randomly choose a small subset

i =

sl ⊂ {1, ..., n}.
Until Stopping criterion.

b) Since yl−1

∈ λ∂˜h(xl−1
i
λ˜h(x) ≥ λ˜h(xl−1

i

i

), we have

) + (cid:104)x − xl−1

i

, yl−1
i

(cid:105).

(11)

Since fi(x) is a differentiable function with L-Lipschitz
gradient, we have

fi(x) ≤ fi(xl−1

)+(cid:104)x−xl−1

i

i

, ∇fi(xl−1

i

)(cid:105)+

(cid:107)x−xl−1

(cid:107)2.

i

L
2

Thus, we get that

fi(x) + λ˜p(x) ≤ T l−1

(x) +

i

(cid:107)x − xl−1

(cid:107)2.

i

(12)

From (9) and (12), we have

L − ρ
2

ρ − L
2n

(cid:88)

i∈sl

Theorem 1. If α∗ = inf f (x) > −∞ and |sl| = b for all
l ≥ 1, then SDCA generates the sequence {xl} such that

T l(xl+1) ≤ T l−1(xl) −

(cid:107)xl − xl−1

(cid:107)2.

i

(13)

a) {f (xl)} is the almost sure convergent sequence.

b) (cid:80)∞

l=1 (cid:107)xl − xl−1(cid:107)2 is almost surely ﬁnite and

liml→∞ (cid:107)xl − xl−1(cid:107) = 0 almost surely.

c) Every limit point of {xl} is a critical point of f with

probability one.

By taking the expectation of the inequality (13) conditioned
on Fl, we have

E (cid:2)T l(xl+1)|Fl

(cid:3) ≤ T l−1(xl)−

b(ρ − L)
2n2

n
(cid:88)

i=1

(cid:107)xl−xl−1

(cid:107)2.

i

By the supermartingale convergence theorem, we conclude
that

i = xl and yl
i = yl−1 for i (cid:54)∈ sl. We denote T l

Proof. a) Let xl
and yl
by

i = yl for i ∈ sl, xl

i = xl−1
i the function given

i

T l
i (x) = λ˜g(x) +

(cid:107)x − xl

i(cid:107)2 − (cid:104)x − xl

i, yl

i − ∇fi(xl
i(cid:105)

ρ
2
i) − ˜h(xl

i),

+ fi(xl

and T l(x) = 1
n
1, it follows that xl+1 = arg min T l(x). Hence, we have

i (x). From the step 2 in Algorithm

i=1 T l

(cid:80)n

T l(xl+1) ≤ T l(xl) =T l−1(xl) +

(cid:88)

[fi(xl)

1
n

(9)

i∈sl
+ λ˜p(xl) − T l−1

i

(xl)].

Let Fl denote the σ-algebra generated by the entire his-
tory of SDCA up to the iteration l, i.e., F0 = σ(x0) and
Fl = σ(x0, ..., xl, s0, ..., sl−1) for all l ≥ 1. By taking
the expectation of the inequality (9) conditioned on Fl, we
have

is almost surely satisﬁed. In particular, we have

∞
(cid:88)

n
(cid:88)

l=1

i=1

∞
(cid:88)

l=1

(cid:107)xl − xl−1

(cid:107)2 < ∞,

i

(cid:107)xl − xl−1(cid:107)2 < ∞,

(14)

(15)

almost surely and hence liml→∞ (cid:107)xl − xl−1(cid:107) = 0 almost
surely.

c) Assume that there exists a sub-sequence {xlk } of {xl}
such that xlk → x∗ almost surely. From (14) and (15),
we have (cid:107)xlk+1 − xlk
i (cid:107) → 0 almost surely. Without
loss of generality, we can suppose that the sub-sequences
ylk
i → y∗ almost surely. We note that ylk
i ) and
by the closed property of the subdifferential mapping ∂˜h,
we have y∗ ∈ λ∂˜h(x∗) with probability one. It follows
from xlk+1 ∈ arg min T lk (x) that T lk (xlk+1) ≤ T lk (x).
Taking k → ∞, we get that

i ∈ λ∂˜h(xlk

λ˜g(x∗) ≤ λ˜g(x)+

(cid:107)x−x∗(cid:107)2−(cid:104)x−x∗, y∗−

∇fi(x∗)(cid:105),

1
n

n
(cid:88)

i=1

E (cid:2)T l(xl+1)|Fl

(cid:3) ≤ T l−1(xl) −

(cid:2)T l−1(xl) − f (xl)(cid:3) .

is almost surely satisﬁed for all x ∈ Rm. Thus, we have

b
n

By the supermartingale convergence theorem, we can con-
clude that the sequence {T l−1(xl) − α∗} converges almost
surely. Moreover,

∞
(cid:88)

l=1

(cid:2)T l−1(xl) − f (xl)(cid:3) < ∞,

(10)

almost surely and hence {f (xl)} converges almost surely.

y∗ −

∇fi(x∗) ∈ ∂λ˜g(x∗),

(16)

with probability one. Therefore,

(cid:34)

y∗ ∈

∇

1
n

n
(cid:88)

i=1

fi(x∗) + ∂λ˜g(x∗)

∩ ∂λ˜h(x∗),

(17)

(cid:35)

with probability one. This implies that x∗ is a critical point
of f with probability one and the proof is complete.

ρ
2

1
n

n
(cid:88)

i=1

Stochastic DCA for the Large-sum of Non-convex Functions Problem

3. Application to Group Variables Selection in

Multiclass Logistic Regression

Logistic regression, introduced by D. Cox in 1958 (Cox,
1958), is a popular method in supervised learning. Logistic
regression has been successfully applied in various real-life
problems such as cancer detection (Kim et al., 2008), med-
ical (Bagley et al., 2001; Subasi & Erc¸elebi, 2005), social
science (King & Zeng, 2001), etc. Especially, logistic re-
gression combined with feature selection has been proved
to be suitable for high dimensional problems, for instance,
document classiﬁcation (Genkin et al., 2007) and microar-
ray classiﬁcation (Liao & Chin, 2007; Kim et al., 2008).

We describe the multiclass logistic regression problem as
follows. Let W be a d × Q matrix, where d and Q are the
number of features and number of classes, respectively. We
denote the i-th column of W by W:,i and b = (b1, ..., bQ) ∈
RQ. In the multiclass logistic classiﬁcation problem, a new
instance x∗ is classiﬁed to class y∗ by using the rule y∗ =
arg maxk p(Y = k|X = x∗), where p(Y = y|X = x) is
the conditional probability deﬁned by

p(Y = y|X = x) =

(18)

:,yx)

exp(by + W T
Q
(cid:80)
k=1

exp(bk + W T

:,kx)

.

Given a training set containing n instances xi and their cor-
responding labels yi ∈ {1, ..., Q}, we aim to ﬁnd (W, b) for
which the total probability of the training instances xi be-
longing to its correct classes yi is maximized. To estimate
(W, b), we maximize the log-likelihood function deﬁned as

L(W, b) := −

(cid:96)(xi, yi, W, b)

(19)

1
n

n
(cid:88)

i=1

where (cid:96)(xi, yi, W, b) = − log p(Y = yi|X = xi). As
mentioned above, to deal with irrelevant and/or redundant
variables in high-dimensional data, we use variables selec-
tion method. Note that a variable j is to be removed if and
only if all components in the row j of W are zero. There-
fore, we can consider each row of W as a group. Denote
by Wj,: the j-th row of the matrix W . The (cid:96)2,0-norm of W ,
i.e., the number of non-zero rows of W , is deﬁned by

(cid:107)W (cid:107)2,0 = |{j ∈ {1, ..., d} : (cid:107)Wj,:(cid:107)2 (cid:54)= 0}|.

Hence, the (cid:96)2,0 regularized multiclass logistic regression
problem is formulated as

(cid:40)

1
n

n
(cid:88)

i=1

min
W,b

(cid:96)(xi, yi, W, b) + λ(cid:107)W (cid:107)2,0

.

(20)

(cid:41)

Observe that the problem (20) takes the form of (2) where
the function fi(W, b) = (cid:96)(xi, yi, W, b).
In this applica-
tion, we use a non-convex approximation of the (cid:96)2,0-norm

based on the piecewise exponential penalty function. This
approximation function has shown its efﬁciency in sev-
eral problems, for instance, variables selection in SVM
(Bradley & Mangasarian, 1998; Le Thi et al., 2008), semi-
supervised support vector machines (Le et al., 2015), sparse
multiclass support vector machines (Le Thi & Nguyen,
2017), sparse signal recovery (Le Thi et al., 2013), sparse
linear discriminant analysis (Le Thi & Phan, 2016a;b),
variables selection in SVM with uncertain data (Le Thi
et al., 2014), etc. Using the piecewise exponential penalty
function, the corresponding approximate problem of (20)
takes the form:

(cid:40)

1
n

n
(cid:88)

i=1

min
W,b

(cid:41)

fi(W, b) + λ˜p(W )

,

(21)

where ˜p(W ) = (cid:80)d
j=1 ηα((cid:107)Wj,:(cid:107)2) with ηα(t) = 1 −
exp(−α|t|). The function ˜p(W ) can be expressed as a DC
function:

˜p(W ) = α

(cid:107)Wj,:(cid:107)2 − ˜h(W ),

d
(cid:88)

j=1

where ˜h(W ) = (cid:80)d

j=1[−1+α|Wj,:(cid:107)2 +exp(−α(cid:107)Wj,:(cid:107)2)].
According to the SDCA scheme in Algorithm 1, at each
i) = ρ(W l, bl) −
i, zl
iteration l, we have to compute (vl
∇fi(W l, bl) + (yl, 0) for i ∈ sl, where

∇bk fi(W l, bl)
= pl
∇W:,k fi(W l, bl) = (cid:0)pl

k(xi) − δkyi
k(xi) − δkyi

(cid:1) xi

(22)

with pl

k(xi) =

k+(W l
h+(W l
and 0 otherwise. The computation of yl is given by

:,k)T xi)
:,h)T xi)

exp(bl
(cid:80)Q
h=1 bl

and δkyi = 1 if k = yi

yl
j,: =






0
λαηα((cid:107)W l
(cid:107)W l
j,:(cid:107)2

if (cid:107)W l

j,:(cid:107)2 = 0

.

(23)

j,:(cid:107)2)

W l
j,:

otherwise

SDCA for solving (21) is described in Algorithm 2.

3.1. Numerical Experiment

3.1.1. DATASETS

To illustrate the performances of algorithms, we performed
numerical tests on real datasets (aloi, covertype, madelon
and sensorless) and simulated datasets (sim 1, sim 2 and
sim 3). Dataset Aloi is a library of object images 1 while
covertype, madelon, sensorless, are taken from the well-
known UCI data repository.

We used the same way as proposed in (Witten & Tibshi-
rani, 2011) to generate simulated datasets. In sim 1, fea-
tures are independent with different means in each class.

1http://aloi.science.uva.nl/

Stochastic DCA for the Large-sum of Non-convex Functions Problem

Algorithm 2 SDCA for solving the problem (21)

Initialization: Choose W 0 ∈ Rd×Q, b0 ∈ RQ, ρ > L,
s0 = {1, ..., n}, l ← 0.
Repeat

1. Compute (vl

i, zl

i) = ρ(W l, bl) − ∇fi(W l, bl) +
i) =

i, zl

(yl, 0) for i ∈ sl using (22)-(23) and keep (vl
(vl−1
i

, zl−1
i
2. Compute (W l+1, bl+1) by

) for i (cid:54)∈ sl.

bl+1
W l+1
j,:

= 1
ρn
= (cid:0)(cid:107)vl

(cid:80)n
i=1 zl
i
j,:(cid:107)2 − λα/ρ(cid:1)

vl
j,:
(cid:107)vl
j:,(cid:107)2

,

+

(24)

where vl

j,: = 1
ρn

(cid:80)n

i=1(vl

i)j,: for j = 1, ..., d.

3. Set l ← l+1 and randomly choose a small subset

sl ⊂ {1, ..., n}.
Until Stopping criterion.

In sim 2, features also have different means in each class,
however they are dependent. The dataset sim 3 has differ-
ent one-dimensional means in each class with independent
features. The procedure for generating simulated datasets
is described as follows.

For sim 1: this dataset consists of four classes. The class
k is sampled from the multivariate normal distribution
N (µk, I), where the mean vector µk ∈ R50 is given by
µkj = 0.5 if 10(k − 1) + 1 ≤ j ≤ 10k and 0 otherwise.
We generate 25, 000 samples for each class.

For sim 2: we generate a dataset with three classes sampled
from the multivariate normal distributions N (µk, Σ), k =
1, 2, 3, where µk ∈ R50 is deﬁned by µkj = 0.4(k − 1) if
j ≤ 40 and 0 otherwise. We use the block diagonal matrix
Σ with ﬁve blocks of dimension 10 × 10 whose element
(j, j(cid:48)) is 0.6|j−j(cid:48)|. 150, 000 instances are generated.

For sim 3: we generate a dataset including four classes as
follows: xi ∈ Ck then xij ∼ N ((k − 1)/3, 1) if j ≤ 100,
k = 1, 2, 3, 4 and xij ∼ N (0, 1) otherwise. We generate
250, 000 instances with equal probabilities for each class.

For pre-processing data, we use standardization to scale the
data.

3.1.2. COMPARATIVE ALGORITHMS

We compare our algorithm with two algorithms: msgl and
liblinear. msgl (Vincent & Hansen, 2014) is a coordinate
gradient descent algorithm for solving the multiclass
logistic regression using (cid:96)2,1 regularization term, i.e., the
(cid:27)

(cid:26)

(cid:96)(xi, yi, W, b) + λ(cid:107)W (cid:107)2,1

convex problem min
W,b
LibLinear (Fan et al., 2008)
is a well-known
package for
solving large-scale problems by using
the coordinate descent algorithm. We use the (cid:96)1-

.

n
(cid:80)
i=1

1
n

regularized logistic regression solver of LibLinear
problem
to

logistic

binary

the

regression
(cid:41)

log(1 + e−yiwT xi) + λ

|wj|

,

and

then

solve
(cid:40) n
(cid:80)
i=1

min
w

d
(cid:80)
j=1

the one-vs-the-rest strategy is used for the multiclass case.

3.1.3. EXPERIMENT SETTING

The comparison of algorithms are performed in terms of
three criteria: classiﬁcation accuracy on test set, sparsity of
solution and running time. Sparsity is computed as the per-
centage of selected features, where a feature j ∈ {1, . . . , d}
is considered to be removed if all absolute values of com-
ponents of row Wj,: are smaller than a threshold (cid:15) = 10−8.

The cross-validation procedure is used for experiments. We
randomly take 80% of the whole dataset as a training set
and the rest is used as test set (20%). This process is re-
peated 10 times and we report the mean and standard devi-
ation of each criterion.

We use the early-stopping condition for SDCA. This is a
well-know technique in machine learning, especially in
stochastic learning which permits to avoid the over-ﬁtting
problem. After each epoch, we compute the accuracy based
on the validation set, then we stop SDCA if the accuracy is
not improved after npatience = 5 epochs. For comparative
algorithms, we use their default stopping parameters. We
also stop algorithms if they exceed 2 hours of running time
in the training process.

the trade-off parameter λ

For SDCA, we set
∈
(cid:8)10−4, 10−3, ...1(cid:9) and the parameter for controlling the
tightness of zero-norm approximation α ∈ {0.5, 1, 2, 5}.
For both LibLinear and msgl, the trade-off parameter
is chosen in interval {10−3, . . . , 104}.

All experiments are performed on a PC Intel (R) Xeon (R)
E5-2630 v2 @2.60 GHz of 32GB RAM.

3.1.4. EXPERIMENT 1 : COMPARISON OF SDCA AND

DCA

Firstly, we will study the impact of batch size on the quality
of solution and the running time of SDCA. The batch size
refers to the size of set of index sl, i.e., the number of com-
ponents hi that are used to compute the subgradients of ¯h
at each iteration (c.f Algorithm 1). In DCA, or full-batch
DCA, all components hi are used, i.e., sl ≡ {1, . . . , n}.
The Table 1 reports the accuracy and the running time of
SDCA as the batch size varies on an arbitrary chosen dataset
(sensorless).

We observe that the running time is smallest (1.78s) with
batch size equals to 10% while giving the second best clas-
siﬁcation accuracy 85.23%, only 0.07% smaller than the
best one. Hence, we choose the batch size as 10% through-

Stochastic DCA for the Large-sum of Non-convex Functions Problem

Table 1. Performance of SDCA as batch size varies

Batch Size
Time (s)
Accuracy (%)

50%
5%
2.93±0.1
1.94±0.50
84.62±1.1 85.23±0.7 83.25±1.2 85.05±0.9 82.77±1.1 84.54±1.1 85.30±0.7 82.88±1.1

15%
2.53±0.1

25%
1.54±0.2

30%
2.24±0.3

40%
2.98±0.4

10%
1.78±0.1

20%
2.06±0.2

Table 2. Comparative results on both simulated and real datasets.
Bold values correspond to best results for each dataset. NA means that the algorithm fails to furnish a result. n, d and Q is the number
of instances, the number of dimensions and the number of classes respectively.

Dataset

Algorithm

Time (s)

Accuracy (%)
STD
0.44
0.47
NA
0.20

Mean
85.05
82.98
NA
81.61

aloi
(n × d) = (108,000×128)
Q = 1,000

covertype
(n × d) = (581,012×54)
Q = 7

madelon
(n × d) = (2,600×500)
Q = 2

sensorless
(n × d) = (58,509×48)
Q = 11

sim 1
(n × d) = (100,000×50)
Q = 4

sim 2
(n × d) = (150,000×50)
Q = 3

sim 3
(n × d) = (250,000×500)
Q = 4

DCA (Full-batch)
SDCA
MSGL
LibLinear

DCA (Full-batch)
SDCA
MSGL
LibLinear

DCA (Full-batch)
SDCA
MSGL
LibLinear

DCA (Full-batch)
SDCA
MSGL
LibLinear

DCA (Full-batch)
SDCA
MSGL
LibLinear

DCA (Full-batch)
SDCA
MSGL
LibLinear

DCA (Full-batch)
SDCA
MSGL
LibLinear

71.30
71.58
71.22
71.54

61.35
62.60
60.48
61.54

90.21
85.11
85.06
75.55

72.11
72.24
72.33
72.62

65.53
68.60
68.42
66.92

99.87
99.93
99.93
99.03

0.09
0.13
0.02
0.19

0.39
1.38
2.37
2.72

0.41
0.83
0.31
0.24

0.57
0.42
0.18
0.38

3.70
0.22
0.03
0.02

0.02
0.01
0.01
0.00

Mean
2414.72
208.67
NA
2732.96

322.98
5.86
525.49
264.88

5.25
0.12
23.92
0.08

34.65
11.76
199.00
216.48

24.67
1.33
214.83
2038.85

76.04
1.74
367.29
2.04
15
151.72
22.83
1581.44
50.50

STD
77.12
50.03
NA
46.38

0.27
1.14
1.10
26.83

0.02
0.12
0.12
0.01

1.79
4.60
41.75
72.05

6.39
0.23
25.40
5.05

1.57
0.27
53.52
0.23

4.75
2.55
14.76
2.96

Sparsity (%)
STD
1.35
3.57
NA
0.00

Mean
97.66
63.87
NA
100.00

100.00
84.72
68.52
100.00

0.80
0.43
0.67
0.58

38.19
40.00
50.00
100.00

84.00
80.00
82.00
80.00

79.33
80.00
82.00
80.00

80.53
80.00
80.20
97.16

0.00
6.48
0.00
0.00

0.04
0.23
0.00
0.06

1.20
4.52
0.00
0.00

2.00
0.00
0.00
0.00

1.15
0.00
0.00
0.00

3.13
0.00
0.00
0.50

out our experiments.

To illustrate the potential gain of SDCA, we compare it with
a DCA for solving the problem (21). From the Table 2, we
see that the gain of running time of SDCA ranges from 11.6
times (aloi) to 55.1 times (covertype).

Concerning the classiﬁcation accuracy, SDCA and DCA are

comparable. SDCA gives slightly better accuracy than DCA
on covertype, sim 1, sim 3, with a gain ranges from 0.06%
to 0.28%. The gain of SDCA is higher on 2 datasets (made-
lon, sim 2), 1.35% and 3.07%. DCA furnishes a better re-
sult on aloi and sensorless, especially the gain is up to 4.9%
on sensorless. The results prove that SDCA can greatly im-
prove the running time of DCA while archiving a similar

Stochastic DCA for the Large-sum of Non-convex Functions Problem

accuracy.

LibLinear fails to suppress features.

3.1.5. EXPERIMENT 2 : SIMULATED DATASET

For synthetic datasets (sim 1, sim 2 and sim 3), we know
in advance the informative features that were used to gen-
erate the datasets. Hence, the purpose of this experiment
is to study the ability of algorithms to select these infor-
mative features in order to furnish a good classiﬁcation ac-
curacy. The comparison is performed with 3 algorithms,
SDCA, msgl and LibLinear. We report the results in
Table 2, and observe that.

For sim 1 dataset, LibLinear gives a slightly better clas-
siﬁcation accuracy (72.62%) comparing to SDCA (72.24%)
and msgl (72.33%). However, SDCA is by far the fastest
algorithm. SDCA is 1532 (resp. 136) times faster than
LibLinear (resp. msgl). Furthermore, SDCA and
LibLinear successfully suppress the 20% uninformative
features, which it also matches with our procedure of gen-
erating this synthetic dataset. msgl fails on this purpose
by selecting 82% of features.

For sim 2 dataset, SDCA is the best algorithm on both crite-
ria: classiﬁcation accuracy and running time. Similarly to
sim 1 dataset, only SDCA and LibLinear can correctly
select the informative features (80%).

For sim 3 dataset, SDCA exceeds LibLinear and
GLASSO on all three comparison criteria: classiﬁcation ac-
curacy, sparsity and speed. LibLinear almost selects all
the features (97.16% selected) but gives 0.89% accuracy
lower than SDCA (99.93%), and it is also 2 times slower
than SDCA. Among the three algorithm, only SDCA suc-
cessfully selects the informative features.

three synthetic datasets, SDCA
To summarize, for all
successfully selects
features.
informative
LibLinear selects the exact features on 2 out of 3
datasets while GLASSO fails on all three datasets.

exact

the

3.1.6. EXPERIMENT 3 : REAL-WORLD DATASETS

In this experiment, we perform the comparative study
between SDCA, msgl and LibLinear on real-world
datasets . We observe from Table 2 that.

For aloi dataset, SDCA only selects 63.87% of features
for a classiﬁcation accuracy of 82.98% while LibLinear
has a worse accuracy with 100% of features used. More-
over, SDCA is the 12.6 times faster than LibLinear while
msgl fails to furnish a result after 2 hours of running time.

For covertype dataset, SDCA furnishes better classiﬁcation
accuracy than LibLinear and msgl. Moreover, SDCA is
by far faster than the two others. SDCA is SDCA is 45 times
faster than LibLinear and 89 times faster than msgl.
Concerning the sparsity of solution, msgl is the best while

The dataset madelon is known to be non-linear. Hence, all
three algorithms furnish quite low classiﬁcation accuracy
(62.38% for SDCA, 61.54% for LibLinear and 60.48%
for msgl). As for the sparsity, SDCA suppresses more fea-
tures than LibLinear and msgl.

sensorless dataset, SDCA is better

For
than both
LibLinear and msgl on all three aspects: classiﬁca-
tion accuracy, sparsity and running time. In terms of clas-
siﬁcation accuracy, the gain of SDCA versus msgl (resp.
LibLinear) is 3.89% (resp. 2.26%). Regarding the run-
ning time, SDCA is 113 times faster than msgl and 137
times faster than LibLinear. As for the sparsity, SDCA
selects 10% less features than msgl while LibLinear
fails to suppress features.

Overall, SDCA gives the best among the three in term of
classiﬁcation accuracy on all 4 datasets. As for running
time, SDCA is by far the fastest algorithm. Concerning the
sparsity of solution, SDCA suppresses more features than
the two others on 3 out of 4 datasets.

4. Conclusions

We have rigorously studied the large-sum optimization
problem involving (cid:96)2,0 regularization. The (cid:96)2,0-norm is ap-
proximated by a DC function, namely the piecewise expo-
nential function. The resulting problem is then reformu-
lated as a DC program and we developed stochastic DCA
to solve it. Exploiting the fact that each component fi(x)
is differentiable with L-Lipschitz gradient, we propose, a
stochastic version of DCA that is very inexpensive. At
each iteration, the algorithm only requires the computing
the subgradients of a small subset of functions and the pro-
jection of points onto balls that is explicitly computed. We
have also proved that the convergence is guaranteed with
probability one. As an application, we applied our algo-
rithm to the group variables selection in multiclass logistic
regression problem. Numerical experiments were carefully
conducted on both synthetic and real-world datasets. The
numerical results show that SDCA greatly improves the
running time of DCA while giving similar accuracy. More-
over, our algorithm SDCA outperforms standard algorithms
(Liblinear and msgl) on all 3 criteria: classiﬁcation
accuracy, sparsity of solution and running time. Especially,
the gain in running time is huge. SDCA is up to 210 times
faster than msgl and 1537 times faster than LibLinear.
We are convinced that stochastic DCA is a promising ap-
proach for handling very large-scale datasets in machine
learning.

Stochastic DCA for the Large-sum of Non-convex Functions Problem

References

Bagley, S. C., White, H., and Golomb, B. A. Logistic re-
gression in the medical literature: Standards for use and
reporting, with particular attention to one medical do-
main. Journal of Clinical Epidemiology, 54(10):979–
985, 2001.

Blondel, Mathieu, Seki, Kazuhiro, and Uehara, Kuni-
aki. Block coordinate descent algorithms for large-scale
sparse multiclass classiﬁcation. Machine Learning, 93
(1):31–52, 2013.

Bradley, Paul S. and Mangasarian, O. L. Feature Selec-
tion via Concave Minimization and Support Vector Ma-
In Proceedings of the Fifteenth International
chines.
Conference on Machine Learning, ICML ’98, pp. 82–
90, San Francisco, CA, USA, 1998. Morgan Kaufmann
Publishers Inc.

Cox, David. The regression analysis of binary sequences
(with discussion). J Roy Stat Soc B, 20:215–242, 1958.

Fan, R.-E., Chang, K.-W., Hsieh, C.-J., Wang, X.-R., and
Lin, C.-J. Liblinear: A library for large linear classiﬁca-
tion. Journal of Machine Learning Research, 9:1871–
1874, 2008. URL https://cran.r-project.
org/web/packages/LiblineaR/index.html.

Genkin, Alexander, Lewis, David D., and Madigan, David.
Large-scale Bayesian logistic regression for text catego-
rization. Technometrics, 49(3):291–304, 2007.

Gu, Quanquan, Li, Zhenhuif, and Han, Jiawei. Linear dis-
criminant dimensionality reduction. In Joint European
Conference on Machine Learning and Knowledge Dis-
covery in Databases, pp. 549–564. Springer, 2011.

Huang, Jian, Wei, Fengrong, and Ma, Shuangge. Semi-
parametric Regression Pursuit. Statistica Sinica, 22(4):
1403–1426, 2012.

Khan, Z., Shafait, F., and Mian, A. Joint Group Sparse PCA
for Compressed Hyperspectral Imaging. IEEE Transac-
tions on Image Processing, 24(12):4934–4942, 2015.

Kim, Jinseog, Kim, Yuwon, and Kim, Yongdai. A
Gradient-Based Optimization Algorithm for LASSO.
Journal of Computational and Graphical Statistics, 17
(4):994–1009, 2008.

King, Gary and Zeng, Langche. Logistic Regression in
Rare Events Data. Political Analysis, 9:137–163, 2001.

Le, H. M., Le Thi, H. A., and Nguyen, M. C. Sparse semi-
supervised support vector machines by DC program-
ming and DCA. Neurocomputing, 153:62–76, 2015.

Le Thi, H. A. and Nguyen, M. C. DCA based algorithms
for feature selection in multi-class support vector ma-
chine. Annals of Operations Research, 249(1):273–300,
2017.

Le Thi, H. A., Nguyen, T. B. T, and Le, H. M. Sparse Sig-
nal Recovery by Difference of Convex Functions Algo-
rithms. In Intelligent Information and Database Systems,
pp. 387–397. Springer, Berlin, Heidelberg, 2013.

Le Thi, H. A., Vo, X. T., and Pham Dinh, T. Feature se-
lection for linear SVMs under uncertain data: Robust
optimization based on difference of convex functions al-
gorithms. Neural Networks, 59:36–50, 2014.

Le Thi, H. A., Pham Dinh, T., Le, H. M., and Vo, X. T.
DC approximation approaches for sparse optimization.
European Journal of Operational Research, 244(1):26–
46, 2015.

Le Thi, Hoai An and Pham Dinh, Tao. The DC (Difference
of Convex Functions) Programming and DCA Revisited
with DC Models of Real World Nonconvex Optimization
Problems. Annals of Operations Research, 133(1-4):23–
46, 2005.

Le Thi, Hoai An and Phan, Duy Nhat. DC Programming
and DCA for Sparse Optimal Scoring Problem. Neuro-
comput., 186(C):170–181, 2016a.

Le Thi, Hoai An and Phan, Duy Nhat. DC programming
and DCA for sparse Fisher linear discriminant analysis.
Neural Computing and Applications, pp. 1–14, 2016b.

Le Thi, Hoai An, Le, Hoai Minh, Nguyen, Van Vinh, and
Pham, Dinh Tao. A DC programming approach for fea-
ture selection in support vector machines learning. Ad-
vances in Data Analysis and Classiﬁcation, 2(3):259–
278, 2008.

Lee, Sangin, Oh, Miae, and Kim, Yongdai. Sparse op-
timization for nonconvex group penalized estimation.
Journal of Statistical Computation and Simulation, 86
(3):597–610, 2016.

Liao, J. G. and Chin, Khew-Voon. Logistic regression for
disease classiﬁcation using microarray data: Model se-
lection in a large p and small n case. Bioinformatics, 23
(15):1945–1951, 2007.

Obozinski, Guillaume, Taskar, Ben, and Jordan, Michael.
Multi-task feature selection. Statistics Department, UC
Berkeley, Tech. Rep, 2, 2006.

Pham Dinh, Tao and Le Thi, Hoai An. Convex analysis
approach to dc programming: Theory, algorithms and
applications. Acta Mathematica Vietnamica, 22(1):289–
355, 1997.

Stochastic DCA for the Large-sum of Non-convex Functions Problem

Pham Dinh, Tao and Le Thi, Hoai An. A D. C. Opti-
mization Algorithm for Solving the Trust-Region Sub-
problem. SIAM Journal of Optimization, 8(2):476–505,
1998.

Phan, Duy Nhat, Le Thi, Hoai An, and Pham Dinh, Tao.
Efﬁcient bi-level variable selection and application to es-
timation of multiple covariance matrices. In Advances in
Knowledge Discovery and Data Mining: 21st Paciﬁc-
Asia Conference, PAKDD 2017, Proceedings, Part I,
volume 10234, pp. 304–316. Springer International Pub-
lishing, 2017.

Reddi, Sashank J., Sra, Suvrit, Poczos, Barnabas, and
Smola, Alexander J. Proximal stochastic methods for
Nonsmooth Nonconvex Finite-Sum Optimization.
In
Advances in Neural Information Processing Systems, pp.
1145–1153, 2016.

Schmidt, Mark, Le Roux, Nicolas, and Bach, Francis. Min-
imizing ﬁnite sums with the stochastic average gradient.
Mathematical Programming, 162(1):83–112, 2015.

Subasi, Abdulhamit and Erc¸elebi, Ergun. Classiﬁcation of
EEG signals using neural network and logistic regres-
sion. Computer Methods and Programs in Biomedicine,
78(2):87–99, 2005.

Sun, Liang, Liu, Jun, Chen, Jianhui, and Ye, Jieping. Efﬁ-
cient Recovery of Jointly Sparse Vectors. In Bengio, Y.,
Schuurmans, D., Lafferty, J. D., Williams, C. K. I., and
Culotta, A. (eds.), Advances in Neural Information Pro-
cessing Systems 22, pp. 1812–1820. Curran Associates,
Inc., 2009.

Tibshirani, Robert. Regression Shrinkage and Selection
Via the Lasso. Journal of the Royal Statistical Society,
Series B, 58:267–288, 1994.

Vincent, Martin and Hansen, Niels Richard. Sparse group
lasso and high dimensional multinomial classiﬁcation.
Comput. Stat. Data Anal., 71:771–786, 2014.

Wang, Lifeng, Chen, Guang, and Li, Hongzhe. Group
SCAD regression analysis for microarray time course
gene expression data. Bioinformatics, 23(12):1486–
1494, 2007.

Witten, Daniela M. and Tibshirani, Robert.

Penalized
classiﬁcation using Fisher’s linear discriminant. Jour-
nal of the Royal Statistical Society: Series B (Statistical
Methodology), 73(5):753–772, 2011.

Yuan, Ming and Lin, Yi. Model selection and estimation in
regression with grouped variables. Journal of the Royal
Statistical Society, Series B, 68:49–67, 2006.

