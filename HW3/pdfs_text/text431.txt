Active Learning for Top-K Rank Aggregation from Noisy Comparisons

Soheil Mohajer 1 Changho Suh 2 Adel Elmahdy 1

Abstract

cant items, say top-K, are often desired to be retrieved.

We explore an active top-K ranking problem
based on pairwise comparisons that are collected
possibly in a sequential manner as per our de-
sign choice. We consider two settings: (1) top-K
sorting in which the goal is to recover the top-K
items in order out of n items; (2) top-K partition-
ing where only the set of top-K items is desired.
Under a fairly general model which subsumes as
special cases various models (e.g., Strong Stochas-
tic Transitivity model, BTL model and uniform
noise model), we characterize upper bounds on
the sample size required for top-K sorting as well
as for top-K partitioning. As a consequence, we
demonstrate that active ranking can offer signif-
icant multiplicative gains in sample complexity
over passive ranking. Depending on the underly-
ing stochastic noise model, such gain varies from
around
log log n . We also present an
algorithm that is applicable to both settings.

log log n to n2 log n

log n

1. Introduction

Ranking is prevalent in a wide variety of applications: so-
cial choice (Caplin & Nalebuff, 1991; Azari Souﬁani et al.,
2013), web search and information retrieval (Dwork et al.,
2001), recommendation systems (Baltrunas et al., 2010),
and crowd sourcing (Chen et al., 2013), to name a few. The
goal of the problem is to bring a consistent ordering to a
collection of items, given partial preference information.
The two main paradigms among a large volume of works
on ranking include spectral ranking algorithms (Negahban
et al., 2016; Dwork et al., 2001; Brin & Page, 1998) and
maximum likelihood estimation (Ford, 1957). These meth-
ods focus on ﬁnding the entire ordering, not being tailored
for many practical applications in which only a few signiﬁ-

1ECE, University of Minnesota, Twin Cities, MN, USA. 2EE,
KAIST, Daejeon, South Korea. Correspondence to: Soheil Moha-
jer <soheil@umn.edu>, Changho Suh <chsuh@kaist.ac.kr>, Adel
Elmahdy <adel@umn.edu>.

where1

∆K =

In an effort to exploit the more practically relevant sce-
nario, (Chen & Suh, 2015) investigated the top-K rank
aggregation which aims to recover the correct set of top-
ranked items only. It characterized the minimax limit on
the sample size (i.e., sample complexity) under the Bradley-
Terry-Luce (BTL) model (Bradley & Terry, 1952; Luce,
1959) where pairs of two items are compared. However, this
development is limited to a passive measurement setting in
which pairwise data are simply given prior to analysis.

Many applications of interest often admit interaction with
users. This enables us to select comparison pairs of items
in an adaptive manner. This way of ranking provides the
potential to reduce a large number of blindly collected mea-
surements while maintaining a ranking accuracy (Tschopp
et al., 2011). This motivates us to examine an adaptive
measurement setting, in which pairwise comparisons are
gathered interacting with a ranker (termed active ranking).
In particular, we intend to address the following two ques-
tions: (a) how much can active ranking offer performance
improvements over passive ranking? (b) how does the limit
on the sample size for top-K ranking scale with K?

To answer this question, we consider a general model in
which the pairwise comparison probabilities are arbitrary
subject to a mild condition (see (5) in Section 2 for details)
and thus which includes as special cases various models
like the BTL model, Strong Stochastic Transitivity (SST)
model (Fishburn, 1973; Shah et al., 2016), and uniform
noise model (Braverman & Mossel, 2008). Two ranking
tasks are taken into consideration: (i) top-K sorting which
takes care of detailed ordering within top-K items; (ii) top-
K partitioning which concerns only the correct set of them.

Contribution. Our contributions are two-folded. The ﬁrst
lies in deriving an upper bound on the sample size:
(cid:19)

(cid:18)

O

(n + K log K)

max(log log n, log K)
∆K

(cid:40) ∆K,S = min

min
j:j≥i
∆K,P = (PK,K+1 −

i∈[K]

(Pij

0.5)2, Sorting;

−

0.5)2, Partitioning.

(1)

(2)

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by
the author(s).

1Note that the notation ∆K here is deﬁned slightly differently

from the one in (Chen & Suh, 2015).

Active Learning for Top-K Rank Aggregation from Noisy Comparisons

2

(cid:31)

(cid:31) · · · (cid:31)

Here Pij = Pi,j indicates the probability of item i being
preferred over item j, and ∆K,S (or ∆K,P) denotes the
parameter w.r.t. top-K sorting (or partitioning). Without
loss of generality, we assume that the ground truth ranking
is the order of 1
n. Notice that the sample
complexity bound reads O(n log log n/∆K) for the small
K regime (e.g, K = O(log n)), and O(K log2 K/∆K) for
the large K regime (e.g., K = Θ(n)). For the regime
K = O(log n) of practical interest, this exhibits signiﬁcant
multiplicative gains of active ranking over passive ranking.
For instance, in the case of top-K sorting, when specializing
our result into the uniform noise model and BTL model, one
and
can demonstrate that the factor gains are Ω

(cid:16) n2 log n
log log n

(cid:17)

(cid:16) log n
log log n

(cid:17)

Ω

, respectively. See Table 1 for further details.

Our second contribution is to develop a computationally-
efﬁcient (nearly)-linear-time algorithm that can achieve the
above bound promised. The algorithm is based on standard
algorithms in TCS literature for the noiseless sorting and
partitioning, where each pairwise order can be retrieved
using a single comparison or the transitive property of the
ranking. However, in a noisy setting of our interest, single
comparison results are not reliable. A key distinction in our
work is to employ repeated pairwise comparisons for each
comparison to combat the noise effect.

Here is how our algorithm works in details. It builds upon
a HEAP data-structure and can be applied to both settings
of sorting and partitioning. The main idea of identifying
top-K items in a dataset of n items is to partition the set
of n items into K subsets, and then identify the top item in
each subset using single-elimination tournament. Next, a
max-HEAP is built to single out the top-1 item among the K
winners of the tournaments. After that, this item is removed
from the system and the max-HEAP is updated by replacing
it by the second top item of the subset this top item belongs
to. We repeat this process until we identify top-K items.
See Fig. 2 for an explanatory example.

It is worth mentioning that the performance of our algorithm
depends on the separability parameter ∆K. The algorithm
is supposed to correctly distinguish between items K and
(K + 1) (in partitioning), or the top K items and the rest
(in sorting). The smaller ∆K, the less reliable the results
of comparison between to-be-distinguished items; hence,
more repetitions are needed for a decision. We characterize
the minimum number of repeated comparisons required to
ensure that the retrieved items are the correct winners. The
carefully chosen number for repeated comparisons together
with a couple of bounding techniques play a key role to
derive the above sample complexity bound. Finally, we
conduct several experiments to corroborate our main results.

Related work. (Chen & Suh, 2015) explored the top-K par-
titioning problem under the non-adaptive comparison model,

and characterized the optimal sample complexity. Subse-
quently, sample complexity analyses were made with regard
to different yet popular ranking paradigms such as simple
counting methods (Shah & Wainwright, 2016) and spectral
methods (Jang et al., 2016) (e.g., RankCentrality (Ne-
gahban et al., 2016)). In this work, we examine an adaptive
measurement setting under a fairly general model, thereby
showing that active ranking can signiﬁcantly outperform
passive ranking for a variety of scenarios.

Recently, (Braverman et al., 2016) developed an active rank-
ing algorithm. Interesingly, for the K = 1 case and under
the uniform noise model, their algorithm can achieve the
same sample complexity as ours for a certain target error
rate. (Szörényi et al., 2015) also focused on the K = 1 case
but under the BTL model, thus developing an algorithm
which however yields a larger sample complexity than ours.
Most recently, (Heckel et al., 2016) proposed an algorithm
for a general problem setting which encompasses top-K
sorting and partitioning of our interest. We found that their
algorithm is outperformed by ours when specializing it to
our settings. See 3.2 for detailed discussion.

There has been a proliferation of active ranking algo-
rithms (Busa-Fekete et al., 2014; Jamieson & Nowak, 2011;
Maystre & Grossglauser, 2015; Ailon, 2012; Braverman
& Mossel, 2008; Wauthier et al., 2013). While interesting
ranking schemes are developed for perfect ranking (Busa-
Fekete et al., 2014; Jamieson & Nowak, 2011; Maystre &
Grossglauser, 2015) and approximate ranking (Jamieson &
Nowak, 2011; Ailon, 2012; Braverman & Mossel, 2008;
Wauthier et al., 2013), they are not customized for top-K
ranking of our interest.

Moreover, the best-K identiﬁcation with adaptive sampling
has been extensively explored under the name of the multi-
armed bandit problem (Gabillon et al., 2011; Bubeck et al.,
2013; Jamieson et al., 2014; Yue et al., 2012) for a so-called
value-based model in which the observation on each item is
drawn only from the distribution underlying this individual.
Also there are many related yet different problem settings
considered in prior literature (Azari Souﬁani et al., 2013;
Hajek et al., 2014; Lu & Boutilier, 2011; Eriksson, 2013).

2. Problem Formulation

E

G

= ([n],

Comparison model. We denote by
) a compari-
son graph in which items i and j are compared if and only if
. More precisely, a multi-edge
(i, j) belongs to the edge set
E
graph is taken into consideration to accommodate repeated
measurements for an observed pair. We take into account
an adaptive comparison graph in which the edge set is dy-
namically selected interacting with a ranker. Speciﬁcally,
[1 : S] where S indicates the total
for a sample instance t
sample size, an edge et = (it, jt) is chosen based on the
pairwise outcomes obtained up to (t

1).

∈

−

Active Learning for Top-K Rank Aggregation from Noisy Comparisons

Pairwise comparisons. Given et = (i, j), the outcome of
the tth comparison, denoted by Yt, is generated according to
(cid:26) 1 with probability Pij
0 with probability 1

Yt =

(3)

Pij,

−

where Yt = 1 indicates that item i is preferred over item j.
The outcomes Yt’s are independent across t. We also repre-
sent the collection of sufﬁcient statistics as

bandit literature. Actually our work focuses on the worst
case scenario as the “error rate (0/1 loss)” that we consid-
ered is the most stringent criterion among others. Hence, the
sample complexity of our model provides an upper bound
for other criteria. Interestingly, the sample complexity of the
proposed algorithm is superior (lower) to that of the PLPAC
algorithm (Szörényi et al., 2015) under the PAC criterion.
See Section 3.2 for details.

Yij :=

(cid:88)

t:et=(i,j),et∈E

Yt; Y :=

Yij : (i, j)
{

∈ E}

.

(4)

3. Main Results

2

(cid:31)

(cid:31) · · · (cid:31)

Sorted-by-Probabilities (SP) model. Without loss of gen-
erality, assume that the ground truth ranking is the order
of 1
n. In fact, the SST model (Fishburn,
1973; Shah et al., 2016) suggests one way to relate the rank-
ing to the model parameters Pij’s by putting the following
constraint2: Pik > Pjk for all k
whenever item
item j. In this work, we introduce a more general
i
model, which we call Sorted-by-Probabilities (SP) model,
by relaxing the constraint as:

i, j

(cid:31)

=

{

}

Pij >

whenever i

j.

(5)

(cid:31)

1
2

Notice that the new constraint (5) is weaker, thus spanning
a larger parameter space. One can readily verify that our
model also subsumes as special cases other prominent mod-
els. Observe that whenever i

j,

(cid:31)

Pij =

(cid:26) 1

2 + γ > 1
2 ,
wi
> 1
2 ,
wi+wj

(uniform noise model);
(BTL model),

(6)

where γ denotes an arbitrary constant
indicates the score of item i.

∈

(0, 0.5) and wi

Performance metric and goal. Given the pairwise compar-
isons, one wishes to know whether or not the top-K ordered
items (or the top-K set) are identiﬁable. In light of this, we
consider the probability of error Pe:

(cid:26) P
P

K)

,

sorting;
partitioning,

ψ(Y )
{
ψ(Y )
{

= (1
= [K]

,

}

Pe(ψ) =

(cid:31) · · · (cid:31)
}
where ψ is any ranking scheme that returns an order of
K indices. Our goal in this work is to characterize the
sample complexity S∗
K, deﬁned as the minimum sample
size above which top-K ranking is feasible, in other words,
Pe can be vanishingly small as n grows.

Remark 1 It should be noted that there are other frame-
works in which different performance metrics are taken
into consideration: “regret” (Yue et al., 2012), and “PAC-
learning” (Szörényi et al., 2015), both introduced in the

As noted in the passive ranking setup (Chen & Suh, 2015),
the most crucial part of top-K partitioning under the BTL
model hinges on separating the two items near the bound-
(cid:16) wK −wK+1
ary, being reﬂected in
. Similarly for top-K
wK +wK+1
sorting, one can easily show that the key measure would be:

(cid:17)2

(cid:16) wi−wi+1
wi+wi+1

(cid:17)2

. We ﬁnd that in our general model,
mini∈[K]
the corresponding key measure is the one deﬁned in (2).
Observe in (2) that Pij
2(wi+wj ) under the BTL
model. Hence, we will use this measure to express our upper
bound on sample complexity as below.

0.5 = wi−wj

−

(log n)−c0 , the
Theorem 1 With probability exceeding 1
top-K order (or top-K set3) can be identiﬁed provided that

−

SK

c1(n + K log K)

≥

max(log log n, log K)
∆K

.

(7)

Here, (c0, c1) are some universal positive constants.

1

−

−

See Section 4 for the proof of Theorem 1 and algorithm
description. There are three points to make. The ﬁrst is that
the above bound is w.r.t. a target error rate that scales like
poly(log n) . Aiming at a smaller target error, we need a larger
sample size. Secondly, the term ∆K, affected by (Pij
0.5)
(see (2)), captures how noisy the comparison data is, i.e.,
0.5) is a sort of the difﬁculty level of separating item
(Pij
i from item j. So the result in Theorem 1 coincides with our
intuition because smaller ∆K means more difﬁcult to rank,
which results in an increase of sample complexity. The last
point is regarding the performance of our algorithm. Since
sorting naturally produces a partitioning, our algorithm is
tailored for the sorting, and hence favors the sorting per-
formance relative to partitioning. Notice for partitioning
that when K = n, the sample complexity bound reads the
order of n(log n)2, which is certainly far from optimality.
Hence, in the next subsection, we provide several interesting
remarks with an emphasis on top-K sorting in which we
advocate the performance of our algorithm.

2We ignore the tie situation as we consider a strict order of
ranking. Precisely speaking, the constraint is called Strict Strong
Stochastic Transitivity (SSST) property (Fishburn, 1973).

3For top-K partitioning, we assume monotonicity in Pij:
Pij ≥ Pik whenever i ≤ j ≤ k, which holds still under a fairly
general model like SST.

(cid:54)
(cid:54)
(cid:54)
Active Learning for Top-K Rank Aggregation from Noisy Comparisons

3.1. Top-K Sorting

Penalty due to noisy measurements: As mentioned ear-
lier, top-K sorting has been extensively explored in the
TCS literature, but only the noiseless setting has been the
main focus, in which sample complexity is characterized as
(Cormen et al., 2009)

Snoiseless,K = Θ(n + K log K).

Comparing (8) to (7), we see that the penalty factor in sam-
ple complexity due to noisy measurements is:

(cid:18) max(log log n, log K)
∆K

(cid:19)

.

O

(8)

(9)

Actually it is not clear whether or not this penalty factor is
fundamental due to the lack of the optimality result. How-
ever, the gap, if any, is up to poly(log n), as long as ∆K is
not too small (scales at most with poly(log n)). This implies
that the degradation over the noiseless setting is low and
therefore our algorithm performs very close to optimum.

How the limit scales with K: Observe in (7) that:
(cid:16) n log log n
∆K
(cid:17)
(cid:16) K log2 K
∆K

, K = O(log n);

, K = Θ(n).

SK =






O

O

(cid:17)

We make one interesting observation in the K = O(log n)
regime of practical interest: the bound is irrelevant to K
under some measurement model. One such example is the
uniform noise model where ∆K = γ2:

Suniform,K = O

(cid:18) n log log n
γ2

(cid:19)

,

(10)

for every K. However, this phenomenon does not carry
over to other noisy models, like the BTL model in which
the noise quality varies according to associated preference
scores. Note that

(cid:32)

SBTL,K = O

n log log n

mini∈[K]

(cid:0) wi−wi+1
wi+wi+1

(cid:1)2

(cid:33)

.

(11)

But our result still suggests that the phenomenon may hold
universally for a variety of statistical models as long as K
is small enough.

Active vs. passive ranking: For illustrative purpose, let
us focus on the interesting regime of K = O(log n), and
consider two models: (1) uniform noise model; (2) BTL
model. In the uniform noise model, Shah-Wainwright (Shah
& Wainwright, 2016) characterized the passive ranking sam-
ple complexity for a certain observation model:

Spassive
uniform,K = Θ

(cid:18) n3 log n
γ2

(cid:19)

,

(12)

& Suh, 2015) characterized the sample complexity under
passive ranking as:

(cid:32)

Spassive
BTL,K = O

(cid:33)
.

n log n

(cid:16) wi−wi+1
wi+wi+1

(cid:17)2

(13)

(cid:17)

(cid:16) log n
log log n

mini∈[K]
Comparing this to (11), we see that the factor gain is
, which is not quite signiﬁcant but still scales
Ω
with n and hence exhibits respectful improvements in high
dimensional regimes. The comparisons are summarized in
Table 1. See Section 5 for experimental results on this.

Robustness: Theorem 1 suggests that the performance gap
between sorting and partitioning is not signiﬁcant. For in-
stance, under the uniform noise model, ∆K’s are the same,
yielding the same sample complexity bound. For the BTL
model, ∆K’s would be similar if wi’s are equidistant. Ex-
perimental results on this are provided in the supplemental.

Computational complexity: A noticeable feature of our al-
gorithm is its low computational complexity. It runs in time
O(n) in the practically-relevant regime of K = O(log n).
For general K, it is nearly linear in n, i.e., O(n + K log K).
Here, this complexity assumes that the input fed to our algo-
rithm is the sufﬁcient statistic of the outcome comparisons:
Yij (see (4)), rather than the entire collection of Yt’s asso-
ciated with the pair (i, j). This will be evident later when
describing the algorithm.

3.2. Comparison to Related Work

(Braverman et al., 2016) developed an active ranking algo-
rithm for the K = 1 case and derived the order-wise tight
sample complexity in terms of target error rate under the
uniform noise model. More concretely, suppose we want
the error probability not to exceed a target error rate δ. Then,
the result of (Braverman et al., 2016) implies

S1,δ = Θ

(cid:18) n log(1/δ)
γ2

(cid:19)

.

(14)

≤

Notice that our result (7) admits the target error rate that
1
scales like
log n , implying that their algorithm can achieve
the same sample complexity as ours for a certain scenario
1
in which δ
log n (see Section 5 for experimental re-
1
log log n , their algorithm
sults). For a relaxed target error like
achieves a slightly smaller sample complexity by a factor of
log log n
log log log n .
(Szörényi et al., 2015) also developed a top-selection al-
gorithm and analyzed sample complexity under the BTL
model as well as a less-stringent PAC criterion. Their sam-
ple complexity bound reads around O(n log n), thus yields
a larger one compared to ours.

for every choice of K. This together with (10) demonstrates
that the factor gain due to active measurements is quite sub-
. In the BTL model, Chen-Suh (Chen
stantial: Ω

(cid:16) n2 log n
log log n

(cid:17)

In another relevant paper, (Heckel et al., 2016) proposed
an active ranking algorithm for a general setting, which
subsumes top-K sorting (as well as top-K partitioning)

Active Learning for Top-K Rank Aggregation from Noisy Comparisons

Noise Model

Uniform Noise

Pij = 0.5 + γ(

1)1{i≺j}

−

BTL model

Pij = wi

wi+wj

Active Measurement
(cid:16) n log log n
γ2

O

(cid:17)

Passive Measurement
(cid:16) n3 log n
γ2

Θ

(cid:17)

(cid:32)

O

(cid:33)

(cid:32)

(cid:33)

n log log n

mini∈[K]

(cid:16) wi−wi+1
wi+wi+1

(cid:17)2

Θ

mini∈[K]

n log n
(cid:16) wi−wi+1
wi+wi+1

(cid:17)2

Gain
(cid:16) n2 log n
log log n

(cid:17)

Ω

(cid:16) log n
log log n

(cid:17)

Ω

Table 1. Top-K sorting: Multiplicative gains of active ranking (this work) over passive ranking for the uniform noise model (Shah &
Wainwright, 2016) and BTL model (Chen & Suh, 2015) in the practically relevant regime K = O(log n).

(cid:17)

(cid:16) n2 log(1/δ)
γ2

as a special case. They also provided a lower bound on
the sample complexity for a class of parametric models,
which is only O(log n) away from the achievable sample
complexity. It is worth mentioning that under the uniform
noise model, the algorithm in (Heckel et al., 2016) requires
pairwise comparisons to achieve an error
O
rate of δ, which is very expensive compared to our algorithm.
Here a key to note is that the uniform noise model does not
ﬁt to the class of parametric models considered by (Heckel
et al., 2016), in which the CDF function Φ in Pij = Φ(wi
−
wj) is assumed to be differentiable, which does not hold in
the uniform noise model where Φ(t) = 1

2 + γ sign(t).

On the other hand, applying the result of (Heckel et al.,
2016) on the BTL model, we get lower and upper bounds
on the sample complexity. To see this in details, consider
a special case of the top-K partitioning problem, where
= wn.
w1 = w2 =
In this case, (Heckel et al., 2016) implies

= wK, and wK+1 = wK+2 =

· · ·

· · ·

cl

n
∆K

log

(cid:19)

(cid:18) 1
2δ

≤

SBTL,K

cu

≤

n
∆K

log

(cid:17)

(cid:16) n
δ

log log

(cid:19)

(cid:18) 4
∆K

≈

where cl = 1/16 and cu
654. Notice that the asymptotic
multiplicative gap between the lower and upper bounds are
on the order of log(n) log log(1/∆K). Moreover, the large
constant-factor gap yields a signiﬁcant performance gap in
the actual experiment. For instance, see Fig. 3(b) where
n = 1024, ∆K = 0.0225, and δ = 0.1. Observe that
108
the lower and upper bounds are 6.6
comparisons, respectively, which are far apart.

103 and 4.5

×

×

4. Proposed Ranking Algorithm

In this section we present our algorithms for sorting and
partitioning tasks, and provide upper bounds for the sample
complexity. We use
) to denote the number of pairwise
(
·
comparisons required in the algorithm.

N

4.1. Top-1 Selection: Single-Elimination Tournament

We ﬁrst focus on the special case of identifying the top
item, i.e., K = 1. The proposed algorithm is essentially a
customized single-elimination tournament, which consists
of multiple layers. In each layer items are paired in a ran-

Algorithm 1 SELECT(X; m)

.
x[1], x[2], . . . , x[n]
}
{

Input: m
Data: X =
Output: a∗: the index of item with the highest score.
(Assume
is a power of 2 for simplicity)
n
X
for i
for (cid:96)

i end for

do a(i)

X
|

← |

←

|

|
1 to
X
|
|
1 to log n do
1 to n/2(cid:96) do
0

1 to m do
(a(2i
−
T + Yt

1), a(2i))

(Yt is deﬁned in Eq. 3)

m
2 then a(i)
a(2i)
←

a(2i

1)

−

←

←
←
for i
←
T
←
for t
←
et
←
T
←
end for
if T
else a(i)
end if
end for

≥

end for
a∗

a(1)

←

dom manner, and one of the items in each pair is selected
to proceed to the next layer, while the other one is elimi-
nated. This decision is made based on pairwise comparisons
between the two items. The distinctive feature relative to
conventional single-elimination tournament is that in order
to combat against the uncertainty of the observations, we re-
peat each binary comparison multiple (say m) times. It turns
out that for a sufﬁciently large m, the algorithm will output
the index of the top item with overwhelming probability.

(cid:100)

|(cid:101)

log

X
|

(see
The algorithm builds a binary tree of depth
Fig. 1). We denote the i-th item index in layer (cid:96) by x(cid:96),i.
Initially, we randomly locate items on the leaves of the tree,
that are denoted by x1,i for i = 1, . . . , n. Then, in each
iteration, a pair in layer (cid:96) is tested, and the winner will
proceed to layer ((cid:96) + 1). Hence, half of the existing items
will be eliminated in each iteration, until we get to the root
layer in which there would be only one surviving item. The
algorithm is formally presented in Algorithm 1.

Number of measurements: The algorithm consists of
/2(cid:96) pairs are being tested in layer (cid:96).
log
|

layers, and

X
|

X
|

|(cid:101)

(cid:100)

Active Learning for Top-K Rank Aggregation from Noisy Comparisons

Algorithm 2 TOP(X; K, m)
Input: Integers K and m
Data: Array X =
Output: Indices of top-K: π(1), π(2), . . . , π(K)
n
for i

x[1], x[2], . . . , x[n]
}

n/K
(cid:101)
1 do

{

.

← (cid:100)
−
x[iQ+1], x[iQ+2],. . ., x[min
(i+1)Q, n
}
{
iQ + SELECT(Ci+1; m)

]
}

X

, Q
← |
|
0 to K
←
Ci+1 ← {
b(i + 1)
←

}

b(1), b(2), . . . , b(K)

end for
Z
BuildHeap(Z, X; m)
for i

← {

1 to K do
Z[1]
←
Z[1]/K
Cj

←
π(i)
j
Cj
Z[1]
Heapify(Z, X, 1; m)

(cid:99)
x[Z[1]]
}
SELECT(Ci; m)

← (cid:98)
←

\ {

←

end for

|

|

when K scales with n =
. Rather, we ﬁrst split the
X
dataset X of n items into K groups each of size n/K,
namely groups C1, C2, . . . , CK. Then we identify the top
item in each sub-group using SELECT, and form a short
list that includes all winners from the sub-groups. Then we
build a (max-)HEAP data-structure for the short list obtained
from the K winners. The HEAP structure allows us to easily
extract the top item from the short list. Once the top item of
the short list is identiﬁed and removed from the list, we go
back to its home sub-group, identify the second top item in
that sub-group, and insert it to the short list. We maintain
the HEAP structure of the short list during the process, to
be able to easily extract the next top item of the list. We
repeat this procedure for (K
1) rounds until we retrieve all
−
the top K items. The main algorithm, TOP is presented in
Algorithm 2. For the sake of completeness, we also present
the algorithms required to build the heap structure and to
insert a new item to an existing heap in the supplemental.

Sample complexity: The sample complexity of the algo-
rithm can be simply evaluated in terms of the input parame-
ters as follows. We ﬁrst identify the top entry of each of the
K sub-groups. Later, during the iterative phase of the algo-
rithm, we need to repeat SELECT algorithm on the remain-
ing elements of sub-groups for another K iterations, which
results in 2K runs of SELECT, each on subgroups of size
at most n/K items. Each run of algorithm SELECT with
[SELECT(Ci; m)]
parameter m on a dataset Ci requires
pairwise comparison, as given in (16).

N

In order to build the heap structure on K sub-winners we
need to make O(K) binary decisions, where we repeat each
comparison m times to deal with the noise. Moreover, in
each iteration one new item is added to the short list. We
need to make O(log K) binary decisions to maintain the

Figure 1. The single-elimination tournament with repeated com-
parisons for n = 8 items. In each round (layer), items are paired.
A decision between a pair of items is made based on the majority
rule among m comparisons. Note that a wrong decision in a pair
that does not include item 1 (e.g., when 7 beats 3 in spite of 3 (cid:31) 7)
will not affect the ultimate output of the algorithm.

Hence, the total number of tests is (cid:80)(cid:100)log |X|(cid:101)
.
X
|
Each test requires m binary comparisons, yielding a total
number of measurements given by

n2−(cid:96)

≤ |

(cid:96)=1

(SELECT(X; m)) = O(m
|

N

X

) = O(mn),

|
= n. It can be shown that if

for a dataset of size

X

(15)

|

|
(1 + ε) ln 2
2

m

≥

log log
|
∆1,S

X

|

,

(16)

then Pe(TopSelection)
(log n)−ε for any ε > 0. This
implies that, with high probability, the SELECT algorithm
can successfully select the top item using a total of

≤

(SELECT(X; m)) = O

N

(cid:16)

X
|

|

log log
∆1

|

X

(cid:17)

|

(17)

pairwise comparisons.

Remark 2 Parallel to this work, the top-selection problem
is studied in (Braverman et al., 2016) under the uniform
noise model. The algorithm in (Braverman et al., 2016) ﬁrst
identiﬁes the top item in a subset of size n/ log n items, and
then iteratively reﬁnes the estimate by further comparing
that to other items in the set. It is shown that the number of
measurements required grows linearly with n, when a con-
stant (non-vanishing) error probability is desired. However,
in order to achieve a vanishing error probability scaling
as 1/poly(log n), the algorithm of (Braverman et al., 2016)
requires the same number (up to a constant factor) of pair-
wise comparisons, as the one presented above.

4.2. Top-K Sorting: A Heap-based Algorithm

In this section we generalize our proposed algorithm to
ﬁnd the top K items along with their order. The proposed
algorithm is built based on the single-elimination algorithm,
which can ﬁnd the the single top item with high probability.
A trivial generalization is to repeat the SELECT algorithm
for K times, which requires a large number of comparisons

1263875125121m67Active Learning for Top-K Rank Aggregation from Noisy Comparisons

into K groups, and run the single-elimination tournament
in each group. The winners will proceed to the HEAP algo-
rithm, and then the HEAP outputs items one by one. The
only difference lies in the performance metric which con-
cerns only the set of K items reported by the algorithm,
regardless of the order. It turns our that a similar analy-
sis holds for this problem, except the fact that the number
of repeated comparisons, m, has a weaker dependency on
the data. More precisely, the algorithm is robust against
wrong binary decision between two items from [K], and
similarly between two items from X
[K]. One needs to
choose m such that the algorithm (with high probability)
can correctly distinguish when s
[K] is compared against
∈
[K]. Consequently, we show that m depends only
q
on ∆K,P, which captures the gap between PK,K+1 and 1/2.

X

∈

\

\

Remark 4 Note that the proposed algorithms do not re-
quire the knowledge of ∆K, and can be executed with any m.
It depends only on the measurement budget. However, de-
pendency of the performance of the algorithms on ∆K is
inevitable, since the success rate depends on the separability
parameter as discussed earlier.

5. Simulation Results

In this section, we empirically evaluate the performance of
the proposed algorithm by conducting Monte Carlo simula-
tions on synthetic data and developing a benchmark compar-
ison against the state-of-the-art active and passive ranking
algorithms in the literature. In an effort to guarantee fair-
ness in the performance comparison, we jointly investigate
the average number of pairwise comparisons and the corre-
sponding empirical success rate of identifying top-K items.
The source code of our algorithm4 is provided to allow for
reproducible research. In addition, we present a more de-
tailed discussion on the performance of our algorithm under
various simulation parameters in the supplemental.

5.1. Comparison to Prior Active Ranking Algorithms

We assess the performance of the proposed algorithm
against two recent active ranking algorithms; the ﬁrst is
proposed by (Braverman et al., 2016), coined “Braverman”,
while the second algorithm is proposed by (Heckel et al.,
2016), coined “Heckel”. For Braverman algorithm, we
sweep over an algorithm parameter (denoted by c in the
paper), such that c
10, to measure the corresponding suc-
cess rate. Heckel algorithm employs a conﬁdence interval
during the process, and we select the following empirical
conﬁdence interval model, that is a function of the algo-
rithm round, t, and the tolerance parameter δ
(0, 0.14]:
log(n/3(log(t) + 1)/δ)/16t.
αt =

(cid:112)

≥

∈

4The

source

accessible
https://github.com/a-elmahdy/
Active-Learning-from-Noisy-Comparisons.git

via GitHub

code

is

at

Figure 2. Sorting algorithm for K = 10 using heap data struc-
ture. Items are split into K = 10 groups of equal size, namely
C1, C2, . . . , C10. The top items of each sub-groups is identiﬁed
using single-elimination tournament. A heap data-structure is then
built for the short list of the winners of the tournaments. This
provides a binary tree, with the property that children of each node
have a rank lower than their parent. Then the root will be reported
as the top item. Next, one goes back to the home-subgroup of
the root, to ﬁnd the second-top item of that group. The top item
found in the heap will be replaced by the second top item, and
heap will be re-arranged to maintain its property. Iterating on this
for (K − 1) = 9 times, one can identify items 1, 2, . . . , 10.

heap structure. Similar to BuildHeap, we repeat each
comparison for m times, and then decide based on a majority
rule. Therefore, we have
[TOP(X, K; m)] (cid:44) 2K
+

[InsertHeap(Z; m)]

[SELECT(Ci; m)]

· N

N

[BuildHeap(Z; m)]+K
O(mn/K) + m

N
= 2K

N
O(K) + m

O(K log K)

·

·

·

= O(mn + mK log K).

(18)
It turns out, from the analysis of probability of error, that the
proposed algorithm can successfully sort the top K items if

m = O

(cid:18) max
log K, log log n
{

}

(cid:19)

.

∆K

Plugging this into (18), we can ﬁnd the sample complexity
of the TOP algorithm as

SK = O

(cid:18) (n + K log K) max
log K, log log n
{
∆K

}

(cid:19)

.

Remark 3 The repetition parameter used in SELECT algo-
rithm, and the one used in HEAP can be potentially different,
and accordingly optimized. However, our analysis shows
that a choice of distinct parameters can provide a marginal
gain only for a tiny range of K. Thus, we rather choose the
same parameter for the sake of simplicity.

4.3. Partitioning

The algorithm we propose for partitioning is exactly iden-
tical to that of the sorting. We (randomly) split the items

·········C1C2b(2)=5b(1)=13C10b(10)=61356914110177291267514171013shortlistheap······Active Learning for Top-K Rank Aggregation from Noisy Comparisons

(a) Uniform noise model.

(b) BTL model.

(c) Active vs. Passive algorithms.

Figure 3. Performance Evaluation of various active and passive ranking algorithms: (a) Active algorithms under the uniform noise model
for different values of K when n = 1024, ∆K,S = ∆K,P = γ2 = 0.0225, and δ = 0.1 (Heckel algorithm parameter); (b) Active
algorithms under BTL model for different values of K when n = 1024, ∆K = 0.0225, wi ∈ (0, 3], 1 ≤ i ≤ n, and δ = 0.1 (Heckel
algorithm parameter); (c) Performance Comparison between the proposed Top-K algorithm versus the Copeland Counting algorithm
(with α = 8 and p = 0.6) under the uniform noise model for different values of K when n = 128, ∆K = γ2 = 0.1.

The plots in Fig. 3(a) indicate the performance of different
active ranking algorithms under the uniform noise model
to identify the top-1 and top-16 items, respectively, when
n = 210 = 1024, ∆K = γ2 = 0.0225 and δ = 0.1. The
ﬁrst plot shows slight improvement in the total number of
pairwise comparisons required to achieve a target success
rate for Braverman algorithm over our Top-1 algorithm.
We also observe that the performance gap between the two
algorithms is negligible at a higher success rate. On the
other hand, the second plot in Fig. 3(a) depicts the signiﬁ-
cant improvement of our Top-K algorithm over Braverman
algorithm5 when K = 16. It is evident that the sample
complexity of Braverman algorithm scales with K when it
is employed for top-K identiﬁcation. We can also see that
the performance gap between Partitioning and Sorting is
insigniﬁcant. These ﬁndings are consistent with our anal-
ysis of the sample complexity of both algorithms. Hence,
the two prime merits of the proposed Top-K algorithm are:
(1) its superior performance compared to Braverman algo-
rithm when K > 1; and (2) error and sample complexity
of Braverman algorithm is limited to uniform noise model,
while our algorithm provably performs well for a wide class
of pairwise comparison models, deﬁned by (5). We refer the
reader to the supplemental for an insightful remark about
our algorithm.

5Braverman algorithm is extended to top-K ranking. We ﬁrst
run the algorithm to retrieve the top-item. Then, we remove it from
the set of items and rerun the algorithm to ﬁnd the second top item.
We keep doing that until we ﬁnd the top-K items.

The plots in Fig. 3(a) also depict performance comparison
between our and Heckel algorithm for Top-K ranking under
the uniform noise model. As it is clear from the ﬁgure, the
proposed algorithm in this work performs signiﬁcantly bet-
ter than Heckel algorithm for this noise model. Furthermore,
Fig. 3(b) shows that our algorithm for identifying top-1
and top-16 ranked items also achieves a better performance
compared to Heckel algorithm under the BTL model.

5.2. Active vs. Passive Ranking

We compare the performance of our active ranking algo-
rithm against a passive ranking algorithm proposed by (Shah
& Wainwright, 2016), coined “Shah”. This simple yet ro-
bust algorithm hinges on Copeland counting algorithm that
recovers the top-K items that win the maximum number
of pairwise comparisons. Moreover, the algorithm makes
no assumptions on the probability model of pairwise com-
parisons. The algorithm parameters are the probability of
making a comparison on any trial, p, the number of trials, r,
and α
8. Note that the number of noisy comparisons asso-
ciated with each pair of items follows a binomial distribution
with parameters p and r.

≥

The plots in Fig. 3(c) illustrate the performance of the
two algorithms under the uniform noise model to recover
the top-1 and top-8, respectively, when n = 27 = 128,
∆K = γ2 = 0.1, α = 8 and p = 0.6. As predicted by our
analysis of the sample complexity gain, we can observe the
considerable gain due to active measurements, even when
the total number of items is modest.

01234567Total Number of Pairwise Comparisons10500.20.40.60.81Success RateProposed, Top-1Braverman, Top-1Heckel, Top-100.20.40.60.811.21.41.61.82Total Number of Pairwise Comparisons10600.20.40.60.81Success RateProposed, Top-16, PartitioningProposed, Top-16, SortingBraverman, Top-16Heckel, Top-16012345678Total Number of Pairwise Comparisons10500.20.40.60.81Success RateProposed, Top-1Heckel, Top-1012345678Total Number of Pairwise Comparisons10500.20.40.60.81Success RateProposed, Top-16Heckel, Top-16102103104105106107108Total Number of Pairwise Comparisons0.10.20.30.40.50.60.70.80.91Success RateProposed, Top-1Shah, Top-1102103104105106107108Total Number of Pairwise Comparisons00.20.40.60.81Success RateProposed, Top-8Shah, Top-8Active Learning for Top-K Rank Aggregation from Noisy Comparisons

Acknowledgment

The authors would like to thank the reviewers who gave
useful comments. C. Suh was supported by the National
Research Foundation of Korea (NRF) grant funded by the
Korea government (MSIP; Ministry of Science, ICT & Fu-
ture Planning) (No. 2015R1C1A1A02036561).

References

Ailon, N. Active learning ranking from pairwise prefer-
ences with almost optimal query complexity. Journal of
Machine Learning, 13:137–164, 2012.

Azari Souﬁani, H., Chen, W., Parkes, D. C., and Xia, L.
Generalized method-of-moments for rank aggregation. In
Neural Information Processing Systems, pp. 2706–2714,
2013.

Baltrunas, L., Makcinskas, T., and Ricci, F. Group rec-
ommendations with rank aggregation and collaborative
ﬁltering. In ACM Conference on Recommender Systems,
pp. 119–126. ACM, 2010.

Bradley, R. A. and Terry, M. E. Rank analysis of incom-
plete block designs: I. the method of paired comparisons.
Biometrika, 39(3-4):324–345, 1952.

Braverman, M. and Mossel, E. Noisy sorting without resam-
pling. In ACM-SIAM symposium on Discrete algorithms,
pp. 268–276, 2008.

Braverman, M., Mao, J., and Weinberg, S. M. Parallel al-
gorithms for select and partition with noisy comparisons.
STOC, 2016.

Brin, S. and Page, L. The anatomy of a large-scale hypertex-
tual web search engine. Computer Networks and ISDN
systems, 30(1):107–117, 1998.

Bubeck, S., Wang, T., and Viswanathan, N. Multiple identi-
ﬁcation in multi-armed bandits. In International Confer-
ence on Machine Learning, 2013.

Busa-Fekete, R., Hüllermeier, E., and Szörényi, B.
Preference-based rank elicitation using statistical models:
The case of mallows. In International Conference on
Machine Learning, pp. 1071–1079, 2014.

Caplin, A. and Nalebuff, B. Aggregation and social choice:
a mean voter theorem. Econometrica, pp. 1–23, 1991.

Chen, X., Bennett, P. N., Collins-Thompson, K., and
Horvitz, E. Pairwise ranking aggregation in a crowd-
sourced setting. In ACM Conference on Web Search and
Data Mining, pp. 193–202. ACM, 2013.

Chen, Y. and Suh, C. Spectral MLE: Top-K rank aggrega-
tion from pairwise comparisons. In International Confer-
ence on Machine Learning, pp. 371–380, 2015.

Cormen, T. H., Leiserson, C. E., Rivest, R. L., and Stein, C.
Introduction to algorithms. MIT press, 3rd edition, 2009.

Dwork, C., Kumar, R., Naor, M., and Sivakumar, D. Rank
aggregation methods for the web. In International con-
ference on World Wide Web, pp. 613–622. ACM, 2001.

Eriksson, B. Learning to top-K search using pairwise com-
parisons. In International Conference on Artiﬁcial Intelli-
gence and Statistics, pp. 265–273, 2013.

Fishburn, P.C. Binary choice probabilites: on the varieties
of stochastic transitivity. Journal of Mathematical Psy-
chology, 10:327–352, 1973.

Ford, L. R. Solution of a ranking problem from binary
comparisons. American Mathematical Monthly, pp. 28–
33, 1957.

Gabillon, V., Ghavamzadeh, M., Lazaric, A., and Bubeck,
S. Multi-bandit best arm identiﬁcation. In Neural Infor-
mation Processing Systems, 2011.

Hajek, B., Oh, S., and Xu, J. Minimax-optimal inference
from partial rankings. In Neural Information Processing
Systems, pp. 1475–1483, 2014.

Heckel, R., Shah, N., Ramchandran, K., and Wainwright,
M. Active ranking from pairwise comparisons and when
parametric assumptions don’t help. arXiv:1606.08842,
2016.

Jamieson, K., Malloy, M., Nowak, R., and Bubeck, S. li-
iUCB: An optimal exploration algorithm for multi-armed
bandits. In Conference on Learning Theory, 2014.

Jamieson, K. G. and Nowak, R. Active ranking using pair-
In Neural Information Processing

wise comparisons.
Systems, pp. 2240–2248, 2011.

Jang, M., Kim, S, Suh, C, and Oh, S. Top-k ranking from
pairwise comparisons: When spectral ranking is optimal.
arXiv preprint arXiv:1603.04153, 2016.

Lu, T. and Boutilier, C. Learning Mallows models with
In International Conference on

pairwise preferences.
Machine Learning, pp. 145–152, 2011.

Luce, R. D.

Individual choice behavior: A theoretical

analysis. Wiley, 1959.

Maystre, L. and Grossglauser, M. Robust active ranking
from sparse noisy comparisons. In arXiv:1502.05556,
2015.

Active Learning for Top-K Rank Aggregation from Noisy Comparisons

Negahban, S., Oh, S., and Shah, D. Rank centrality: Rank-
ing from pairwise comparisons. Operations Research,
2016.

Shah, N. B. and Wainwright, M. J. Simple, robust and
optimal ranking from pairwise comparisons. 2016. URL
http://arxiv.org/abs/1512.08949.

Shah, N. B, Balakrishnan, S., Guntuboyina, A., and Wain-
wright, M. J. Stochastically transitive models for pairwise
comparisons: Statistical and computational issues. Inter-
national Conference on Machine Learning, 2016.

Szörényi, B., Busa-Fekete, R., Paul, A., and Hüllermeier, E.
Online rank elicitation for Plackett-Luce: A dueling ban-
dits approach. In Neural Information Processing Systems,
2015.

Tschopp, D., Diggavi, S., Delgosha, P., and Mohajer, S.
Randomized algorithms for comparison-based search. In
Neural Information Processing Systems, 2011.

Wauthier, F., Jordan, M., and Jojic, N. Efﬁcient ranking
from pairwise comparisons. In International Conference
on Machine Learning, pp. 109–117, 2013.

Yue, Y., Broder, J., Kleinberg, R, and Joachims, T. The
k-armed dueling bandits problem. Journal of Computer
and System Sciences, 2012.

