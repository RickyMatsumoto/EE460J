Coherent Probabilistic Forecasts for Hierarchical Time Series

Souhaib Ben Taieb 1 James W. Taylor 2 Rob J. Hyndman 1

Abstract
Many applications require forecasts for a hierar-
chy comprising a set of time series along with
aggregates of subsets of these series. Hierar-
chical forecasting require not only good predic-
tion accuracy at each level of the hierarchy, but
also the coherency between different levels —
the property that forecasts add up appropriately
across the hierarchy. A fundamental limitation
of prior research is the focus on forecasting the
mean of each time series. We consider the situa-
tion where probabilistic forecasts are needed for
each series in the hierarchy, and propose an algo-
rithm to compute predictive distributions rather
than mean forecasts only. Our algorithm has the
advantage of synthesizing information from dif-
ferent levels in the hierarchy through a sparse
forecast combination and a probabilistic hierar-
chical aggregation. We evaluate the accuracy of
our forecasting algorithm on both simulated data
and large-scale electricity smart meter data. The
results show consistent performance gains com-
pared to state-of-the art methods.

1. Introduction

Producing forecasts that support decision-making in a hi-
erarchical structure is a central problem for many organi-
zations. For example, retail sales forecasts typically form
a hierarchy, with the inventory control system of a retail
outlet relying on forecasts for store-level demand, while
forecasts of regionally aggregated demand are needed for
managing inventory at a distribution centre (Kremer et al.,
2016). Another context where a hierarchy naturally arises
is electricity demand, where the bottom level might consist
of time series of the electricity consumption of individual
customers, while the top level could be the total load on
the grid. Forecasts of electricity consumption are needed at

1Monash University, Melbourne, Australia 2University of
Oxford, Oxford, UK. Correspondence to: Souhaib Ben Taieb
<souhaib.bentaieb@monash.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

various levels of aggregation in order to operate the power
grid efﬁciently and securely (van Erven & Cugliari, 2015).

Producing accurate forecasts for these hierarchical struc-
tures is particularly challenging. First, the many time series
involved can interact in varying and complex ways. In par-
ticular, time series at different levels of the hierarchy can
contain very different patterns (see, for example, Figure
3); time series at the bottom level are typically very noisy
sometimes exhibiting intermittency, while aggregated se-
ries at higher levels are much smoother. As a result, a naive
bottom-up approach whereby forecasts of aggregates are
generated by summing the forecasts of the corresponding
series in the lower levels is unlikely to deliver accurate re-
sults when the aggregation involves a large number of se-
ries (Hyndman et al., 2011). Second, in order to ensure
coherent decision-making at the different levels of a hierar-
chy, it is essential that the forecast of each aggregated series
should equal the sum of the forecasts of the corresponding
disaggregated series. Unfortunately, independently fore-
casting each time series within each level is very unlikely
to deliver coherent forecasts. Finally, the bottom level can
consist of several thousand or even millions of time series,
which can induce a massive computational load.

Recent work in this area (Wickramasuriya et al., 2015; van
Erven & Cugliari, 2015) has focused on a two-stage ap-
proach in which base forecasts are ﬁrst produced indepen-
dently for each series in the hierarchy; these are then com-
bined to generate coherent revised forecasts (see Section 2).
The rationale behind this approach is both to improve fore-
cast accuracy due to the synthesis of information from dif-
ferent forecasts, as well as to produce coherent forecasts.
A fundamental limitation of actual research is that it has
looked only at the problem of forecasting the mean of each
time series. This contrasts with the shift in the forecasting
literature over the past two decades towards probabilistic
forecasting (Gneiting & Katzfuss, 2014). This form of pre-
diction quantiﬁes the uncertainty, which enables improved
decision making and risk management (see, for example,
Berrocal et al. (2010)).

We address the key problem of generating probabilistic
forecasts for large-scale hierarchical time series. This is
particularly challenging since it is requires the estimation
of the entire distribution of future observations, not only
the mean (Kneib, 2013; Hothorn et al., 2014). Furthermore,

Coherent Probabilistic Forecasts for Hierarchical Time Series

because of the hierarchical structure, this problem also in-
volves computing the distribution of hierarchical sums of
random variables in high dimensions. Finally, another chal-
lenge is the possible variety of distributions in the hierar-
chy. In fact, although the distributions become more nor-
mally distributed with the aggregation level as a conse-
quence of the central limit theorem, the series at lower lev-
els often exhibit non-normality including multi-modality
and high levels of skewness.

We propose an algorithm that computes predictive distri-
butions under the form of random samples for each series
in the hierarchy. First, probabilistic forecasts are indepen-
dently computed for all series in the hierarchy, and sam-
ples are computed from the associated predictive distribu-
tions. Then, a sequence of permutations extracted from
estimated copulas are applied to the multivariate samples
in a hierarchical manner to restore the dependencies be-
tween the variables before computing the sums (see Sec-
tion 3). Finally, the algorithm computes sparse forecast
combinations for all series in the hierarchy, where the com-
bination weights are estimated by solving a possibly high-
dimensional LASSO problem (see Section 3.2). The result
is a set of coherent probabilistic forecasts for each series in
the hierarchy.

Our algorithm has multiple advantages compared to the
(1) it
state-of-the art hierarchical forecasting methods:
quantiﬁes the uncertainty in the predictions for the entire
hierarchy while satisfying the aggregation constraints; (2) it
is scalable to high-dimensional hierarchies since the prob-
lem is decomposed into multiple lower-dimensional sub-
problems; and (3) it synthesizes information from different
levels in the hierarchy to estimate the marginal distributions
and the dependence structures through the mean forecast
combination and the hierarchical aggregation, respectively.

We evaluate our algorithm using both simulated data sets
(see Section 4.2) and a large scale electricity smart meter
data set (see Section 4.3).

2. Mean Hierarchical Forecasting

A hierarchical time series is a multivariate time series with
a hierarchical structure. Figure 1 gives an example with
ﬁve bottom series and three aggregate series. The differ-
ent observations in the hierarchy satisfy the following ag-
gregation constraints: yt = yA,t + yB,t, yA,t = yAA,t +
yAB,t+yAC,t and yB,t = yBA,t+yBB,t for all time periods
t = 1, . . . , T .

Let at be an r-vector containing the observations at the
different levels of aggregation at time t, bt be an m-vector
with the observations at the bottom level only, and yt =
(at bt)(cid:48) be an n-vector that contains the observations of
all series in the hierarchy with n = r + m. For the ex-

yt

yA,t

yB,t

yAA,t

yAB,t

yAC,t

yBA,t

yBB,t

Figure 1. Example of a hierarchical time series .

ample in Figure 1, we have at = (yt, yA,t, yB,t)(cid:48), bt =
(yAA,t, yAB,t, . . . , yBB,t)(cid:48), r = 3, and m = 5. We can
then write yt = Sbt, where S = (cid:2)S(cid:48)
∈ {0, 1}n×m
is the summing matrix, Sa ∈ {0, 1}r×m and Im is an iden-
tity matrix of order m.

a Im

(cid:3)(cid:48)

Suppose we have access to T historical observations,
y1, . . . , yT , of a hierarchical time series. Under mean
squared error (MSE) loss, the optimal h-period-ahead fore-
casts are given by the conditional mean (Gneiting, 2011),
i.e.

E[yT +h|y1, . . . , yT ] = S E[bT +h|y1, . . . , yT ],

(1)

where h = 1, 2, . . . , H.

It is possible to compute forecasts for all series at all levels
independently, which we call base forecasts. For example,
we can estimate E[yi,T +h|yi,1, . . . , yi,T ] for i = 1, . . . , n,
i.e. for all series in the hierarchy. This approach is very
ﬂexible since we can use different forecasting methods for
each series and aggregation level. However, the aggrega-
tion constraints will not necessarily be satisﬁed.

Deﬁnition 1. The coherency errors of the h-period-ahead
ˆbT +h)(cid:48) are given by
base forecasts ˆyT +h = (ˆaT +h
ˆrT +h = ˆaT +h − Sa

ˆbT +h.

In other words, ˆrT +h is a vector containing the magnitude
of constraint violations for each aggregate series.
Deﬁnition 2. The h-period-ahead base forecasts ˆyT +h =
ˆbT +h)(cid:48) are (mean) coherent if ˆrT +h = 0, i.e. if
(ˆaT +h
there are no coherency errors.

Since the optimal mean forecasts in (1) are coherent by
deﬁnition,
it seems sensible to impose the aggregation
constraints when generating hierarchical mean forecasts.
Also, from a decision-making perspective, coherent fore-
casts will guarantee coherent decisions over the entire hier-
archy.

2.1. Best Linear Unbiased Mean Revised Forecasts

Hyndman et al. (2011) proposed coherent hierarchical
mean forecasts of the following form:

˜yT +h = SP ˆyT +h,

(2)

Coherent Probabilistic Forecasts for Hierarchical Time Series

for some appropriately chosen matrix P ∈ Rm×n, and
where ˆyT +h are some base forecasts.

This approach has multiple advantages: (1) the forecasts
are coherent by construction; (2) the forecasts are gener-
ated by combining forecasts from all levels; and (3) mul-
tiple hierarchical forecasting methods can be represented
including bottom-up forecasts with
as particular cases,
(cid:3), and top-down forecasts with P =
P = (cid:2)0m×r|1m×m
(cid:3) where p is a vector of proportions that
(cid:2)pm×1|0m×(n−1)
sum to one.
Theorem 1. (Adapted from Wickramasuriya et al., 2015)
Let Wh be the positive deﬁnite covariance matrix of the h-
period-ahead base forecast errors, ˆeT +h = yT +h − ˆyT +h,
i.e. Wh = E[ˆeT +h ˆe(cid:48)

T +h].
Then, assuming unbiased base forecasts,
the best
(i.e. having minimum sum of variances) linear unbi-
ased revised forecasts are given by (2) with P =
(S(cid:48)W −1
h . We will denote this method MinT.

h S)−1S(cid:48)W −1

In practice, the error covariance matrix Wh needs to be es-
timated using historical observations of the base forecast
errors. Wickramasuriya et al. (2015) estimated W1, and
assumed that Wh ∝ W1, since the estimation of Wh is
challenging for h > 1. To trade off bias and estimation
variance, structural assumptions on the entries of the sam-
ple covariance matrix have also been considered in Hynd-
man et al. (2016).

2.2. Optimal Mean Combination and Reconciliation

The approach presented in the previous section applies both
combination and reconciliation of the forecasts at the same
time. van Erven & Cugliari (2015) proposed splitting the
problem into two independent steps: “ﬁrst one comes up
with the best possible forecasts for the time series without
worrying about aggregate consistency; and then a recon-
ciliation procedure is used to make the forecasts aggregate
consistent”.

Given some possibly incoherent base forecasts ˆyT +h, and
a weight matrix A ∈ Rn×n, they proposed a method called
GTOP, which solves the following quadratic optimization
problem:

minimize
xa∈Rr,xb∈Rm

(cid:18)xa
xb
subject to (xa xb)(cid:48) ∈ A ∩ B,

A ˆyT +h − A

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(3)

reconciled and the base forecasts. When A = I and B = ∅,
the problem reduces to ﬁnding the closest reconciled fore-
casts to the base forecasts in terms of sum of squared errors
(SSE).

a x∗

A distinctive advantage of the GTOP approach compared
to MinT is the guarantee of producing revised forecasts
˜yT +h = (x∗
b )(cid:48) with the same or smaller SSE than
the base forecasts ˆyT +h. Furthermore, compared to MinT,
the base forecasts are not required to be unbiased. Also,
by separating forecast combination and reconciliation, the
GTOP approach allows the inclusion of regularization in
the forecast combination step. One comparative weakness
of GTOP is that it does not have a closed-form solution in
the general case.

3. Probabilistic Hierarchical Forecasting

There has been a shift in the forecasting literature, over the
past two decades, towards probabilistic forecasting (Gneit-
ing & Katzfuss, 2014). This form of prediction quantiﬁes
the uncertainty, which enables improved decision making
and risk management. GTOP does not provide any quantiﬁ-
cation of the uncertainty in the predictions, and, although
MinT allows the calculation of the forecast variances, this
might not be enough to fully describe the uncertainty in the
predictions.

We propose an algorithm to compute, for all series in the hi-
erarchy, the conditional predictive cumulative distribution
function:

Fi,T +h(y|y1, . . . , yT ) = P(yi,T +h ≤ y|y1, . . . , yT ),

rather than just the conditional mean E[yi,T +h|y1, . . . , yT ]
and conditional variance V[yi,T +h|y1, . . . , yT ], with i =
1, . . . , n.

As with mean forecasts, it is possible to independently
compute probabilistic forecasts for each series in the hi-
erarchy, but, again, these forecasts will not necessarily be
coherent. In fact, hierarchical probabilistic forecasts are co-
herent if the predictive distribution of each aggregate series
is equal to the distribution of the sum of the children series.
Naturally, probabilistic coherency implies mean coherency
as given in Deﬁnition 2.

3.1. Bottom-Up Probabilistic Forecasting

where A = {(xa xb)(cid:48) : xa = Saxb} is the set of coherent
vectors, and B is an additional set that allows the speciﬁca-
tion of additional constraints.

The solution of the previous problem is also equivalent to
an optimal strategy in a minimax problem where the goal
is to minimize the maximum error between the loss of the

With mean forecasts, it was possible to compute coherent
bottom-up forecasts for the ith aggregated series by simply
summing the associated lowest level mean forecasts, i.e.
ˆbt where si is the ith row of the S matrix, and
˜yit = si
i = 1, . . . , r. Now, given some base probabilistic forecasts
for all the bottom series, how do we compute the bottom-up
coherent probabilistic forecasts for all aggregated series?

Coherent Probabilistic Forecasts for Hierarchical Time Series

Since each aggregate series is the sum of a subset of bot-
tom series, bottom-up probabilistic forecasting is harder to
compute than mean forecasting because we need to com-
pute the joint distribution of the component random vari-
ables. The marginal predictive distributions are not enough.

Deﬁnition 3. Let X1, . . . , Xd be a set of continuous ran-
dom variables with joint distribution function F . Then, the
distribution of Z = (cid:80)d

i=1 Xi is given by

FX1+···+Xd (z) =

1{x1+· · ·+xd ≤ z} dF (x1, . . . , xd).

(cid:90)

Rd

(4)

the joint distribution, we can use the cop-
To model
ula framework (Nelsen, 2007). Copulas originate from
Sklar’s theorem (Sklar, 1959), which states that
for
any continuous distribution function F with marginals
F1, . . . , Fd, there exists a unique function C : [0, 1]d →
[0, 1] such that F can be written as F (x1, . . . , xn) =
C(F1(x1), . . . , Fd(xd)).
In other words, starting from
marginal predictive distributions for each series, and using
a copula for the dependence structure, we can ﬁrst compute
the joint distribution, and then compute the distribution of
the sum using (4).

Although it is convenient to decompose the estimation
of the joint distribution into the estimation of multiple
marginal predictive distributions and one copula, the num-
ber of bottom series can be large in practice, which im-
plies a high-dimensional copula. Furthermore, in highly
disaggregated time series data, the bottom series are often
very noisy, and as a result, the estimation of the dependence
structure between all bottom series will be very challeng-
ing.

Since we are only interested in speciﬁc aggregations, we
can avoid explicitly modelling the (often) high-dimensional
copula that describes the dependence between all bottom
series. Building on the approach proposed by Arbenz
et al. (2012), we propose to decompose the possibly high-
dimensional copula into multiple lower-dimensional copu-
las for all child series of each aggregate series.

Example 3.1. Let us consider the hierarchy given
A classical bottom-up approach
in Figure 1.
joint distribution of
would require modelling the
(yAA,t, yAB,t, yAC,t, yBA,t, yBB,t).
the distri-
bution of all aggregate series yA,t, yB,t and yt can be
computed using (4).

Then,

However, since the marginals and the copula completely
specify the joint distribution, the following procedure al-
lows us to compute the marginal predictive distributions of
all aggregates using three lower-dimensional copulas in a
hierarchal manner:

1. Compute FAA,t, FAB,t, FAC,t, FBA,t, and FBB,t.

2. Compute FA,t using C1(FAA,t, FAB,t, FAC,t).
3. Compute FB,t using C2(FBA,t, FBB,t).
4. Compute Ft using C3(FA,t, FB,t).

Except in some special cases where the distribution of the
sum can be computed analytically, we would typically re-
sort to Monte Carlo simulations.

By Sklar’s theorem, we can write F (x1, . . . , xd) =
P(X1 ≤ x1, . . . , Xd ≤ xd) = C(F1(x1), . . . , Fd(xd)).
Suppose we have samples xi
k ∼ Fi, and uk =
(u1

k) ∼ C, k = 1, . . . , K, then we can compute

k, . . . , ud

ˆF (x1, . . . , xd) = ˆC( ˆF1(x1), . . . , ˆFd(xd)),
where ˆFi are the empirical margins and ˆC is the empirical
copula (see R¨uschendorf, 2009, and the references therein),
given respectively by

ˆFi(x) =

1{xi

k ≤ x}, x ∈ R,

1
K

K
(cid:88)

k=1

and

ˆC(u) =

1
K

K
(cid:88)

k=1

(cid:26) rk(u1
k)
1
K

≤ u1, . . . ,

rk(ud
k)
K

(cid:27)

≤ ud

,

1, . . . , ui

k) is the rank of

for u = (u1, . . . , ud) ∈ [0, 1]d, where rk(ui
k within the set {ui
ui
K}.
The procedure of applying empirical copulas to empirical
margins can be efﬁciently represented in terms of sample
reordering. In fact, the order statistics ui
(K) of the
samples ui
K induce a permutation pi of the integers
{1, . . . , K}, deﬁned by pi(k) = rk(ui
k) for k = 1, . . . , K.
If we then apply the permutations to each independent
marginal sample {xi
K}, the reordered samples in-
herit the multivariate rank dependence structure from the
copula ˆC. We can then compute the samples for the sum
{x1, . . . , xK} where xk = (cid:80)d

(1), . . . , ui

1, . . . , ui

1, . . . , xi

i=1 xi
k.

Introducing a dependence structure into originally inde-
pendent marginal samples goes back to Iman & Conover
(1982) who considered the special case of normal copu-
las. A similar idea has been considered more recently in
Schefzik et al. (2013) to specify multivariate dependence
structure with applications to weather forecasting.

Since we are interested in multivariate forecasting, we will
need another version of Sklar’s theorem for conditional
joint distributions proposed by Patton (2006):

If yt|Ft−1 ∼ F (·|Ft−1),
with yit|Ft−1 ∼ Fi(·|Ft−1),
then

i = 1, . . . , n,

F (y|Ft−1) = C(F1(y1|Ft−1), . . . , Fn(yn|Ft−1)|Ft−1).

Coherent Probabilistic Forecasts for Hierarchical Time Series

As in Patton (2012), we will assume the following structure
for our series:

yit = µi(yt−1, yt−2, . . . ) + σi(yt−1, yt−2, . . . )εit,

(5)

where εit|yt−1, yt−2, · · · ∼ Fi(0, 1). In other words, each
series can have a potentially time-varying conditional mean
and variance, but the standardized residual, εit, has a con-
stant conditional distribution for simplicity. See Fan & Pat-
ton (2014) for a review on copulas in econometrics.

The following algorithm describes how to compute the
bottom-up samples using the reordering procedure for a
complete hierarchy:
Algorithm 1. (Bottom-up Probabilistic Forecasting)

1. For all series in the hierarchy, as deﬁned in (5), model
the conditional marginal distributions; i.e. compute ˆµi
and ˆσi for i = 1, . . . , n.

2. Then, compute the standardized residuals ˆεit =
(yi,t − ˆµi,t)/ˆσi,t, and deﬁne the permutations pi(t) =
rk(ˆεit), where i = 1, . . . , n and t = 1, . . . , T .

3. For all bottom series i = r + 1, . . . , n:

(a) Compute h-period ahead conditional marginal

predictive distributions ˆFi,T +h.

(b) Extract a discrete sample of size K = T , say
i,T +h(k/K + 1), and

K, where xi

k = ˆF −1

xi
1, . . . , xi
k = 1, . . . , K.

4. For all aggregate series i = 1, . . . , r:

(a) Let i(1), . . . , i(nc) be the nc children series of

the aggregate series i.

(b) Recursively compute

k = xi(1)
xi

(pi(1)(k)) + · · · + xi(nc)

(pi(nc )(k)),

where xi
{xi

1, . . . , xi

(k) denotes the kth order statistics of

K}, i.e. xi

(1) ≤ xi

(2) ≤ · · · ≤ xi

(K).

Similarly to the classical bottom-up algorithm, Algorithm 1
produces coherent samples by construction. Furthermore,
the samples of each aggregate are computed using only the
predictive distributions of the bottom series. However, Al-
gorithm 1 has two main advantages compared to a classi-
cal bottom-up algorithm: (1) instead of estimating a high-
dimensional copula for the dependence between all the bot-
tom series, we only need to specify the joint dependence
between the child series of each aggregate series, and (2)
since each copula is estimated at different aggregate levels,
we can beneﬁt from better estimation since the series are
smoother, and easier to model and forecast.

3.2. Mean Forecast Combination and Reconciliation

Algorithm 1 computes bottom-up probabilistic forecasts
by estimating the copula dependence functions using data
from different levels of the hierarchy. However, the result-
ing mean forecasts are equal to classical bottom-up fore-
casts, i.e. no data from other levels is used. In order to

further improve the accuracy of our probabilistic forecasts,
we add a mean forecast combination step, which allows
to exploit possibly better mean forecasts from higher lev-
els. Forecast combination is known to improve forecasts
in many cases (Timmermann, 2006; Genre et al., 2013).
We could adjust the means of our predictive distributions
using the MinT revised forecasts. However, as van Erven
& Cugliari (2015), we propose to ﬁrst combine the mean
forecasts, and then apply a reconciliation step.

Let ˆyT +h be the means of our predictive distributions. We
compute the following forecast combination:

˘yt = Q ˆyt,

(6)

(cid:3)(cid:48)

∈ Rn×n is a weight matrix.

where Q = (cid:2)q1, . . . , qn
Since the combined mean forecasts ˘yt are not necessar-
ily coherent, we also apply a reconciliation step using the
GTOP approach described in Section 2.2. More precisely,
we solve the quadratic optimization problem in (3), and ob-
tain reconciled forecasts ˜yt.

Since the total number of series in the hierarchy, n, can
be very large compared to the number of observations T ,
it is necessary to use some regularization for the weights.
Therefore, we will estimate the weights by solving the fol-
lowing L1 optimization problem:

minimize
Q

1
T

T
(cid:88)

t=1

(cid:107)yt − Q ˆyt(cid:107)2 +

λi (cid:107)qi(cid:107)1 ,

n
(cid:88)

i=1

where λi ≥ 0 is a regularization parameter for the ith
weight vector qi. The previous problem can be rewritten
as

minimize
q1,...,qn

n
(cid:88)

T
(cid:88)

1
T

i=1

t=1

(yit − ˆy(cid:48)

tqi)2 +

λi (cid:107)qi(cid:107)1 ,

n
(cid:88)

i=1

which is decomposable in the vectors qi. As a result, we
can solve the n problems independently. Our implemen-
tation of the LASSO is based on a cyclical coordinate de-
scent algorithm (Friedman et al., 2007), and the regular-
ization parameters are selected by minimizing time series
cross-validated errors (Hyndman & Athanasopoulos, 2014,
Section 2.5).

The forecast combination that we are considering in (6) has
multiple advantages compared to the MinT forecast combi-
nation in (2). First, since Q ∈ Rn×n, all series in the hi-
erarchy can beneﬁt directly from the forecast combination,
not only the bottom series as in MinT with P ∈ Rm×n.
Second, we do not assume the base forecast are unbiased,
and we do not seek to compute unbiased revised forecasts
as in MinT. We rather seek to optimize the weights in order
to obtain combined forecasts with low forecast errors; i.e.

Coherent Probabilistic Forecasts for Hierarchical Time Series

with the right trade-off between bias and estimation vari-
ance. Finally, even if we start with coherent base fore-
casts, we can still apply a forecast combination, and even-
tually reconcile them later. In contrast with MinT, no fore-
cast combination will be applied in that case. Of course,
MinT has the advantage of having a closed-form solution,
which does not require the solution of n possibly high-
dimensional regression problems. Finally, our reconciled
forecasts are guaranteed to have smaller or equal SSE than
the combined forecasts, which is guaranteed by the GTOP
method as discussed in Section 2.2. Our ﬁnal algorithm can
be summarized as follows:

Algorithm 2. (Mean Combined and Reconciled Proba-
bilistic Forecasting)

1. Run Algorithm 1 to obtain bottom-up samples for
K with i =

all series in the hierarchy, say xi
1, . . . , n.

1, . . . , xi

2. Extract mean forecasts ˆyT +h from all base predictive
distributions ˆFi,T +h, and compute combined forecasts
˘yT +h given in (6).

3. Given a weight matrix A, and using the combined
forecasts ˘yT +h as base forecasts, solve the optimiza-
tion problem in (3) to obtain reconciled forecasts
˜yT +h.

4. Compute revised samples ˜xi

k =
xi
k +θi and θi = (ˇyi,t− ˆyi,t)+(˜yi,t− ˘yi,t) = ˘yi,t− ˆyi,t
is an adjustment term, with i = 1, . . . , n.

K where ˜xi

1, . . . , ˜xi

tribution is reported (Gneiting & Raftery, 2007). Given an
h-period-ahead cumulative predictive distribution function
ˆFt+h and an observation yt+h, the CRPS can be deﬁned as
(Gneiting & Ranjan, 2011):

CRPS( ˆFt+h, yt+h) =

(cid:16) ˆF −1

QSτ

t+h(τ ), yt+h

dτ,

(cid:17)

(cid:90) 1

0

where QSτ is the quantile score, deﬁned as

QSτ

t+h(τ ), yt+h

(cid:17)

(cid:16) ˆF −1
(cid:16)

= 2

1{yt+h ≤ ˆF −1

t+h(τ )} − τ

(cid:17) (cid:16) ˆF −1

t+h(τ ) − yt+h

(cid:17)

,

which is also known as the pinball or check loss (Koenker
& Bassett, 1978).

In order to quantify the gain/loss of the different methods
with respect to the base forecasts, we compute the Skill
Score deﬁned as (SCOREBASE − SCORE)/SCOREBASE
where SCORE is the considered evaluation score. Low val-
ues of the score are desirable, and so high positive values
are preferable for the skill score. In the following experi-
ments, SCORE will be computed by averaging the CRPS
or QS over all observations in the test set. Finally, as pro-
posed by Laio & Tamea (2007), we will plot the QSτ (skill
score) versus τ as a diagnostic tool in the comparison of
the different methods.

Algorithm 2 computes coherent forecasts since both the
bottom-up samples (computed using Algorithm 1) and the
reconciled means are coherent.

4.2. Simulated Data

4. Experiments

(2) NAIVEBU:

We compare the following forecasting methods: (1) BASE:
the base predictive distributions;
the
naive bottom-up forecasts computed by summing inde-
pendent samples from the bottom predictive distribu-
tions (without forecast combination); (3) PERMBU: the
bottom-up forecasts computed using Algorithm 1 (with-
(4) PERMBU-MINT: sim-
forecast combination);
out
to PERMBU with mean forecasts computed us-
ilar
the forecasts are
ing MinT;
computed using Algorithm 2 with A = I;
and
similar to PERMBU-GTOP1 but
(6) PERMBU-GTOP2:
); i.e. bottom-up instead
, 1, . . . , 1
with A = diag(0, . . . , 0
(cid:124) (cid:123)(cid:122) (cid:125)
(cid:124) (cid:123)(cid:122) (cid:125)
m
r
of reconciled combined mean forecasts.

(5) PERMBU-GTOP1:

4.1. Probabilistic Forecast Evaluation

We evaluate our predictive distributions using the contin-
uous ranked probability score (CRPS), which is a proper
scoring rule, i.e. the score is maximized when the true dis-

We begin with simulated time series, implemented using
the same processes as Wickramasuriya et al. (2015) to eval-
uate different hierarchical forecasting methods. However,
we focus on distributional forecasts rather than mean fore-
casts. We used a hierarchy with four bottom series, where
the two pairs of bottom series are aggregated in two ag-
gregate series, which are then aggregated in a top series.
Hence, the hierarchy is composed of n = 7 series, m = 4
bottom series and r = 3 aggregate series.

Each series in the bottom level
is generated from an
ARIMA(p, d, q) process, with p and q taking values of 0,
1 and 2 with equal probability and d taking values of 0 and
1 with equal probability. The parameters are chosen ran-
domly from a uniform distribution from a speciﬁc param-
eter space for each each component of the ARIMA pro-
cess (see Table 3.2 in Wickramasuriya et al. (2015)). The
error terms of the bottom-level ARIMA processes have a
multivariate Gaussian distribution with a covariance struc-
ture that allows a strongly positive correlation among series
with the same parents, but a moderately positive correlation
among series with different parents.

For each series, we generate T = 100, 300 or 500 observa-
tions, with an additional H = 10 observations as a test set.

Coherent Probabilistic Forecasts for Hierarchical Time Series

We ﬁt an ARIMA model by minimizing the AIC, and com-
pute 10-period ahead Gaussian predictive distributions as
base forecasts. The whole process is repeated 2, 000 times.

Figure 2 shows the results for T = 100. The ﬁrst panel
gives the CRPS skill score for each horizon; the second and
third panels show the QS skill score averaged over horizons
h = 1–6 and h = 7–10, respectively; the last panel gives
the CRPS skill score for the bottom level.

In the ﬁrst panel, we can see that PERMBU has a better
skill score than NAIVEBU until horizon 6, and vice versa
for the subsequent horizons. The second panel shows that
PERMBU outperforms NAIVEBU especially in the lower
and upper tails. In other word, the independence assump-
tion of NAIVEBU is not valid, and modelling the depen-
dence structure between the children series of each aggre-
gated series provides better tail forecasts for the aggregate
series. The third panel shows that NAIVEBU has consis-
tently better QS skill score compared to PERMBU for hori-
zons 7–10. This suggests that using one-period ahead de-
pendence structure for 7 to 10-period ahead forecasts (i.e.
using a misspeciﬁed dependence structure) is worse than
assuming independence.

The ﬁrst panel also shows that the methods using forecast
combinations have signiﬁcantly increased the CRPS skill
score compared to PERMBU. This suggests that the mean
forecast combination step is particularly useful in further
improving the distributional forecasts. Furthermore, we
can see that PERMBU-GTOP2 has better skill score than
PERMBU-MINT until horizon 6. This shows the beneﬁt
of our forecast combination, which learns the best combi-
nation weights, without making an unbiasedness assump-
tion. The better skill score of PERMBU-GTOP2 compared
to PERMBU-GTOP1 suggests an advantage in splitting the
forecast combination and reconciliation steps. The same
observations can be made in the last panel for the bottom
level.

Finally, with a larger training set size (T = 300 and
T = 500), the forecast combination methods have similar
skill scores, as can be seen in Figures A1 and A2 in the ap-
pendix. With more observations, the ﬁtted ARIMA model
becomes more accurate, and therefore, forecast combina-
tion is less likely to improve the base forecasts. However,
even with a large training set, modeling the dependence
structure is still important, as shown by the better skill score
of PERMBU compared to NAIVEBU.

4.3. Electricity Smart Meter Data

We used smart meter electricity consumption data collected
by four energy supply companies in Great Britain (AE-
COM, 2011). Consumption was recorded at half-hourly
intervals for more than 14,000 households, along with ge-

Figure 2. Skill CRPS and skill QS for aggregate and bottom lev-
els for T = 100. A positive/negative skill gives the percentage
of increase/decrease in forecast accuracy with respect to the base
forecasts.

ographic and demographic information. In our study, we
were interested only in relatively long time series without
missing values, and this led us to use data recorded at 1,578
meters for the period 20 April 2009 to 31 July 2010, inclu-
sive. Each series, therefore, consisted of T = 22, 464 half-
hourly observations. We constructed a hierarchy based on
geographical information comprising four levels of aggre-
gation with m = 1, 578 series in the bottom level of the
hierarchy, and r = 55 aggregated series in the other three
levels of the hierarchy . Figure 3 presents observations for
a one-week period for just one series taken from each of
the four levels of the hierarchy. The values shown on the
right hand side of the ﬁgure correspond to the number of
bottom level series that have been summed to give each of
the aggregated series in the ﬁgure.

We considered the problem of one-day-ahead (i.e. the next
H = 48 half-hours) probabilistic demand forecasting, with
a forecast origin at 23:30 for each day. We split each
time series into training, validation and test sets; the ﬁrst 12
months for training, the next month for validation and the
remaining, approximately, three months for testing. Each
model is re-estimated before forecasting each day in the test
set using a rolling window of the historical observations.

We used different forecasting methods for the aggregate
and bottom series. For the aggregate series, we capture the
yearly cycle, the within-day and within-week seasonalities
using seasonal Fourier terms with coefﬁcients estimated by

246810−0.040.00Aggregate levelsHorizonSkill CRPS0.00.20.40.60.81.0−0.3−0.10.0Aggregate levels − h = 1−6Probability levelSkill Quantile ScoreBASEPERMBU−GTOP2NAIVEBUPERMBUPERMBU−MINTPERMBU−GTOP10.00.20.40.60.81.0−0.06−0.020.02Aggregate levels − h = 7−10Probability levelSkill Quantile Score2468100.000.020.04Bottom levelHorizonSkill CRPSCoherent Probabilistic Forecasts for Hierarchical Time Series

the other methods, which are penalized by the QS.

Overall, the ﬁrst panel shows that the mean forecast com-
bination methods have better skill score than the base fore-
casts. We found that 75% of the series have less than 100
non-zero weights (see appendix); i.e. many forecast combi-
nations were very sparse — an advantage of our approach
compared to MinT, which produces dense combination
weights. Furthermore, we can see that PERMBU-GTOP1 is
dominating the other methods for almost all aggregations.
This suggests that computing bottom-up mean combined
forecasts is better than reconciling the aggregate and bot-
tom combined mean forecasts. This can be explained by
the fact that PERMBU already produces competitive fore-
casts with the base forecasts, and so reconciling the bottom
combined forecasts with the aggregate combined forecasts
is unlikely to improve the ﬁnal forecasts.

Finally, the ﬁrst panel shows that all the mean forecast
combination methods have lower skill score than the base
forecasts for the bottom series (i.e. for the ﬁrst aggrega-
tion). This suggests that improving the forecast accuracy at
the bottom level using forecast combination is particularly
challenging especially with very noisy time series. How-
ever, the forecast improvement at the aggregate levels are
magnitudes larger than the decrease in accuracy at the bot-
tom level.

We have proposed an algorithm to compute coherent proba-
bilistic forecasts for hierarchical time series. The algorithm
provides samples from coherent predictive distributions for
each series in the hierarchy. To do so, we ﬁrst generate in-
dependent samples from all series in the hierarchy. Then a
sequence of permutations are applied to the samples in or-
der to restore the dependencies between the children series
of all aggregate series. Finally, a sparse forecast combina-
tion is applied using the base mean forecasts of all series
in the hierarchy. Our algorithm has the advantage of syn-
thesizing information from multiple levels in the hierarchy.
Using simulated data, and a large scale electricity demand
data set, we showed that restoring the dependencies of the
children series consistently improves the forecast accuracy,
especially in the tails, while the mean forecast combining
weights provide an additional improvement by enabling a
synthesis of information from the different forecasts. Our
algorithm can be used to produce coherent probabilistic
forecasts for hierarchical time series in many applications.

Figure 3. One week of electricity demand with different number
of aggregated series.

Figure 4. CRPS skill for different aggregations and average QS
of all aggregate series. A positive/negative CRPS skill gives the
percentage of decrease/increase in CRPS with respect to the base
forecasts. Higher skill score and lower QS are better.

5. Conclusion

LASSO. After extracting the trend and seasonalities, we
ﬁtted an ARIMA model and computed Gaussian predic-
tive distributions. This is justiﬁed by the fact that aggre-
gate series are often smoother and easier to forecast, and
by the central limit theorem. For the base forecasts, we
implemented the kernel density estimation approach that
performed the best in the work of Arora & Taylor (2016).

In Figure 4, the ﬁrst panel gives the skill score for differ-
ent aggregations computed using the average half-hourly
CRPS over the test set, while the second panel shows the
average QS of all aggregated series. In the ﬁrst panel, we
can see that PERMBU has better skill score than NAIVEBU
especially for large aggregations. The second panel shows
that PERMBU, by modelling the dependence structure, has
contributed to signiﬁcantly decrease the QS in the lower
tail. By analyzing the forecasts (not shown here), we no-
ticed that NAIVEBU is penalized both for not being able to
capture the trend at the top (i.e. a bad mean forecasts), and
for having too sharp predictive distributions (i.e. computed
using a bad dependence structure). The fact that NAIVEBU
seems competitive at moderately large quantiles can be ex-
plained by the unnecessarily wide prediction intervals for

Time1578450179681010.00.51.01.52.02.53.0−100510152025Log10(number of aggregated meters)CRPS skill (%)lllllllllllllllNAIVEBUPERMBUPERMBU−MINTPERMBU−GTOP1PERMBU−GTOP20.00.20.40.60.81.00.00.51.01.52.0Aggregate levelsProbability levelQSCoherent Probabilistic Forecasts for Hierarchical Time Series

References

AECOM. Energy demand research project: Final anal-
ysis. Technical report, AECOM House, Hertfordshire,
UK, 2011.

Arbenz, Philipp, Hummel, Christoph, and Mainik, Georg.
Copula based hierarchical risk aggregation through sam-
ple reordering. Insurance, Mathematics & Economics,
51(1):122–133, 2012.

Arora, Siddharth and Taylor, James W. Forecasting elec-
tricity smart meter data using conditional kernel density
estimation. Omega, 59, Part A:47–59, 2016.

Berrocal, Veronica J, Raftery, Adrian E, Gneiting, Tilmann,
and Steed, Richard C. Probabilistic weather forecasting
for winter road maintenance. Journal of the American
Statistical Association, 105(490):522–537, 2010.

Fan, Yanqin and Patton, Andrew J. Copulas in economet-
rics. Annual Review of Economics, 6(1):179–200, 2014.

Friedman, Jerome, Hastie, Trevor, H¨oﬂing, Holger, and
Tibshirani, Robert. Pathwise coordinate optimization.
The Annals of Applied Statistics, 1(2):302–332, Decem-
ber 2007.

Genre, V´eronique, Kenny, Geoff, Meyler, Aidan, and Tim-
mermann, Allan. Combining expert forecasts: Can any-
thing beat the simple average? International Journal of
Forecasting, 29(1):108–121, 2013.

Gneiting, Tilmann. Making and evaluating point fore-
casts. Journal of the American Statistical Association,
106(494):746–762, June 2011.

Gneiting, Tilmann and Katzfuss, Matthias. Probabilistic
forecasting. Annual Review of Statistics and Its Applica-
tion, 1(1):125–151, January 2014.

Gneiting, Tilmann and Raftery, Adrian E. Strictly proper
Journal
scoring rules, prediction, and estimation.
of the American Statistical Association, 102(477):359–
378, 2007.

Gneiting, Tilmann and Ranjan, Roopesh. Comparing den-
sity forecasts using threshold- and Quantile-Weighted
scoring rules. Journal of Business & Economic Statis-
tics, 29(3):411–422, 2011.

Hothorn, Torsten, Kneib, Thomas, and B¨uhlmann, Peter.
Conditional transformation models. Journal of the Royal
Statistical Society. Series B, Statistical methodology, 76
(1):3–27, 2014.

Hyndman, Rob J, Ahmed, Roman A, Athanasopoulos,
George, and Shang, Han Lin. Optimal combination fore-
casts for hierarchical time series. Computational Statis-
tics & Data Analysis, 55(9):2579–2589, 1 September
2011.

Hyndman, Rob J, Lee, Alan J, and Wang, Earo. Fast
computation of reconciled forecasts for hierarchical and
grouped time series. Computational Statistics & Data
Analysis, 97:16–32, May 2016.

Iman, Ronald L and Conover, W J. A distribution-free ap-
proach to inducing rank correlation among input vari-
ables. Communications in Statistics - Simulation and
Computation, 11(3):311–334, 1982.

Kneib, Thomas. Beyond mean regression. Statistical Mod-

elling, 13(4):275–303, 1 August 2013.

Koenker, Roger and Bassett, Gilbert. Regression quantiles.
Econometrica: journal of the Econometric Society, 46
(1):33–50, 1978.

Kremer, Mirko, Siemsen, Enno, and Thomas, Douglas J.
The sum and its parts: Judgmental hierarchical forecast-
ing. Management Science, 62(9):2745–2764, 2016.

Laio, F and Tamea, S. Veriﬁcation tools for probabilistic
forecasts of continuous hydrological variables. Hydrol-
ogy and Earth System Sciences, 11(4):1267–1277, 2007.

Nelsen, Roger B. An introduction to copulas. Springer

Science & Business Media, 2007.

Patton, A J. Copula methods for forecasting multivariate
time series. Handbook of economic forecasting, (April):
1–76, 2012.

Patton, Andrew J. Modelling asymmetric exchange rate de-
pendence. International Economic Review, 47(2):527–
556, 1 May 2006.

R¨uschendorf, Ludger. On the distributional transform,
sklar’s theorem, and the empirical copula process. Jour-
nal of Statistical Planning and Inference, 139(11):3921–
3927, 1 November 2009.

Schefzik, Roman, Thorarinsdottir, Thordis L, and Gneit-
ing, Tilmann. Uncertainty quantiﬁcation in complex
simulation models using ensemble copula coupling. Sta-
tistical Science: a review journal of the Institute of Math-
ematical Statistics, 28(4):616–640, November 2013.

Sklar, M. Fonctions de r´epartition `a n dimensions et leurs

marges. Universit´e Paris 8, 1959.

Hyndman, Rob J and Athanasopoulos, George. Forecast-
ing: principles and practice. OTexts, 20 September
2014.

Timmermann, A. Forecast combinations. In Handbook of
Economic Forecasting, volume 1, pp. 135–196. Elsevier,
2006.

Coherent Probabilistic Forecasts for Hierarchical Time Series

van Erven, Tim and Cugliari, Jairo. Game-Theoretically
optimal reconciliation of contemporaneous hierarchical
time series forecasts. In Modeling and Stochastic Learn-
ing for Forecasting in High Dimensions, Lecture Notes
in Statistics, pp. 297–317. Springer International Pub-
lishing, 2015.

Wickramasuriya, Shanika L, Athanasopoulos, George, and
Hyndman, Rob J. Forecasting hierarchical and grouped
time series through trace minimization. Technical Report
15/15, Monash University, 2015.

