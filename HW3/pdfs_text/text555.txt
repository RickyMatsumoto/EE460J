Fractional Langevin Monte Carlo: Exploring L´evy Driven Stochastic
Differential Equations for Markov Chain Monte Carlo

Umut S¸ ims¸ekli 1

Abstract

Along with the recent advances in scalable
Markov Chain Monte Carlo methods, sampling
techniques that are based on Langevin diffu-
sions have started receiving increasing attention.
These so called Langevin Monte Carlo (LMC)
methods are based on diffusions driven by a
Brownian motion, which gives rise to Gaussian
proposal distributions in the resulting algorithms.
Even though these approaches have proven suc-
cessful in many applications, their performance
can be limited by the light-tailed nature of the
Gaussian proposals.
In this study, we extend
classical LMC and develop a novel Fractional
LMC (FLMC) framework that is based on a fam-
ily of heavy-tailed distributions, called α-stable
L´evy distributions. As opposed to classical ap-
proaches,
the proposed approach can possess
large jumps while targeting the correct distribu-
tion, which would be beneﬁcial for efﬁcient ex-
ploration of the state space. We develop novel
computational methods that can scale up to large-
scale problems and we provide formal conver-
gence analysis of the proposed scheme. Our ex-
periments support our theory: FLMC can pro-
vide superior performance in multi-modal set-
tings, improved convergence rates, and robust-
ness to algorithm parameters.

1. Introduction

Markov Chain Monte Carlo (MCMC) techniques that are
based on continuous diffusions have become increasingly
popular due to their success in large-scale Bayesian ma-
chine learning. In these techniques, the goal is to generate
samples from a target distribution π, by forming a contin-

1LTCI, T´el´ecom ParisTech, Universit´e Paris-Saclay,
75013, Paris, France. Correspondence to: Umut S¸ ims¸ekli
<umut.simsekli@telecom-paristech.fr>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

uous diffusion which has π as a stationary distribution. In
practice, π is usually known up to a normalization constant,
i.e. π(X) ∝ φ(X) = exp(−U (X)) for X ∈ RD, where
φ is called the unnormalized target density and U is called
the potential energy function.

Originated in statistical physics (Rossky et al., 1978),
Langevin Monte Carlo (LMC) is constructed upon the
Langevin diffusion that is deﬁned by the following stochas-
tic differential equation (SDE) (Roberts & Stramer, 2002):

dXt = −∇U (Xt)dt +

2dBt,

(1)

√

where Bt denotes the standard D-dimensional Brownian
motion. Under certain regularity conditions on U , the so-
lution process (Xt)t≥0 can be shown to be ergodic with
π (Roberts & Stramer, 2002), which allows us to gener-
ate samples from π by simulating the continuous-time pro-
cess (1) in discrete-time. This approach paves the way
for the celebrated Unadjusted Langevin Algorithm (ULA)
(Roberts & Stramer, 2002), that is given as follows:
¯Xn+1 = ¯Xn − ηn+1∇U ( ¯Xn) + (cid:112)2ηn+1∆Bn+1,

(2)

where n denotes the iterations, (ηn)n is a sequence of
step-sizes, and (∆Bn)n is a sequence of independent and
identically-distributed (i.i.d.)
standard Gaussian random
variables. Convergence properties of ULA have been stud-
ied in (Lamberton & Pages, 2003).

In a statistical physics context, Xt often represents the po-
sition of a particle (at time t) that is under the inﬂuence of a
random force. In this case, the Langevin equation (1) is mo-
tivated by the hypothesis that this random force is the sum
of many i.i.d. random ‘pulses’, whose variance is assumed
to be ﬁnite (Yanovsky et al., 2000). Then, by the central
limit theorem (CLT), the sum of these pulses converges to
a Gaussian random variable, which justify the choice of the
Brownian motion in the Langevin equation (1).

A natural question arises if we relax the ﬁnite variance as-
sumption and allow the random pulses to have inﬁnite vari-
ance. In such circumstances, the ‘usual’ CLT would not
hold; however, one can still show that the sum of these
pulses converges to a broader class of heavy-tailed distribu-
tions called α-stable (or L´evy-stable) distributions (L´evy,

Fractional Langevin Monte Carlo

Figure 1. Top: probability density functions of SαS . Bottom:
illustration of α-stable L´evy motions.

2. Technical Background

We support our theoretical results by several synthetic and
real experiments. Our experiments show that the proposed
approach forms a viable alternative to classical LMC with
additional beneﬁts, such as providing superior performance
in multi-modal settings, higher convergence rates, and ro-
bustness to algorithm parameters. The proposed approach
also opens up several interesting future directions, as we
will point out in Section 5.

Stable distributions: Stable distributions are heavy-tailed
distributions. They are the limiting distributions in the gen-
eralized central limit theorem: the properly scaled sum of
i.i.d. random variables, which do not necessarily have ﬁ-
nite variance, will converge to an α-stable random variable
(Samorodnitsky & Taqqu, 1994). In this study, we are in-
terested in the centered symmetric α-stable (SαS) distribu-
tion, which is a special case of α-stable distributions.

The SαS distribution can be seen as a heavy-tailed gener-
alization of the centered Gaussian distribution. The prob-
ability density function (pdf) of an SαS distribution can-
not be written in closed-form except for certain special
cases; however, the characteristic function of the distri-
bution can be written as follows: X ∼ SαS(σ) ⇐⇒
E[exp(iωX)] = exp(−|σω|α). Here, α ∈ (0, 2] is called
the characteristic exponent and determines the tail thick-
ness of the distribution: as α gets smaller, SαS becomes
heavier-tailed. The parameter σ ∈ R+ is called the scale
parameter and measures the spread of X around 0.

As an important special case of SαS, we obtain the Gaus-
sian distribution SαS(σ) = N (0, 2σ2) for α = 2. In Fig-
ure 1, we illustrate the (approximately computed) pdf of
the symmetric α-stable distribution for different values of
α. As can be clearly observed from the ﬁgure, the tails of
the distribution vanish quickly when α = 2 (i.e. Gaussian),
whereas the tails get thicker as we decrease α.

An important property of the α-stable distributions is that
their moments can only be deﬁned up to the order α, i.e.
E[|X|p] < ∞ if and only if p < α for α ∈ (0, 2); im-
plying that X has inﬁnite variance for α (cid:54)= 2. Moreover,
even though the pdf of SαS does not admit an analytical
form, it is straightforward to draw random samples from
stable distributions (Chambers et al., 1976), where efﬁcient
implementations are readily available in public software li-
braries such as the GNU Scientiﬁc Library (gnu.org/
software/gsl).

SDEs driven by symmetric stable L´evy processes : In
this study, we are interested in SDEs driven by symmetric
α-stable L´evy processes, which are deﬁned as follows:

dXt = b(Xt−, α)dt + dLα
t ,

(3)

1937). Since the law of the random force is non-Gaussian
in this case, the Brownian motion would not be appropriate
in (1) and it needs to be replaced with the α-stable L´evy
motion, which will be described in Section 2.

As opposed to the Brownian motion, which is almost surely
continuous, the L´evy motion can contain discontinuities
that are often referred to as ‘jumps’. Due to these jumps,
the SDEs that are driven by L´evy motions are also called
anomalous diffusions. It has been noticed that this heavy-
tailed nature of the L´evy processes can be more appro-
priate for modeling natural phenomena that might incur
large variations; a situation often encountered in statisti-
cal physics (Eliazar & Klafter, 2003), ﬁnance (Mandelbrot,
2013), and signal processing (Kuruoglu, 1999).

Despite the fact that L´evy-driven SDEs have been studied
in more general Monte Carlo contexts (e.g. for ﬁnancial
simulations) (Konakov & Menozzi, 2011; Mikuleviˇcius &
Zhang, 2011), surprisingly, their use in MCMC has been
left widely unexplored.
In the statistical physics litera-
ture, Ditlevsen (1999) considered a L´evy-driven SDE with
a double-well potential and investigated its waiting-times.
In a similar context, Eliazar & Klafter (2003) developed
an approximate technique based on Tauberian theorems for
targeting a L´evy-driven system to a pre-speciﬁed distribu-
tion, where they required the target distribution to be ex-
actly evaluated. Whilst being relevant, the applicability and
the impact of these approaches are rather limited in the do-
main of machine learning.

In this study, we explore the use of L´evy-driven SDEs
within MCMC. Encouraged by earlier studies that illustrate
the beneﬁts of using heavy-tailed distributions in MCMC
(e.g., improved convergence rates) (Stramer & Tweedie,
1999; Jarner & Roberts, 2007), we aim at investigating the
potential beneﬁts of the usage of the L´evy motions in LMC,
in lieu of the classical Brownian motion. We extend classi-
cal LMC and develop a novel Fractional LMC framework,
which targets the correct distribution even in the presence
of the jumps induced by the L´evy motion. We then de-
velop novel computational methods that can scale up to
large-scale problems and provide formal theoretical anal-
ysis of the convergence behavior of the proposed approach.

-10-50510x10-310-210-1p(x)α=1.5α=1.7α=2.0051015202530t-50050Lαtα=1.5α=1.7α=2.0Fractional Langevin Monte Carlo

where b is called the drift and is chosen as a function of
α in our context, and Xt− will be deﬁned in the sequel.
Here, Lα
t denotes the D-dimensional α-stable L´evy motion
with independent components, i.e. each component of Lα
t
forms an independent scalar α-stable L´evy motion, which
is deﬁned as follows for α ∈ (0, 2] (Duan, 2015):

(i)
(ii)

0 = 0 almost surely.

Lα
For t0 < t1 < · · · < tN , the increments (Lα
tn
Lα
) are independent (n = 1, . . . , N ).
t − Lα

s ) and Lα

t−s have the same

tn−1

−

(iii) The difference (Lα

distribution: SαS((t − s)1/α) for s < t.

(iv) Lα

t has stochastically continuous sample paths (i.e.
continuous in probability): for all δ > 0 and s ≥ 0,
p(|Lα

s | > δ) → 0 as t → s.

t − Lα

Due to the stochastic continuity property, α-stable L´evy
motions can have a countable number of discontinuities,
which are often referred to as ‘jumps’. As illustrated in
Figure 1 (bottom), the size of these jumps becomes larger
as α get smaller, since SαS becomes heavier tailed. As a
consequence, the sample paths of these processes are con-
tinuous from the right and they have left limits at every time
(Duan, 2015): Xt− hence denotes the left limit of Xt at
time t. Therefore, these processes are called c`adl`ag, i.e. the
French acronym for ‘continue `a droite, limite `a gauche’.

√

Similarly to the symmetric α-stable distributions, the sym-
metric α-stable L´evy motions Lα
t coincide with a scaled
2Bt when α = 2. This can be simply
Brownian motion
veriﬁed by observing that the difference Lα
s follows
a Gaussian distribution N (0, 2(t − s)) and Lα
t becomes al-
most surely continuous everywhere.

t − Lα

Riesz potentials and fractional differentiation:
Frac-
tional calculus aims to generalize differentiation (and inte-
gration) to fractional orders (Herrmann, 2014). The canon-
ical example of fractional differentiation can be given as
the half-derivative operator, which coincides with the ﬁrst-
order derivative when applied twice to any function.

In this study, we are interested in fractional Riesz deriva-
tives (Riesz, 1949), which are closely related to α-stable
distributions. The fractional Riesz derivative directly gen-
eralizes the second-order differentiation to fractional or-
ders and it is a non-local operator. In the one dimensional
case, it is deﬁned by the following identity:

Dγf (x) (cid:44) F −1{|ω|γ ˆf (ω)},

(4)

where F denotes the Fourier transform and ˆf (ω) =
F{f (x)}. Here, γ > −1 is the order of the differentiation:
for γ ∈ (−1, 0) we obtain the Riesz potentials1, which will
be our main source of interest, and for γ = 2 we obtain the

1For γ < 0, Dγ corresponds to fractional integration. How-
ever, we follow the fractional calculus literature and still refer to
it as fractional differentiation.

usual second-order differentiation up to a sign difference,
i.e. D2f (x) = −d2f (x)/dx2. Note that D1f (x) does not
coincide with ﬁrst-order differentiation in general.

3. Fractional Langevin Monte Carlo

In this section, we present our main results and construct
the proposed Fractional LMC framework step by step. We
ﬁrst develop a L´evy-driven SDE that targets the correct dis-
tribution and analyze the weak convergence properties of
its Euler discretization. Afterwards, we develop numerical
methods for approximate simulation of the proposed SDE
and present formal analysis of the approximation error of
the numerical schemes and the weak error analysis of the
corresponding Euler discretizations.

In the rest of this paper, we restrict α to be in (1, 2] in order
the mean of the process to exist. Besides, in all our anal-
yses we focus on the scalar case (D = 1) for simplicity;
however, all our results can be extended for D > 1. All the
proofs are provided in the supplementary document.

3.1. Invariant measure and weak convergence analysis

Our ﬁrst goal is to ﬁnd a drift b in such a way that the
Markov process (Xt)t≥0 that is a c`adl`ag solution of the
SDE in (3) would have the target distribution π as an in-
variant distribution. In the following theorem, we present
our ﬁrst main result.
Theorem 1. Consider the SDE (3), where b is deﬁned as:
b(x, α) (cid:44) (cid:0)Dα−2fπ(x)(cid:1)/φ(x).

(5)

Here, fπ(x) (cid:44) −φ(x)∂xU (x) and Dγ is deﬁned in (4).
Then, π is an invariant measure of the Markov process
(Xt)t≥0 that is a c`adl`ag solution of the SDE given in (3).
Furthermore, if b is Lipschitz continuous, then π is the
unique invariant measure of the process (Xt)t≥0.

The Lipschitz continuity of ∂xU is a standard condition in
LMC for ensuring the uniqueness of the invariant measure,
albeit it is often violated in practical applications. In our
context, we need b to be Lipschitz continuous for unique-
ness, a condition which cannot be easily veriﬁed for α (cid:54)= 2.
Here, it is also worth noting that when α → 2, we ob-
tain the classical Langevin diffusion (1), as limα→2 Lα
t =
√

2Bt and limα→2 b(x, α) = −∂xU (x).

Theorem 1 suggests that if we could generate continuous
sample paths from (Xt)t≥0, then we could use them as
samples drawn from π. However, this is not possible since
the drift b does not admit an analytical form in general, and
even if it could be computed exactly, we still could not sim-
ulate the SDE (3) exactly as it is a continuous-time process.

For now, let us assume that we can exactly compute the
drift b and focus on simulating the SDE by considering

Fractional Langevin Monte Carlo

its Euler-Maruyama discretization (Duan, 2015; Panloup,
2008), which is given as follows:

¯Xn+1 = ¯Xn + ηn+1b( ¯Xn, α) + η1/α

n+1∆Lα

n+1

(6)

where n = 1, . . . , N denotes the time-steps, N is the to-
tal number of time-steps (i.e. iterations), (ηn)n is a se-
quence of step-sizes, and (∆Lα
n)n is a sequence of i.i.d.
standard symmetric α-stable random variables, i.e. ∆Lα
n ∼
SαS(1). We can clearly observe that this discretization
schema is a fractional generalization of ULA given in (2),
where it coincides with ULA when α = 2.

The Euler-Maruyama scheme in (6) lets us approximately
compute the expectation of a test function g under the tar-
get density π, i.e. ν(g) (cid:44) (cid:82) g(X)π(dX), by using sam-
n=1 ηng( ¯Xn),
ple averages, given as: ¯νN (g) (cid:44) 1
HN
where HN = (cid:80)N
n=1 ηn. Even though the convergence
properties of the estimators obtained via ULA have been
well-established (Roberts & Stramer, 2002; Durmus &
Moulines, 2015), it is not clear whether the estimator ¯νN (g)
converges to the true expectation ν(g) for α (cid:54)= 2.

(cid:80)N

For the convergence analysis, we make use of relatively
recent results from the applied probability literature (Pan-
loup, 2008). In order to establish the convergence of our
estimator, we need certain conditions to be satisﬁed. First,
we have a rather standard assumption on the step-sizes:
H1. limn→∞ ηn = 0,

limN→∞ HN = ∞,

i.e. the step-sizes are required to be decreasing and their
sum is required to diverge. Secondly, we need a more tech-
nical Lyapunov condition in order to ensure the stochastic
process to be mean-reverting.
H2. Let V : R → R∗
+ be a function in C2, satisfying
lim|x|→∞ V (x) = ∞, |∂xV | ≤ C
V for some C > 0,
and ∂2
xV is bounded. There exists a ∈ (0, 1], δ > 0 and
β ∈ R, such that |b|2 ≤ CV a and b(∂xV ) ≤ β − δV a,
where b is deﬁned in (5).

√

Under these conditions, we present the following corol-
lary to Theorem 1 and (Panloup, 2008, Theorem 2), where
we establish the weak convergence of the Euler-Maruyama
scheme deﬁned in (6).
Corollary 1. Assume that b is Lipschitz continuous and
the conditions H1 and H2 hold. If the test function g =
o(cid:0)V p/2+a−1(cid:1) with p ∈ (0, 1/2], then the following holds:

lim
N→∞

¯νN (g) = ν(g),

almost surely.

This corollary shows that under certain regularity and Lya-
punov conditions, the Euler-Maruyama scheme in (6) still
weakly converges for α (cid:54)= 2, as long as the drift can be
computed exactly. Note that we consider the Lipschitz con-
dition for ensuring the uniqueness of the invariant measure;

however, this is not a crucial assumption as one can show
that every weak limit of the sequence {¯νN }N is an invariant
probability for the SDE in (3).

3.2. Numerical approximation

Even though Corollary 1 ensures the weak convergence of
the Euler scheme, its practical implication is somewhat lim-
ited since the Riesz derivatives cannot be computed exactly
in general. In this section, we develop and analyze numer-
ical methods for approximately computing the drift b.

In (Ortigueira, 2006), it has been shown that for γ ∈
(−1, 2), the Riesz derivative Dγ of a function f (x) can
be deﬁned as the limit of the fractional centered difference
h, given as: Dγf (x) = limh→0 ∆γ
operator ∆γ
hf (x), where
(cid:88)∞

gγ,kf (x − kh),

(7)

∆γ

hf (x) (cid:44) (1/hγ)

k=−∞

2 − k + 1)Γ( γ
and gγ,k (cid:44) (−1)kΓ(γ + 1)/(Γ( γ
2 + k +
1)). By using the above deﬁnition, we can rewrite our drift
as: b(x, α) = (cid:0)limh→0 ∆α−2
fπ(x)(cid:1)/φ(x), where fπ(x) is
deﬁned in Theorem 1.

h

We now propose our ﬁrst numerical scheme for approxi-
mating the drift b by following C¸ elik & Duman (2012):

b(x, α) ≈ ˜bh,K(x, α) (cid:44) (cid:0)∆α−2

h,K fπ(x)(cid:1)/φ(x),

(8)

where ∆γ
operator, deﬁned as follows:

h,K is the truncated fractional central difference

∆γ

h,Kf (x) (cid:44) (1/hγ)

(cid:88)K

k=−K

gγ,kf (x − kh).

(9)

Here, we merely replaced the Riesz derivative with the cen-
tral difference operator where we ﬁxed h and truncated the
inﬁnite summation in order the numerical scheme to be
computationally tractable. We provide a numerically sta-
ble implementation of (8) in the supplementary document.

The scheme in (8) provides us a practical way for approx-
imately computing the drift. However, for ﬁxed h and K,
this approach would yield a certain approximation error
and therefore Corollary 1 would no longer hold if we re-
place b by ˜b in (6). Throughout this section, we analyze
this approximation error and the weak error of the Euler
scheme with the approximate drift.

We ﬁrst analyze the approximation error of our numerical
scheme in (8). Since φ(x) is constant for a given x, we
focus on |Dγfπ(x) − ∆γ
h,Kfπ(x)|. Here, we ﬁrst need a
technical regularity condition on fπ.
H3. fπ(x) ∈ C3(R) and all derivatives up to order three
belong to L1(R).

We need an additional assumption on fπ, which ensures the
tails of the target distribution π vanish sufﬁciently quickly.

H4. |fπ(x − kh)| ≤ C exp(−|k|h) for some C > 0 and
|k| > K for some K ∈ N+.

3.3. Multidimensional case

Fractional Langevin Monte Carlo

Now, we present our second main result.

Theorem 2. Assume that the conditions H3 and H4 hold.
Then, for γ ∈ (−1, 0), the following bound holds:

(cid:12)
(cid:12)Dγfπ(x) − ∆γ

h,Kfπ(x)(cid:12)

(cid:12) = O(cid:0)h2 + 1/(hK)(cid:1),

(10)

as h goes to zero.

Theorem 2 shows that the error induced by our numerical
approximation scheme is bounded and can be made arbi-
trarily small by decreasing h and increasing K. We can
also observe that for ﬁxed K, the optimal h = O(K −1/3).

The hidden constant in the right hand side of (10) is al-
lowed to depend on x and let it be denoted as C(x). In
order to ease the analysis, in the rest of the paper we will
assume that supx C(x)/φ(x) < ∞, so that Theorem 2 can
be directly used for bounding the error |b − ˜b| for any x.
Note that this a mild assumption and holds trivially when
X belongs to a bounded domain (e.g. the setting in (Wang
et al., 2015)).

We now consider the following Euler-Maruyama dis-
cretization of (3) with the approximate drift:

˜Xn+1 = ˜Xn + ηn+1

˜bh,K( ˜Xn, α) + η1/α

n+1∆Lα

n+1,

(11)

where the corresponding estimator is deﬁned as: ˜νN (g) (cid:44)
(1/HN ) (cid:80)N
n=1 ηng( ˜Xn). Even in this approximate Euler-
scheme, we still obtain ULA as a special case of (11), as
˜bh,K(x, α) = −∂xU (x).
we have limα→2

As opposed to ¯νN (g), ˜νN (g) does not converge to ν(g)
due to the error induced by the numerical approximation.
However, fortunately, the weak error of this Euler scheme
can still be bounded, as we show in the following theorem.
For this result, we need an additional ergodicity condition2.
H5. The SDE (3) and dXt = ˜bh,K(Xt, α)dt + dLα
t are ge-
ometrically ergodic with their unique invariant measures.

Theorem 3. Assume that the conditions H1, 3 and 5 hold,
H2 holds for ˜b, and K is chosen in such a way that H4 holds
for any x. Finally, assume that |∂xg| is bounded. Then, the
following bound holds almost surely:

(cid:12)
(cid:12)ν(g) − limN→∞ ˜νN (g)(cid:12)

(cid:12) = O(cid:0)h2 + 1/(hK)(cid:1).

(12)

This theorem shows that the weak error of the discretization
in (11) is dominated by the numerical error induced by ˜b
and can be made arbitrarily small by tuning h and K.

2Proving the ergodicity of the SDEs in H5 is beyond the scope
of this study; more information can be found in (Masuda, 2007).

Even though we have focused on the scalar case (i.e. D =
1) so far, we can generalize the presented results to vector
processes by using the same proof strategies since the com-
ponents of Lα
t are independent3. For D > 1, the drift turns
out to be a multidimensional generalization of (5) and has
the following form: (for d = 1, . . . , D)

[b(x, α)]d = Dα−2

xd

{−φ(x)∂xd U (x)}/φ(x),

(13)

where [v]i denotes the i’th component of a vector v and
Dα
xd denotes the partial fractional Riesz derivative along
the direction xd (Ortigueira et al., 2014). With this deﬁni-
tion of the multidimensional drift, similar to the scalar case,
we obtain the classical Langevin equation as a special case
of (3), since limα→2 b(x, α) = −∇U (x) for D > 1.

In applications, we can approximate (13) by applying the
same numerical technique presented in (8) to each dimen-
sion d. However, for large D, this approach would be im-
practical since it would require the fractional derivatives to
be computed D times at each iteration.

In this section, we propose a second scheme for approx-
imating the fractional Riesz derivatives. The current ap-
proach is a computationally more efﬁcient variant of the
ﬁrst numerical scheme presented in (7) and it is given as
follows: Dγfπ(x) ≈ gγ,0fπ(x), where gγ,0 = Γ(γ +
1)/Γ( γ
2 + 1)2 for x ∈ R. In other words, we approximate
the fractional derivatives by using only the ﬁrst term of the
centered difference operator deﬁned in (7). When all the
partial fractional derivatives in (13) are approximated with
this approach, the multidimensional drift greatly simpliﬁes
and has the following form: (for D > 1)

b(X, α) ≈ ˆb(X, α) (cid:44) −cα∇U (X),

(14)

where cα (cid:44) Γ(α − 1)/Γ(α/2)2. We ﬁnally consider a dis-
cretization of (3) where the drift is approximated by (14)
and ultimately propose the Fractional Langevin Algorithm
(FLA), deﬁned as follows:

ˆXn+1 = ˆXn − ηn+1cα∇U ( ˆXn) + η1/α

n+1∆Lα

n+1.

(15)

Similar to the previous discretization schemes given in
(6) and (11), FLA generalizes ULA as well,
since
ˆb(x, α) = −∇U (x). Besides, FLA has the ex-
limα→2
act same computational complexity as ULA, since it only
requires to compute ∇U and generate ∆Lα
n. Another in-
teresting observation is that cα increases as α decreases,

3While extending our results to D > 1, the independence of
the components of Lα
t turns out to be a crucial requirement since
the spectral measure of the corresponding multivariate stable dis-
tribution becomes discrete (Nolan, 2008). Our results cannot be
directly extended to SDEs that are driven by other multivariate
stable processes, such as isotropic stable processes (Nolan, 2013).

Fractional Langevin Monte Carlo

implying that FLA tends to increase the ‘weight’ of the gra-
dient as the driving process becomes heavier-tailed.

We now present our last theoretical result where we analyze
the approximation error of the simpliﬁed scheme for D =
1, and present it as a corollary to Theorems 2 and 3.
Corollary 2. Assume that the conditions H3 and 4 hold.
Let Kx ∈ N+ be a value that satisﬁes H4 for a given x,
and let r : R → R+ be a function deﬁned as:

r(x) (cid:44)

(cid:88)

(cid:12)
(cid:12)
(cid:12)

k∈

−Kx,Kx
(cid:74)

\0
(cid:75)

gγ,kfπ(x − kh)
gγ,0fπ(x)

+ 1

1/γ

.

(cid:12)
(cid:12)
(cid:12)

Then, for −1 < γ < 0, the following bound holds:
(cid:12)
(cid:12)
(cid:12) = O(cid:0)r2(x) + 1/(r(x)Kx)(cid:1).
(cid:12)Dγfπ(x) − gγ,0fπ(x)
(cid:12)
(cid:12)

Furthermore, if H1 holds, H2 and 5 hold for ˆb, and |∂xg| is
bounded, then, the following bound holds:
ˆνN (g)(cid:12)

(cid:12) = O(cid:0)r2(x∗) + 1/(r(x∗)Kx∗ )(cid:1)

(cid:12)
(cid:12)ν(g) − lim
N→∞

almost surely, where x∗ = arg maxx[r2(x) + 1/(r(x)Kx)]
and ˆνN (g) (cid:44) (1/HN ) (cid:80)N

n=1 ηng( ˆXn).

Here, the term r(x) plays a similar role as the parameter h
in (7). This corollary shows that the approximation qual-
ity of (14) may vary depending on the particular x where
Dγfπ(x) is evaluated, and depending on the values of Kx
and r(x), ˆb might even provide more accurate approxima-
tions than ˜b does. As a result, we observe that the weak
error is dominated by the largest numerical error induced
by ˆb. On the other hand, even if ˆb would have a higher
approximation error when compared to ˜b, we would expect
that the scheme in (15) to be better behaved than (11), since
it is less prone to numerical instability.

3.4. Large-scale Bayesian posterior sampling

In Bayesian machine learning, the target distribution π is
often chosen as the Bayesian posterior: π(X) = p(X|Y ),
where Y ≡ {Yi}NY
i=1 is a set of observed i.i.d. data
points. This choice of the target distribution imposes
the following form on the potential energy: U (X) =
−((cid:80)NY
i=1 log p(Yi|X) + log p(X)), where p(Yi|X) is the
likelihood function and p(X) is the prior distribution.

In large scale applications, NY becomes very large and
therefore computing ∇U at each iteration can be compu-
Inspired by the Stochastic Gradient
tationally inhibitive.
Langevin Dynamics (SGLD) algorithm (Welling & Teh,
2011), which extends ULA to large-scale settings, we ex-
tend FLA by replacing the exact gradients ∇U in (15) with
an unbiased estimator, given as follows:

∇ ˜Un(X) = −[∇ log p(X) +

∇ log p(Yi|X)],

NY
NΩ

(cid:88)

i∈Ωn

Figure 2. Top: the double-well potential. Middle: the empirical
distribution obtained via ULA (corresponds to FLA with α = 2).
Bottom: the empirical distribution obtained via FLA (α = 1.7).

where Ωn ⊂ {1, . . . , NY } is a random data subsample that
is drawn with replacement at iteration n and NΩ (cid:28) NY
denotes the number of elements in Ω. We call the resulting
algorithm Stochastic Gradient FLA (SG-FLA). Note that
SG-FLA coincides with SGLD when α = 2. We leave the
convergence analysis of SG-FLA as a future work.

4. Experiments

The double-well potential: We conduct our ﬁrst set of
experiments on a synthetic setting where we consider the
double-well potential, deﬁned as follows:

U (x) = (x + 5)(x + 1)(x − 1.02)(x − 5)/10 + 0.5.

We illustrate the double-well potential in Figure 2 (top).
It can be observed that the potential contains two well-
separated modes with different heights, which makes the
problem challenging.

In our ﬁrst experiment, we consider our ﬁrst discretization
scheme presented in (11), where we approximate the true
drift b, by ˜b. Here, we use decreasing step-sizes that are
determined as ηn = (aη/n)bη , where we ﬁx aη = 10−7
and bη = 0.6. In each experiment, we generate N = 5000
samples by using (11) and estimate the mean of the target
distribution π by using the sample average. For each α, we
run this scheme for different values of h and K, repeat each
experiment 5 times, and monitor the bias, where the ground
truth is obtained via a numerical integrator.

We ﬁrst ﬁx h = 0.06 and monitor the bias for increasing
values of K. Here, we deﬁne the notion of an optimal K
as the smallest K, for whose larger values the performance
improvement becomes negligible. As we can observe from
Figure 3 (top), the bias is gracefully degrading for increas-
ing K, where the optimal K depends on the choice of α.
We also observe that, modest values of K seem sufﬁcient
for obtaining accurate results, especially for small α.

-6-4-20246x0510φ(x)×105-6-4-20246x00.020.04Frequency-6-4-20246x00.010.02FrequencyFractional Langevin Monte Carlo

Table 1. Evaluation of the accuracy of ˆb.

α = 1.5 α = 1.6 α = 1.7 α = 1.8 α = 1.9

ˆκ(α)

19.31

14.12

12.72

8.64

7.03

Figure 3. Evaluation of the scheme in (11) on the estimation of
the mean of the double-well potential. Top: the average bias vs
K for a ﬁxed h. Bottom: the average bias vs h for a ﬁxed K.

Figure 4. The average bias obtained via FLA for different values
of α. Note that FLA corresponds to ULA when α = 2.

In our second experiment, we ﬁx K = 15 and monitor the
bias for different values of h. The results are illustrated in
Figure 3 (bottom). We observe that the results support our
theory: for very small values of h, the term 1/(hK) in the
bound of Theorem 3 dominates since K is ﬁxed. There-
fore, we observe a drop in the bias as we increase h up to
a certain point, and then the bias gradually increases along
with h. The results show that the performance becomes
more sensitive to the value of h, as α becomes smaller.

Even though the results in Figure 3 are promising, in prac-
tical applications we would not be able to use the scheme
in (8) due to computational issues. In our next experiment,
we aim to assess the approximation error of our second ap-
proximation scheme ˆb given in (14). However, the error
|b(x, α) −ˆb(x, α)| cannot be measured in a straightforward
manner, since b cannot be computed exactly and the error
itself depends on the particular point x.

(cid:75)

(cid:74)

Here, we develop an intuitive accuracy criterion for getting
better insight into this error, where the aim is to compute
the value of K for which ˜bh,K(x, α) and ˆb(x, α) would
yield similar approximation errors on average. For a given
x and ﬁxed h, we ﬁrst choose a large enough K (cid:63) ∈ N+
and compute b(cid:63)(x, α) (cid:44) ˜bh,K(cid:63) (x, α) as our reference for
1, K (cid:63)
b(x, α). Then, for K ∈
, we compute the approx-
imation error e(x, α, K) (cid:44) |˜bh,K(x, α) − b(cid:63)(x, α)| and
the error induced by the ultimate approximation scheme:
ˆe(x, α) (cid:44) |ˆb(x, α) − b(cid:63)(x, α)|. We then ﬁnd the value
of K for which e(x, α, K) and ˆe(x, α) are the closest:
κ(x, α) = arg minK |e(x, α, K) − ˆe(x, α)|. We ﬁnally
evaluate κ on I different points {xi}I
i=1 and use the aver-
age of these values as the measure of accuracy of ˆb, deﬁned
as: ˆκ(α) = (1/I) (cid:80)I
i=1 κ(xi, α). Intuitively, this value is
expected to be large when ˆb yields a low error.
In order to assess the accuracy of ˆb in the double-well prob-
lem, we compute ˆκ(α) for different values of α, where we
ﬁx h = 0.06, K (cid:63) = 170, and choose {xi}i as I = 200
evenly-spaced points from the interval [−5, 5]. The results
are given in Table 4. The results show that, despite its sim-

plicity, ˆb is able to provide reasonably accurate estimates
for b. We observe that for α = 1.6, ˆκ(α) becomes 14.12,
which is even larger than the optimal K for α = 1.6, as
shown in Figure 3. Therefore, it is promising to use ˆb in real
applications since it yields sufﬁciently accurate approxima-
tions with less computational requirements and does not re-
quire additional tuning for h and K.

In our last experiment on the double-well potential, we
evaluate the ultimately proposed approach FLA on estima-
tion of the mean of the target distribution. Similarly to the
previous experiments, we run FLA for different values of
α, where we try several values for the hyper-parameters aη
and bη and report the best results for each α. In each ex-
periment, we generate N = 50000 samples by using (15)
and repeat the procedure 10 times. We ﬁrst illustrate two
typical empirical distributions obtained via FLA and ULA
in Figure 2 (middle, bottom). It can be clearly observed
that ULA can locate only one of the modes, whereas FLA
is able to locate both of the modes, thanks to the jumps
of the α-stable processes. This circumstance also reﬂects
in the average bias, as illustrated in Figure 4. The results
show that for α = 2 the average bias is around 3, implying
that the algorithm concentrates on either one of the modes
at each trial, whereas we observe that the bias rapidly de-
creases as we decrease α. The best performance is achieved
when α = 1.75. Finally we note that these results are also
in line with the best-performing results given in Figure 3.

Matrix factorization:
In our second set of experi-
ments, we switch to a large-scale Bayesian machine learn-
ing context. We explore the use of SG-FLA on a large-
scale link prediction application where we consider the fol-
lowing probabilistic matrix factorization model (Gemulla
et al., 2011; Salakhutdinov & Mnih, 2008): Ail ∼
N (0, 1), Blj ∼ N (0, 1), Yij|A, B ∼ N (cid:0)(cid:80)
l AilBlj, 1(cid:1),
where Y ∈ RI×L is the observed data matrix with possi-
ble missing entries, and A ∈ RI×L and B ∈ RL×J are
the latent factor matrices. The aim in this application is to
predict the missing values of Y by using a low-rank ap-
proximation. Recently, SGLD has been proven successful
on similar models (Ahn et al., 2015; S¸ ims¸ekli et al., 2015;

2468101214161820K024Biasα=1.9α=1.8α=1.7α=1.600.020.040.060.080.10.120.140.16h024Biasα=1.9α=1.8α=1.7α=1.61.51.61.71.81.92α0123BiasFLAFractional Langevin Monte Carlo

Figure 5. The performance of SG-FLA on a link prediction appli-
cation. Top: ML-1M, middle: ML-10M, bottom: ML-20M.

Durmus et al., 2016; S¸ ims¸ekli et al., 2017).

In this set of experiments, we apply SG-FLA on the three
MovieLens movie ratings datasets (grouplens.org):
MovieLens 1Million (ML-1M), 10Million (ML-10M), and
20Million (ML-20M). The ML-1M dataset contains 1 mil-
lion non-zero entries, where I = 3883 (movies) and
J = 6040 (users). The ML-10M dataset contains 10 mil-
lion non-zero entries, where I = 10681 and J = 71567.
Finally, the ML-20M dataset contains 20 million ratings,
where I = 27278 and J = 138493. In our experiments,
we randomly select 10% of the data as the test set and use
the remaining data for generating the samples. The rank
L is set to 10 for all datasets. In all experiments, we use
decreasing step-sizes, where we ﬁx bη = 0.51 and try
several values for aη and report the best results. We set
NΩ = NY /10 where NY denotes the number of non-zero
entries in a given dataset.

Figure 5 shows the root mean squared-errors (RMSE) that
are obtained on the three test sets. In all these experiments,
we observe that the rate of convergence of SG-FLA in-
creases as we decrease α from 2.0 (i.e. SGLD) to 1.3. In
the case when α < 1.3, the jumps induced by the stable-
L´evy motion becomes very large and the performance starts
degrading. These results show that SG-FLA can be consid-
ered as a viable alternative to SGLD in large scale settings
and it can provide improved performance over SGLD via
minor algorithmic modiﬁcations, which come with the ex-
pense of tuning an additional parameter α.

Sigmoid Belief Networks: In our last set of experiments,
we investigate the use of SG-FLA on Sigmoid Belief Net-
works (SBN) (Gan et al., 2015), which have been investi-
gated in recent Stochastic Gradient MCMC studies (Chen
et al., 2015). We make use of the software provided in
(Chen et al., 2015) and employ the identical experimental
setup described therein: the binary observed data are as-
sumed to be generated from a single binary hidden layer
with sigmoid activations. The overall model is applied on

Figure 6. The test log-likelihoods obtained via SG-FLA on SBNs,
as a function of step-size η.

the MNIST dataset, which contains 70K binary images (of
size 28 × 28) corresponding to different digits.

In our experiments, we use an SBN with 100 hidden units.
We use a training set of 60K images and 10K images for
testing, set the size of the data subsample NΩ = 200, and
run SG-FLA for 5000 iterations for training. Finally, we es-
timate the test likelihoods by using an annealed importance
sampler (Salakhutdinov & Murray, 2008).

As opposed to our previous experiments, we use constant
step-sizes in these experiments, i.e. ηn = η for all n, and
investigate the performance of SG-FLA on SBNs for dif-
ferent values of η and α. The results are illustrated in Fig-
ure 6. We can observe that for small values of η, SG-FLA
yields similar test likelihoods for all values of α. However,
as we increase the step size, we observe that the test likeli-
hood of SGLD (α = 2) starts to diverge, whereas SG-FLA
becomes more robust to large step sizes as α gets smaller.
When α = 1.6 the test likelihood stays almost constant for
increasing values of η. We do not observe an improvement
in the performance for α < 1.6.

5. Conclusion and Future Directions

In this study, we explored the use of L´evy-driven SDEs
within MCMC and presented a novel FLMC framework.
We ﬁrst showed that FLMC targets the correct distribution
and then developed novel and scalable computational meth-
ods for practical applications. We provided formal analysis
of the convergence properties and the approximation qual-
ity of the proposed numerical schemes. We supported our
theory with several experiments, which showed that FLMC
brings various beneﬁts, such as providing superior perfor-
mance in multi-modal settings, higher convergence rates,
and robustness to algorithm parameters.

The proposed framework opens up several interesting fu-
(i) the use of FLMC in simulated an-
ture directions:
nealing for global optimization (Chen et al., 2016), where
the jumps might bring further advantages (ii) extension of
FLMC to ‘stable-like’ processes (Bass, 1988), where α can
depend on X (iii) incorporation of the local geometry for
faster convergence (Patterson & Teh, 2013; Li et al., 2016;
S¸ ims¸ekli et al., 2016a) (iv) the use of SG-FLA in Bayesian
model selection (S¸ ims¸ekli et al., 2016b).

050100150200250300350400Iterations (n)1.522.53Test RMSEα=2.00α=1.60α=1.40α=1.30050100150200250300350400450500Iterations (n)1.522.5Test RMSEα=2.00α=1.70α=1.50α=1.30050010001500Iterations (n)1.522.533.5Test RMSEα=2.00α=1.70α=1.50α=1.300.511.522.5Step-size(η)×10-4-300-250-200-150-100Test Log-likelihoodα=2.0α=1.9α=1.8α=1.7α=1.6Fractional Langevin Monte Carlo

Acknowledgments

The author would like to thank to Alain Durmus for his
helps on the proofs, and to Roland Badeau, A. Taylan
Cemgil, and Ga¨el Richard for fruitful discussions. The au-
thor would also like to thank to Changyou Chen for sharing
the code used in the experiments conducted on SBNs. This
work is partly supported by the French National Research
Agency (ANR) as a part of the FBIMATRIX project (ANR-
16-CE23-0014), and the EDISON 3D project (ANR-13-
CORD-0008-02).

References

Duan, J. An Introduction to Stochastic Dynamics. Cam-

bridge University Press, New York, 2015.

Durmus, A. and Moulines, E. Non-asymptotic convergence
analysis for the unadjusted Langevin algorithm. arXiv
preprint arXiv:1507.05021, 2015.

Durmus, A., S¸ ims¸ekli, U., Moulines, E., Badeau, R., and
Richard, G. Stochastic gradient Richardson-Romberg
Markov Chain Monte Carlo. In NIPS, 2016.

Eliazar, I. and Klafter, J. L´evy-driven Langevin systems:
Targeted stochasticity. Journal of statistical physics, 111
(3):739–768, 2003.

Ahn, S., Korattikara, A., Liu, N., Rajan, S., and Welling,
M. Large-scale distributed Bayesian matrix factorization
using stochastic gradient MCMC. In KDD, 2015.

Gan, Z., Henao, R., Carlson, D. E., and Carin, L. Learning
deep sigmoid belief networks with data augmentation. In
AISTATS, volume 38, pp. 268–276, 2015.

Bass, R. F. Uniqueness in law for pure jump Markov pro-
cesses. Probability Theory and Related Fields, 79(2):
271–287, 1988.

Gemulla, R., Nijkamp, E., J., Haas. P., and Sismanis,
Large-scale matrix factorization with distributed

Y.
stochastic gradient descent. In ACM SIGKDD, 2011.

C¸ elik, C. and Duman, M. Crank–Nicolson method for the
fractional diffusion equation with the Riesz fractional
derivative. Journal of Computational Physics, 231(4):
1743–1750, 2012.

Chambers, J. M., Mallows, C. L., and Stuck, B. W. A
method for simulating stable random variables. Jour-
nal of the american statistical association, 71(354):340–
344, 1976.

Chen, C., Ding, N., and Carin, L. On the convergence of
stochastic gradient MCMC algorithms with high-order
integrators. In Advances in Neural Information Process-
ing Systems, pp. 2269–2277, 2015.

Chen, C., Carlson, D., Gan, Z., Li, C., and Carin, L.
Bridging the gap between stochastic gradient MCMC
and stochastic optimization. In AISTATS, 2016.

S¸ ims¸ekli, U., Badeau, R., Cemgil, A. T., and Richard,
G. Stochastic quasi-Newton Langevin Monte Carlo. In
ICML, 2016a.

Herrmann, R. Fractional calculus: an introduction for

physicists. World Scientiﬁc, 2014.

Jarner, S. F. and Roberts, G. O. Convergence of heavy-
tailed Monte Carlo Markov Chain algorithms. Scandi-
navian Journal of Statistics, 34(4):781–815, 2007.

Konakov, V. and Menozzi, S. Weak error for stable driven
stochastic differential equations: Expansion of the densi-
ties. Journal of Theoretical Probability, 24(2):454–478,
2011.

Kuruoglu, E. E. Signal processing in α-stable noise envi-
ronments: a least lp-norm approach. PhD thesis, Uni-
versity of Cambridge, 1999.

Lamberton, D. and Pages, G. Recursive computation of the
invariant distribution of a diffusion: the case of a weakly
mean reverting drift. Stochastics and dynamics, 3(04):
435–451, 2003.

L´evy, P. Th´eorie de l’addition des variables al´eatoires.

Gauthiers-Villars, Paris, 1937.

S¸ ims¸ekli, U., Badeau, R., Richard, G., and Cemgil,
A. T.
efﬁ-
cient Bayesian model selection via stochastic gradient
MCMC. In ICASSP, 2016b.

Stochastic thermodynamic integration:

Li, C., Chen, C., Carlson, D., and Carin, L. Preconditioned
stochastic gradient Langevin dynamics for deep neural
networks. In AAAI Conference on Artiﬁcial Intelligence,
2016.

S¸ ims¸ekli, U., Durmus, A., Badeau, R., Richard, G.,
Moulines, E., and Cemgil, A. T. Parallelized stochas-
tic gradient Markov Chain Monte Carlo algorithms for
non-negative matrix factorization. In ICASSP, 2017.

Ditlevsen, P. D. Anomalous jumping in a double-well po-

tential. Physical Review E, 60(1):172, 1999.

Mandelbrot, B. B.

Fractals and Scaling in Finance:
Discontinuity, Concentration, Risk. Selecta Volume E.
Springer Science & Business Media, 2013.

Masuda, H. Ergodicity and exponential β-mixing bounds
for multidimensional diffusions with jumps. Stochastic
processes and their applications, 117(1):35–56, 2007.

Fractional Langevin Monte Carlo

Mikuleviˇcius, R. and Zhang, C. On the rate of convergence
of weak Euler approximation for nondegenerate SDEs
driven by L´evy processes. Stochastic Processes and their
Applications, 121(8):1720–1748, 2011.

Stramer, O. and Tweedie, R. L. Langevin-type mod-
els ii: self-targeting candidates for MCMC algorithms.
Methodology and Computing in Applied Probability, 1
(3):307–328, 1999.

Wang, Y. X., Fienberg, S. E., and Smola, A. J. Privacy for
free: Posterior sampling and stochastic gradient Monte
Carlo. In ICML, pp. 2493–2502, 2015.

Welling, M. and Teh, Y. W. Bayesian learning via stochas-
tic gradient Langevin dynamics. In International Con-
ference on Machine Learning, pp. 681–688, 2011.

Yanovsky, V. V., Chechkin, A. V., Schertzer, D., and Tur,
A. V. L´evy anomalous diffusion and fractional Fokker–
Planck equation. Physica A: Statistical Mechanics and
its Applications, 282(1):13–34, 2000.

Nolan, J. P. An overview of multivariate stable distribu-

tions. Technical Report, 2008.

Nolan, J. P. Multivariate elliptically contoured stable dis-
tributions: theory and estimation. Computational Statis-
tics, 28(5):2067–2089, 2013.

Ortigueira, M. D. Riesz potential operators and inverses
via fractional centred derivatives. International Journal
of Mathematics and Mathematical Sciences, 2006, 2006.

Ortigueira, M. D., Laleg-Kirati, T. M., and Machado, J.
A. T. Riesz potential versus fractional Laplacian. Jour-
nal of Statistical Mechanics, (09), 2014.

Panloup, F. Recursive computation of the invariant measure
of a stochastic differential equation driven by a L´evy pro-
cess. The Annals of Applied Probability, 18(2):379–426,
2008.

Patterson, S. and Teh, Y. W. Stochastic gradient Rie-
mannian Langevin dynamics on the probability simplex.
In Advances in Neural Information Processing Systems,
2013.

Riesz, M. L’int´egrale de Riemann-Liouville et le probl`eme

de Cauchy. Acta mathematica, 81(1):1–222, 1949.

Roberts, G. O. and Stramer, O. Langevin Diffusions
and Metropolis-Hastings Algorithms. Methodology and
Computing in Applied Probability, 4(4):337–357, De-
cember 2002. ISSN 13875841.

Rossky, P. J., Doll, J. D., and Friedman, H. L. Brownian
dynamics as smart Monte Carlo simulation. The Journal
of Chemical Physics, 69(10):4628–4633, 1978.

Salakhutdinov, R. and Mnih, A. Bayesian probabilistic ma-
trix factorization using Markov Chain Monte Carlo. In
ICML, pp. 880–887, 2008.

Salakhutdinov, R. and Murray, I. On the quantitative anal-
In ICML, pp. 872–879,

ysis of deep belief networks.
2008.

Samorodnitsky, G. and Taqqu, M. S. Stable non-Gaussian
random processes: stochastic models with inﬁnite vari-
ance, volume 1. CRC press, 1994.

S¸ ims¸ekli, U., Koptagel, H., G¨uldas¸, H., Cemgil, A. T.,
¨Oztoprak, F., and Birbil, S¸ . ˙I. Parallel stochastic gradi-
ent Markov Chain Monte Carlo for matrix factorisation
models. arXiv preprint arXiv:1506.01418, 2015.

