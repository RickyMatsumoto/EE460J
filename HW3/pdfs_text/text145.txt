5. Appendix

Nearly Optimal Robust Matrix Completion

We divide this section into ﬁve parts. In the ﬁrst part we prove some common lemmas. In the second part we give the
convergence guarantee for PG-RMC . In the third part we give another algorithm which has a sample complexity of
O(µ4r3n log2 n log µ2rσ∗
) and prove its convergence guarantees. In the fourth part we prove a generalized form of lemma
1. In the ﬁfth part we present some additional experiments.

(cid:15)

1

For the sake of convenience in the following proofs, we will deﬁne some notations here.

We deﬁne p = |Ωk,t|

mn and we consider the following equivalent update step for L(t+1) in the analysis:

L(t+1) := Pk(M (t))
H := E(t) + βG

(cid:101)S(t) := HT ζ

(cid:0)M − L(t)(cid:1)

D := L(t) − L∗ + (cid:101)S(t) − (cid:101)S∗

(cid:18)

G := 1
β

M (t) := L∗ + H
E(t) := (cid:101)S∗ − (cid:101)S(t)
(cid:19)
PΩq,t
p
n (cid:107)D(cid:107)∞√
p
1| ≥ . . . ≥ |σ∗

I −
√
2

β :=

D

The singular values of L∗ are denoted by σ∗
singular values of M (t) where |λ1| ≥ . . . ≥ |λn|.

1, . . . , σ∗

r where |σ∗

r | and we will let λ1, . . . , λn denote the

5.1. Common Lemmas

We will begin by restating some lemmas from previous work that we will use in our proofs.

First, we restate Weyl’s perturbation lemma from (Bhatia, 1997), a key tool in our analysis:
Lemma 2. Suppose B = A + E ∈ Rm×n matrix. Let λ1, · · · , λk and σ1, · · · , σk be the singular values of B and A
respectively such that λ1 ≥ · · · ≥ λk and σ1 ≥ · · · ≥ σk. Then:

This lemma establishes a bound on the spectral norm of a sparse matrix.
Lemma 3. Let S ∈ Rm×n be a sparse matrix with row and column sparsity ρ. Then,

|λi − σi| ≤ (cid:107)E(cid:107)2 ∀ i ∈ [k].

(cid:107)S(cid:107)2 ≤ ρ max{m, n} (cid:107)S(cid:107)∞

Proof. For any pair of unit vectors u and v, we have:

v(cid:62)Su =

(cid:88)

viujSij ≤

(cid:88)

1≤i≤m,1≤j≤n

1≤i≤m,1≤j≤n

(cid:33)

(cid:32)

i + u2
v2
j
2

|Sij|





1
2

≤

(cid:88)

(cid:88)

v2
i

|Sij| +

(cid:88)

(cid:88)

u2
j

|Sij|

1≤i≤m

1≤j≤n

1≤j≤n

1≤i≤m


 ≤ ρ max{m, n} (cid:107)S(cid:107)∞

Lemma now follows by using (cid:107)S(cid:107)2 = maxu,v,(cid:107)u(cid:107)2=1,(cid:107)v(cid:107)2=1 uT Sv.

Now, we deﬁne a 0-mean random matrix with small higher moments values.
Deﬁnition 1 (Deﬁnition 7, (Jain & Netrapalli, 2015)). H is a random matrix of size m × n with each of its entries drawn
independently satisfying the following moment conditions:

E[hij] = 0,

|hij| < 1, E[|hij|k] ≤

1
max{m,n} ,

for i, j ∈ [n] and 2 ≤ k ≤ 2 log n.

We now restate two useful lemmas from (Jain & Netrapalli, 2015):
Lemma 4 (Lemma 8 and 10 of (Jain & Netrapalli, 2015)). We have the following two claims:
• Suppose H satisﬁes Deﬁnition 1. Then, w.p. ≥ 1 − 1/n10+log α, we have: (cid:107)H(cid:107)2 ≤ 3

√

α.

Nearly Optimal Robust Matrix Completion

• Let A be a m × n matrix with n ≥ m. Suppose Ω ⊆ [m] × [n] is obtained by sampling each element with probability

p ≥ 1

4n . Then, the following matrix H satisﬁes Deﬁntion 1:
(cid:18)

√

H :=

p
n (cid:107)A(cid:107)∞

√
2

(cid:19)

A −

PΩ(A)

.

1
p

Lemma 5 (Lemma 13, (Jain & Netrapalli, 2015)). Let A ∈ Rn×n be a symmetric matrix with eigenvalues σ1, · · · , σn
where |σ1| ≥ · · · ≥ |σn|. Let B = A + C be a perturbation of A satisfying (cid:107)C(cid:107)2 ≤ σk
2 and let Pk(B) = U ΛU (cid:62) be the
rank-k projection of B. Then, Λ−1 exists and we have:

1. (cid:13)

(cid:13)A − AU Λ−1U (cid:62)A(cid:13)

2. (cid:13)

(cid:13)AU Λ−aU (cid:62)A(cid:13)

(cid:13)2 ≤ 4

(cid:16) |σk|
2

(cid:13)2 ≤ |σk+1| + 5 (cid:107)C(cid:107)2,
(cid:17)−a+2

∀a ≥ 2.

We now provide a lemma that bounds (cid:107) · (cid:107)∞ norm of an incoherent matrix with its operator norm.
Lemma 6. Let A ∈ Rm×n be a rank r, µ-incoherent matrix. Then for any C ∈ Rn×m, we have:

(cid:107)ACA(cid:107)∞ ≤

(cid:107)ACA(cid:107)2

µ2r
√
mn

Proof. Let A = U ΣV (cid:62). Then, ACA = U U (cid:62)ACAV V (cid:62). The lemma now follows by using deﬁnition of incoherence
with the fact that (cid:107)U (cid:62)ACAV (cid:107)2 ≤ (cid:107)ACA(cid:107)2.

We now present a lemma that shows improvement in the error (cid:107)L − L∗(cid:107)∞ by using gradient descent on L(t).
Lemma 7. Let L∗, Ω, (cid:101)S∗ satisfy Assumptions 1,2,3 respectively. Also, let the following hold for the t-th inner-iteration of
any stage q:

(cid:13)L∗ − L(t)(cid:13)
1. (cid:13)
(cid:13)∞ ≤ 2µ2r
m
(cid:13) (cid:101)S∗ − (cid:101)S(t)(cid:13)
(cid:13)
≤ 8µ2r
(cid:13)
(cid:13)
(cid:13)∞
m

2.

(cid:0)σ∗

(cid:0)σ∗

2

k+1 + (cid:0) 1
k+1 + (cid:0) 1

2

(cid:1)z

(cid:1)z

(cid:1)

(cid:1)

σ∗
k

σ∗
k

3. Supp( (cid:101)S(t)) ⊆ Supp( (cid:101)S∗)
k and σ∗
L(t) − L∗ + (cid:101)S(t) − (cid:101)S∗(cid:17)

where z ≥ −3 and σ∗
(cid:16)

I −

(cid:17) (cid:16)

PΩq,t
p

n−(10+log α):

k+1 are the k and (k + 1)th singular values of L∗. Also, let E1 = (cid:101)S(t) − (cid:101)S∗ and E3 =
be the error terms deﬁned also in (6). Then, the following holds w.p ≥ 1 −

(cid:107)E1 + E3(cid:107)2 ≤

(cid:18)

1
100

σ∗
k+1 +

(cid:19)z

(cid:19)

σ∗
k

(cid:18) 1
2

(8)

Proof. Note from Lemma 4,

E3 =

I −

(cid:18)

1
β

1
β

(cid:19) (cid:16)

PΩq,t
p

L(t) − L∗ + (cid:101)S(t) − (cid:101)S∗(cid:17)

,

√
satisﬁes Deﬁnition 1 with β = 2
√

n

p · (cid:107)L(t) − L∗ + (cid:101)S(t) − (cid:101)S∗(cid:107)∞.

We now bound the spectral norm of E1 + E3 as follows:

(cid:107)E1 + E3(cid:107)2 ≤ (cid:107)E1(cid:107)2 + β ·

(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
β

E3

(cid:13)
(cid:13)
(cid:13)
(cid:13)2
(cid:18) 1
2
(cid:18) 1
2

(ζ1)
≤ ρn

(cid:19)z

(cid:19)

σ∗
kq

(cid:19)z

(cid:19)

.

σ∗
kq

(cid:18)

(cid:18)

(ζ2)
≤

(ζ3)
≤

1
200

1
100

σ∗
kq+1 +

σ∗
kq+1 +

√

+ 3β

α,

(cid:13)
(cid:13)

(cid:13) (cid:101)S(t) − (cid:101)S∗(cid:13)
(cid:13)
(cid:13)∞
(cid:114) n
60µ2r
p
m

+

√

α

(cid:18)(cid:12)
(cid:12)σ∗
(cid:12)

kq+1

(cid:12)
(cid:12)
(cid:12) +

(cid:18) 1
2

(cid:19)

(cid:19)z (cid:12)
(cid:12)σ∗
(cid:12)

kq

(cid:12)
(cid:12)
(cid:12)

,

where (ζ1) follows from Lemma 3 and 4, (ζ2) follows by our assumptions on ρ, (cid:13)
assumption that n = O (m) and (ζ3) follows from our assumption on p.

(cid:13)L(t) − L∗(cid:13)

(cid:13)∞,

(cid:13)
(cid:13)

(cid:13) (cid:101)S(t) − (cid:101)S∗(cid:13)
(cid:13)
(cid:13)∞

and our

Nearly Optimal Robust Matrix Completion

In the following lemma, we prove that the value of the threshold computed using σk(M (t)) = σk(L∗ + E1 + E3), where
E1, E3 are deﬁned in (6), closely tracks the threshold that we would have gotten had we had access to the true eigenvalues
of L∗, σ∗
k.
Lemma 8. Let L∗, Ω, (cid:101)S∗ satisfy Assumptions 1,2,3 respectively. Also, let the following hold for the t-th inner-iteration of
any stage q:

(cid:13)L∗ − L(t)(cid:13)
1. (cid:13)
(cid:13)∞ ≤ 2µ2r
m
(cid:13) (cid:101)S∗ − (cid:101)S(t)(cid:13)
(cid:13)
≤ 8µ2r
(cid:13)
(cid:13)
(cid:13)∞
m

2.

(cid:0)σ∗

(cid:0)σ∗

2

k+1 + (cid:0) 1
k+1 + (cid:0) 1

2

(cid:1)z

(cid:1)z

(cid:1)

(cid:1)

σ∗
k

σ∗
k

3. Supp( (cid:101)S(t)) ⊆ Supp( (cid:101)S∗)

where z ≥ −3 and σ∗
(cid:16)

PΩq,t
p
≥ 1 − n−(10+log α):

I −

(cid:17) (cid:16)

k and σ∗
L(t) − L∗ + (cid:101)S(t) − (cid:101)S∗(cid:17)

k+1 are the k and (k + 1)th singular values of L∗. Also, let E1 = (cid:101)S(t) − (cid:101)S∗ and E3 =
be the error terms deﬁned also in (6). Then, the following holds ∀z > −3 w.p

(cid:32)

7
8

σ∗
k+1 +

(cid:18) 1
2

(cid:19)z+1

(cid:33)

(cid:32)

σ∗
k

≤

λk+1 +

(cid:18) 1
2

(cid:19)z+1

(cid:33)

(cid:32)

λk

≤

σ∗
k+1 +

9
8

(cid:19)z+1

(cid:33)

σ∗
k

,

(cid:18) 1
2

(9)

where λk := σk(M (t)) = σk(L∗ + E1 + E3) and E1, E3 are deﬁned in (6).

Proof. Using Weyl’s inequality (Lemma 2), we have: : |λk − σ∗
now proceed to prove the lemma as follows:

k| ≤ (cid:107)E1 + E3(cid:107)2 and (cid:12)

(cid:12)λk+1 − σ∗

k+1

(cid:12)
(cid:12) ≤ (cid:107)E1 + E3(cid:107)2 We

(cid:19)z+1

(cid:12)
(cid:12)
(cid:12)
λk+1 +
(cid:12)
(cid:12)

(cid:18) 1
2

λk − σ∗

k+1 −

(cid:19)z+1

(cid:18) 1
2

(cid:32)

(cid:18) 1
2

σ∗
k

≤ (cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:19)z+1(cid:33) (ζ)
≤

≤ (cid:107)E1 + E3(cid:107)2

1 +

(cid:32)

≤

1
8

σ∗
k+1 +

(cid:19)z+1

(cid:33)

σ∗
k

,

(cid:18) 1
2

(cid:12)λk+1 − σ∗

k+1

(cid:12)
(cid:12) +

(cid:19)z+1

|λk − σ∗

k| ,

(cid:18)

1
100

σ∗
k+1 +

(cid:19)z

(cid:19) (cid:32)

σ∗
k

1 +

(cid:19)z+1(cid:33)

,

(cid:18) 1
2

(cid:18) 1
2

(cid:18) 1
2

where (ζ) follows from Lemma 7 and the last inequality follows from the assumption that z ≥ −3.

Next, we show that the projected gradient descent update (6) leads to a better estimate of L∗, i.e., we bound (cid:107)L(t+1)−L∗(cid:107)∞.
Under the assumptions of the below given Lemma, the proof follows arguments similar to (Netrapalli et al., 2014) with
additional challenge that arises due to more involved error terms E1, E3.

Our proof proceeds by ﬁrst symmetrizing our matrices by rectangular dilation. We ﬁrst begin by noting some properties of
symmetrized matrices used in the proof of the following lemma.
Remark 1. Let A be a m × n dimensional matrix with singular value decomposition U ΣV (cid:62). We denote its symmetrized

version by As :=

(cid:21)

(cid:20) 0 A(cid:62)
A 0

. Then:

1. The eigenvalue decomposition of As is given by As = UsΣsU (cid:62)

Us :=

1
√
2

(cid:21)

(cid:20)V
V
U −U

s where
(cid:20)Σ
0 −Σ

Σs :=

0

(cid:21)

2. P2k (As) =

3. We have A2j

s =

(cid:20)

0
Pk(A)

(cid:21)
Pk(A(cid:62))
0
(cid:20)(A(cid:62)A)j
0

(cid:21)

0
(AA(cid:62))j

A2j+1
s

=

(cid:20)
0
(AA(cid:62))jA

(cid:21)

(A(cid:62)A)jA(cid:62)
0

4. We have

Nearly Optimal Robust Matrix Completion

UsΣ−j

s U (cid:62)

s =

UsΣ−j

s U (cid:62)

s =

(cid:20)V Σ−jV (cid:62)
0

(cid:20)
0
U Σ−jV (cid:62)

(cid:21)

(cid:21)

0
U Σ−jU (cid:62)

V Σ−jU (cid:62)
0

when j is even

when j is odd

Lemma 9. Let L = Pk(L∗ + H), where H is any perturbation matrix that satisﬁes the following:

1. (cid:107)H(cid:107)2 ≤

σ∗
k
4

2. ∀i ∈ [n], a ≤ (cid:100) log n

2 (cid:101) with υ ≤

σ∗
k
4
(cid:13)
(cid:0)H (cid:62)H(cid:1)a
(cid:13)e(cid:62)
i
i H (cid:62) (cid:0)HH (cid:62)(cid:1)a

(cid:13)
(cid:13)e(cid:62)

(cid:13)2 , (cid:13)
(cid:13)2 , (cid:13)
k is the kth singular value of L∗. Also, let L∗ satisfy Assumption 1. Then, the following holds:
µ2r
m

(cid:113) r
m
(cid:113) r
(cid:13)2 ≤ (υ)2a+1µ
m

(cid:0)HH (cid:62)(cid:1)a
i H (cid:0)H (cid:62)H(cid:1)a

(cid:13)2 ≤ (υ)2aµ
V ∗(cid:13)

k+1 + 20 (cid:107)H(cid:107)2 + 8υ(cid:1)

(cid:107)L − L∗(cid:107)∞ ≤

V ∗(cid:13)
U ∗(cid:13)

(cid:13)e(cid:62)
i
(cid:13)e(cid:62)

U ∗(cid:13)

(cid:0)σ∗

where σ∗

where µ and r are the rank and incoherence of the matrix L∗ respectively.

Proof. Let Ls, Hs and L∗

s denote the symmetrized forms of L, H and L∗ respectively. Now, we have:

Ls = P2k (L∗

s + Hs)

Let l = m + n. Let λ1, · · · , λl be the eigenvalues of Ms = L∗
corresponding eigenvectors of Ms. Using Lemma 2 along with the assumption on (cid:107)Hs(cid:107)2, we have: |λ2k| ≥ 3σ∗
4 .
Let U ΛV be the eigen vector decomposition of L. Let UsΛsU (cid:62)
Remark 1 we have ∀ i ∈ [2k]:

s + Hs with |λ1| ≥ |λ2| · · · ≥ |λl|. Let u1, u2, · · · , ul be the

s to be the eigen vector decomposition of Ls. Then, using

k

As |λ2k| ≥ 3σ∗

k

4 and (cid:107)Hs(cid:107)2 ≤ 1

4 σ∗

k, we can apply the Taylor’s series expansion to get the following expression for ui:

(L∗

s + Hs) ui = λiui,

i.e.

(cid:18)

I −

(cid:19)

Hs
λi

ui =

L∗
sui
λi

.

ui =





1
λi

∞
(cid:88)

j=0

(cid:18) Hs
λi

(cid:19)j


L∗
sui
λi

.

That is,

Ls =

λiuiu(cid:62)

i =

λ−1
i

2k
(cid:88)

i=1

(cid:88)

0≤s,t<∞

(cid:19)s

(cid:18) Hs
λi

L∗

suiu(cid:62)

i L∗
s

(cid:19)t

,

(cid:18) Hs
λi

2k
(cid:88)

i=1

(cid:88)

2k
(cid:88)

=

0≤s,t<∞

i=1

λ−(s+t+1)
i

H s

s L∗

suiu(cid:62)

i L∗

sH t

s =

H s

s L∗

sUsΛ−(s+t+1)
s

U (cid:62)

s L∗

sH t
s.

(cid:88)

0≤s,t<∞

Subtracting L∗

s on both sides and taking operator norm, we get:

(cid:107)Ls − L∗

s(cid:107)∞ = (cid:13)

(cid:13)UsΛsU (cid:62)

s − L∗
s

H s

s L∗

sUsΛ−(s+t+1)
s

U (cid:62)

s L∗

sH t

s − L∗
s

(cid:88)

(cid:13)
(cid:13)∞ =

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
s − L∗
(cid:13)∞ +
s

0≤s,t<∞

(cid:88)

(cid:13)
(cid:13)H s
(cid:13)

1≤s+t<∞

,

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)∞
(cid:13)
sH t
(cid:13)
(cid:13)∞
s

.

= (cid:13)

(cid:13)L∗

sUsΛ−1

s U (cid:62)

s L∗

s L∗

sUsΛ−(s+t+1)
s

U (cid:62)

s L∗

(10)

(11)

(12)

(13)

(14)

Nearly Optimal Robust Matrix Completion

We separately bound the ﬁrst and the second term of RHS. The ﬁrst term can be bounded as follows:

(cid:13)
(cid:13)L∗

sUsΛ−1

s U (cid:62)

s L∗

s − L∗
s

(cid:13)
(cid:13)∞

(ζ1)
=

(cid:13)
(cid:13)
L∗
(cid:13)
s
(cid:13)

(cid:20)
0
U Λ−1V (cid:62)

(cid:21)

V Λ−1U (cid:62)
0

L∗

s − L∗
s

(cid:13)
(cid:13)
(cid:13)
(cid:13)∞

≤ (cid:13)

(cid:13)L∗V Λ−1U (cid:62)L∗ − L∗(cid:13)
(cid:13)∞

(ζ2)
≤

µ2r
√
mn

(cid:13)L∗V Λ−1U (cid:62)L∗ − L∗(cid:13)
(cid:13)
(cid:13)2

(ζ3)
≤

µ2r
√
mn

(cid:0)(cid:12)
(cid:12)σ∗

k+1

(cid:12)
(cid:12) + 5 (cid:107)H(cid:107)2

(cid:1) ,

where (ζ1) follows Remark 1, (ζ2) from Lemma 6 and (ζ3) follows from Claim 1 of Lemma 5 after symmetrization.

We now bound second term of RHS of (10) which we again split in two parts. We ﬁrst bound the terms with s + t > log n:

(cid:13)
(cid:13)H s
(cid:13)

s L∗

sUsΛ(s+t+1)
s

U (cid:62)

s L∗

sH t
s

s L∗

sUsΛ−(s+t+1)
s

U (cid:62)

s L∗

sH t
s

(cid:13)
(cid:13)
(cid:13)∞

≤

(cid:13)
(cid:13)H s
(cid:13)

(cid:18)

(cid:19)(s+t−1)

2
σ∗
k

≤ 4 (cid:107)H(cid:107)2

(cid:107)H(cid:107)2

≤

(cid:107)H(cid:107)2

4
n

(cid:18) 1
2

(cid:19)(s+t−1−log n)

≤ 4

µ2r
m

(cid:107)H(cid:107)2

(cid:19)−(s+t−1)

(cid:13)
(cid:13)
(cid:13)2

(ζ1)
≤ (cid:107)Hs(cid:107)s+t

2

(ζ2)
≤ 4 (cid:107)H(cid:107)2

4

(cid:18) 2
σ∗
k
(cid:19)(s+t−1)

(cid:18) 1
2
(cid:19)(s+t−1−log n)
(cid:18) 1
2

,

where (ζ1) follows from the second claim of Lemma 5 and noting that (cid:107)Hs(cid:107)2 = (cid:107)H(cid:107)2 and (ζ2) follows from assumption
on (cid:107)H(cid:107)2 and using the fact that s + t ≥ log n.
Summing up over all terms with s + t > log n, we get from (13) and (12):

(cid:107)Ls − L∗

s(cid:107)∞ ≤

(cid:0)(cid:12)
(cid:12)σ∗

k+1

(cid:12)
(cid:12) + 20 (cid:107)H(cid:107)2

(cid:1) +

(cid:88)

µ2r
m

(cid:13)
(cid:13)H s
(cid:13)

s L∗

sUsΛ−(s+t+1)
s

U (cid:62)

s L∗

sH t
s

(cid:13)
(cid:13)
(cid:13)∞

0<s+t≤log n

where the ﬁrst inequality follows because m ≤ n.

Now, for terms corresponding to 1 ≤ s + t ≤ log n, we have:

(cid:13)
(cid:13)H s
(cid:13)

s L∗

sUsΛ−(s+t+1)
s
(cid:18)

≤

max
q1∈[m+n]

U (cid:62)

s L∗

sH t
s

(cid:13)
(cid:13)
(cid:13)∞

=

max
q1∈[m+n],q2∈[m+n]

(cid:12)
(cid:12)e(cid:62)
(cid:12)

q1

H s

s L∗

(cid:13)
(cid:13)e(cid:62)
q1

H s

s U ∗
s

(cid:19) (cid:13)
(cid:13)Σ∗
(cid:13)

(cid:13)
(cid:13)2

s(U ∗

s )(cid:62)UsΛ−(s+t+1)
s

U (cid:62)

s U ∗

s Σ∗
s

sUsΛ−(s+t+1)
s
(cid:18)

(cid:13)
(cid:13)
(cid:13)2

max
q2∈[m+n]

U (cid:62)

s L∗

sH t

seq2

(cid:12)
(cid:12)
(cid:12)

(cid:13)
(cid:13)e(cid:62)
q2

H tU ∗
s

(cid:13)
(cid:13)2

(cid:19)

,

(15)

We will now bound the terms, max

. Note from Remark 1.1 that U ∗

(cid:13)
(cid:13)e(cid:62)
q1

H s

s U ∗
s

(cid:13)
(cid:13)2

q1∈[m+n]

s = 1√
2

(cid:20)V ∗
V ∗
U ∗ −U ∗

(cid:21)

. Now, we have

the following cases for H s
s :

H j

s =

(cid:34)(cid:0)H (cid:62)H(cid:1) s
0

2

(cid:35)

0
(cid:0)HH (cid:62)(cid:1) s

2

when s is even H j

s =

(cid:34)
0
H (cid:0)H (cid:62)H(cid:1)(cid:98) s
2 (cid:99)

(cid:35)

H (cid:62) (cid:0)HH (cid:62)(cid:1)(cid:98) s
2 (cid:99)
0

when s is odd

In these two cases, we have:

H s

s U ∗

s = 1√
2

(cid:34)(cid:0)H (cid:62)H(cid:1) s
(cid:0)HH (cid:62)(cid:1) s

(cid:0)H (cid:62)H(cid:1) s
2 V ∗
2 U ∗ − (cid:0)HH (cid:62)(cid:1) s

2 V ∗
2 U ∗

(cid:35)

H s

s U ∗

s = 1√
2

(cid:34)

H (cid:62) (cid:0)HH (cid:62)(cid:1)(cid:98) s
2 (cid:99)
H (cid:0)H (cid:62)H(cid:1)(cid:98) s
2 (cid:99)

U ∗ −H (cid:62) (cid:0)HH (cid:62)(cid:1)(cid:98) s
2 (cid:99)
H (cid:0)H (cid:62)H(cid:1)(cid:98) s
2 (cid:99)
V ∗

V ∗

U ∗

(cid:35)

This leads to the following 4 cases for max

(cid:13)
(cid:13)e(cid:62)
q1

H s

s U ∗
s

(cid:13)
(cid:13)2

:

q1∈[m+n]

for s even

for s odd max
q(cid:48)∈[n]

max
q(cid:48)∈[n]
(cid:13)
(cid:13)
(cid:13)e(cid:62)

q(cid:48)

(cid:13)
2 V ∗(cid:13)
(cid:0)H (cid:62)H(cid:1) s
(cid:13)
(cid:13)
(cid:13)e(cid:62)
(cid:13)2
U ∗(cid:13)
q(cid:48)H (cid:62) (cid:0)HH (cid:62)(cid:1)(cid:98) s
2 (cid:99)
(cid:13)
(cid:13)2

q(cid:48)

max
q(cid:48)∈[m]
(cid:13)
(cid:13)
(cid:13)e(cid:62)

(cid:13)
2 U ∗(cid:13)
(cid:0)HH (cid:62)(cid:1) s
(cid:13)
(cid:13)
(cid:13)e(cid:62)
(cid:13)2
V ∗(cid:13)
q(cid:48)H (cid:0)H (cid:62)H(cid:1)(cid:98) s
2 (cid:99)
(cid:13)
(cid:13)2

max
q(cid:48)∈[m]

Nearly Optimal Robust Matrix Completion

We can now bound the terms in (15) as follows:

(cid:13)
(cid:13)H s
(cid:13)

s L∗

sUsΛ−(s+t+1)
s

U (cid:62)

s L∗

sH t
s

(ζ1)
≤

(cid:13)
(cid:13)
(cid:13)∞

µ2r
m

υs+t (cid:13)
(cid:13)L∗
(cid:13)

sUsΛ−(s+t+1)
s

U (cid:62)

s L∗
s

(cid:13)
(cid:13)
(cid:13)2

(ζ2)
≤

4µ2r
m

υs+t

(cid:18) 2
σ∗
k

(cid:19)s+t−1

≤

4µ2r
m

υ

(cid:18) 1
2

(cid:19)s+t−1

(16)

where (ζ1) follows from the second assumption of the Lemma and the preceding argument and (ζ2) follows from Claim 2
of Lemma 5 and the ﬁnal step follows from our bound on υ.

Finally, note from the Remark 1 that (cid:107)L∗
and combining with (14), the lemma is proved.

s − Ls(cid:107)∞ = (cid:13)

(cid:13)L∗ − L(t+1)(cid:13)

(cid:13)∞. Now, summing up (16) over all 1 ≤ s + t ≤ log n

1. (cid:13)

(cid:13)L∗ − L(t)(cid:13)

In the next lemma, we show that with the threshold chosen in the algorithm, we show an improvement in the estimation of
(cid:101)S∗ by (cid:101)S(t).
Lemma 10. In the tth iterate of the qth stage, assume the following holds:
k+1 + (cid:0) 1
2
≤ ζ (t) ≤ 9
8 η

2. 7
8 η
where σ∗
M (t) and, r and µ are the rank and incoherence of the m × n matrix L∗ respectively. Then we have

k+1 are the k and (k + 1)th singular values of L∗, λk and λk+1 are the k and (k + 1)th singular values of

(cid:0)σ∗
(cid:13)∞ ≤ 2µ2r
(cid:17)z
(cid:16) 1
(cid:17)
σ∗
2
k

k and σ∗

σ∗
k+1 +

σ∗
k+1 +

(cid:16) 1
2

σ∗
k

σ∗
k

(cid:17)z

(cid:1)z

(cid:16)

(cid:17)

(cid:16)

m

(cid:1)

⊆ Supp

(cid:16)

(cid:101)S∗(cid:17)

1. Supp

(cid:16)

(cid:101)S(t)(cid:17)
(cid:13) (cid:101)S(t) − (cid:101)S∗(cid:13)
(cid:13)
(cid:13)∞

(cid:13)
(cid:13)

2.

≤ 8µ2r
m

(cid:0)σ∗

k+1 + (cid:0) 1

2

(cid:1)z

(cid:1)

σ∗
k

Proof. We ﬁrst prove the ﬁrst claim of the lemma. Consider an index pair (i, j) /∈ Supp( (cid:101)S∗).

(cid:12)
(cid:12)Mij − L(t)
(cid:12)

ij

(cid:12)
(cid:12)
(cid:12) ≤

(cid:18)

2µ2r
m

σ∗
k+1 +

(cid:19)z

(cid:19) (ζ1)
≤

σ∗
k

(cid:18) 1
2

16µ2r
7mη

ζ (t)

(ζ2)
≤ ζ (t)

where (ζ1) follows from the second assumption of the lemma and (ζ2) follows from our setting of η = 4µ2r
do not threshold any entry that is not corrupted by (cid:101)S∗.
Now, we prove the second claim of the lemma. Consider an index entry (i, j) ∈ Supp( (cid:101)S∗). Here, we consider two cases:

m . Hence, we

1. The entry (i, j) ∈ Supp( (cid:101)S(t)): Here the entry (i, j) is thresholded. We know that L(t)

ij + (cid:101)S(t)

ij = L∗

ij + (cid:101)S∗

ij from which

(cid:12)
(cid:12) (cid:101)S(t)
(cid:12)

ij − (cid:101)S∗
ij

(cid:12)
(cid:12)
(cid:12) =

(cid:12)
(cid:12)L∗
(cid:12)

ij − L(t)

ij

(cid:12)
(cid:12)
(cid:12) ≤

(cid:13)
(cid:13)

(cid:13)L∗ − L(t)(cid:13)
(cid:13)
(cid:13)∞

2. The entry (i, j) /∈ Supp( (cid:101)S(t)): Here the entry (i, j) is not thresholded. We know that

(cid:12)
(cid:12)
(cid:12)L∗

ij + (cid:101)S∗

ij − L(t)

ij

(cid:12)
(cid:12)
(cid:12) ≤ ζ (t) from

we get

which we get

(cid:12)
(cid:12) (cid:101)S∗
(cid:12)

ij

(ζ2)
≤

(cid:12)
(cid:12) ≤ ζ (t) +
(cid:12)
36µ2r
8m
(cid:18)
8µ2r
m

≤

(cid:12)
ij − L(t)
(cid:12)L∗
(cid:12)
(cid:18)

ij

σ∗
k+1 +
(cid:18) 1
2

σ∗
k+1 +

(cid:12)
(cid:12)
(cid:12)
(cid:18) 1
2
(cid:19)z

(cid:19)z

(cid:19)

σ∗
k

(cid:19)

σ∗
k

(cid:18)

+

2µ2r
m

σ∗
k+1 +

(cid:19)z

(cid:19)

σ∗
k

(cid:18) 1
2

where (ζ2) follows from the second assumption along with our setting of η = 4 µ2r
m .

The above two cases prove the second statement of the lemma.

Nearly Optimal Robust Matrix Completion

We will now prove Lemma 1
Proof of Lemma 1: Recall the deﬁnitions of E1 =

(cid:16)

(cid:101)S∗ − (cid:101)S(t)(cid:17)

, E2 = (cid:0)L(t) − L∗(cid:1) , E3 =

(cid:16)

I −

(cid:17)

PΩq,t
p

(E2 − E1) and

(cid:113) n

β = 2
that the matrix 1

p (cid:107)E2 − E1(cid:107)∞. Recall that H := E1 + E3 From Lemma 4, we have that 1

β E3 satisﬁes Deﬁnition 1. This implies

β (E1 + E3) satisﬁes the conditions of Lemma 14. Now, we have ∀1 ≤ a ≤ (cid:100)log n(cid:101) and ∀i ∈ [n]:

(cid:13)ei(HH (cid:62))aU ∗(cid:13)
(cid:13)

(cid:13)2 = β2a

(cid:32)(cid:18) 1
β

(cid:19) (cid:18) 1
β

H

H

(cid:19)(cid:62)(cid:33)a

U ∗

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)2

ei

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:18) ρn
β

(ζ)
≤ β2a

(cid:107)E1(cid:107)∞ + c log n

(cid:19)2a

(cid:114) r
µ
m

≤ µ

(cid:18)

(cid:114) r
m

(cid:114) n
p

ρn (cid:107)E1(cid:107)∞ + 2c

((cid:107)E1 − E2(cid:107)∞) log n

(cid:19)2a

where (ζ) follows from the application of Lemma 14 along with the incoherence assumption on U ∗. The other statements
of the lemma can be proved in a similar manner by invocations of the different claims of Lemma 14.

(cid:3)

5.2. Algorithm PG-RMC

Proof of Theorem 1: We know that T ≥ log( 20µ2nrσ∗
We know from Lemma 11 that:
(cid:13)∞ ≤ 8µ2r

(cid:13)E(T )(cid:13)

≤ 8µ2r

1. (cid:13)

(cid:1)T −3

(cid:17)

(cid:16)

m

2

(cid:15)

1

kq+1 + (cid:0) 1
σ∗
(cid:16)

2. (cid:13)

(cid:13)L(T ) − L∗(cid:13)

(cid:13)∞ ≤ 2µ2r
Combining this with Lemmas 2 and 7, we get:

kq+1 + (cid:0) 1
σ∗

m

2

kq+1 + (cid:15)

10n

σ∗
kq
(cid:1)T −3 (cid:12)
(cid:12)
(cid:12)σ∗

kq

m σ∗
(cid:12)
(cid:17)
(cid:12)
(cid:12)

≤ 2µ2r

m σ∗

kq+1 + (cid:15)

10n

). Consider the stage q reached at the termination of the algorithm.

(cid:12)
(cid:12)
(cid:12) ≥ σ∗
(cid:12)σkq+1(M (T ))
(cid:12)
(cid:12)

kq+1 −

(cid:18)

1
100

σ∗
kq+1 +

(cid:19)

m(cid:15)
10nµ2r

(17)

When the while loop terminates, ησkq+1

(cid:0)M (T )(cid:1) < (cid:15)

2n , which from (17), implies that σ∗

kq+1 < m(cid:15)

7nµ2r . So we have:

(cid:107)L − L∗(cid:107)∞ =

(cid:13)
(cid:13)

(cid:13)L(T ) − L∗(cid:13)
(cid:13)
(cid:13)∞

≤

2µ2r
m

σ∗
kq+1 +

(cid:15)
10n

≤

(cid:15)
2n

.

We will now bound the number of iterations required for the PG-RMC to converge.

32

(cid:1)q

kq+1 ≤ 17

From claim 2 of Lemma 12, we have σ∗
kq−1+1 ∀q ≥ 1. By recursively applying this inequality, we get
kq+1 ≤ (cid:0) 17
kq+1 < (cid:15)
σ∗
1. We know that when the algorithm terminates, σ∗
σ∗
σ∗
1 is an upper bound for
(cid:17)
(cid:16) 7µ2rσ∗
σ∗
kq+1, an upper bound for the number of iterations is 5 log
. Also, note that an upper bound to this quantity is
(cid:15)
used to partition the samples provided to the algorithm. This happens with probability ≥ 1−T 2n−(10+log α) ≥ 1−n− log α.
This concludes the proof.

7µ2r . Since, (cid:0) 17

32 σ∗

(cid:1)q

(cid:3)

32

1

In the following lemma, we show that we make progress simultaneously in the estimation of both (cid:101)S∗ and L∗ by (cid:101)S(t) and
L(t). We make use of Lemmas 9 and 10 to show progress in the estimation of one affects the other alternatively. We also
emphasize the roles of the following quantities in enabling us to prove our convergence result:

1. (cid:107)H(cid:107)2 - We use Lemma 7 to bound this quantity
2. The analysis of the following 4 quantities is crucial to obtaining error bounds in (cid:107)(cid:107)∞ norm

for j even

for j odd max
q(cid:48)∈[n]

(cid:0)H (cid:62)H(cid:1) j

(cid:13)
(cid:13)
e(cid:62)
max
(cid:13)
q(cid:48)
(cid:13)
q(cid:48)∈[n]
(cid:13)
q(cid:48)H (cid:62) (cid:0)HH (cid:62)(cid:1)(cid:98) j
(cid:13)
2 (cid:99)
e(cid:62)
(cid:13)
(cid:13)

2 V ∗

(cid:13)
(cid:13)
(cid:13)
(cid:13)2
U ∗

(cid:13)
(cid:13)
(cid:13)
(cid:13)2

(cid:0)HH (cid:62)(cid:1) j

(cid:13)
(cid:13)
e(cid:62)
max
(cid:13)
q(cid:48)
(cid:13)
q(cid:48)∈[m]
(cid:13)
q(cid:48)H (cid:0)H (cid:62)H(cid:1)(cid:98) j
(cid:13)
2 (cid:99)
e(cid:62)
(cid:13)
(cid:13)

max
q(cid:48)∈[m]

2 U ∗

(cid:13)
(cid:13)
(cid:13)
(cid:13)2
(cid:13)
(cid:13)
V ∗
(cid:13)
(cid:13)2

We use Lemma 1 to bound this quantity.

Nearly Optimal Robust Matrix Completion

Lemma 11. Let L∗, Ω, (cid:101)S∗ and (cid:101)S(t) satisfy Assumptions 1,2,3 respectively. Then, in the tth iteration of the qth stage of
Algorithm 1, (cid:101)S(t) and L(t) satisfy:

(cid:32)
(cid:12)
(cid:12)σ∗
(cid:12)

7
8

η

kq+1

(cid:12)
(cid:12)
(cid:12) +

(cid:18) 1
2

≤

8µ2r
m

⊆ Supp

(cid:13)
(cid:13)

(cid:13) (cid:101)S(t) − (cid:101)S∗(cid:13)
(cid:13)
(cid:13)∞
(cid:101)S(t)(cid:17)
(cid:33)
(cid:12)
(cid:12)
(cid:12)

(cid:19)t−2 (cid:12)
(cid:12)σ∗
(cid:12)

Supp

(cid:16)

kq

≤ ζ (t+1) ≤

(cid:13)
(cid:13)

(cid:13)L(t) − L∗(cid:13)
(cid:13)
(cid:13)∞

≤

2µ2r
m

(cid:16)

kq+1

(cid:32)
(cid:12)
(cid:12)σ∗
(cid:12)
(cid:101)S∗(cid:17)
,
(cid:32)
(cid:12)
(cid:12)σ∗
(cid:12)

η

9
8
(cid:32)
(cid:12)
(cid:12)σ∗
(cid:12)

kq+1

(cid:12)
(cid:12)
(cid:12) +

(cid:18) 1
2

(cid:19)t−3 (cid:12)
(cid:12)σ∗
(cid:12)

kq

(cid:33)
(cid:12)
(cid:12)
(cid:12)

,

(cid:33)

(cid:12)
(cid:12)
(cid:12)

and

(cid:12)
(cid:12)
(cid:12) +

(cid:18) 1
2

kq+1

(cid:12)
(cid:12)
(cid:12) +

(cid:18) 1
2

(cid:19)t−3 (cid:12)
(cid:12)σ∗
(cid:12)

kq

(cid:19)t−2 (cid:12)
(cid:12)σ∗
(cid:12)
(cid:33)
(cid:12)
(cid:12)
(cid:12)

kq

.

with probability ≥ 1 − ((q − 1)T + t − 1)n−(10+log α) where T is the number of iterations in the inner loop.

Proof. We prove the lemma by induction on both q and t. Recall that E(t) = (cid:101)S∗ − (cid:101)S(t)

Base Case: q = 1 and t = 0
We begin by ﬁrst proving an upper bound on (cid:107)L∗(cid:107)∞. We do this as follows:

(cid:12)
(cid:12)L∗
ij

(cid:12)
(cid:12) =

ku∗
σ∗

ikv∗
jk

≤

σ∗
k

(cid:12)
(cid:12)u∗

ikv∗
jk

(cid:12)
(cid:12) ≤ σ∗
1

(cid:12)
(cid:12)u∗

ikv∗
jk

(cid:12)
(cid:12) ≤

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

r
(cid:88)

k=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

r
(cid:88)

k=1

r
(cid:88)

k=1

µ2r
√
mn

σ∗
1

where the last inequality follows from Cauchy-Schwartz and the incoherence of U ∗. This directly proves the third claim
of the lemma for the base case. Recall, that ζ (0) = ησ∗
1. We now have from the thresholding step and the incoherence
assumption on L∗:

(ζ)
≤ 8µ2r
m

(cid:0)8σ∗
k1

(cid:1) , and

1. (cid:13)

(cid:13)E(0)(cid:13)
(cid:13)∞ ≤ 8µ2r
(cid:101)S(t)(cid:17)
(cid:16)

2 + 2σ∗
m (σ∗
1)
(cid:101)S∗(cid:17)
(cid:16)

⊆ Supp

.

2. Supp

where (ζ) follows from Lemma 12.

Finally, from Lemma 8, we have:

η (cid:0)σ∗

k1+1 + 4σ∗
k1

(cid:1) ≤ ζ (1) = η

(cid:16)

7
8

σk1+1(M (t)) + 4σk1(M (t))

≤

(cid:17)

9
8

η (cid:0)σ∗

k1+1 + 4σ∗
k1

(cid:1)

So the base case of induction is satisﬁed.

Induction over t
We ﬁrst prove the inductive step over t (for a ﬁxed q). By inductive hypothesis we assume that:
a) (cid:13)

(cid:1)t−3

(cid:17)

(cid:16)

σ∗
kq

(cid:13)E(t)(cid:13)
(cid:13)∞ ≤ 8µ2r
(cid:101)S(t)(cid:17)
(cid:16)

m

b) Supp

⊆ Supp

2

kq+1 + (cid:0) 1
σ∗
(cid:101)S∗(cid:17)
(cid:16)
(cid:16)

.

c) (cid:13)

(cid:13)L∗ − L(t)(cid:13)
(cid:13)∞ ≤ 2µ2r
m
(cid:1)t−2 (cid:12)
(cid:12)
(cid:16)(cid:12)
(cid:12) + (cid:0) 1
(cid:12)
(cid:12)
(cid:12)
(cid:12)σ∗
(cid:12)σ∗

kq+1 + (cid:0) 1
σ∗
(cid:12)
(cid:17)
(cid:12)
(cid:12)

kq+1

kq

2

2

d) 7
8 η

(cid:1)t−3

(cid:17)

σ∗
kq

with probability 1 − ((q − 1)T + t − 1)n−(10+log α). Then by Lemma 9, we have:

≤ ζ (t+1) ≤ 9
8 η

(cid:16)(cid:12)
(cid:12)
(cid:12)σ∗

kq+1

(cid:12)
(cid:12) + (cid:0) 1
(cid:12)

2

(cid:1)t−2 (cid:12)
(cid:12)
(cid:12)σ∗

kq

(cid:12)
(cid:12)
(cid:12)

(cid:17)

(cid:13)
(cid:13)

(cid:13)L(t+1) − L∗(cid:13)
(cid:13)
(cid:13)∞

≤

(cid:16)

µ2r
m

σ∗
kq+1 + 20 (cid:107)H(cid:107)2 + 8υ

(cid:17)

(18)

From Lemma 1, we have:

Nearly Optimal Robust Matrix Completion

υ ≤ ρn

+ 8βα log n

(cid:13)
(cid:13)

(cid:13)E(t)(cid:13)
(cid:13)
(cid:13)∞

(cid:32)

(ζ1)
≤

1
100

σ∗
kq+1 +

(cid:18) 1
2

(cid:19)t−3

(cid:33)

σ∗
kq

+ 8βα log n

(cid:32)

(ζ2)
≤

1
50

σ∗
kq+1 +

(cid:18) 1
2

(cid:19)t−3

(cid:33)

σ∗
kq

(19)

where (ζ1) follows from our assumptions on ρ and our inductive hypothesis on (cid:13)
assumption on p and by noticing that (cid:107)D(cid:107)∞ ≤ (cid:13)
From Lemma 7:

(cid:13)L∗ − L(t)(cid:13)

(cid:13)∞ + (cid:13)

(cid:13)E(t)(cid:13)

(cid:13)E(t)(cid:13)

(cid:13)∞ and (ζ2) follows from our

(cid:13)∞. Recall that D = L(t) − L∗ + (cid:101)S(t) − (cid:101)S∗.

(cid:107)H(cid:107)2 ≤

σ∗
kq+1 +

(cid:32)

1
100

(cid:19)t−3

(cid:33)

σ∗
kq

(cid:18) 1
2

(20)

with probability ≥ 1 − n−(10+log α). From Equations (20), (19) and (18), we have:
(cid:13)L∗ − L(t+1)(cid:13)
(cid:13)
(cid:13)∞

σ∗
kq+1 +

2µ2r
m

(cid:18) 1
2

(cid:19)t−2

(cid:13)
(cid:13)

(cid:32)

≤

σ∗
kq

(cid:33)

which by union bound holds with probability ≥ 1 − ((q − 1)T + t)n−(10+log α). Hence, using Lemma 10 and our inductive
hypothesis on ζ (t+1) we have:

1. (cid:13)

(cid:13)E(t+1)(cid:13)
(cid:16)

(cid:13)∞ ≤ 8µ2r
(cid:101)S(t+1)(cid:17)

m

2. Supp

⊆ Supp

(cid:16)

kq+1 + (cid:0) 1
σ∗
(cid:16)
(cid:101)S∗(cid:17)

2

.

(cid:1)t−2

(cid:17)

σ∗
kq

which also holds with probability ≥ 1 − ((q − 1)T + t)n−(10+log α). This concludes the proof for induction over t.
(cid:13)∞ and (cid:13)
Finally, from Lemma 8 and our bounds on (cid:13)

(cid:13)L∗ − L(t+1)(cid:13)

(cid:13)∞, we have:

(cid:13)E(t+1)(cid:13)

(cid:32)
(cid:12)
(cid:12)σ∗
(cid:12)

7
8

η

kq+1

(cid:12)
(cid:12)
(cid:12) +

(cid:18) 1
2

(cid:19)t−1 (cid:12)
(cid:12)σ∗
(cid:12)

kq

(cid:12)
(cid:12)
(cid:12)

(cid:33)

≤ ζ (t+2) ≤

(cid:32)
(cid:12)
(cid:12)σ∗
(cid:12)

9
8

η

kq+1

(cid:12)
(cid:12)
(cid:12) +

(cid:18) 1
2

(cid:19)t−1 (cid:12)
(cid:12)σ∗
(cid:12)

kq

(cid:12)
(cid:12)
(cid:12)

(cid:33)

Induction Over Stages q
We now prove the induction over q. Suppose the hypothesis holds for stage q. At the end of stage q, we have:

(cid:1)T −3

(cid:17)

≤

σ∗
kq

8µ2rσ∗
m

kq +1

+ (cid:15)

10n , and

(cid:16)

kq+1 + (cid:0) 1
σ∗
(cid:101)S∗(cid:17)
(cid:16)

2

.

1. (cid:13)

m

(cid:13)E(T )(cid:13)
(cid:13)∞ ≤ 8µ2r
(cid:101)S(T )(cid:17)
(cid:16)
(cid:12)
(cid:12) + (cid:0) 1
(cid:12)

(cid:16)(cid:12)
(cid:12)
(cid:12)σ∗

2

2. Supp

⊆ Supp

3. 7
8 η

(cid:1)T −2 (cid:12)
(cid:12)
(cid:12)σ∗
with probability ≥ 1 − (qT − 1)n−(10+log α). From Lemmas 2 and 7, we get:

≤ ζ (T +1) ≤ 9
8 η

(cid:1)T −2 (cid:12)
(cid:12)
(cid:12)σ∗

(cid:12)
(cid:12) + (cid:0) 1
(cid:12)

(cid:16)(cid:12)
(cid:12)
(cid:12)σ∗

(cid:12)
(cid:17)
(cid:12)
(cid:12)

kq+1

kq+1

kq

kq

2

(cid:17)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)σkq+1

(cid:16)

M (T )(cid:17)

− σ∗

kq+1

(cid:12)
(cid:12)
(cid:12) ≤ (cid:107)H(cid:107)2 ≤

1
100

(cid:18)

σ∗
kq+1 +

(cid:19)

m(cid:15)
10nµ2r

(21)

with probability 1 − n−(10+log α). We know that ησkq+1

(cid:0)M (t)(cid:1) ≥ (cid:15)

2n which with (21) implies that

(cid:12)
(cid:12)
(cid:12)σ∗

kq+1

(cid:12)
(cid:12) > m(cid:15)
(cid:12)

10nµ2r .

(cid:13)
(cid:13)

(cid:13)L(T +1) − L∗(cid:13)
(cid:13)
(cid:13)∞

(cid:32)

(cid:18)

≤

≤

2µ2r
m

2µ2r
m

σ∗
kq+1 +

σ∗
kq+1 +

(cid:18) 1
2
σ∗
kq+1
2

(cid:19)T −2

(cid:33)

σ∗
kq

≤

(cid:18)

2µ2r
m

σ∗
kq+1 +

(cid:19)

m(cid:15)
20nµ2rn

(cid:19)

≤

(cid:16)

2µ2r
m

2σ∗

kq+1

(cid:17) (ζ4)
≤

(cid:16)

2µ2r
m

(cid:17)

8σ∗

kq+1

Nearly Optimal Robust Matrix Completion

where (ζ4) follows from Lemma 12. By union bound this holds with probability ≥ 1 − qT n−(10+log α).

Now, from Lemma 10 and the inductive hypothesis on ζ T +1, we have through a similar series of arguments as above:

1. (cid:13)

(cid:13)E(0)(cid:13)

2. Supp

(cid:16)

8σ∗

kq+1

(cid:17)

m

(cid:13)∞ ≤ 8µ2r
(cid:101)S(0)(cid:17)
(cid:16)

⊆ Supp

(cid:16)

(cid:101)S∗(cid:17)

which holds with probability ≥ 1 − qT n−(10+log α).
Recall, now that L(0) = L(T +1). Finally, from Lemma 8 and our bounds on (cid:13)

(cid:13)E(0)(cid:13)

(cid:13)∞ and (cid:13)

(cid:13)L(0) − L∗(cid:13)

(cid:13)∞, we have:

7
8

η

(cid:16)(cid:12)
(cid:12)σ∗
(cid:12)

kq+1+1

(cid:12)
(cid:12)
(cid:12) + 4

(cid:12)
(cid:12)σ∗
(cid:12)

kq+1

(cid:17)

(cid:12)
(cid:12)
(cid:12)

≤ ζ (1) ≤

9
8

η

(cid:16)(cid:12)
(cid:12)σ∗
(cid:12)

kq+1+1

(cid:12)
(cid:12)
(cid:12) + 4

(cid:12)
(cid:12)σ∗
(cid:12)

kq+1

(cid:17)

(cid:12)
(cid:12)
(cid:12)

Lemma 12. Suppose at the beginning of the qth stage of algorithm 1:

1. (cid:13)

(cid:13)L∗ − L(0)(cid:13)

(cid:13)∞ ≤

2µ2r
m

(cid:16)

2σ∗

kq−1+1

(cid:17)

2. (cid:13)

(cid:13)E(0)(cid:13)

(cid:13)∞ ≤

8µ2r
m

(cid:16)

2σ∗

kq−1+1

(cid:17)

Then, the following hold:

1. σ∗
kq

≥ 15

32 σ∗

kq−1+1

2. σ∗

kq+1 ≤ 17

32 σ∗

kq−1+1

with probability ≥ 1 − n−(10+log α)

Proof. We know that:

λkq ≤ σ∗
kq

+ (cid:107)H(cid:107)2 ,

λkq−1+1 ≥ σ∗

kq−1+1 − (cid:107)H(cid:107)2 ,

λkq ≥

λkq−1+1
2

Combining the three inequalities, we get:

σ∗
kq

≥

σ∗
kq−1+1 − 3 (cid:107)H(cid:107)2
2

Applying Lemma 7, we get the ﬁrst claim of the lemma.

Similar to the ﬁrst claim, we have:

λkq+1 ≥ σ∗

kq+1 − (cid:107)H(cid:107)2 ,

λkq−1+1 ≤ σ∗

kq−1+1 + (cid:107)H(cid:107)2 ,

λkq+1 ≤

λkq−1+1
2

Again, combining the three inequalities, we get:

σ∗
kq+1 ≤

σ∗
kq−1+1 + 3 (cid:107)H(cid:107)2
2

Another application of Lemma 7 gives the second claim.

Nearly Optimal Robust Matrix Completion

Algorithm 3 (cid:98)L = R-RMC(Ω, PΩ(M ), (cid:15), r, η, σ): Non-convex Robust Matrix Completion
1: Input: Observed entries Ω, Matrix PΩ(M ) ∈ Rm×n, convergence criterion (cid:15), target rank r, thresholding parameter η,

/*Number of inner iterations*/

(cid:15)

upper bound on σ∗
1 σ
2: T ← 10 log 20µ2nrσ
3: Partition Ω into rT + 1 subsets {Ω0} ∪ {Ωq,t : q ∈ [r], t ∈ [T ]} using 2
4: L(0) = 0, ζ (0) ← ησ
5: M (0) ← mn
6: q ← 0
7: while σq+1(M (0)) > (cid:15)
8:
9:
10:
11:

q ← q + 1
for Iteration t = 0 to t = T do

|Ω0| PΩ0(M − HT ζ(M ))

|Ωq,t| PΩq,t(L(t) + S(t) − M )

2ηm do

S(t) = Hζ(PΩq,t(M − L(t)))
M (t) = L(t) − mn
L(t+1) = Pq(M (t))
Set threshold ζ (t+1) ← η

(cid:16)

σq+1(M (t)) + (cid:0) 1

(cid:1)t

2

(cid:17)
σq(M (t))

12:

13:

end for
S(0) = S(T ), L(0) = L(T +1), M (0) = M (T ), ζ (0) = ζ (T +1)

14:
15:
16: end while
17: Return: L(T +1)

5.3. Algorithm R-RMC

/*Projection onto set of sparse matrices*/
/*Gradient Descent Update*/

/*Projected Gradient Descent step*/

Proof of Theorem 2: We know that T ≥ log( 20µ2nrσ∗

1

).

(cid:15)

Consider the stage q reached at the termination of the algorithm. We know from Lemma 13 that:

1. (cid:13)

(cid:13)E(T )(cid:13)

(cid:13)∞ ≤ 8µ2r

m

q+1 + (cid:0) 1
σ∗

2

(cid:1)T −1

(cid:16)

(cid:17)

σ∗
q

≤ 8µ2r

m σ∗

q+1 + (cid:15)
10n

2. (cid:13)

(cid:13)L(T ) − L∗(cid:13)

(cid:13)∞ ≤ 2µ2r

m

q+1 + (cid:0) 1
σ∗

2

(cid:1)T −1

(cid:16)

(cid:17)

σ∗
q

≤ 2µ2r

m σ∗

q+1 + (cid:15)
10n

Combining this with Lemmas 2 and 7, we get:

σq+1(M (T )) ≥ σ∗

q+1 −

σ∗
q+1 +

(cid:18)

1
100

(cid:19)

m(cid:15)
10nµ2r

(22)

When the while loop terminates, ησq+1

(cid:0)M (T )(cid:1) < (cid:15)

2n , which from (22), implies that σ∗

q+1 < m(cid:15)

7nµ2r . So we have:

(cid:107)L − L∗(cid:107)∞ =

(cid:13)
(cid:13)

(cid:13)L(T ) − L∗(cid:13)
(cid:13)
(cid:13)∞

≤

2µ2r
m

|σ∗

kq+1| +

(cid:15)
10n

≤

(cid:15)
2n

.

(cid:3)

As in the case of the proof of Theorem 1, the following lemma shows that we simultaneously make progress in both
the estimation of L∗ and (cid:101)S∗ by L(t) and (cid:101)S(t) respectively. Similar to Lemma 11, we make use of Lemmas 10 and
9 to show how improvement in estimation of one of the quantities affects the other and the other ﬁve terms, (cid:107)H(cid:107)2,
V ∗(cid:13)
V ∗(cid:13)
(cid:13)
(cid:13)
max
(cid:13)2
(cid:13)2
q(cid:48)∈[n]
are analyzed the same way:
Lemma 13. Let L∗, Ω, (cid:101)S∗ and (cid:101)S(t) satisfy Assumptions 1,2,3 respectively. Then, in the tth iteration of the qth stage of

q(cid:48)H (cid:62) (cid:0)HH (cid:62)(cid:1)j

q(cid:48)H (cid:0)H (cid:62)H(cid:1)j

and max
q(cid:48)∈[m]

U ∗(cid:13)
(cid:13)
(cid:13)2

U ∗(cid:13)
(cid:13)
(cid:13)2

(cid:0)HH (cid:62)(cid:1)j

(cid:0)H (cid:62)H(cid:1)j

, max
q(cid:48)∈[m]

, max
q(cid:48)∈[n]

(cid:13)
(cid:13)
(cid:13)e(cid:62)

(cid:13)
(cid:13)
(cid:13)e(cid:62)

(cid:13)
(cid:13)
(cid:13)e(cid:62)

(cid:13)
(cid:13)
(cid:13)e(cid:62)

q(cid:48)

q(cid:48)

Algorithm 3, (cid:101)S(t) and L(t) satisfy:

Nearly Optimal Robust Matrix Completion

(cid:32)

σ∗
q+1 +

(cid:19)t−1

(cid:33)

σ∗
q

,

(cid:18) 1
2

(cid:13)
(cid:13)

(cid:13) (cid:101)S(t) − (cid:101)S∗(cid:13)
(cid:13)
(cid:13)∞
(cid:101)S(t)(cid:17)
(cid:33)

Supp

(cid:16)

(cid:19)t

≤

8µ2r
m

⊆ Supp

(cid:12)
(cid:12)σ∗
q

(cid:12)
(cid:12)

≤ ζ (t+1) ≤

(cid:13)
(cid:13)

(cid:13)L(t) − L∗(cid:13)
(cid:13)
(cid:13)∞

≤

2µ2r
m

(cid:16)

(cid:101)S∗(cid:17)
,
(cid:32)
(cid:12)
(cid:12)σ∗

η

9
8
(cid:32)

σ∗
q+1 +

(cid:12)
(cid:12) +

q+1

(cid:33)

(cid:19)t

(cid:18) 1
2

(cid:12)
(cid:12)σ∗
q

(cid:12)
(cid:12)

and

(cid:19)t−1

(cid:33)

σ∗
q

.

(cid:18) 1
2

(cid:32)
(cid:12)
(cid:12)σ∗

(cid:12)
(cid:12) +

q+1

(cid:18) 1
2

7
8

η

with probability ≥ 1 − ((q − 1)T + t − 1)n−(10+log α) where T is the number of iterations in the inner loop.

Proof. We prove the lemma by induction on both q and t.

Base Case: q = 1 and t = 0
We begin by ﬁrst proving an upper bound on (cid:107)L∗(cid:107)∞. We do this as follows:

(cid:12)
(cid:12)L∗
ij

(cid:12)
(cid:12) =

ku∗
σ∗

ikv∗
jk

≤

(cid:12)
(cid:12)σ∗

ku∗

ikv∗
jk

(cid:12)
(cid:12) ≤ σ∗
1

(cid:12)
(cid:12)u∗

ikv∗
jk

(cid:12)
(cid:12) ≤

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

r
(cid:88)

k=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

r
(cid:88)

k=1

r
(cid:88)

k=1

µ2r
m

σ∗
1

where the last inequality follows from Cauchy-Schwartz and the incoherence of U ∗. This directly proves the third claim
of the lemma for the base case. Recall that ζ (0) = ησ∗
1. We also note that due to the thresholding step and the incoherence
assumption on L∗, we have:

1. (cid:13)

(cid:13)E(0)(cid:13)
(cid:13)∞ ≤ 8µ2r
(cid:16)
(cid:101)S(t)(cid:17)

2 + 2σ∗
m (σ∗
1)
(cid:16)
(cid:101)S∗(cid:17)

⊆ Supp

.

2. Supp

From Lemma 8 and our bounds on E(0) and (cid:13)

(cid:13)L(1) − L∗(cid:13)

(cid:13)∞, we have:

7
8

η (|σ∗

2| + |σ∗

1|) ≤ ζ (1) ≤

η (|σ∗

2| + |σ∗

1|)

9
8

So the base case of induction is satisﬁed.

Induction over t
We ﬁrst prove the inductive step over t (for a ﬁxed q). By inductive hypothesis we assume that:
(cid:17)

(cid:16)

a) (cid:13)

(cid:13)E(t)(cid:13)
(cid:13)∞ ≤ 8µ2r
(cid:101)S(t)(cid:17)
(cid:16)

m

b) Supp

⊆ Supp

|σ∗

2

q+1| + (cid:0) 1
(cid:101)S∗(cid:17)
(cid:16)
(cid:16)

.

(cid:1)t−1

|σ∗
q |

(cid:13)∞ ≤ 2µ2r

m

|σ∗

q+1| + (cid:0) 1

2

(cid:1)t−1

|σ∗
q |

(cid:17)

c) (cid:13)

(cid:13)L∗ − L(t)(cid:13)
(cid:16)(cid:12)
(cid:12)σ∗

q+1

d) 7
8 η

(cid:12)
(cid:12) + (cid:0) 1

2

(cid:1)t (cid:12)

(cid:12)σ∗
q

(cid:12)
(cid:12)

(cid:17)

≤ ζ (t+1) ≤ 9
8 η

(cid:16)(cid:12)
(cid:12)σ∗

q+1

(cid:12)
(cid:12) + (cid:0) 1

2

(cid:1)t (cid:12)

(cid:12)σ∗
q

(cid:12)
(cid:12)

(cid:17)

with probability 1 − ((q − 1)T + t − 1)n−(10+log α).

Then by Lemma 9, we have:

(cid:13)
(cid:13)

(cid:13)L(t+1) − L∗(cid:13)
(cid:13)
(cid:13)∞

≤

µ2r
m

(cid:16)

|σ∗

kq+1| + 20 (cid:107)H(cid:107)2 + 8υ

(cid:17)

(23)

Nearly Optimal Robust Matrix Completion

From Lemma 1, we have:

υ ≤ ρn

+ 8βα log n

(cid:13)
(cid:13)

(cid:13)E(t)(cid:13)
(cid:13)
(cid:13)∞

(cid:32)

(ζ1)
≤

1
100

σ∗
q+1 +

(cid:19)t−1

(cid:33)

σ∗
q

(cid:18) 1
2

+ 8βα log n

(cid:32)

(ζ2)
≤

1
50

σ∗
q+1 +

(cid:19)t−1

(cid:33)

σ∗
q

(cid:18) 1
2

(24)

where (ζ1) follows from our assumptions on ρ and our inductive hypothesis on (cid:13)
assumption on p and by noticing that (cid:107)D(cid:107)∞ ≤ (cid:13)
From Lemma 7:

(cid:13)L∗ − L(t)(cid:13)

(cid:13)∞ + (cid:13)

(cid:13)E(t)(cid:13)

(cid:13)E(t)(cid:13)

(cid:13)∞ and (ζ2) follows from our

(cid:13)∞. Recall that D = L(t) − L∗ + (cid:101)S(t) − (cid:101)S∗.

(cid:107)H(cid:107)2 ≤

(cid:32)

1
100

σ∗
q+1 +

(cid:19)t−1

(cid:33)

σ∗
q

(cid:18) 1
2

(25)

with probability ≥ 1 − n−(10+log α). From Equations (25), (24) and (23), we have:

(cid:13)
(cid:13)

(cid:13)L∗ − L(t+1)(cid:13)
(cid:13)
(cid:13)∞

≤

2µ2r
m

(cid:32)

σ∗
q+1 +

(cid:33)

(cid:19)t

(cid:18) 1
2

σ∗
q

which by union bound holds with probability ≥ 1 − ((q − 1)T + t)n−(10+log α). Hence, using Lemma 10 and the inductive
hypothesis on ζ (t+1) we have:

1. (cid:13)

(cid:13)E(t+1)(cid:13)
(cid:16)

(cid:13)∞ ≤ 8µ2r
(cid:101)S(t+1)(cid:17)

m

2. Supp

⊆ Supp

(cid:16)

2

q+1 + (cid:0) 1
σ∗
(cid:16)
(cid:101)S∗(cid:17)

.

(cid:17)

(cid:1)t

σ∗
q

which also holds with probability ≥ 1 − ((q − 1)T + t)n−(10+log α). This concludes the proof for induction over t.
(cid:13)∞ and (cid:13)
Finally, using Lemma 8 and our bounds on (cid:13)

(cid:13)L(t+1) − L∗(cid:13)

(cid:13)∞, we have:

(cid:13)E(t+1)(cid:13)

(cid:32)
(cid:12)
(cid:12)σ∗

(cid:12)
(cid:12) +

q+1

(cid:18) 1
2

7
8

η

(cid:19)t+1

(cid:33)

(cid:12)
(cid:12)σ∗
q

(cid:12)
(cid:12)

≤ ζ (t+2) ≤

(cid:32)
(cid:12)
(cid:12)σ∗

(cid:12)
(cid:12) +

q+1

(cid:18) 1
2

9
8

η

(cid:19)t+1

(cid:33)

(cid:12)
(cid:12)σ∗
q

(cid:12)
(cid:12)

Induction Over Stages q
We now prove the induction over q. Suppose the hypothesis holds for stage q. At the end of stage q, we have:

1. (cid:13)

m

(cid:13)E(T )(cid:13)
(cid:13)∞ ≤ 8µ2r
(cid:101)S(T )(cid:17)
(cid:16)
(cid:12)
(cid:12) + (cid:0) 1

(cid:16)(cid:12)
(cid:12)σ∗

q+1

2

(cid:16)

2

q+1 + (cid:0) 1
σ∗
(cid:101)S∗(cid:17)
(cid:16)
(cid:17)
(cid:12)
(cid:12)

(cid:12)σ∗
q

(cid:1)T (cid:12)

2. Supp

⊆ Supp

3. 7
8 η

with probability ≥ 1 − (qT − 1)n−(10+log α).

From Lemmas 2 and 7 we get:

(cid:1)T −1

(cid:17)

σ∗
q

≤

8µ2rσ∗

q+1

m

+ (cid:15)
10n

≤ ζ (T +1) ≤ 9
8 η

(cid:16)(cid:12)
(cid:12)σ∗

q+1

(cid:12)
(cid:12) + (cid:0) 1

2

(cid:1)T (cid:12)

(cid:12)σ∗
q

(cid:12)
(cid:12)

(cid:17)

(cid:12)
(cid:12)
(cid:12)σq+1

(cid:16)

M (T )(cid:17)

− σ∗

q+1

(cid:12)
(cid:12)
(cid:12) ≤ (cid:107)H(cid:107)2 ≤

1
100

(cid:18)

σ∗
q+1 +

(cid:19)

m(cid:15)
10nµ2r

(26)

with probability 1 − n−(10+log α). We know that ησq+1

(cid:0)M (t)(cid:1) ≥ (cid:15)

2n which with (26) implies that σ∗

q+1 > m(cid:15)

10nµ2r .

(cid:13)
(cid:13)

(cid:13)L(T +1) − L∗(cid:13)
(cid:13)
(cid:13)∞

(cid:32)

(cid:18)

≤

≤

2µ2r
m

2µ2r
m

σ∗
q+1 +

σ∗
q+1 +

(cid:18) 1
2
σ∗
q+1
2

(cid:19)T

(cid:33)

σ∗
q

≤

(cid:18)

2µ2r
m

σ∗
q+1 +

(cid:19)

m(cid:15)
20µ2rn

(cid:19)

≤

2µ2r
m

(cid:0)2σ∗

q+1

(cid:1)

Nearly Optimal Robust Matrix Completion

By union bound this holds with probability ≥ 1 − qT n−(10+log α).

Now, from Lemma 10 and our inductive hypothesis on ζ (T +1), we have through a similar series of arguments as above:

1. (cid:13)

(cid:13)E(0)(cid:13)
(cid:13)∞ ≤ 8µ2r
(cid:16)
(cid:101)S(0)(cid:17)

m

(cid:1)

(cid:0)2σ∗
q+1
(cid:16)

(cid:101)S∗(cid:17)

⊆ Supp

2. Supp

which holds with probability ≥ 1 − qT n−(10+log α).
Recall, now that L(0) = L(T +1). Finally, from Lemma 8 and our bounds on (cid:13)

(cid:13)E(0)(cid:13)

(cid:13)∞ and (cid:13)

(cid:13)L(0) − L∗(cid:13)

(cid:13)∞, we have:

7
8

η (cid:0)(cid:12)

(cid:12)σ∗

q+2

(cid:12) + (cid:12)
(cid:12)

(cid:12)σ∗

q+1

(cid:12)
(cid:1) ≤ ζ (1) ≤
(cid:12)

η (cid:0)(cid:12)

(cid:12)σ∗

q+2

(cid:12) + (cid:12)
(cid:12)

(cid:12)σ∗

q+1

(cid:1)

(cid:12)
(cid:12)

9
8

5.4. Proof of a generalized form of Lemma 1

Lemma 14. Suppose H = H1 + H2 and H ∈ Rm×n where H1 satisﬁes Deﬁnition 1 (Deﬁnition 7 from (Jain &
Netrapalli, 2015)) and H2 is a matrix with column and row sparsity ρ. Let U be a matrix with rows denoted as
u1, . . . , um and let V be a matrix with rows denoted as v1, . . . , vn. Let eq be the qth vector from standard basis. Let
τ = max{max
i∈[m]

(cid:107)vi(cid:107)}. Then, for 0 ≤ a ≤ log n:

(cid:107)ui(cid:107) , max
i∈[n]

max
q∈[n]
(cid:13)
(cid:13)e(cid:62)
(cid:13)

max
q∈[n]

(cid:13)
(cid:13)e(cid:62)
(cid:13)

q

(cid:0)H (cid:62)H(cid:1)a

V

q H (cid:62) (cid:0)HH (cid:62)(cid:1)a

U

(cid:13)
(cid:13)
(cid:13)2

, max
q∈[m]
(cid:13)
(cid:13)e(cid:62)
(cid:13)

, max
q∈[m]

q

(cid:0)HH (cid:62)(cid:1)a

(cid:13)
(cid:13)e(cid:62)
(cid:13)
q H (cid:0)H (cid:62)H(cid:1)a

U

V

(cid:13)
(cid:13)
(cid:13)2
(cid:13)
(cid:13)
(cid:13)2

(cid:13)
(cid:13)
(cid:13)2

≤ (ρn (cid:107)H2(cid:107)∞ + c log n)2aτ

≤ (ρn (cid:107)H2(cid:107)∞ + c log n)2a+1τ

with probability n−2 log c

4 +4.

Proof. Similar to (Jain & Netrapalli, 2015), we will prove the statement for q = 1 and it can be proved for q ∈ [n] by
taking a union bound over all q. For the sake of brevity, we will prove only the inequality:

(cid:13)
(cid:13)e(cid:62)
(cid:13)

q

max
q∈[n]

(cid:0)H (cid:62)H(cid:1)a

V

(cid:13)
(cid:13)
(cid:13)2

≤ (ρn (cid:107)H2(cid:107)∞ + c log n)2aτ

The rest of the lemma follows by applying similar arguments to the appropriate quantities.

Let ω : [2a] → {1, 2} be a function used to index a single term in the expansion of (H (cid:62)H)a. We express the term as
follows:

We will now ﬁx one such term ω and then bound the length of the following random vector:

(H (cid:62)H)a =

H (cid:62)

ω(2i−1)Hω(2i)

(cid:88)

a
(cid:89)

ω

i=1

vω = e(cid:62)
1

(H (cid:62)

ω(2i−1)Hω(2i))V

a
(cid:89)

i=1

Let α be used to denote a tuple (i, j) of integers used to index entries in a matrix. Let T (i) be used to denote the parity
function computed on i, i.e, 0 if i is divisible by 2 and 1 otherwise. This function indicates if the matrix in the expansion
is transposed or not. We now introduce Bp,q
(i,j), p ∈ {1, 2} which are deﬁned as
follows:

(i,j),(k,l), p ∈ {1, 2}, q ∈ {0, 1} and Ap

Nearly Optimal Robust Matrix Completion

Ap

(i,j) := δi,1(δp,1 + δp,21{(i,j)∈Supp(H2)})

Bp,q

(i,j),(k,l) := (δq,1δj,l + δq,0δi,k)(δp,1 + δp,21{(k,l)∈Supp(H2)})

where δi,j = 1 if i = j and 0 otherwise. We will subsequently write the random vector vω in terms of the individual entries
of the matrices. The role of Bp,q
(i,j) is to ensure consistency in the terms used to describe vω. We will use
hi,α to refer to (Hi)α.

(i,j),(k,l) and Ap

With this notation in hand, we are ready to describe vω.

(cid:88)

vω =

α1,...,α2a
α1(1)=1

Aω(1)
α1

Bω(2),T (2)
α1α2

. . . Bω(2a),T (2a)

α2a−1α2a

hω(1),α1 · · · hω(2a),α2a vα2a(2)

We now write the squared length of vω as follows:

Xω =

(cid:88)

α1,...,α2a,α(cid:48)
α1(1)=1,α(cid:48)

1,...,α(cid:48)
2a
1(1)=1

Aω(1)
α1

Bω(2),T (2)
α1α2

. . . Bω(2a),T (2a)

α2a−1α2a

hω(1),α1 · · · hω(2a),α2a

Aω(1)
α1

Bω(2),T (2)
1α(cid:48)
2

α(cid:48)

. . . Bω(2a),T (2a)
2a−1α(cid:48)

α(cid:48)

2a

hω(1),α(cid:48)

· · · hω(2a),α(cid:48)

(cid:104)vα2a(2), vα(cid:48)

2a(2)(cid:105)

2a

1

We can see from the above equations that the entries used to represent vω are deﬁned with respect to paths in a bipartite
graph. In the following, we introduce notations to represent entire paths rather than just individual edges:

Let α := (α1, . . . , α2a) and

Now, we can write:

ζα := Aω(1)

α1

Bω(2),T (2)
α1α2

. . . Bω(2a),T (2a)

α2a−1α2a

hω(1),α1 . . . hω(2a),α2a

Xω =

(cid:88)

ζαζα(cid:48) (cid:104)vα2a(2), vα(cid:48)

2a(2)(cid:105)

α,α(cid:48)
α1(1)=α(cid:48)

1(1)=1

Calculating the kth moment expansion of Xω for some number k, we obtain:

E[X k

ω] =

(cid:88)

α1,...,α2k

E[ζα1 . . . ζα2k (cid:104)vα1

2a(2), vα2

2a(2)(cid:105) . . . (cid:104)vα2k−1

(2), vα2k

2a(2)(cid:105)]

2a

(27)

l(cid:48) . Additionally, each (s, l) such that ω(l) = 2 is in a separate equivalence class.

We now show how to bound the above moment effectively. Notice that the moment is deﬁned with respect to a collection
of 2k paths. We denote this collection by ∆ := (α1, . . . , α2k). For each such collection, we deﬁne a partition Γ(∆) of
the index set {(s, l) : s ∈ [2k], l ∈ [2a]} where (s, l) and (s(cid:48), l(cid:48)) are in the same equivalence class if ω(l) = ω(l(cid:48)) = 1 and
l = αs(cid:48)
αs
We bound the expression in (27) by partitioning all possible collections of 2k paths based on the partitions deﬁned by them
in the above manner. We then proceed to bound the contribution of any one speciﬁc path to (27) following a particular
partition Γ, the number of paths satisfying that particular partition and ﬁnally, the total number of partitions. Consider a
partition Γ with non-zero contribution to the kth moment. Since, H1 is a matrix with 0 mean, any equivalence class of
Γ containing an index (s, l) such that ω(l) = 1 contains at least two elements (Otherwise, for any ∆ satisfying Γ has 0
contribution to the kth as the element in the singleton equivalence class has mean 0).

We proceed to bound (27) by taking absolute values:

E[X k

ω] ≤

(cid:88)

α1,...,α2k

E[|ζα1 | . . . |ζα2k||(cid:104)vα1

2a(2), vα2

2a(2)(cid:105)| . . . |(cid:104)vα2k−1

(2), vα2k

2a(2)(cid:105)|]

2a

(28)

Nearly Optimal Robust Matrix Completion

We now ﬁx one particular partition and bound the contribution to (28) of all collections of paths ∆ that correspond to a
valid partition Γ.

We construct from Γ a directed multigraph G. The equivalence classes of Γ form the vertex set of G, V (G). There are
4 kinds of edges in G where each type is indexed by a tuple (p, q) where p ∈ {1, 2}, q ∈ {0, 1}. We denote the edge
sets corresponding to these 4 edge types by E(1,0), E(1,1), E(2,0) and E(2,1) respectively. An edge of type (p, q) exists
from equivalence class γ1 to equivalence class γ2 if there exists (s, l) ∈ γ1 and (s(cid:48), l(cid:48)) ∈ γ2 such that l(cid:48) = l + 1, s = s(cid:48),
ω(s(cid:48)) = p and T (l(cid:48)) = q.

The summation in 28 can be written as follows:

E[|ζα1| . . . |ζα2k |
(cid:32) 2k
(cid:89)

≤ τ 2k

(cid:12)
(cid:12)
(cid:12)(cid:104)vα1

2a(2), vα2
2a−1
(cid:89)

(cid:12)
(cid:12)
(cid:12) . . .
2a(2)(cid:105)

(cid:12)
(cid:12)
(cid:12)(cid:104)vα2k−1
2a
(cid:33)

Aω(1)
αs
1

Bω(l+1),T (l+1)

αs

l ,αs

l+1

s=1
(cid:32) 2k
(cid:89)

(ζ1)
≤ τ 2k

l=1

2a−1
(cid:89)

Aω(1)
αs
1

Bω(l+1),T (l+1)

αs

l ,αs

l+1

s=1

l=1

E

(cid:33)

(2), vα2k
(cid:34)(cid:32) 2k
(cid:89)

(cid:12)
(cid:12)
(cid:12)]
2a(2)(cid:105)
2a
(cid:12)
(cid:89)
(cid:12)
(cid:12)hω(l),αs

l

(cid:12)
(cid:12)
(cid:12)

s=1

l=1

(cid:33)(cid:35)

(cid:89)

(cid:89)

1
n

γ∈V1(G)
(cid:33)

γ∈V2(G)

(cid:107)H2(cid:107)∞

=

τ 2k (cid:107)H2(cid:107)w2
∞
nw1

(cid:32) 2k
(cid:89)

s=1

Aω(1)
αs
1

Bω(l+1),T (l+1)

αs

l ,αs

l+1

2a−1
(cid:89)

l=1

where (ζ1) follows from the moment conditions on H1. V1(G) and V2(G) are the vertices in the graph corresponding to
tuples (i, j) such that ω(j) = 1 and ω(j) = 2 respectively and w1 = |V1(G)|, w2 = |V2(G)|.

We ﬁrst consider an equivalence class γ1 such that there exists an index (s, l) ∈ γ1 and l = 1. We form a spanning tree
T1 of all the nodes reachable from γ1 with γ1 as root. We then remove the nodes V (T1) from the graph G and repeat

this procedure until we obtain a set of l trees T1, . . . , Tl with roots γ1, . . . , γl such that

V (Gi) = V (G). This happens

because every node is reachable from some equivalence class which contains an index of the form (s, 1). Also, each of
these trees Ti, ∀ i ∈ [l] is disjoint in their vertex sets. Given this decomposition, we can factorize the above product as
follows:

l
(cid:83)
i=1

E[X k

ω|Γ] ≤

τ 2k (cid:107)H2(cid:107)w2
∞
nw1

l
(cid:89)

(cid:88)

Aω(1)
αγj

(cid:89)

B1,0

αγ αγ(cid:48)

j=1

αγ ,γ∈Tj

{γ,γ(cid:48)}∈E(1,0)(Tj )

(cid:89)

B1,1

αγ αγ(cid:48)

(cid:89)

B2,0

αγ αγ(cid:48)

(cid:89)

B2,1

αγ αγ(cid:48)

(29)

{γ,γ(cid:48)}∈E(1,1)(Tj )

{γ,γ(cid:48)}∈E(2,0)(Tj )

{γ,γ(cid:48)}∈E(2,1)(Tj )

where the inner sum is over all possible assignments to the elements in the equivalence classes of tree Tj.

For a single connected component, we can compute the summation bottom up from the leaves. First, notice that as each
Bi,j

αγ ,αγ(cid:48) is bounded by 1:

(cid:80)
αγ(cid:48)
(cid:80)
αγ(cid:48)

αγ αγ(cid:48) ≤ ρn (cid:80)
B2,1
αγ(cid:48)
αγ αγ(cid:48) = n (cid:80)
B1,1
αγ(cid:48)

B2,0

αγ αγ(cid:48) ≤ ρn
B1,0

αγ αγ(cid:48) = n

Where the ﬁrst two follow from the sparsity of H2. Every node in the tree Tj with the exception of the root has a single
incoming edge. For the root, γj, we have:

Nearly Optimal Robust Matrix Completion

(cid:80)
α1

Aω(1)

α1 ≤ ρn for ω(1) = 2 (cid:80)
α1

Aω(1)

α1 = n for ω(1) = 1

From the above two observations, we have:

(cid:88)

Aω(1)
α1

(cid:89)

B1,0

αγ αγ(cid:48)

(cid:89)

B1,1

αγ αγ(cid:48)

(cid:89)

α1,...,αvj

{γ,γ(cid:48)}∈E(1,0)(Tj )

{γ,γ(cid:48)}∈E(1,1)(Tj )

{γ,γ(cid:48)}∈E(2,0)(Tj )

B2,0

αγ αγ(cid:48)

(cid:89)

{γ,γ(cid:48)}∈E(2,1)(Tj )

B2,1

αγ αγ(cid:48) ≤ (ρn)w2,j nw1,j

where wk,j represents the number of vertices in the jth component which contain tuples (y, z) such that ω(z) = k for
k ∈ {1, 2}.

Plugging the above in (29) gives us

E[X k

ω(Γ)] ≤

τ 2k (cid:107)H2(cid:107)w2
∞
nw1

(ρn)

(cid:80)

j w2,j n

(cid:80)

j w1,j = τ 2k (cid:107)H2(cid:107)w2

∞ (ρn)w2

Let a1 and a2 be deﬁned as |{i : ω(i) = 1}| and |{i : ω(i) = 2}| respectively (Note that w2 = 2a2k).
ming up over all possible partitions (there are at most (2a1k)2a1k of them), we get our ﬁnal bound on E
τ 2k(ρn (cid:107)H2(cid:107)∞)2a2k(2a1k)2a1k.
Now, we bound the probability that ˆXω is too large. Choosing k =
inequality, we obtain:

(cid:108) log n
a1

(cid:109)

and applying the kth moment Markov

Sum-
(cid:105)

as

(cid:104) ˆX k

ω

Pr

(cid:104)(cid:12)
(cid:12)
(cid:12)

ˆXω

(cid:12)
(cid:12) > (c log n)2a1τ 2(ρn (cid:107)H2(cid:107)∞)2a2
(cid:12)

(cid:105)

1
(c log n)2a1τ 2(ρn (cid:107)H2(cid:107)∞)2a2

(cid:19)k

k(cid:21) (cid:18)

(cid:19)2ka1

≤ E

(cid:20)(cid:12)
(cid:12)
ˆXω
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:18) 2ka1
c log n
≤ n−2 log c

≤

4

Taking a union bound over all the 22a possible ω, over values of a from 1 to log n and over the n values of q, and summing
up the high probability bound over all possible values of ω, we get the required result.

5.5. Additional Experimental Results

We detail some additional experiments performed with Algorithm 1 in this section. The experiments were performed on
synthetic data and real world data sets.
Synthetic data. We generate a random matrix M ∈ R2000×2000 in the same way as described in Section 4. In these
experiments our aim is to analyze the behavior of the algorithm in extremal cases. We consider two of such cases : 1)
sampling probability is very low (Figure 3 (a)), 2) number of corruptions is very large (Figure 3 (b)). In the ﬁrst case, we
see that the we get a reasonably good probability of recovery (∼ 0.8) even with very low sampling probability (0.07). In
the second case, we observe that the time taken to recover seems almost independent of the number of corruptions as long
as they are below a certain threshold. In our experiments we saw that on increasing the ρ to 0.2 the probability of recovery
went to 0. To compute the probability of recovery we ran the experiment 20 times and counted the number of successful
runs.

Foreground-background separation. We present results for one more real world data set in this section. We applied
our PG-RMC method (with varying p) to the Escalator video. Figure 4 (a) shows one frame from the video. Figure 4
(b) shows the extracted background from the video by using our method (PG-RMC , Algorithm 1) with probability of
sampling p = 0.05. Figure 4 (c) compares objective function value for different p values.

Nearly Optimal Robust Matrix Completion

(a)

(b)

Figure 3: We run the PG-RMC algorithm with extremal values of sampling probability and fraction of corruptions, and
record the probability with which we recover the original matrix, (a) : time vs probability of recovery for very small values
of sampling probability, (b) : time vs probability of recovery for large number of corruptions (ρn2)

(a)

(b)

(c)

Figure 4: PG-RMC on Escalator video. (a): a video frame (b): an extracted background frame (c): time vs error for
different sampling probabilities; PG-RMC takes 7.3s while St-NcRPCA takes 52.9s

Time(s)0510Prob of recovery00.51n=2000,µ=1,r=5,ρ=0.01log||L∗−ˆL||F≤0.1p = 0.09p = 0.08p = 0.07p = 0.06Time(s)0510Prob of recovery00.51n=2000,µ=1,r=5,p=0.1log||L∗−ˆL||F≤0.1ρ=0.08ρ=0.1ρ=0.18Time(s)0204060log||M−ˆL−ˆS||F-20-1001020µ=1,r=5p = 0.01p = 0.05p = 0.1St-NcRPCA