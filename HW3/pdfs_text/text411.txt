Nonnegative Matrix Factorization for Time Series Recovery
From a Few Temporal Aggregates

Jiali Mei 1 2 Yohann De Castro 1 Yannig Goude 1 2 Georges H´ebrail 2

Abstract
Motivated by electricity consumption reconstitu-
tion, we propose a new matrix recovery method
using nonnegative matrix factorization (NMF).
The task tackled here is to reconstitute electric-
ity consumption time series at a ﬁne temporal
scale from measures that are temporal aggregates
of individual consumption. Contrary to existing
NMF algorithms, the proposed method uses tem-
poral aggregates as input data, instead of matrix
entries. Furthermore, the proposed method is ex-
tended to take into account individual autocorre-
lation to provide better estimation, using a recent
convex relaxation of quadratically constrained
quadratic programs. Extensive experiments on
synthetic and real-world electricity consumption
datasets illustrate the effectiveness of the pro-
posed method.

1. Introduction

In this paper, we propose a new matrix recovery method
using nonnegative matrix factorization (NMF, Lee & Seung
(1999)) where matrix columns represent time series at a
ﬁne temporal scale. Moreover, only temporal aggregates of
these time series are observed.

The method has its motivation in the context of electricity
load balancing, where time series represent electric power
consumption. To avoid failure in the electricity network,
suppliers are typically required by transmission system op-
erators (TSO) to supply as much electricity as their con-
sumers consume at every moment. This mechanism is
called balancing.
In the context of an open electricity
market, all market participants, such as suppliers, utility
traders, and large consumers, have a balance responsibil-
ity: any imbalance caused within the perimeter of a par-

1EDF Lab Paris-Saclay, 91120 Palaiseau, France 2LMO, Univ.
Paris-Sud, CNRS, Universite Paris-Saclay, 91405 Orsay, France.
Correspondence to: Jiali Mei <jiali.mei@u-psud.fr>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

ticipant is billed by the TSO. To calculate the imbalance
caused by a market participant, one needs an estimation
of the consumption and production within its perimeter
at a small temporal scale, for example, half-hourly (RTE
(2014), SVK (2016), REE (2016)).

However, for many customers (for instance residential)
within a perimeter, electricity consumption is not recorded
at that scale. Although smart meter readings may be
recorded locally up to every minute, utility companies often
have very limited access to such data, due to data transmis-
sion and processing costs and/or privacy issues. Following
a ﬁxed schedule, cumulative consumption of each meter is
recorded by the utility company, for instance every day or
every month. By differentiating consecutive readings, the
utility obtains the consumption of a customer between two
reading dates. Currently, TSOs use proportional rules to
reconstitute consumption from these measurements, based
on national consumption proﬁles adjusted by temperature.
In this article, we develop an NMF-based matrix recovery
method providing a solution to consumption reconstitution
from such temporal aggregates.

Recent advances in matrix completion have made it clear
that when a large number of individuals and features are
involved, even partial data could be enough to recover
much of lost information, thanks to the low-rank prop-
erty (Cand`es & Recht, 2009): although the whole data ma-
trix V∗ ∈ RT ×N is only partially known, if V∗ = WH,
where W ∈ RT ×K, H ∈ RK×N , with K much smaller
than both T and N , one could recover V∗ entirely under
some conditions over the sampling process.

In this article, we adress electricity consumption reconsti-
tution as a matrix recovery problem. Consider the electric-
ity consumption of N consumers during T periods. Since
consumption is always positive, the N time series are or-
ganized into a nonnegative matrix V∗ ∈ RT ×N
. An entry
of this matrix, v∗
t,n represents, for example, the electricity
consumption of Consumer n for Period t.

+

Information about consumption is revealed as meter read-
ings which do not correspond to matrix entries but to cumu-
lative sums of each column of V∗: at a meter-reading date
t, we observe that Consumer n has consumed (cid:80)t
i=1 v∗
i,n

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

since the ﬁrst period. Several readings are available for
each consumer.

ativity (Recht et al., 2010; Cand`es & Plan, 2011; Zuk &
Wagner, 2015).

An alternative matrix representation could be to deﬁne en-
tries directly as the cumulative consumption since the ﬁrst
period. Again, this matrix has missing values and a ma-
trix completion algorithm can be applied. However, this
cumulative matrix has increasing columns, which is quite
different from matrices considered in the standard matrix
completion literature, where matrix completion error is typ-
ically bounded by the upper bound on matrix.

We represent meter readings as linear measures on the con-
sumption matrix V∗. Temporal aggregates are derived
from meter readings by differentiating consecutive read-
ings: we will consider these temporal aggregates as ”obser-
vations” in the rest of the paper. We consider D scalar ob-
servations, represented by a data vector a ≡ A(V∗) ∈ RD
+ ,
where A is a D-dimensional linear operator. To recover V∗
from a, we look for a low-rank NMF of V∗: WH (cid:39) V∗,
where W ∈ RT ×K
. The columns of W are
+
K nonnegative factors, which can be interpreted as typical
proﬁles of the N time series, and the columns of H as the
weights of each individual. The problem is formalized as
the minimization of a quadratic loss function under non-
negativity and data constraints:

, H ∈ RK×N

+

min
V, W, H

(cid:96)(V, W, H) = (cid:107)V − WH(cid:107)2
F

s.t. V ≥ 0, W ≥ 0, H ≥ 0, A(V) = a,

(1)
where X ≥ 0 (or x ≥ 0) means that the matrix X (or the
vector x) is element-wise nonnegative.

Note the difference between (1) and another potential esti-
mator,

min
W, H

ˆ(cid:96)(W, H) = (cid:107)A(WH) − a(cid:107)2
2

s.t. W ≥ 0, H ≥ 0,

(2)

The NMF literature is generally focused on full observa-
tion (Gillis, 2014; Alquier & Guedj, 2016), or on matrix
completion (Gillis & Glineur, 2011; Xu & Yin, 2013) Ran-
dom projection measurements are used in an NMF context
in (Pnevmatikakis & Paninski, 2013), where a maximum
likelihood estimator is developed based on a speciﬁc gen-
erative model in neural imaging. The particular form of
measurement operator considered here arises from meter
reading, and can be used in other ﬁelds, such as Internet
trafﬁc matrix estimation (Roughan et al., 2012). Because
of our choice of estimator (1) over estimator (2), we derive
a novel algorithm for this measurement operator, which
has a smaller time complexity than previously studied ones
(more details in Section 2.1).

In real-world applications, global information such as tem-
poral autocorrelation could be available in addition to mea-
surements. Previous approaches combining matrix factor-
ization and autoregressive structure are often focused on
obtaining factors that are more smooth and/or sparse, both
in NMF (Chen & Cichocki, 2005; F´evotte & Idier, 2011;
Smaragdis et al., 2014) and without nonnegativity (Udell
et al., 2016; Yu et al., 2015). Our objective is different from
these studies: we try to further improve the matrix recov-
ery by constraining temporal correlation on individual time
series (not factors). We use a recent convex relaxation of
quadratically constrained quadratic programs (Ben-Tal &
den Hertog, 2013) to deduce a closed-form projection step
in this case.

We propose an algorithm to solve (1) in Section 2.1. To
take into account individual autocorrelation, a second algo-
rithm is proposed in Section 2.2. In Section 3, both algo-
rithms are validated on synthetic and real electricity con-
sumption datasets, compared to a linear benchmark and a
state-of-art matrix completion method.

studied in (Roughan et al., 2012). If V is a solution to (1), it
satisﬁes exactly the measurement constraint, but is approx-
imately low-rank, while WH, a solution to (2) is exactly
of low rank, but only matches the measurements approxi-
mately. Since in our application, the estimated time series
matrix is to be used for billing, the match to metering data
is essential. Therefore, we use (1) in this work.

2. Reconstitution of time series with NMF

2.1. Iterative algorithm with simplex projection

We represent temporal aggregation by a linear operator A.
For each 1 ≤ d ≤ D, the d-th measurement on X, A(X)d,
is the sum of several consecutive rows on one column of
X, that is,

1.1. Prior works

The measurement operator A is a special instance of the
trace regression model (Rohde & Tsybakov, 2011) which
generalizes the matrix completion setting. In matrix com-
pletion, each measurement is exactly one entry. Various
forms of linear measurements other than matrix completion
have been considered for matrix recovery without nonneg-

A(X)d =

(cid:88)

xt,n,

(t,n)∈Id

where Id = {(t, n)|t0(d)+1 ≤ t ≤ t0(d)+h(d), n = nd},
is the index set over h(d) consecutive periods of Con-
sumer nd, starting from Period t0(d) + 1. Each measure-
ment covers a disjoint index set. All entries of X are not
necessarily involved in the measurements.

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

A block Gauss-Seidel algorithm (Algorithm 1) is used to
solve (1). We alternate by minimizing (cid:96)(V, W, H) over
W, H or V, keeping the other two matrices ﬁxed. Meth-
ods from classical NMF problems are used to update W
and H (Kim et al., 2014). In the implementation, we use
two variants that seem similarly efﬁcient (more details in
Section 3): Hierarchical Alternating Least Squares (HALS,
Cichocki et al. (2007)), and a matrix-base NMF solver with
Nesterov-type acceleration (NeNMF, Guan et al. (2012)).

When W and H are ﬁxed, the optimization problem on
V is equivalent to D simplex projection problems, one for
each scalar measurement. For 1 ≤ d ≤ D, we have to
solve

min
vId

(cid:107)vId −

t0(d)+h(d)
(cid:88)

t=t0(d)+1

wthnd (cid:107)2

s.t. vId ≥ 0, v(cid:48)
Id

1 = ad.

(3)

The simplex projection algorithm introduced by Chen &
Ye (2011) solves this subproblem efﬁciently. Deﬁne the
operator, PA, as the orthogonal projection into the simplex
A ≡ {X ∈ RT ×N
|A(X) = a}. A is the intersection
of the afﬁne subspace {X ∈ RT ×N |A(X) = a} and the
ﬁrst orthant. Projector PA encodes the measurement data
a = A(V∗). In Algorithm 1, we apply PA to a working
value of V in order to obtain its projection in A.

+

Contrary to previously studied algorithms (Roughan et al.,
2012), by choosing estimator (1) over (2), the simplex pro-
jection step is separated from the classical NMF update
steps in our algorithm. Instead of multiplying the rank and
the complexity introduced by the number of measurements,
we have an algorithm whose complexity is the sum of the
two. In cases where the number of measurements is large,
this difference can be crucial. 1

Algorithm 1 Block coordinate descent for NMF from tem-
poral aggregates
input PA, 1 ≤ K ≤ min{T, N }

Initialize W0, H0 ≥ 0, V0 = PA(W0H0), i = 0
while Stopping criterion is not satisﬁed do

Wi+1 = Update(Wi, Hi, Vi)
Hi+1 = Update(Wi+1, Hi, Vi)
Vi+1 = PA(Wi+1Hi+1)
i = i + 1

end while

output Vi ∈ A, Wi ∈ RT ×K

, Hi ∈ RK×N

+

+

A classical stopping criterion in the NMF literature is based
on Karush-Kuhn-Tucker (KKT) conditions on (1) (Gillis,

1This intuition is conﬁrmed by the comparison of Algorithm 1
and our implementation of the algorithm proposed in (Roughan
et al., 2012).

2014, Section 3.1.7). We calculate

R(W)i,j = |(WH − V)H(cid:48))i,j|1Wi,j (cid:54)=0,
and R(H)i,j = |(W(cid:48)(WH − V))i,j|1Hi,j (cid:54)=0.

The algorithm is stopped if (cid:107)R(W)(cid:107)2
for a small threshold (cid:15) > 0.

F + (cid:107)R(H)(cid:107)2

F ≤ (cid:15),

Convergence to a stationary point has been proved for past
NMF solvers with the full observation or the matrix com-
pletion setting (Guan et al. (2012); Kim et al. (2014)). Our
algorithms have similar convergence property. Although
the subproblems on W and H do not necessarily have
unique optimum, the projection of V attains a unique min-
imizer. By Grippo & Sciandrone (2000, Proposition 5), the
convergence to a stationary point is guaranteed.

Algorithm 1 can be generalized to other types of measure-
ment operators A, as long as a projection into the simplex
deﬁned by the data constraint A(X) = a and the positivity
constraint can be efﬁciently computed.

2.2. From autocorrelation constraint to penalization

In addition to the measurements in a, we have some prior
knowledge on the temporal autocorrelation of the individu-
als. To take into account information about autocorrelation,
we add a penalization term to the original matrix recovery
problem, replacing (1) by:

min
V,W,H

(cid:107)V − WH(cid:107)2

F − λ

v(cid:48)

n∆ρn vn

N
(cid:88)

n=1

s.t. V ≥ 0, W ≥ 0, H ≥ 0, A(V) = a,

(4)
where λ ≥ 0 is a single ﬁxed penalization parameter, and
∆ρn is a symmetric matrix precised shortly after. In the
rest of this section, we ﬁrst show by Theorem 1, that with
an appropriately chosen value of λ, adding the penalization
term v(cid:48)
n∆ρnvn is equivalent to impose that the temporal
autocorrelation of vn to be at least equal to ρn, a prior
threshold. Then we modify the Algorithm 1 to solve this
penalized problem.

For 1 ≤ n ≤ N , suppose that the lag-1 autocorrelation of
Individual n’s time series is at least equal to a threshold ρn
(e.g. from historical data, excluded from observed tempo-
ral aggregates), that is,

T −1
(cid:88)

t=1

T
(cid:88)

t=1

v2
t,n.

vt+1,nvt,n ≥ ρn

(5)

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

Notice that with the lag matrix,

∆ =

1
0

0

0
0

0











:
:
0 0

0
1

0
. . .
...

...
...
. . .
. . .
0


0
0






1

0

:

,

t=1 vt+1,nvt,n = v(cid:48)

we have (cid:80)T −1
n∆vn. Deﬁne ∆ρ ≡ ∆ +
∆(cid:48) − 2ρI, for a threshold −1 ≤ ρ ≤ 1. Inequality (5) is
then equivalent to

Imposing (6) would require one to solve, at each iteration,
N quadratically constrained quadratic programs (QCQP)
of the form:

v(cid:48)

n∆ρn vn ≥ 0.

min
x
s.t.

||x − x0||2

x(cid:48)Sx ≥ 0,

where S is a general symmetric matrix, not necessarily
semi-deﬁnite positive. This means that the QCQP is in gen-
eral a non-convex problem. Let δ be the vector of eigenval-
ues of ∆. By eigendecomposition, S = U(cid:48)DU. where the
matrix U is orthogonal. The entries of δ are the diagonal
entries of D. The following theorem justiﬁes the choice of
penalization term in (4), by showing with an appropriate λ,
adding this penalization term is equivalent to imposing the
autocorrelation constraint (5).
Theorem 1. Suppose that δ1, the largest eigenvalue of S,
is strictly positive. Suppose that z0 ≡ Ux0 has no zero
component. Then there exists 0 ≤ λ < 1
, that veriﬁes
δ1
(cid:80)T
2(1−λδt)2 = 0, so that x∗ ≡ (I − λS)−1x0 is an

t=1 δt

z2
0,t

optimal solution of (7).

Proof. We follow Ben-Tal & den Hertog (2013) to obtain
a convex relaxation of (7).

Deﬁne z ≡ Ux, z0 ≡ Ux0, yt ≡ 1
Recall that δ1 > 0, and that ∀t, 1 ≤ t ≤ T , z0,t (cid:54)= 0.

2 z2

t , ∀1 ≤ t ≤ T .

Problem (7) is equivalent to the non-convex problem

min
y,z

1(cid:48)y − z(cid:48)

0z

1
2

1
2

Now consider its convex relaxation

min
y,z

1(cid:48)y − z(cid:48)

0z

s.t. − δ(cid:48)y ≤ 0,

z2
t − yt ≤ 0,

∀1 ≤ t ≤ T.

By Ben-Tal & den Hertog (2013, Theorem 3), if (z∗, y∗) is
an optimal solution of (9), and if 1
t , ∀1 ≤ t ≤

t )2 = y∗

2 (z∗

(6)

(7)

(8)

(9)

T , then (z∗, y∗) is also an optimal solution of (8), which
makes x∗ = U(cid:48)z∗ an optimal solution of (7).

2 ˆz2

look for such a solution to (9) by exam-
We will
ining its ﬁrst-order conditions of optimality.
Prob-
lem (9) is convex, and it veriﬁes the Slater condition:
∃(ˆy, ˆz), −δ(cid:48) ˆy < 0, 1
t < ˆyt, ∀1 ≤ t ≤ T . This is true,
because δ1 > 0. We could choose an arbituary value of
ˆy1 > 0 and strictly positive but small values for other
components of ˆy so as to have −δ(cid:48) ˆy < 0, and ˆz = 0.
Thus, Problem (9) always has an optimal solution, because
the objective function is coercive over the constraint. This
shows the existence of (z∗, y∗).

Now we show that 1
2 (z∗
conditions of (9) are veriﬁed by (z∗, y∗).
there is some dual variable λ ≥ 0, µ ∈ RT

t )2 = y∗

t , ∀1 ≤ t ≤ T . The KKT
In particular,

+ that veriﬁes,

1 − λδ − µ = 0,
−δ(cid:48)y∗ ≤ 0,
λδ(cid:48)y∗ = 0,
t = 0,

(z∗

t )2 − y∗

−z0,t + µtz∗
1
2
1
(z∗
2

t )2 − y∗

∀1 ≤ t ≤ T,

t ≤ 0,

∀1 ≤ t ≤ T,

µt(

t ) = 0,

∀1 ≤ t ≤ T.

(10)

(11)

(12)

(13)

(14)

(15)

Since z0,t (cid:54)= 0, we have µt (cid:54)= 0, z∗
t = 1
by (13). Therefore, by (15), y∗

z0,t, ∀1 ≤ t ≤ T

t = 1
µt
t )2, ∀1 ≤ t ≤ T .
2 (z∗

By (10), the values of µt = 1 − λδt can be deduced from
that of λ. Since µ > 0, we obtain that λ < 1
δ1

.

t = z0,t
By (13), z∗
1−λδt
U(cid:48)z∗ = U(cid:48)(I − λD)−1z∗
solution for (7).

, ∀1 ≤ t ≤ T . This shows that x∗ =
0 = (I − λS)−1x0 is an optimal

Theorem 1 shows that with a well chosen λ, the constraint
in (7) can be replaced by a penalization.

There are in fact two cases. Either x0 veriﬁes the con-
straint, in which case λ = 0, and x∗ = x0 is the solution.
Otherwise, λ > 0. We replug the values of

y∗
t =

(z∗

t )2 =

1
2

z2
0,t
2(1 − λδt)2

T
(cid:88)

t=1

δtz2
0,t

2(1 − λδt)2 = 0.

When W and H are ﬁxed, the subproblem of (4) on V can

s.t. − δ(cid:48)y ≤ 0,

z2
t = yt,

∀1 ≤ t ≤ T.

back into (12), and obtain that λ veriﬁes

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

be separated into N constrained problems of the form,

(cid:107)x − x0(cid:107)2 − λx(cid:48)∆ρn x,

min
x
s.t. Anx = cn,
x ≥ 0,

(16)

where x0 is the n-th column of WH, cn is the observa-
tions on the n-th column, and An is a matrix which encodes
the measurement operator over that column. The following
theorem shows how to solve this problem.

Theorem 2. Suppose that S is a symmetric matrix with
eigenvalues δ, and λ1 > 0. Suppose A ∈ Rm,l a full-rank
matrix with m ≤ l, x0 ∈ Rl, c ∈ Rm, λ ≥ 0. Deﬁne
Q ≡ (I − λS)−1A(cid:48)(A(I − λS)−1A(cid:48))−1. If λ < 1
, then
δρ,1
Qc + (I − QA)(I − λS)−1x0 is a minimizer of

(cid:107)x − x0(cid:107)2 − λx(cid:48)Sx,

min
x
s.t. Ax = c,

(17)

Proof. Let l be the dimension of c. Deﬁne IC as the indi-
cator function for the constraint of (17), that is

IC(x) = 0, if Ax = c,
and IC(x) = +∞, if Ax (cid:54)= c.

Problem (17) is then equivalent to

min
x

F (x) ≡

1
2

1
2

(cid:107)x − x0(cid:107)2 −

λx(cid:48)Sx + IC(x).

(18)

The subgradient of (18) is ∂F (x) = {x − x0 − λSx −
A(cid:48)(cid:15)|(cid:15) ∈ Rl}. When λ < 1
, (18) is convex. Therefore,
δ1
x∗ is a minimizer if and only if 0 ∈ ∂F (x), and Ax∗ = c.
That is, ∃(cid:15) ∈ Rl,

(I − λS)x∗ − x0 − A(cid:48)(cid:15) = 0,
Ax∗ = c.

The vector (cid:15) thereby veriﬁes A(I − λS)−1(x0 + A(cid:48)(cid:15)) = c.
The l-by-l matrix A(I − λS)−1A(cid:48) is invertible, because
l is smaller than m, and A is of full rank (because each
measurement covers disjoint periods). Therefore,

(cid:15) = (A(I − λS)−1A(cid:48))−1(c − A(I − λS)−1x0),
x∗ = (I − λS)−1(x0 + A(cid:48)(cid:15))

= Qc + (I − QA)(I − λS)−1x0.(cid:3)

In our particular problem, the eigenvalues of ∆ρn are

δρn,t = 2 cos(

π) − 2ρn,

t
T + 1

with t taking every value from 1 to T . This means that for
most of the autocorrelation threshold that we could need to

impose (−1 ≤ ρn ≤ 1), ∆ρn has both strictly positive and
strictly negative eigenvalues, allowing the above theorems
to apply.
Both I − λ∆ρn and An(I − λ∆ρn )−1A(cid:48)
n are invertible
with λ < δρn,1. The matrix inversion only needs to be
done once for each individual. After computing Qn ≡ (I−
λ∆ρn )−1A(cid:48)
n)−1, Qncn and (I −
QnAn)(I − λ∆ρn )−1 for each n, we use Algorithm 2 to
solve (4).

n(An(I − λ∆ρn )−1A(cid:48)

Algorithm 2 Block coordinate descent for NMF from tem-
poral aggregates and autocorrelation penalty
input ρn, An, Qn, Qncn, ∀1 ≤ n ≤ N, and 1 ≤ K ≤

min{T, N }
Initialize W0, H0 ≥ 0, V0 = PA(W0H0), i = 0
while Stopping criterion is not satisﬁed do

Wi+1 = Update(Wi, Hi, Vi)
Hi+1 = Update(Wi+1, Hi, Vi)
for all 1 ≤ n ≤ N do

vi+1
=
n
λ∆ρn )−1Wi+1hi+1

n )+

(Qncn + (I − QnAn)(I −

end for
i = i + 1

end while

output Vi ∈ A, Wi ∈ RT ×K

, Hi ∈ RK×N

+

+

Choosing λ An optimal value of λ could be calculated.
Substituting the values of y∗ in (12), shows that the optimal
λ is a root of the polynomial (cid:80)T
2(1−λδρ,t)2 . The
root-ﬁnding is too expensive to perform at every iteration.
However, the optimal λ veriﬁes

t=1 δρ,t

z2
0,t

0 < λ <

1
δρ,1

,

where δρ,1 = 2 cos( 1
T +1 π) − 2ρ is the biggest eigen-
value of ∆ρ. This gives us a good enough idea about how
large a λ to use. In the numerical experiments, we chose
λ = min(1,
) in the penalization when the con-
straint in (7) is active, and λ = 0 (no penalization) when
the constraint is veriﬁed by x0.

1
2 maxn δρn,1

3. Experimental results

We use one synthetic dataset and three real-world elec-
tricity consumption datasets to evaluate the proposed al-
gorithms.
In each dataset, the individual autocorrelation
is calculated on historical data from the corresponding
datasets, not used for evaluation.

• Synthetic data: 20 independent Gaussian processes
with Matern covariance function (shifted to be non-
negative) are sampled over 150 periods to form the

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

factor matrix W. A 20-by-120 weight matrix H is
generated by sampling from a standard normal dis-
tribution truncated at 0, independantly for each entry.
The data matrix is obtained as W×H (T = 150, N =
120). This matrix is exactly of rank 20.

electricity

consumption

• French
(proprietary
dataset):
daily consumption of 636 medium-
voltage feeders gathering each around 1,500 con-
sumers based near Lyon in France during 2012
(T = 365, N = 636).

• Portuguese

electricity consumption (Trindade,
2016) daily consumption of 370 Portuguese clients
during 2014 (T = 365, N = 370).

• Electricity consumption of small Irish compa-
nies (Commission for Energy Regulation, Dublin,
2011a;b) daily consumption of 426 small Irish com-
panies during 200 days in 2010 (T = 200, N = 426).

For each individual in a dataset, we generate observations
by selecting a number of observation periods. The tem-
poral aggregates are the sum of the time series between
two consecutive observation periods. The observation pe-
riods are chosen in two possible ways: periodically (at reg-
ular intervals with the ﬁrst observation period sampled at
random), or uniformly at random. The regular intervals
for periodic observations are p ∈ {2, 3, 5, 7, 10, 15, 30}.
This is motivated by the real application where meter read-
ings are recorded regularly. With random observations,
we use sampling rates that are equivalent to the regular
intervals. That is, the number of observations D veriﬁes
T N = 1
D
p ∈ {0.5, 0.33, 0.2, 0.14, 0.1, 0.07, 0.03}.
We apply the following methods to recover the data matrix
from each set of sampled observations:

• interpolation Temporal aggregates are distributed

equally over the covered periods.

• softImpute As an alternative method, we apply a
state-of-art matrix completion algorithm to complete
the cumulative matrix. The observed entries are the
cumulative values of the column from the ﬁrst period
to the observation dates. We use a nuclear-norm min-
imization algorithm, implemented in the R package,
softImpute (Mazumder et al. (2010)), to complete the
cumulative consumption matrix, before differentiating
each column to obtain recovered matrix. To choose
the thresholding parameter, we use the warm start pro-
cedure documented in softImpute.

• HALS, and NeNMF These are the proposed matrix
recovery algorithms using two classical W and H
update implementations: HALS, and NeNMF. When

1
2 maxn δρn ,1

autocorrelation penalization is used, we choose λ =
), as explained in the previous sec-
min(1,
tion. The rank used in proposed algorithms is chosen
by a 5-fold cross validation procedure: we split the
observations randomly into 5 folds, and apply the al-
gorithm to 4 of the 5 folds with ranks 2 ≤ K ≤ 30.
We then calculate the (cid:96)2-distance between the tempo-
ral aggregates on the recovered matrix with the 1-fold
holdout. Repeating this procedure onto the 5 folds
separately, we choose the rank which minimizes the
average (cid:96)2-distance, to perform the algorithm on all
observations.

With a recovered matrix V obtained in an algorithm
run, we compute the relative root-mean-squared error
(RRMSE):

RRMSE(V, V∗) =

(cid:107)V − V∗(cid:107)F
(cid:107)V∗(cid:107)F

.

Each experiment (dataset, sampling scheme, sampling rate,
recovery method, unpenalized or penalized) is run three
times, and the average RRMSE is reported in Figure 1. The
ﬁgure is zoomed to show the RRMSE of the proposed al-
gorithms. Much higher error rates for reference methods
are sometimes not shown.

On sample sets with random observation periods (lower
panel), proposed methods (HALS and NeNMF, blue and
purple lines), whether unpenalized (solid lines) or penal-
ized (dashed lines), out-performs the interpolation bench-
mark (red solid lines) by large in all datasets. This is espe-
cially the case when the sampling rate is small, i.e. when
the task is more difﬁcult. On the Irish dataset (lower panel,
furthest to the right), penalized HALS and NeNMF (dashed
blue and purple lines) are an improvement to unpenalized
HALS and NeNMF when the sampling rate is low.

With periodic observations (upper panel), the RRMSE is
higher for every method. Proposed unpenalized methods,
HALS and NeNMF (blue and purple solid lines) are equiv-
alent to interpolation benchmark (red solid lines) for syn-
thetic data, but sometimes worse for real datasets. Real
electricity consumption has signiﬁcant weekly periodicity,
which is poorly captured by observations at similar peri-
ods. However, this shortcoming of the unpenalized method
is more than compensated for by the penalization (dashed
blue and purple lines).

We notice that penalized HALS and NeNMF consistently
outperform interpolation with both observation schemes.
This makes penalized methods particularly useful for the
application of electricity consumption reconstituion, where
it may be costly to install a random observation scheme,
or to change the current periodic observation scheme to a
random one.

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

Figure 1. Mean RRMSE of the recovered matrices over three separate runs over the four datasets. On the samples with random ob-
servation periods, proposed methods (HALS and NeNMF, blue and purple lines, both penalized and unpenalized) out-performs the
interpolation benchmark (solid red line). On the samples with regular observation periods, unpenalized HALS and NeNMF (solid blue
and purple lines) are similar to the interpolation benchmark, whiled penalized HALS and NeNMF (dashed blue and purple lines) are an
important improvement. The softImpute method (solid green line) only has comparable performance in two of the datasets, in the easiest
task (50% sampling rate at random periods). In most cases, RRMSE of softImpute is larger than 100%.

It is also interesting to note that the rank chosen by the
cross validation procedure is higher in higher sampling rate
scenarios (Figure 2). This shows that the cross validation
procedure is able to relax the rank constraint when more
information is available in the data.

The traditional matrix completion method seems to fail in
this application: softImpute (green solid lines) only has
comparable results to interpolation or proposed methods in
two of the four datasets, with 50% sampling rate in the ran-
dom sampling scheme, which is the easiest case. In most
cases, softImpute has an RRMSE much larger than 100%,
and thus is not shown in the graphic. This indicates that
the cumulative matrix considered in this application does
not verify assumptions which guarantee matrix completion
success.

4. Perspectives

Motivated by a new industrial application, we extended
NMF to use temporal aggregates as input data, by adding
a projection step into NMF algorithms. With appropriate
projection algorithms, this approach could be further gen-
eralized to other types of data, such as disaggregating spa-
tially aggregated data, or general linear measures. When
such information is available, we introduce a penalization
on individual autocorrelation, which improves the recovery
performance of the base algorithm. This component can be
generalized to larger lags (with a matrix ∆ with 1’s fur-
ther off the diagonal), or multiple lags (by adding several
lag matrices together). It is also possible to generalize this
approach to other types of expert knowledge through addi-
tional constraints on V.

SyntheticFrenchPortugueseIrish0.000.250.500.751.000.000.250.500.751.00periodicrandom0.10.20.30.40.50.10.20.30.40.50.10.20.30.40.50.10.20.30.40.5Sampling rate (DTN)RRMSEalgorithminterpolationsoftImputeHALSNeNMFpenalizedunpenalizedpenalizedNonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

Figure 2. The rank chosen by the cross validation procedure generally increases with the sampling rate, for the four datasets. This shows
that procedure is able to relax the rank constraint when more information is available in the data.

Acknowledgements

We thank Jean-Marc Aza¨ıs for his input and the anonymous
reviewers for pointing out applications with similar prob-
lem settings.

References

Alquier, Pierre and Guedj, Benjamin. An Oracle Inequality
for Quasi-Bayesian Non-Negative Matrix Factorization.
axXiv preprint arXiv:1601.01345, 2016.

Ben-Tal, Aharon and den Hertog, Dick. Hidden conic
quadratic representation of some nonconvex quadratic
optimization problems. Mathematical Programming,
143(1-2):1–29, 2013. doi: 10.1007/s10107-013-0710-8.

Cand`es, Emmanuel J. and Plan, Yaniv. Tight Oracle In-
equalities for Low-Rank Matrix Recovery From a Min-
IEEE
imal Number of Noisy Random Measurements.
Transactions on Information Theory, 57(4):2342–2359,
2011. doi: 10.1109/TIT.2011.2111771.

Cand`es, Emmanuel J. and Recht, Benjamin. Exact Matrix
Completion via Convex Optimization. Foundations of

Computational Mathematics, 9(6):717–772, 2009. doi:
10.1007/s10208-009-9045-5.

Chen, Yunmei and Ye, Xiaojing. Projection Onto A Sim-

plex. arXiv preprint arXiv:1101.6081, 2011.

Chen, Zhe and Cichocki, Andrzej. Nonnegative ma-
trix factorization with temporal smoothness and/or spa-
tial decorrelation constraints. Laboratory for Advanced
Brain Signal Processing, RIKEN, Tech. Rep, 68, 2005.

Cichocki, Andrzej, Zdunek, Rafal, and Amari, Shun-ichi.
Hierarchical ALS algorithms for nonnegative matrix and
In Independent Component
3D tensor factorization.
Analysis and Signal Separation, pp. 169–176. Springer,
2007.

Commission for Energy Regulation, Dublin. Electricity
smart metering customer behaviour trials ﬁndings report.
2011a.

Commission for Energy Regulation, Dublin. Results of
electricity coast-beneﬁt analysis, customer behaviour tri-
als and technology trials commission for energy regula-
tion. 2011b.

SyntheticFrenchPortugueseIrish5101520255101520periodicrandom0.10.20.30.40.50.10.20.30.40.50.10.20.30.40.50.10.20.30.40.5Sampling rate (DTN)Rank chosen by cross validationalgorithmHALSNeNMFNonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

Roughan, M., Zhang, Y., Willinger, W., and Qiu, L. Spatio-
Temporal Compressive Sensing and Internet Trafﬁc Ma-
trices (Extended Version). IEEE/ACM Transactions on
Networking, 20(3):662–676, June 2012. doi: 10.1109/
TNET.2011.2169424.

RTE.

Balance Responsible Entity System.
//clients.rte-france.com/lang/an/
clients_producteurs/services_clients/
dispositif_re.jsp, May 2014.

http:

Smaragdis, Paris, F´evotte, C´edric, Mysore, Gautham J.,
Mohammadiha, Nasser, and Hoffman, Matthew. Static
and Dynamic Source Separation Using Nonnegative
IEEE Signal Process-
Factorizations: A uniﬁed view.
ing Magazine, 31(3):66–75, 2014. doi: 10.1109/MSP.
2013.2297715.

SVK.

Balance responsibility.

http://www.svk.
se/en/stakeholder-portal/Electricity-
market/Balance-responsibility/, October
2016.

Trindade, Artur. UCI Maching Learning Repository -
ElectricityLoadDiagrams20112014 Data Set. http:
//archive.ics.uci.edu/ml/datasets/
ElectricityLoadDiagrams20112014, 2016.

Udell, Madeleine, Horn, Corinne, Zadeh, Reza, and Boyd,
Stephen. Generalized Low Rank Models. Foundations
and Trends in Machine Learning, 9(1), 2016. doi: 10.
1561/2200000055.

Xu, Yangyang and Yin, Wotao. A Block Coordinate De-
scent Method for Regularized Multiconvex Optimization
with Applications to Nonnegative Tensor Factorization
and Completion. SIAM Journal on Imaging Sciences, 6
(3):1758–1789, 2013. doi: 10.1137/120887795.

Yu, Hsiang-Fu, Rao, Nikhil, and Dhillon, Inderjit S. High-
dimensional Time Series Prediction with Missing Val-
ues. arXiv preprint arXiv:1509.08333, 2015.

Zuk, Or and Wagner, Avishai. Low-Rank Matrix Recovery
In Pro-
from Row-and-Column Afﬁne Measurements.
ceedings of The 32nd International Conference on Ma-
chine Learning, pp. 2012–2020, 2015.

F´evotte, C´edric and Idier, J´erˆome. Algorithms for nonneg-
ative matrix factorization with the beta-divergence. Neu-
ral Computation, 23(9):2421–2456, 2011.

Gillis, Nicolas. The why and how of nonnegative ma-
trix factorization. Regularization, Optimization, Kernels,
and Support Vector Machines, 12:257, 2014.

Gillis, Nicolas and Glineur, Franc¸ois. Low-rank matrix ap-
proximation with weights or missing data is NP-hard.
SIAM Journal on Matrix Analysis and Applications, 32
(4):1149–1165, 2011.

Grippo, Luigi and Sciandrone, Marco. On the conver-
gence of the block nonlinear Gauss–Seidel method un-
der convex constraints. Operations Research Letters, 26
(3):127–136, 2000.

Guan, Naiyang, Tao, Dacheng, Luo, Zhigang, and Yuan,
Bo. NeNMF: An Optimal Gradient Method for Nonneg-
ative Matrix Factorization. IEEE Transactions on Signal
Processing, 60(6):2882–2898, 2012. doi: 10.1109/TSP.
2012.2190406.

Kim, Jingu, He, Yunlong, and Park, Haesun. Algorithms
for nonnegative matrix and tensor factorizations: A uni-
ﬁed view based on block coordinate descent framework.
Journal of Global Optimization, 58(2):285–319, 2014.

Lee, Daniel D. and Seung, H. Sebastian. Learning the parts
of objects by non-negative matrix factorization. Nature,
401(6755):788–791, 1999.

Mazumder, Rahul, Hastie, Trevor, and Tibshirani, Robert.
Spectral regularization algorithms for learning large in-
Journal of machine learning re-
complete matrices.
search, 11(Aug):2287–2322, 2010.

Pnevmatikakis, Eftychios A and Paninski, Liam. Sparse
nonnegative deconvolution for compressive calcium
imaging: Algorithms and phase transitions. In Burges,
C. J. C., Bottou, L., Welling, M., Ghahramani, Z., and
Weinberger, K. Q. (eds.), Advances in Neural Informa-
tion Processing Systems 26, pp. 1250–1258. Curran As-
sociates, Inc., 2013.

Recht, Benjamin, Fazel, Maryam, and Parrilo, Pablo A.
Guaranteed minimum-rank solutions of linear matrix
equations via nuclear norm minimization. SIAM review,
52(3):471–501, 2010.

REE.

Balance responsible party.

https://www.

esios.ree.es/en/glossary\#letterB,
2016.

Rohde, Angelika and Tsybakov, Alexandre B. Estima-
tion of high-dimensional low-rank matrices. The Annals
of Statistics, 39(2):887–930, 2011. doi: 10.1214/10-
AOS860.

