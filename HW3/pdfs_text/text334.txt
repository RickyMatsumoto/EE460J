Appendix: Understanding Black-box Predictions via Inﬂuence Functions

Pang Wei Koh 1 Percy Liang 1

A. Deriving the inﬂuence function Iup,params

For completeness, we provide a standard derivation of the
inﬂuence function Iup,params in the context of loss minimiza-
tion (M-estimation). This derivation is based on asymp-
totic arguments and is not fully rigorous; see van der Vaart
(1998) and other statistics textbooks for a more thorough
treatment.
Recall that ˆθ minimizes the empirical risk:

R(θ) def=

L(zi, θ).

(1)

1
n

n
(cid:88)

i=1

Next, since ˆθ(cid:15),z → ˆθ as (cid:15) → 0, we perform a Taylor expan-
sion of the right-hand side:

0 ≈

(cid:104)
∇R(ˆθ) + (cid:15)∇L(z, ˆθ)
+
(cid:105)
(cid:104)
∇2R(ˆθ) + (cid:15)∇2L(z, ˆθ)

(cid:105)

∆(cid:15),

where we have dropped o((cid:107)∆(cid:15)(cid:107)) terms.

Solving for ∆(cid:15), we get:

(cid:104)
∇2R(ˆθ) + (cid:15)∇2L(z, ˆθ)

∆(cid:15) ≈ −
(cid:104)
∇R(ˆθ) + (cid:15)∇L(z, ˆθ)

(cid:105)

.

(cid:105)−1

(6)

(7)

We further assume that R is twice-differentiable and
strictly convex in θ, i.e.,

Since ˆθ minimzes R, we have ∇R(ˆθ) = 0. Keeping only
O((cid:15)) terms, we have

def= ∇2R(ˆθ) =

Hˆθ

∇2

θL(zi, ˆθ)

(2)

1
n

n
(cid:88)

i=1

exists and is positive deﬁnite. This guarantees the existence
of H −1

, which we will use in the subsequent derivation.

ˆθ

The perturbed parameters ˆθ(cid:15),z can be written as

ˆθ(cid:15),z = arg min
θ∈Θ

{R(θ) + (cid:15)L(z, θ)} .

(3)

Deﬁne the parameter change ∆(cid:15) = ˆθ(cid:15),z − ˆθ, and note that,
as ˆθ doesn’t depend on (cid:15), the quantity we seek to compute
can be written in terms of it:

dˆθ(cid:15),z
d(cid:15)

=

d∆(cid:15)
d(cid:15)

.

(4)

Since ˆθ(cid:15),z is a minimizer of (3), let us examine its ﬁrst-
order optimality conditions:

0 = ∇R(ˆθ(cid:15),z) + (cid:15)∇L(z, ˆθ(cid:15),z).

(5)

1Stanford University, Stanford, CA. Correspondence to:
Pang Wei Koh <pangwei@cs.stanford.edu>, Percy Liang <pli-
ang@cs.stanford.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

∆(cid:15) ≈ − ∇2R(ˆθ)−1∇L(z, ˆθ)(cid:15).

(8)

Combining with (2) and (4), we conclude that:

dˆθ(cid:15),z
d(cid:15)

(cid:12)
(cid:12)
(cid:12)(cid:15)=0

∇L(z, ˆθ)

= −H −1

ˆθ
def= Iup,params(z).

(9)

(10)

B. Inﬂuence at non-convergence

Consider a training point z. When the model parameters
˜θ are close to but not at a local minimum, Iup,params(z) is
approximately equal to a constant (which does not depend
on z) plus the change in parameters after upweighting z and
then taking a single Newton step from ˜θ. The high-level
idea is that even though the gradient of the empirical risk at
˜θ is not 0, the Newton step from ˜θ can be decomposed into
a component following the existing gradient (which does
not depend on the choice of z) and a second component
responding to the upweighted z (which Iup,params(z) tracks).

(cid:80)n

Let g def= 1
i=1 ∇θL(zi, ˜θ) be the gradient of the em-
n
pirical risk at ˜θ; since ˜θ is not a local minimum, g (cid:54)= 0.
After upweighting z by (cid:15), the gradient at ˜θ goes from
g (cid:55)→ g + (cid:15)∇θL(z, ˜θ), and the empirical Hessian goes from
θL(z, ˜θ). A Newton step from ˜θ therefore
H˜θ (cid:55)→ H˜θ + (cid:15)∇2
changes the parameters by:

N(cid:15),z

def= −

(cid:104)
H˜θ + (cid:15)∇2

θL(z, ˜θ)

(cid:105)−1 (cid:104)

(cid:105)
g + (cid:15)∇θL(z, ˜θ)

.

(11)

Appendix: Understanding Black-box Predictions via Inﬂuence Functions

(cid:16)

(cid:17)
g + (cid:15)∇θL(z, ˜θ)

Ignoring terms in (cid:15)g, (cid:15)2, and higher, we get N(cid:15),z ≈
−H −1
. Therefore, the actual change
˜θ
due to a Newton step N(cid:15),z is equal to a constant −H −1
g
(that doesn’t depend on z) plus (cid:15) times Iup,params(z) =
−H −1
˜θ

∇θL(z, ˜θ) (which captures the contribution of z).

˜θ

References

van der Vaart, A. W. Asymptotic statistics. Cambridge

University Press, 1998.

