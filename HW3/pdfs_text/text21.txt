Follow the Compressed Leader:
Faster Online Learning of Eigenvectors and Faster MMWU

Zeyuan Allen-Zhu * 1 Yuanzhi Li * 2

Abstract

√

is fundamental

The online problem of computing the top eigen-
to machine learning.
vector
The famous matrix-multiplicative-weight-update
(MMWU) framework solves this online prob-
lem and gives optimal regret. However, since
MMWU runs very slow due to the computa-
tion of matrix exponentials, researchers proposed
the follow-the-perturbed-leader (FTPL) frame-
d worse than
work which is faster, but a factor
the optimal regret for dimension-d matrices. We
propose a follow-the-compressed-leader frame-
work which, not only matches the optimal regret
of MMWU (up to polylog factors), but runs no
slower than FTPL. Our main idea is to “com-
press” the MMWU strategy to dimension 3 in
the adversarial setting, or dimension 1 in the
stochastic setting. This resolves an open ques-
tion regarding how to obtain both (nearly) opti-
mal and efﬁcient algorithms for the online eigen-
vector problem.

1 Introduction

Finding leading eigenvectors of symmetric matrices is one
of the most primitive problems in machine learning. In this
paper, we study the online variant of this problem, which
is a learning game between a player and an adversary (Nie
et al., 2013; Kotłowski & Warmuth, 2015; Dwork et al.,
2014; Garber et al., 2015; Abernethy et al., 2015).

Online Eigenvector Problem. The player plays T unit-
norm vectors w1, . . . , wT ∈ Rd in a row; after playing wk,
the adversary picks a feedback matrix Ak ∈ Rd×d that is

*Equal contribution .

Future version of this paper shall
be found at https://arxiv.org/abs/1701.01722.
1Microsoft Research 2Princeton University. Correspondence
to: Zeyuan Allen-Zhu <zeyuan@csail.mit.edu>, Yuanzhi Li
<yuanzhil@cs.princeton.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

symmetric and satisﬁes 0 (cid:22) Ak (cid:22) I.1 Both these assump-
tions are for the sake of simplicity and can be relaxed.2 The
player then receives a gain
w(cid:62)

k Akwk = Ak • wkw(cid:62)

k ∈ [0, 1] .

The regret minimization problem asks us the player to de-
sign a strategy to minimize regret, that is, the difference
between the total gain obtained by the player and that by
the a posteriori best ﬁxed strategy u ∈ Rd:

minimize max
u∈Rd

(cid:80)T

k=1Ak • (uu(cid:62) − wkw(cid:62)
k )

= λmax

(cid:0)A1 + · · · + AT ) −

w(cid:62)

k Akwk .

T
(cid:88)

k=1

The name comes from the fact that the player chooses only
vectors in a row, but wants to compete against the leading
eigenvector in hindsight. To make this problem meaning-
ful, the feedback matrix Ak, is not allowed to depend on
wk but can depend on w1, . . . , wk−1.

1.1 Known Results

The most famous solution to the online eigenvector prob-
lem is the matrix multiplicative-weight-update (MMWU)
method, which has also been used towards efﬁcient algo-
rithms for SDP, balanced separators, Ramanujan sparsi-
ﬁers, and even in the proof of QIP = PSPACE.

MMWU. At iteration k, deﬁne Wk = exp(ηΣk−1)
Tr exp(ηΣk−1)
where Σk−1 := A1 +· · ·+Ak−1 and η > 0 is the learning
rate. Then, compute its eigendecomposition

Wk = exp(ηΣk−1)

Tr exp(ηΣk−1) = (cid:80)d

j=1 pj · yjy(cid:62)
j

where vectors yj are normalized eigenvectors. Now, the
MMWU strategy instructs the player to choose wk = yj

1We denote by A (cid:23) B spectral dominance that is equivalent

to saying that A − B is positive semideﬁnite (PSD).

2Firstly, all the results cited and stated in this paper, after scal-
ing, generalize to the scenario when the eigenvalues of Ak are
in the range [l, r] for arbitrary l, r ∈ R. For notational simplic-
ity, we have assumed l = 0 and r = 1 in this paper. Secondly,
if Ak is not symmetric or even rectangular, classical reductions
can turn such a problem into an equivalent online game with only
symmetric matrices (see Sec 2.1 of (Garber et al., 2015)).

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

√

√

each with probability pj. The best choice η =
T
T log d) (Orecchia,
yields a total expected regret O(
2011), and this is optimal up to constant (Arora et al.,
2012). It requires some additional, but standard, effort to
turn this into a high-conﬁdence result.

log d/

√

Unfortunately, the per-iteration running time of MMWU is
at least O(dω) due to eigendecomposition, where dω is the
complexity for multiplying two d × d matrices.3

MMWU-JL.
Some researchers also use the Johnson-
Lindenstrauss (JL) compression to reduce the dimension
of Wk from MMWU to make it more efﬁciently com-
putable (Peng & Tangwongsan, 2012; Allen-Zhu et al.,
2016; 2015; Lee & Sun, 2015). Speciﬁcally, they compute
a sketch matrix Y = W1/2
k Q using a random Q ∈ Rd×m,
and then use YY(cid:62) to approximate Wk. If the dimension
m is (cid:101)O(1/σ2), this compression incurs an average regret
loss of σ. We call this method MMWU-JL for short.4
T ), one must
Unfortunately, to maintain a total regret (cid:101)O(
let σ ≈ T −1/2. Therefore, JL compresses the matrix expo-
nential to dimension (cid:101)O(T ), and is only useful when T ≤ d.

√

FTPL. Researchers also study the follow-the-perturbed-
leader (FTPL) strategy (Kotłowski & Warmuth, 2015;
Dwork et al., 2014; Garber et al., 2015; Abernethy et al.,
2015). Most notably, Garber, Hazan and Ma (Garber
et al., 2015) proposed to compute an (approximate) lead-
ing eigenvector of the matrix Σk−1 + rr(cid:62) at iteration k,
where r is a random vector whose norm is around
Unfortunately, the total regret of FTPL is (cid:101)O(
is a factor
ing only when T ≥ d. This factor
realized in practice, see Figure 1.

dT ), which
d worse than the optimum regret, and interest-
d loss can indeed be

dT .

√

√

√

√

1.2 Our Main Results

We propose a follow-the-compressed-leader (FTCL) strat-
egy that, at a high level, compresses the MMWU strategy to
dimension m = 3 as opposed to dimension m = (cid:101)Θ(T ) in
MMWU-JL. Our FTCL strategy has signiﬁcant advantages
over previous results because:

√

• FTCL has regret (cid:101)O(

T ) which is optimal up to poly-

√

log factors (as opposed to

d in FTPL).

• Each iteration of FTCL is dominated by solving a log-

arithmic number of linear systems.

Since solving linear systems is generally no slower than
computing eigenvectors or matrix exponentials, the per-

3In fact, it is known that eigendecomposition has complexity
O(dω) when all the eigenvalues are distinct, and could possibly
go up to O(d3) when some eigenvalues are equal (Pan & Chen,
1999).

4Through the paper, we use the (cid:101)O notation to hide polyloga-

rithmic factors in T, d and 1/ε if applicable.

iteration complexity of FTCL is no slower than FTPL, and
much faster than MMWU and MMWU-JL. We shall make
this comparison more explicit in Section 3.

1.3 Our Side Result: Stochastic Online Eigenvector

We also study the special case of the online eigenvector
problem where the adversary is stochastic, meaning that
A1, . . . , AT are chosen i.i.d. from a common distribution
whose expectation equals some matrix B, independent of
the player’s actions. For this problem,

• Garber et al. (Garber et al., 2015) showed a block power
method gives a total regret O((cid:112)T log(dT )), and runs
in O(nnz(ΣT )) time per iteration. (We denote nnz(M)
the time to multiply M to a vector.)

• Shamir (Shamir, 2016) showed Oja’s algorithm5 has
√
d

dT log(T )), which is a factor

√

a total regret O(
worse than optimum.

√

In this paper, we show that Oja’s algorithm in fact only has
T log d) for this stochastic setting, which
a total regret O(
√
log d factor. Most importantly, the k-th
is optimal up to a
iteration of Oja’s runs in only O(nnz(Ak)) time.

Example. Since in low-rank or sparse cases it usually
satisﬁes nnz(ΣT ) = d2 and nnz(Ak) = O(d), our result
can be faster than block power method by a factor O(d).

Our proof relies on a compression view of Oja’s algorithm
which compresses MMWU to dimension m = 1. Our
proof is one-paged, indicating that FTCL might be a bet-
ter framework of designing online algorithms for matrices.

1.4 Our Results in a More Reﬁned Language
Denoting by λ := 1
T λmax(A1 + · · · AT ), we have λ ≤ 1
according to the normalization Ak (cid:22) I.
In general, the
smaller λ is, the better a learning algorithm should behave.
In the previous subsections, we have followed the tradi-
tion and discussed our results and prior works assuming the
worst possibility of λ. This has indeed simpliﬁed notations.

√

λT ).

If λ is much smaller than 1, our complexity bounds can
be improved to quantities that depend on λ. We call this
the λ-reﬁned language. At a high level, for our FTCL, in
both the adversarial and stochastic settings, the total regret
√
T ) to (cid:101)O(
improves from (cid:101)O(
We have an information-theoretic lower bound of Ω(
λT )
for the total regret in this λ-reﬁned language, see full ver-
sion. This lower bound even holds for the stochastic prob-
lem, even when the matrices Ak are of rank 1.
As for prior work, it has been recorded that (cf. Theorem
3.1 of (Allen-Zhu et al., 2015)) the MMWU and MMWU-
JL methods have total regret O(
λT log d). The block

√

√

5Here is a simple description of Oja’s algorithm: beginning
with a random Gaussian vector u ∈ Rd, at each iteration k,
choose wk to be (I+ηAk−1) · · · (I+ηA1)u after normalization.

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

(a) random

(b) diagonal

(c) diagonal+rotation

Figure 1: We generate synthetic data to verify that the total regret of FTPL can indeed be poorer than MMWU or our FTCL. We explain
how matrices Ak are chosen in Appendix A. We have d = 100 and the x-axis represents the number of iterations.

Paper

MMWU

MMWU-JL(T ≤ d only)

FTPL (T ≥ d only)

this paper

block power method

this paper

Total Regret

Time Per Iteration

Minimum Total Time
for ε Average Regreta

√

√

√

√

(cid:101)O(
(cid:101)O(
(cid:101)O(
(cid:101)O(

T )

T )

dT )

T )

√

√

T )

T )

(cid:101)O(
(cid:101)O(

at least O(dω)
Mexp × (cid:101)O(T )
Mev ×1

(cid:1)

ε2

(cid:101)O(cid:0) dω
(cid:101)O(cid:0) 1
(cid:101)O(cid:0) d1.5
Theorem 3 (cid:101)O(cid:0) 1
(cid:101)O(cid:0) 1

ε4.5 nnz(Σ)(cid:1)
ε3.5 nnz(Σ)(cid:1)
ε2.5 nnz(Σ)(cid:1) and
ε2.5 nnz(Σ)

Theorem 1&2 Mlin × (cid:101)O(1)

↓ stochastic online eigenvector only ↓
O(cid:0)nnz(Σ)(cid:1)
Theorem 4 O(cid:0)nnz(A)(cid:1)

(cid:101)O(cid:0) 1
Theorem 4 (cid:101)O(cid:0) 1

ε2 nnz(Σ)(cid:1)
ε2 nnz(A)(cid:1)

3
4 nnz(A)

1

4 + 1

ε2 nnz(Σ)(cid:1)

Table 1: Comparison of known methods for the online eigenvector problem. We denote by nnz(M) the time needed to multiply M to a

vector, by Σ = A1 + · · · + AT , and by nnz(A) = maxk∈[T ]

(cid:8)nnz(Ak)(cid:9) ≤ nnz(Σ).

• Mexp is the time to compute e−M multiplied with a vector, where M ∈ Rd×d satisﬁes 0 (cid:22) M (cid:22) (cid:101)O(T 1/2) · I.
• Mev is the time to compute the leading eigenvector of matrix M to multiplicative accuracy O(T −3/2d1/2) ∈ (0, 1).
• Mlin is the time to solve a linear system for matrix M ∈ Rd×d, where M is PSD and of condition number ≤ (cid:101)O(T 1/2).
• If using iterative methods, the worst-case values Mev, Mexp, Mlin are

Mev = (cid:101)O(cid:0) min{T

3

4 d− 1

4 nnz(Σ), dω}(cid:1) ≥ Mexp = (cid:101)O(cid:0) min{T

1

4 nnz(Σ), dω}(cid:1) ≥ Mlin = (cid:101)O(cid:0) min{min{d, T

1

4 }nnz(Σ), dω}(cid:1) ,

where dω is the time needed to multiply two d × d matrices.
(cid:101)O(cid:0)T

4 + nnz(Σ)(cid:1).

3
4 nnz(A)

1
4 nnz(Σ)

1

If using stochastic iterative methods, Mlin is at most

aThe total time complexity of the ﬁrst Tε rounds where Tε is the earliest round to achieve an ε average regret.

√

power method (for the stochastic setting) has total regret
λT ), by modifying the proof in (Garber et al., 2015).
(cid:101)O(
To the best of our knowledge, FTPL has not been analyzed
in the λ-reﬁned language. We compare with prior work in
Table 2 in the appendix for this λ-reﬁned language.

1.5 Other Related Works

The multiplicative weight update (MWU) method is a sim-
ple but extremely powerful algorithmic tool that has been
repeatedly discovered in theory of computation, machine
learning, optimization, and game theory (see for instance
the survey (Arora et al., 2012) and the book (Cesa-Bianchi
Its natural matrix extension, matrix-
& Lugosi, 2006)).
multiplicative-weight-update (MMWU) (Orecchia, 2011),
has been used towards efﬁcient algorithms for solving
semideﬁnite programs (Arora & Kale, 2007; Allen-Zhu

et al., 2016; Peng & Tangwongsan, 2012), balanced separa-
tors (Orecchia et al., 2012), Ramanujan sparsiﬁers (Allen-
Zhu et al., 2015; Lee & Sun, 2015), and even in the proof of
QIP = PSPACE (Jain et al., 2011). Some authors also refer
to MMWU as the follow-the-regularized-leader strategy or
FTRL for short, because MMWU can be analyzed from a
mirror-descent view with the matrix entropy function as its
regularizer.

√

For the online eigenvector problem, if the feedback ma-
dT ) total regret of
trices Ak are only of rank-1, the (cid:101)O(
FTPL can be improved to (cid:101)O(d1/4T 1/2). This is ﬁrst shown
by Dwork et al. (Dwork et al., 2014) and independently
by Kotłowski and Warmuth (Kotłowski & Warmuth, 2015).
Abernethy et al. showed FTPL strategies can be analyzed
using a FTRL framework (Abernethy et al., 2014).

010203040500200040006000800010000Total RegretFTPLthis paperMMWU051015200200040006000800010000Total RegretFTPLthis paperMMWU0501001500200040006000800010000Total RegretFTPLthis paperMMWUFollow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

Researchers also put efforts to understand high-rank vari-
ants of the online eigenvector problem. Nie et al. stud-
ied the high-rank variant using MMWU (Nie et al., 2013),
but their per-iteration complexity is also high due to eigen-
decomposition. Some authors study a very different on-
line model for computing the top k eigenvectors (Boutsidis
et al., 2015; Karnin & Liberty, 2015): they wish to output
O(k · poly(1/ε)) vectors instead of k but with a good PCA
reconstruction error.

The stochastic online eigenvector problem is related but
different from streaming PCA (Hardt & Price, 2014; Allen-
Zhu & Li, 2016b). In streaming PCA, we are given i.i.d.
random matrices with an expectation B and asked to ﬁnd a
unit vector w with large w(cid:62)Bw in the end, without worry-
ing about the per-iteration gain. The cited papers use dif-
ferent techniques from ours and do not imply our result on
stochastic online eigenvector.

For the most efﬁcient ofﬂine eigenvectors algorithms, we
refer interested readers to our paper (Allen-Zhu & Li,
2016a) (for PCA / SVD) and (Allen-Zhu & Li, 2017) (for
CCA and generalized eigendecomposition).

1.6 Roadmap

We introduce notations in Section 2, and compare the
per-iteration complexity of FTCL to prior work in
Section 3. We discuss high-level intuitions and techniques
in Section 4. We introduce a new trace inequality in
Section 5, and state our main FTCL result for an oblivi-
ous adversary in Section 6. We extend it to the adversarial
setting and discuss how to implement FTCL fast in the full
version of this paper. Finally, in Section 8 we provide our
FTCL result for a stochastic adversary.

Our results are stated directly in the λ-reﬁned language.

2 Notations and Preliminaries
Deﬁne Σk := (cid:80)k
i=1 Ai for every k = 0, 1, . . . , T . Since
each Ak is positive semi-deﬁnite (PSD), we can ﬁnd Pk ∈
Rd×d such that Ak = PkP(cid:62)
k ; we only use Pk for anal-
ysis purpose only. Given two matrices A, B ∈ Rd×d,
we write A • B := Tr(A(cid:62)B). We write A (cid:23) B if
A, B are symmetric matrices and A − B is PSD. We write
[A]i,j the (i, j)-th entry of A. We use (cid:107)M(cid:107)2 to denote
the spectral norm of a matrix M. We use nnz(M) to de-
note time needed to multiply matrix M ∈ Rd×d with an
arbitrary vector in Rd. In particular, nnz(M) is at most d
plus the number of non-zero elements in M. We denote
(cid:8)nnz(Ak)(cid:9).
nnz(A) := maxk∈[T ]
Suppose x1, · · · , xt ∈ R are drawn i.i.d. from the standard
Gaussian N (0, 1), then χ = (cid:80)t
i has a chi-squared
distribution of t-degree freedom. χ−1 is called inverse-chi-
squared distribution of t-degree freedom. It is known that
E[χ−1] = 1

i=1 x2

t−2 for t ≥ 3.

3 Detailed Comparison to Prior Work

We compare the per-iteration complexity of our results
more closely to prior work.

In the stochastic setting, Oja’s method runs in time
nnz(Ak) for iteration k, and therefore is clearly faster than
the block power method which runs in time nnz(Σk).
In the adversarial setting, it is clear that the per-iteration
complexities of FTPL and FTCL are no greater than
MMWU, because computing the leading eigenvector and
the matrix inversion are both faster than computing the full
eigendecomposition. In the rest of this section, we compare
MMWU-JL, FTPL and FTCL more closely. They respec-
tively have per-iteration complexities
(cid:101)O(T ) × Mexp, 1 × Mev,

(cid:101)O(1) × Mlin

and

where
• In MMWU-JL, we denote by Mexp the time needed for
computing exp(ηΣk−1/2) multiplied to a vector. Re-
call that η = (cid:101)Θ(T −1/2).

• In FTPL, following the tradition, we denote by Mev
the time needed for computing the top eigenvector of
Σk−1 + rr(cid:62), where the norm of r is O(

dT ).

√

• In FTCL, we denote by Mlin the time needed for solving
a linear system with matrix M = cI − ηΣk−1, where
M (cid:23) 1

e I and η = (cid:101)Θ(T −1/2).

For exact computations, one may generally derive that
Mexp ≥ Mev ≥ Mlin. However, for large-scale applications,
one usually applies iterative methods for the three tasks. It-
erative methods utilize matrix sparsity, and have running
times that depend on matrix properties.

Worst-case Complexity. We compute that:
• Mexp in the worst case is (cid:101)O(min{T 1/4nnz(ΣT ), dω}).
The ﬁrst is because if using Chebyshev approximation,
one can compute exp(ηΣk−1/2) applied to a vector in
·nnz(Σk−1)(cid:1). The second
time at most (cid:101)O(cid:0)(cid:107)ηΣk−1(cid:107)1/2
is because one can compute the singular value decom-
position of Σk−1 in time (cid:101)O(dω) and then compute the
matrix exp(ηΣk−1/2) directly.

2

• Mev

is

in

the

case

worst
(cid:101)O(min{T 3/4d−1/4nnz(ΣT ), dω}).
The ﬁrst is so because, as proved in (Garber et al.,
2015), it sufﬁces to compute the top eigenvector of
Σk−1 + rr(cid:62) up to a multiplicative error O(T − 3
2 ).6
If one applies Lanczos method,
this is in time
4 nnz(ΣT )(cid:1). (Recall that it only works when
(cid:101)O(cid:0)T 3
T ≥ d). The second is because the leading eigenvec-
tor of a d × d matrix can be computed directly in time
O(dω).

4 d− 1

2 d 1

6A multiplicative error δ means to ﬁnd x such that x(cid:62)(Σk−1+

rr(cid:62))x ≥ (1 − δ)λmax(Σk−1 + rr(cid:62)).

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

• Mlin

in

the

worst

case

is

4 , d}nnz(ΣT ), dω}(cid:1).
(cid:101)O(cid:0) min{min{T 1
The ﬁrst is because our matrix M has a condition num-
ber at most O(ηT ) = (cid:101)O(T 1/2). If using conjugate gra-
dient (Shewchuk, 1994), one can solve a linear system
4 , d}nnz(ΣT )(cid:1). The
for M in time at most (cid:101)O(cid:0) min{T 1
second is because the inverse of a d × d matrix can be
computed directly in time O(dω) (Bunch & Hopcroft,
1974).

• Mlin

can
(cid:101)O(cid:0) min (cid:8)T 1
4 nnz(ΣT ) 3
using stochastic iterative methods.

4 nnz(A) 1

be

improved

to
4 + nnz(ΣT ), dω(cid:9)(cid:1) if

In sum, if using iterative methods, the worst case values of
Mlin, Mev, Mexp are on the same magnitude. Since the per-
iteration cost of FTCL is only (cid:101)O(Mlin), this is no slower
than O(Mev) of FTPL, and much faster than O(T × Mexp)
of MMWU-JL.

Practical Complexity.
There are many algorithms to
compute leading eigenvectors, including Lanczos method,
shift-and-invert, and the (slower) power method. The per-
formance may depend on other properties of the matrix,
including “how well-clustered the eigenvalues are.”

There are also numerous ways to compute matrix inver-
sions, including conjugate gradient, accelerated coordinate
descent, Chebyshev method, accelerated SVRG, and many
others. Some of them also run faster when the eigenvalues
form clusters (Shewchuk, 1994).
In particular, for a random Gaussian matrix Σk−1 (with di-
mension 100 ∼ 5000), using the default scientiﬁc package
SciPy of Python, Mev is roughly 3 times of Mlin.

Since FTPL requires d
Total Worst-Case Complexity.
times more iterations in order to achieve the same average
regret as FTCL or MMWU, in the last column of Table 1,
we also summarize the minimum total time complexity
needed to achieve an ε average regret.

If nnz(ΣT ) = d2 and nnz(A) = O(d), the

Examples.
total complexity needed to achieve an ε average regret:
(cid:101)O(d3.5ε−3.5) (FTPL)
(cid:101)O(d3ε−2) (MMWU)

(cid:101)O(d2ε−2 + d1.75ε−2.5) (us)
(cid:101)O(d2ε−4.5) (MMWU-JL)

In the λ-reﬁned setting, one can revise the complexity
bounds accordingly. We ignore the details in this short ver-
sion and present them in Table 2 in the appendix.

4 High-Level Discussion of Our Techniques

Revisit MMWU. We ﬁrst revisit the high-level idea be-
hind the proof of MMWU. Recall Wk = exp(ckI +
ηΣk−1) where ck is the unique constant such that
TrWk = 1. The main proof step (see for instance The-
orem 3.1 of (Allen-Zhu et al., 2015)) is to use the equality

TrWk = TrWk+1 = 1 to derive a relationship between
ck − ck+1 and the gain value Wk • Ak at this iteration.
More speciﬁcally, using the Golden-Thompson inequality
we have

Tr(cid:0)eckI+ηΣk (cid:1) ≤ Tr(cid:0)eckI+ηΣk−1 eηAk (cid:1)
= Tr(cid:0)WkeηAk (cid:1) ≈ Tr(cid:0)eckI+ηΣk−1(cid:1) + ηWk • Ak .

One can also use convexity to show

Tr(cid:0)eck+1I+ηΣk (cid:1) − Tr(cid:0)eckI+ηΣk (cid:1) ≤ ck+1 − ck .
Adding these two inequalities, and using the fact that
TrWk = TrWk+1 = 1, we immediately have ck −
ck+1 (cid:46) ηWk •Ak. In other words, the gain value Wk •Ak
at iteration k, up to a factor η, is lower bounded by the
decrement of ck. On the other hand, it is easy to see
c1 − cT +1 ≥ ηλmax(ΣT ) − O(log d) from c1 = − log d
and the deﬁnition of cT +1. Together, we can derive that

(cid:80)T

k=1 Wk • Ak (cid:38) λmax(ΣT ) .

In the rest of this section, we perform a thought experiment
to “modify” the above MMWU analysis step-by-step. In
the end, the intuition of our FTCL shall become clear to
the reader.

Thinking Step 1. We wish to choose a random Gaussian
vector u ∈ Rd and “compress” MMWU to dimension 1
in the direction of u. More speciﬁcally, we deﬁne Wk =
exp(ckI + ηΣk−1) but this time ck is the unique constant
such that Tr(Wkuu(cid:62)) = u(cid:62)Wku = 1. In such a case,
we wish to say that

Tr(cid:0)eckI+ηΣk uu(cid:62)(cid:1) = Tr(cid:0)eckI+ηΣk−1+ηAk uu(cid:62)(cid:1)

((cid:63))

• Ak .

:= W1/2

k uu(cid:62)W1/2

k uu(cid:62)W1/2

≤ Tr(cid:0)e(ckI+ηΣk−1)/2uu(cid:62)e(ckI+ηΣk−1)/2eηAk (cid:1)
= Tr(cid:0)W1/2
k eηAk (cid:1)
≈ Tr(Wkuu(cid:62)) + ηW1/2
k
then we could de-
If the above inequality were true,
k u which is a unit vector (because
ﬁne wk
Tr(Wkuu(cid:62)) = 1) and the gain w(cid:62)
k • Ak
would again be proportional to the change of this new po-
tential function Tr(cid:0)eckI+ηΣk−1uu(cid:62)(cid:1). This idea almost
worked except that inequality ((cid:63)) is false due to the non-
commutativity of matrices.7
Perhaps the most “immediate” idea to ﬁx this issue is to
use the randomness of uu(cid:62). Recall that E[uu(cid:62)] = I if we
choose properly normalize u, and therefore it “seems like”
we have E[Tr(Wkuu(cid:62))] = Tr(Wk) and the inequality
will go through. Unfortunately, this idea fails for a funda-
mental reason: the normalization constant ck depends on

k Akwk = wkw(cid:62)

7A analogy for this effect can be found in the inequality
Tr(eA) ≤ Tr(eB) for every A (cid:22) B. This inequality becomes
false when multiplied with uu(cid:62) and in general eA (cid:22) eB is false.

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

u, so Wk is not independent from the randomness of u.8

Thinking Step 2. Since Gaussian vectors are rotationally
invariant, we switch wlog to the eigenbasis of Σk−1 so Wk
is a diagonal matrix. We make an important observation:9

ck depends only on |u1|, . . . , |ud|,

but not on the 2d possible signs of u1, . . . , ud.

For this reason, we can ﬁx a diagonal matrix D and con-
sider all random uu(cid:62) which agree with D on its diagonal,10
All of such vectors u give the same normalization constant
ck, and it satisﬁes E[uu(cid:62)|D] = D. This implies that we
can now study the conditional expected potential change
E (cid:2)Tr(cid:0)eckI+ηΣk uu(cid:62)(cid:1) − Tr(cid:0)eckI+ηΣk−1 uu(cid:62)(cid:1)(cid:12)

(cid:12)D(cid:3)

= Tr(cid:0)eckI+ηΣk D(cid:1) − Tr(cid:0)eckI+ηΣk−1D(cid:1) ,

or if we denote by B = ckI + ηΣk−1, we want to study the
difference Tr(cid:0)eB+ηAk D(cid:1) − Tr(cid:0)eBD(cid:1) only in the special
case that D and B are simultaneously diagonalizable.
Thinking Step 3. A usual way to bound Tr(cid:0)eB+ηAk D(cid:1)−
Tr(cid:0)eBD(cid:1) is to deﬁne f (η) := Tr(cid:0)eB+ηAk D(cid:1) and bound
f (η) by its Taylor series f (0) + f (cid:48)(0)η + 1
2 f (cid:48)(cid:48)(0)η2 + · · · .
The zero-order derivative f (0) is Tr(cid:0)eBD(cid:1). The ﬁrst-
order derivative f (cid:48)(0) = Tr(AkeBD) = eB/2DeB/2 •Ak
behaves exactly in the way we hope, and this strongly relies
on the commutativity between B and D. Unfortunately,
higher-order derivatives f (k)(0) beneﬁt less and less from
the commutativity between B and D due to the existence
of terms such as AkeBDeBAkD. For this reason, we need
to (1) truncate the Taylor series and (2) use different ana-
lytic tools. This motivates us to use the following regime
that can be viewed as a “low-degree” version of MMWU:

A Quick Detour.
In a recent result, the authors of (Allen-
Zhu et al., 2015) generalized MMWU to (cid:96)1−1/q regular-
ized strategies. For every q ≥ 2, they deﬁne Xk =
(ckI − ηΣk−1)−q where ck is the unique constant such
that ckI − ηΣk−1 (cid:31) 0 and TrXk = 1.11 This is a
generalization of MMWU because when q ≈ log d, the
matrix Xk behaves nearly the same as Wk; in particu-
lar, it gives the same regret bound. The analysis behind

8In fact, ck can be made almost independent from u if we
replace uu(cid:62) with QQ(cid:62) where Q is a random d × m matrix for
some very large m. That was the main idea behind MMWU-JL.
(cid:0)|ui|2 ·

9This is because, Tr(eckI−ηΣk−1 uu(cid:62)) = (cid:80)d

i=1

eck−ηλi (cid:1) where λi is the i-th eigenvalue of Σk−1.
10That is, all random uu(cid:62) such that (cid:107)ui(cid:107)2

i ∈ [d]. For simplicity we also denote this event as D.

2 = Di,i for each

11The name “(cid:96)1−1/q strategies” comes from the following fact.
Recall MMWU naturally arises as the follow-the-regularized-
leader strategy, where the regularizer is the matrix entropy.
If
the entropy function is replaced with a negative (cid:96)1−1/q norm, the
resulting strategy becomes Xk. We encourage interested readers
to see the introduction of (Allen-Zhu et al., 2015) for more back-
ground, but we shall make this present paper self-contained.

this new strategy is to keep track of the potential change in
Tr(cid:0)(ckI−ηΣk−1)−(q−1)(cid:1) as opposed to Tr(cid:0)eckI+ηΣk−1(cid:1),
and then use the so-called Lieb-Thirring inequality (see
Section 5) to replace the use of Golden-Thompson. (Note
that ck is choosen with respect to q but the potential is with
respect to q − 1.)

Thinking Step 4.
Let us now replace MMWU strate-
gies in our Thinking Steps 1,2,3 with (cid:96)1−1/q regularized
strategies. Such strategies have two advantages: (1) they
help us overcome the issue for higher-order terms in Think-
ing Step 3, and (2) solving linear systems is more efﬁcient
than computing matrices exponentials. We shall choose
q = Θ(log(dT )) in the end.

Speciﬁcally, we prepare a random vector u and deﬁne the
normalization constant ck to be the unique one satisfying
Tr(cid:0)(ckI − ηΣk−1)−quu(cid:62)(cid:1) = Tr(Xkuu(cid:62)) = 1. At itera-
tion k, we let the player choose strategy X1/2
k u which is a
unit vector.

If one goes through all the math carefully (using Woodbury
formula), this time we are entitled to upper bound the trace
difference of the form Tr(cid:0)(B+ηC)q−1D(cid:1)−Tr(cid:0)Bq−1D(cid:1)
where D is simultaneously diagonalizable with B but not
C. Similar to Thinking Step 3, we can deﬁne f (η) :=
Tr(cid:0)(B + ηC)q−1D(cid:1) and bound this polynomial f (η) us-
ing its Taylor expansion at point 0. Commutativity between
B and D helps us compute f (cid:48)(0) = (q − 1)Tr(Bq−2CD)
but again we cannot bound higher-derivatives directly. For-
tunately, this time f (η) is a degree q − 1 polynomial so we
can use Markov brothers’ inequality to give an upper bound
on its higher-order terms. This is the place we lose a few
extra polylogarithmic factors in the total regret.

Thinking Step 5. Somehow necessarily, even the second-
order derivative f (cid:48)(cid:48)(0) can depend on terms such as 1/Dii
where Dii = |ui|2 is the i-th diagonal entry of D. This
quantity, over the Gaussian random choice of ui, does not
have a bounded mean. More generally, the inverse chi-
squared distribution with degree t (recall Section 2) has a
bounded mean only when t ≥ 3. For this reason, instead
of picking a single random vector u ∈ Rd, we need to pick
three random vectors u1, u2, u3 ∈ Rd and replace all the
(cid:1) in the
(cid:0)u1u(cid:62)
occurrences of uu(cid:62) with 1
3
previous thinking steps. As a result, each Dii becomes a
chi-squared distribution of degree 3 so the issue goes away.
This is why we claimed in the introduction that

1 + u2u(cid:62)

2 + u3u(cid:62)
3

we can compress MMWU to dimension 3.

Thinking Step 6.
Putting together previous steps, we
T log3(dT )),
obtain a FTCL strategy with total regret O(
factor
which is worse
O(log2.5(dT )). We call this method FTCLobl and in-
clude its analysis in Section 6. However, FTCLobl only
works for an oblivious adversary (i.e., when A1, . . . , AT

than MMWU only by a

√

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

are ﬁxed a priori) and gives an expected regret. To turn
it into a robust strategy against adversarial A1, . . . , AT ,
and to make the regret bound work with high conﬁdence,
we need to re-sample u1, u2, u3 every iteration. We call
this method FTCLadv. A careful but standard analysis with
Azuma inequality helps us reduce FTCLadv to FTCLobl. We
state this result in the full version.

Running Time. As long as q is an even integer, the com-
putation of “(ckI − ηΣk−1)−1 applied to a vector” (or
in other words, solving linear systems) becomes the bot-
tleneck for each iteration of FTCLobl and FTCLadv. How-
ever, as long as q ≥ Ω(log(dT )), we show that the condi-
tion number of the matrix ckI − ηΣk−1 is at most ηT =
Θ(T 1/2). Conjugate gradient solves each such linear sys-
tem in worst-case time (cid:101)O(min{T 1/4, d} × nnz(Σk−1)).

Compress to 1-d in Stochastic Online Eigenvector.
If
the adversary is stochastic, we observe that Oja’s algorithm
corresponds to a potential function Tr(cid:0)(I + ηAk) · · · (I +
ηA1)uu(cid:62)(I + ηA1) · · · (I + ηAk)(cid:1). Because the matrices
are drawn from a common distribution, this potential be-
haves similar to the matrix exponential but compressed to
dimension 1, namely Tr(cid:0)eη(A1+···+Ak)uu(cid:62)(cid:1). In fact, just
using linearity of expectation carefully, one can both up-
per and lower bound this potential. We state this result in
Section 8 (and it can be proved in one page!)

5 A New Trace Inequality

Prior work on MMWU and its extensions rely heavily
the Golden-
on one of the following trace inequalities:
Thompson inequality

Tr(eA+ηB) ≤ Tr(cid:0)eAeηB(cid:1)

and the Lieb-Thirring inequality
Tr(cid:0)(A+ηB)k(cid:1) ≤ Tr(cid:0)Ak/2(I+ηA−1/2BA−1/2)kAk/2(cid:1) .
Due to our compression framework in this paper, we need
inequalities of type
“ Tr(eA+ηBD) ≤ Tr(cid:0)eηBeA/2DeA/2(cid:1) ”
“ Tr(cid:0)(A + ηB)kD(cid:1)

≤ Tr(cid:0)(I + ηA−1/2BA−1/2)kAk/2DAk/2(cid:1) ” (5.1)
like “generalizations” of Golden-
which look almost
Thompson and Lieb-Thirring (by setting D = I). Un-
fortunately, such generalizations do not hold for an arbi-
trary D. For instance, if the ﬁrst “generalization” holds
for every PSD matrix D then it would imply “ eA+ηB (cid:22)
eA/2eηBeA/2 ” which is a false inequality due to matrix
non-commutativity.

In this paper, we show that if D is commutative with A,
then the “generalization” (5.1) holds for the zeroth and ﬁrst
order terms with respect to η. As for higher order terms,
we can control it using Markov brothers’ inequality. (Proof
see full paper.)

Lemma 5.1. For every symmetric matrices A, B, D ∈
Rd×d, every integer k ≥ 1, every η∗ ≥ 0, and every η ∈
[0, η∗/k2], if A and D are commutative, then

(A + ηB)k • D − Ak • D ≤ kηB • Ak−1D
(cid:18) ηk2
η∗

(cid:110)(cid:12)
(cid:12)(A + η(cid:48)B)k • D − Ak • D(cid:12)
(cid:12)

max
η(cid:48)∈[0,η∗]

(cid:19)2

+

(cid:111)

.

6 Oblivious Online EV + Expected Regret

In this section we ﬁrst focus on a simpler oblivious setting.
A1, . . . , AT are T PSD matrices chosen by the adversary
in advance, and they do not depend on the player’s actions
in the T iterations. We are interested in upper bounding the
total expected regret

k=1

λmax

(cid:0) (cid:80)T

E[w(cid:62)

k=1 Ak

k Akwk] ,

(cid:1) − (cid:80)T
where the expectation is over player’s random choices
wk ∈ Rd (recall (cid:107)wk(cid:107)2 = 1).
In the full version, we generalize this result to the full ad-
versarial setting along with high-conﬁdence regret.
Our algorithm FTCLobl is presented in Algorithm 1. It is
parameterized by an even integer q ≥ 2 and a learning rate
η > 0. It initializes with a rank-3 Wishart random matrix
U. For every k ∈ [T + 1], we denote by Xk := (cid:0)ckI −
ηΣk−1

where ck > 0 is the unique constant s.t.12
and Tr(cid:0)XkU(cid:1) = 1 .

ckI − ηΣk−1 (cid:31) 0

(cid:1)−q

k UX1/2

k ] = X1/2

At iteration k ∈ [T ], the player plays a random unit vec-
tor wk, among the three eigenvectors of X1/2
k . It
k UX1/2
satisﬁes E[wkw(cid:62)
k .
We prove the following theorem for the total regret of
FTCLobl(T, q, η) in the full version of this paper:
Theorem 1. If we have an oblivious adversary, there ex-
ists absolute constant C > 1 such that if q ≥ 3 log(2dT )
and η ∈ (cid:2)0,

(cid:3), then FTCLobl(T, q, η) satisﬁes

1
11q3

T
(cid:88)

(cid:104)

E

(cid:105)

w(cid:62)

k Akwk

k=1

Corollary 6.1.
(cid:1)
Θ(cid:0) log−3(dT )
λmax(ΣT )

√

≥ (cid:0)1 − Cηq5 log(dT )(cid:1)λmax(ΣT ) −

4
η

If q = 3 log(2dT ) and η =

(cid:80)T

k=1

(cid:104)

E

w(cid:62)

k Akwk

(cid:105)

(λ-reﬁned language)

≥ λmax(ΣT ) − O

(cid:16)(cid:112)λmax(ΣT ) log3(dT )
(cid:17)

,

or choosing the same q but η = Θ(cid:0) log−3(dT )
√
T
(cid:16)√
(cid:105)

(cid:80)T

k=1

(cid:104)
w(cid:62)

E

k Akwk

≥ λmax(ΣT )−O

(cid:1) we have

(cid:17)
T log3(dT )
(general language)

.

12This ck is unique because Tr(cid:0)XkU(cid:1) is a strictly decreasing

function for ck > ηλmax(Σk−1).

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

Algorithm 1 FTCLobl(T, q, η)
Input: T , number of iterations; q ≥ 2, an even integer,

η, the learning rate.

(cid:5) theory-predicted choice q = Θ(log(dT ))
(cid:5) theory-predicted choice η = log−3(dT )/(cid:112)λmax(ΣT )

(cid:1).

(cid:0)u1u(cid:62)

1 + u2u(cid:62)

2 + u3u(cid:62)
3

1: Choose u1, u2, u3 ∈ Rd where the 3d coordinates are i.i.d. drawn from N (0, 1).
2: U ← 1
3
3: for k ← 1 to T do
Σk−1 ← (cid:80)k−1
i=1 Ai.
4:
Denote by Xk ← (cid:0)ckI − ηΣk−1
Compute X1/2
k UX1/2
Choose wk ← yj with probability pj.
Play strategy wk and receive matrix Ak.

where ck is the constant s.t.

j=1 pj · yjy(cid:62)

k = (cid:80)3

(cid:1)−q

5:

6:
7:
8:
9: end for

ckI − ηΣk−1 (cid:31) 0

and Tr(cid:0)XkU(cid:1) = 1 .

j where y1, y2, y3 are orthogonal unit vectors in Rd.

(cid:5) it satisﬁes p1, p2, p3 ≥ 0 and p1 + p2 + p3 = 1.

7 Missing Theorems

In the full version of this paper, we state Theorem 2, a sim-
ilar result of Theorem 1 but (1) with a high-conﬁdence re-
gret bound and (2) for the adversarial setting: Ak may de-
pend on the player’s strategies w1, . . . , wk−1. In the full
version, we also provide Theorem 3, which addresses the
worst-case complexity for implementing the matrix inver-
sion steps in FTCLobl.

8 Stochastic Online Eigenvector

Consider the special case when the matrices A1, . . . , AT
are generated i.i.d. from a common distribution whose ex-
pectation equals B. This is known as the stochastic online
eigenvector problem, and we wish to minimize the regret

(cid:80)T

k=1 w(cid:62)

k Akwk − T · λmax(B) .

We revisit Oja’s algorithm: beginning with a random Gaus-
sian vector u ∈ Rd, at each iteration k, let wk be (I +
ηAk−1) · · · (I + ηA1)u after normalization. It is clear that
wk can be computed from wk−1 in time nnz(A).
In the full version, we prove the next theorem in one page:

Theorem 4. There exists C > 1 such that, for every
p ∈ (0, 1), if η ∈ (cid:2)0, (cid:112)p/(60T λmax(B))(cid:3) in Oja’s algo-
rithm, we have with probability at least 1 − p:
(cid:80)T

k Akwk ≥ (1−2η)T ·λmax(B)−C· log(d+log(1/p))

k=1 w(cid:62)

η

.

Corollary 8.1. Choosing η =
have with prob. ≥ 1 − p:

(cid:80)T

k=1 w(cid:62)

k Akwk ≥ T · λmax(B)
(cid:112)T · λmax(B)
√
p

− O(cid:0)

√

p/(cid:112)60T λmax(B), we

· log(d + log(1/p))(cid:1) .

(λ-reﬁned language)

Choosing η =

p/

60T , we have with prob. ≥ 1 − p:

√

√

(cid:80)T

k=1 w(cid:62)
k Akwk ≥ T · λmax(B)
√
T
√
p

· log(d + log(1/p))(cid:1) .

− O(cid:0)

(general language)

The proof of Theorem 4 uses a potential function analysis
which is similar to the matrix exponential potential used in
MMWU, but compressed to dimension 1.

9 Conclusions

We give a new learning algorithm FTCL for the online
eigenvector problem.
It matches the optimum regret ob-
tained by MMWU, but runs much faster. It matches the fast
per-iteration running time of FTPL, but has a much smaller
regret.
In the stochastic setting, our side result on Oja’s
algorithm also outperforms previous results. We believe
our novel idea of “follow the compressed leader” may ﬁnd
other applications in the future.

Acknowledgement

We thank Yin Tat Lee for discussing the problem regarding
how to compress MMWU to constant dimension in 2015.
We thank Elad Hazan for suggesting us the problem and
for several insightful discussions. We thank Dan Garber
and Tengyu Ma for clarifying some results of prior work
(Garber et al., 2015).

References

Abernethy, Jacob, Lee, Chansoo, Sinha, Abhinav, and
Tewari, Ambuj. Online linear optimization via smooth-

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

ing. In COLT, pp. 807–823, 2014.

Abernethy, Jacob, Lee, Chansoo, and Tewari, Ambuj.
Spectral smoothing via random matrix perturbations.
ArXiv e-prints, abs/1507.03032, 2015.

Allen-Zhu, Zeyuan and Li, Yuanzhi. LazySVD: Even
Faster SVD Decomposition Yet Without Agonizing
Pain. In NIPS, 2016a.

Allen-Zhu, Zeyuan and Li, Yuanzhi. First Efﬁcient Con-
vergence for Streaming k-PCA: a Global, Gap-Free, and
Near-Optimal Rate. ArXiv e-prints, abs/1607.07837,
July 2016b.

Allen-Zhu, Zeyuan and Li, Yuanzhi. Doubly Accelerated
Methods for Faster CCA and Generalized Eigendecom-
position. In Proceedings of the 34th International Con-
ference on Machine Learning, ICML ’17, 2017.

Allen-Zhu, Zeyuan and Yuan, Yang.

Improved SVRG
for Non-Strongly-Convex or Sum-of-Non-Convex Ob-
jectives. In ICML, 2016.

Allen-Zhu, Zeyuan, Liao, Zhenyu, and Orecchia, Lorenzo.
Spectral Sparsiﬁcation and Regret Minimization Be-
In Proceedings of the
yond Multiplicative Updates.
47th Annual ACM Symposium on Theory of Computing,
STOC ’15, 2015.

Allen-Zhu, Zeyuan, Lee, Yin Tat, and Orecchia, Lorenzo.
Using optimization to obtain a width-independent, par-
In Pro-
allel, simpler, and faster positive SDP solver.
ceedings of the 27th ACM-SIAM Symposium on Discrete
Algorithms, SODA ’16, 2016.

Arora, Sanjeev and Kale, Satyen. A combinatorial, primal-
dual approach to semideﬁnite programs. In Proceedings
of the thirty-ninth annual ACM symposium on Theory of
computing - STOC ’07, pp. 227, New York, New York,
USA, 2007. ACM Press.
ISBN 9781595936318. doi:
10.1145/1250790.1250823.

Arora, Sanjeev, Hazan, Elad, and Kale, Satyen. The Mul-
tiplicative Weights Update Method: a Meta-Algorithm
and Applications. Theory of Computing, 8:121–164,
2012. doi: 10.4086/toc.2012.v008a006.

Boutsidis, Christos, Garber, Dan, Karnin, Zohar, and Lib-
erty, Edo. Online principal components analysis. In Pro-
ceedings of the Twenty-Sixth Annual ACM-SIAM Sympo-
sium on Discrete Algorithms, pp. 887–901. SIAM, 2015.

Bunch, James R and Hopcroft, John E. Triangular fac-
torization and inversion by fast matrix multiplication.
Mathematics of Computation, 28(125):231–236, 1974.

Cesa-Bianchi, Nicolo and Lugosi, Gabor.

Prediction,
Learning, and Games. Cambridge University Press,
Cambridge, 2006. ISBN 9780511546921. doi: 10.1017/
CBO9780511546921.

Dwork, Cynthia, Talwar, Kunal, Thakurta, Abhradeep, and
Zhang, Li. Analyze gauss: optimal bounds for privacy-
preserving principal component analysis. In STOC, pp.
11–20. ACM, 2014.

Frostig, Roy, Ge, Rong, Kakade, Sham M., and Sidford,
Aaron. Un-regularizing: approximate proximal point
and faster stochastic algorithms for empirical risk min-
imization. In ICML, volume 37, pp. 1–28, 2015. URL
http://arxiv.org/abs/1506.07512.

Garber, Dan and Hazan, Elad. Fast and simple PCA via
convex optimization. ArXiv e-prints, September 2015.

Garber, Dan, Hazan, Elad, and Ma, Tengyu. Online learn-
ing of eigenvectors. In Proceedings of the 32nd Interna-
tional Conference on Machine Learning (ICML-15), pp.
560–568, 2015.

Hardt, Moritz and Price, Eric. The noisy power method:
A meta algorithm with applications. In NIPS, pp. 2861–
2869, 2014.

Jain, Rahul, Ji, Zhengfeng, Upadhyay, Sarvagya, and Wa-
Journal of the ACM

trous, John. QIP = PSPACE.
(JACM), 58(6):30, 2011.

Karnin, Zohar and Liberty, Edo. Online pca with spectral
bounds. In Proceedings of the 28th Annual Conference
on Computational Learning Theory (COLT), pp. 505–
509, 2015.

Kotłowski, Wojciech and Warmuth, Manfred K. Pca with
gaussian perturbations. ArXiv e-prints, abs/1506.04855,
2015.

Lee, Yin Tat and Sun, He. Constructing linear-sized spec-
In FOCS, pp.

tral sparsiﬁcation in almost-linear time.
250–269. IEEE, 2015.

Lin, Hongzhou, Mairal, Julien, and Harchaoui, Zaid.
A Universal Catalyst
for First-Order Optimization.
In NIPS, 2015. URL http://arxiv.org/pdf/
1506.02186v1.pdf.

Nesterov, Yurii. Introductory Lectures on Convex Program-
ming Volume: A Basic course, volume I. Kluwer Aca-
demic Publishers, 2004. ISBN 1402075537.

Nie, Jiazhong, Kotłowski, Wojciech, and Warmuth, Man-
In Interna-
fred K. Online pca with optimal regrets.
tional Conference on Algorithmic Learning Theory, pp.
98–112. Springer, 2013.

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

Orecchia, Lorenzo. Fast Approximation Algorithms for
Graph Partitioning using Spectral and Semideﬁnite-
Programming Techniques. PhD thesis, EECS Depart-
ment, University of California, Berkeley, May 2011.

Orecchia, Lorenzo, Sachdeva, Sushant, and Vishnoi,
Nisheeth K. Approximating the exponential, the lanczos
method and an (cid:101)O(m)-time spectral algorithm for bal-
anced separator. In STOC ’12. ACM Press, November
2012.

Pan, Victor Y and Chen, Zhao Q. The complexity of the
matrix eigenproblem. In Proceedings of the thirty-ﬁrst
annual ACM symposium on Theory of computing, pp.
507–516. ACM, 1999.

Peng, Richard and Tangwongsan, Kanat. Faster and sim-
pler width-independent parallel algorithms for positive
semideﬁnite programming. In Proceedinbgs of the 24th
ACM symposium on Parallelism in algorithms and ar-
chitectures - SPAA ’12, pp. 101, New York, New York,
USA, January 2012.

Shalev-Shwartz, Shai. SDCA without Duality, Regulariza-

tion, and Individual Convexity. In ICML, 2016.

Shamir, Ohad. Convergence of stochastic gradient descent

for pca. In ICML, 2016.

Shewchuk, Jonathan Richard. An introduction to the conju-
gate gradient method without the agonizing pain, 1994.

Wendel, J. G. Note on the gamma function. The American

Mathematical Monthly, 55(9):563–564, 1948.

