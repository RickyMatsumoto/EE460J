Developing Bug-Free Machine Learning Systems With Formal Mathematics

Daniel Selsam 1 Percy Liang 1 David L. Dill 1

Abstract

Standard methodology: test it empirically

Debug

Noisy data, non-convex objectives, model mis-
speciﬁcation, and numerical instability can all
cause undesired behaviors in machine learning
systems. As a result, detecting actual imple-
mentation errors can be extremely difﬁcult. We
demonstrate a methodology in which developers
use an interactive proof assistant to both imple-
ment their system and to state a formal theorem
deﬁning what it means for their system to be cor-
rect. The process of proving this theorem inter-
actively in the proof assistant exposes all imple-
mentation errors since any error in the program
would cause the proof to fail. As a case study,
we implement a new system, Certigrad, for opti-
mizing over stochastic computation graphs, and
we generate a formal (i.e. machine-checkable)
proof that the gradients sampled by the system
are unbiased estimates of the true mathematical
gradients. We train a variational autoencoder us-
ing Certigrad and ﬁnd the performance compara-
ble to training the same model in TensorFlow.

Program

Test

Our methodology: verify it mathematically

Debug

Specify

Program

Prove

Figure 1. A high-level comparison of our methodology with the
standard methodology for developing machine learning systems.
Instead of relying on empirical testing to expose implementation
errors, we ﬁrst formally specify what our system is required to
do in terms of the underlying mathematics, and then try to for-
mally prove that our system satisﬁes its speciﬁcation. The process
of proving exposes implementation errors systematically and the
(program → prove → debug) loop eventually terminates with a
bug-free system and a machine-checkable proof of correctness.

1. Introduction

Machine learning systems are difﬁcult to engineer for many
fundamental reasons. First and foremost, implementation
errors can be extremely difﬁcult to detect—let alone to lo-
calize and address—since there are many other potential
causes of undesired behavior in a machine learning system.
For example, an implementation error may lead to incor-
rect gradients and so cause a learning algorithm to stall, but
such a symptom may also be caused by noise in the training
data, a poor choice of model, an unfavorable optimization
landscape, an inadequate search strategy, or numerical in-
stability. These other issues are so common that it is often
assumed that any undesired behavior is caused by one of
them. As a result, actual implementation errors can persist

1Stanford University, Stanford, CA. Correspondence to:

Daniel Selsam <dselsam@stanford.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

indeﬁnitely without detection.1 Errors are even more difﬁ-
cult to detect in stochastic programs, since some errors may
only distort the distributions of random variables and may
require writing custom statistical tests to detect.

Machine learning systems are also difﬁcult to engineer be-
cause it can require substantial expertise in mathematics
(e.g.
linear algebra, statistics, multivariate analysis, mea-
sure theory, differential geometry, topology) to even under-
stand what a machine learning algorithm is supposed to do
and why it is thought to do it correctly. Even simple algo-
rithms such as gradient descent can have intricate justiﬁ-
cations, and there can be a large gap between the mechan-
ics of an implementation—especially a highly-optimized
one—and its intended mathematical semantics.

1Theano (Bergstra et al., 2010) has been under develop-
ment for almost a decade and yet there is a recent GitHub is-
sue (https://github.com/Theano/Theano/issues/4770) reporting a
model for which the loss continually diverges in the middle of
training. Only after various experiments and comparing the be-
havior to other systems did the team agree that it is most likely an
implementation error. As of this writing, neither the cause of this
error nor the set of models it affects have been determined.

Developing Bug-Free Machine Learning Systems With Formal Mathematics

In this paper, we demonstrate a practical methodology for
building machine learning systems that addresses these
challenges by enabling developers to ﬁnd and eliminate im-
plementation errors systematically without recourse to em-
pirical testing. Our approach makes use of a tool called
an interactive proof assistant (Gordon, 1979; Gordon &
Melham, 1993; Harrison, 1996; Nipkow et al., 2002; Owre
et al., 1992; Coq Development Team, 2015-2016; de Moura
et al., 2015), which consists of (a) a programming lan-
guage, (b) a language to state mathematical theorems, and
(c) a set of tools for constructing formal proofs of such the-
orems. Note: we use the term formal proof to mean a proof
that is in a formal system and so can be checked by a ma-
chine.

In our approach, developers use the theorem language (b)
to state a formal mathematical theorem that deﬁnes what it
means for their implementation to be error-free in terms
of the underlying mathematics (e.g. multivariate analy-
sis). Upon implementing the system using the program-
ming language (a), developers use the proof tools (c) to
construct a formal proof of the theorem stating that their
implementation is correct. The ﬁrst draft of any implemen-
tation will often have errors, and the process of interactive
proving will expose these errors systematically by yield-
ing impossible proof obligations. Once all implementation
errors have been ﬁxed, the developers will be able to com-
plete the formal proof and be certain that the implementa-
tion has no errors with respect to its speciﬁcation. More-
over, the proof assistant can check the formal proof auto-
matically so no human needs to understand why the proof
is correct in order to trust that it is. Figure 1 illustrates this
process.

Proving correctness of machine learning systems requires
building on the tools and insights from two distinct ﬁelds:
program veriﬁcation (Leroy, 2009; Klein et al., 2009; Chli-
pala, 2013; Chen et al., 2015), which has aimed to prove
properties of computer programs, and formal mathemat-
ics (Rudnicki, 1992; Gonthier, 2008; Gonthier et al., 2013;
Hales et al., 2015), which has aimed to formally repre-
sent and generate machine-checkable proofs of mathemat-
ical theorems. Both of these ﬁelds make use of interactive
proof assistants, but the tools, libraries and design patterns
developed by the two ﬁelds focus on different problems and
have remained largely incompatible. While the methodol-
ogy we have outlined will be familiar to the program ver-
iﬁcation community, and while reasoning formally about
the mathematics that underlies machine learning will be fa-
miliar to the formal mathematics community, proving such
sophisticated mathematical properties of large (stochastic)
software systems is a new goal and poses many new chal-
lenges.

To explore these challenges and to demonstrate the prac-

W1

W2

x

∗

softplus N (·, I)

∗

sigmoid

cost

L(W1, W2) = Ez∼N (softplus(W1x),I) [cost(x, σ(W2z))]

Figure 2. An example stochastic computation graph representing
a simple variational autoencoder. Stochastic nodes are indicated
by rounded rectangles. The loss function for the graph is the ex-
pected value of the cost node over the stochastic choices, which
in this case is a single sample from a Gaussian distribution.

ticality of our approach, we implemented a new machine
learning system, Certigrad, for optimizing over stochas-
tic computation graphs (Schulman et al., 2015). Stochas-
tic computation graphs extend the computation graphs that
underly systems like TensorFlow (Abadi et al., 2015) and
Theano (Bergstra et al., 2010) by allowing nodes to repre-
sent random variables and by deﬁning the loss function for
a graph to be the expected value of the sum of the leaf nodes
over the stochastic choices. See Figure 2 for an example of
a stochastic computation graph. We implement our system
in the Lean Theorem Prover (de Moura et al., 2015), a new
interactive proof assistant still under active development for
which the integration of programming and mathematical
reasoning is an ongoing design goal. We formally state and
prove functional correctness for the stochastic backpropa-
gation algorithm: that the sampled gradients are indeed un-
biased estimates of the gradients of the loss function with
respect to the parameters.

We note that provable correctness need not come at the
expense of computational efﬁciency: proofs need only be
checked once during development and they introduce no
runtime overhead. Although the algorithms we verify in
this work lack many optimizations, most of the running
time when training machine learning systems is spent mul-
tiplying matrices, and we are able to achieve competi-
tive performance simply by linking with an optimized li-
brary for matrix operations (we used Eigen (Guennebaud
et al., 2010)).2 To demonstrate practical feasibility em-
pirically, we trained an Auto-Encoding Variational Bayes
(AEVB) model (Kingma & Welling, 2014) on MNIST us-
ing ADAM (Kingma & Ba, 2014) and found the perfor-
mance comparable to training the same model in Tensor-
Flow.

2Note that the validity of our theorem becomes contingent on
Eigen’s matrix operations being functionally equivalent to the ver-
sions we formally proved correct.

Developing Bug-Free Machine Learning Systems With Formal Mathematics

We summarize our contributions:

1. We present

(i.e.
the ﬁrst application of
machine-checkable) proof techniques to developing
machine learning systems.

formal

2. We describe a methodology that can detect implemen-
tation errors systematically in machine learning sys-
tems.

3. We demonstrate that our approach is practical by de-
veloping a performant implementation of a sophisti-
cated machine learning system along with a machine-
checkable proof of correctness.

2. Motivation

When developing machine learning systems, many pro-
gram optimizations involve extensive algebraic derivations
to put mathematical expressions in closed-form . For exam-
ple, suppose you want to compute the following quantity
efﬁciently:

(cid:90)

x

N (x; µ, Diag(σ2)) log N (x; 0, In×n).

(1)

You expand the density functions, grind through the algebra
by hand and eventually derive the following closed form
expression:

−

1
2

(cid:34) n
(cid:88)

i=1

(cid:0)σ2

i − µ2
i

(cid:1) + n log 2π

(2)

(cid:35)

You implement a procedure to compute this quantity and
include it as part of a larger program, but when you run
your ﬁrst experiment, your plots are not as encouraging as
you hoped. After ruling out many other possible expla-
nations, you eventually decide to scrutinize this procedure
more closely. You implement a na¨ıve Monte Carlo esti-
mator for the quantity above, compare it against your pro-
cedure on a few random inputs and ﬁnd that its estimates
are systematically biased. What do you do now? If you
re-check your algebra carefully, you might notice that the
sign of µ2
i is wrong, but wouldn’t it be easier if the com-
piler checked your algebra for you and found the erroneous
step? Or better yet, if it did the algebra for you in the ﬁrst
place and could guarantee the result was error-free?

3. Background: The Lean Theorem Prover

To develop software systems with no implementation er-
rors, we need a way to write computer programs, mathe-
matical theorems, and mathematical proofs all in the same

Formal
Informal
(cid:82) (λ x, f x y)
(cid:82) f (x, y) dx
(cid:82) f (x, y)
?
∇θf (g(θ))|θ0 ∇ (λ θ, f (g θ)) θ0
∇f (g(θ))
?

Figure 3. Translating informal usages of the integral and gradient
to our formal representation. Note that whereas some of the in-
formal examples are too ambiguous to interpret without additional
information, the Lean representation is always unambiguous.

language. All three capabilities are provided by the new in-
teractive proof assistant Lean (de Moura et al., 2015). Lean
is an implementation of a logical system known as the Cal-
culus of Inductive Constructions (Coquand & Huet, 1988),
and its design is inspired by the better-known Coq Proof
Assistant (Coq Development Team, 2015-2016). Our de-
velopment makes use of certain features that are unique to
Lean, but most of what we present is equally applicable
to Coq, and to a lesser extent, other interactive theorem
provers such as Isabelle/HOL (Nipkow et al., 2002).

To explain and motivate the relevant features of Lean, we
will walk through applying our methodology to a toy prob-
lem: writing a program to compute the gradient of the soft-
plus function. We can write standard functional programs
in Lean, such as softplus:
def splus (x : R) : R := log (1 + exp x)

We can also represent more abstract operations such as in-
tegrals and gradients:
(cid:82) (f : R → R) : R

∇ (f : R → R) (θ : R) : R

Here the intended meaning of (cid:82) f is the integral of the
function f over all of R, while the intended meaning of
∇ f θ is the gradient (i.e. the derivative) of the function f
at the point θ. Figure 3 shows how to represent common
idioms of informal mathematics in our formal representa-
tion; note that whereas some of the informal examples are
too ambiguous to interpret without additional information,
the Lean representation is always unambiguous.

We can represent mathematical theorems in Lean as well.
For example, we can use the following predicate to state
that a particular function f is differentiable at a point θ:
is_diff (f : R → R) (θ : R) : Prop

The fact that the return type of is_diff is Prop indicates
that it is not a computer program to be executed but rather
that it represents a mathematical theorem.

We can also state and assume basic properties about the
gradient, such as linearity:
∀ (f g : R → R) (θ : R), is_diff f θ ∧ is_diff g θ →
∇ (f + g) θ = ∇ f θ + ∇ g θ

Developing Bug-Free Machine Learning Systems With Formal Mathematics

Returning to our running example, we can state the theorem
that a particular function f computes the gradient of the
softplus function:
def gsplus_spec (f : R → R) : Prop :=
∀ x, f x = ∇ splus x

Suppose we try to write a program to compute the gradient
of the softplus function as follows:
def gsplus (x : R) : R := 1 / (1 + exp x)

The application gsplus_spec gsplus represents the
proposition that our implementation gsplus is correct, i.e.
that it indeed computes the gradient of the softplus function
for all inputs.

We can try to formally prove theorems in Lean interac-
tively:

theorem gsplus_correct : gsplus_spec gsplus :=
lean: (cid:96) gsplus_spec gsplus
user: expand_def gsplus_spec,
lean: (cid:96) ∀ x, gsplus x = ∇ splus x
user: introduce x,
lean: x : R (cid:96) gsplus x = ∇ splus x
user: expand_defs [gsplus, splus],
lean: x : R (cid:96) 1 / (1 + exp x) = ∇ (λ x, log (1 + exp x)) x
user: simplify_grad,
lean: x : R (cid:96) 1 / (1 + exp x) = exp x / (1 + exp x)

The lines beginning with lean show the current state of
the proof as displayed by Lean, which at any time con-
sists of a collection of goals of the form assumptions
(cid:96) conclusion. Every line beginning with user invokes a
tactic, which is a command that modiﬁes the proof state
in some way such that Lean can automatically construct
proofs of the original goals given proofs of the new ones.
Here the simplify_grad tactic rewrites exhaustively with
known gradient rules—in this case it uses the rules for log,
exp, addition, constants, and the identity function. The ﬁnal
goal is clearly not provable, which means we have found an
implementation error in gsplus. Luckily the goal tells us
exactly what gsplus x needs to return: gsplus x = exp x
/ (1 + exp x). Once we ﬁx the implementation of gsplus,
the proof script that failed before now succeeds and gen-
erates a machine-checkable proof that the revised gsplus
is bug-free. Note that we need not have even attempted
to implement gsplus before starting the proof, since the
process itself revealed what the program needs to compute.
We will revisit this phenomenon in §4.5.

In the process of proving the theorem, Lean constructs
a formal proof certiﬁcate that can be automatically veri-
ﬁed by a small stand-alone executable, whose soundness is
based on a well-established meta-theoretic argument em-
bedding the core logic of Lean into set theory, and whose
implementation has been heavily scrutinized by many de-
velopers. Thus no human needs to be able to understand

why a proof is correct in order to trust that it is.3

Although we cannot execute functions such as gsplus di-
rectly in the core logic of Lean (since a real number is an
inﬁnite object that cannot be stored in a computer), we can
execute the ﬂoating-point approximation inside Lean’s vir-
tual machine:

vm_eval gsplus π −− answer: 0.958576

4. Case Study: Certiﬁed Stochastic

Computation Graphs

Stochastic computation graphs are directed acyclic graphs
in which each node represents a speciﬁc computational op-
eration that may be deterministic or stochastic (Schulman
et al., 2015). The loss function for a graph is deﬁned to
be the expected value of the sum of the leaf nodes over the
stochastic choices. Figure 2 shows the stochastic computa-
tion graph for a simple variational autoencoder.

Using our methodology, we developed a system, Certigrad,
which allows users to construct arbitrary stochastic com-
putation graphs out of the primitives that we provide. The
main purpose of the system is to take a program describing
a stochastic computation graph and to run a randomized al-
gorithm (stochastic backpropagation) that, in expectation,
provably generates unbiased samples of the gradients of the
loss function with respect to the parameters.

4.1. Overview of Certigrad

We now brieﬂy describe the components of Certigrad,
some of which have no analogues in traditional software
systems.4

Mathematics libraries. There is a type that represents ten-
sors of a particular shape, along with basic functions (e.g.
exp, log) and operations (e.g.
the gradient, the integral).
There are assumptions about tensors (e.g. gradient rules
for exp and log), and facts that are proved in terms of those
assumptions (e.g.
the gradient rule for softplus). There
is also a type that represents probability distributions over
vectors of tensors, that can be reasoned about mathemat-
ically and that can also be executed procedurally using a
pseudo-random number generator.

Implementation. There is a data structure that represents
stochastic computation graphs, as well as an implementa-
tion of stochastic backpropagation. There are also func-
tions that optimize stochastic computation graphs in var-
ious ways (e.g. by integrating out parts of the objective

3This appealing property can be lost when an axiom is as-

sumed that is not true. We discuss this issue further in §4.3.

4The complete development can be found at www.github.com/

dselsam/certigrad.

Developing Bug-Free Machine Learning Systems With Formal Mathematics

function), as well as basic utilities for training models (e.g.
stochastic gradient descent).

Speciﬁcation. There is a collection of theorem statements
that collectively deﬁne what it means for the implementa-
tion to be correct. For Certigrad, there is one main theorem
that states that the stochastic backpropagation procedure
yields unbiased estimates of the true mathematical gradi-
ents. There are also other theorems that state that individual
graph optimizations are sound.

Proof. There are many helper lemmas to decompose the
proofs into more manageable chunks, and there are tactic
scripts to generate machine-checkable proofs for each of
the lemmas and theorems appearing in the system. There
are also tactic programs to automate certain types of rea-
soning, such as computing gradients or proving that func-
tions are continuous.

Optimized libraries. While the stochastic backpropagation
function is written in Lean and proved correct, we execute
the primitive tensor operations with the Eigen library for
linear algebra. There is a small amount of C++ code to
wrap Eigen operations for use inside Lean’s virtual ma-
chine.

The rest of this section describes the steps we took to de-
velop Certigrad, which include sketching the high-level
architecture, designing the mathematics libraries, stating
the main correctness theorem and constructing the formal
proof. Though many details are speciﬁc to Certigrad, this
case study is designed to illustrate our methodology and we
expect other projects will follow a similar process. Note:
Certigrad supports arbitrarily-shaped tensors, but doing so
introduces more notational complexity than conceptual dif-
ﬁculty and so we simplify the presentation that follows by
assuming that all values are scalars.

4.2. Informal speciﬁcation

The ﬁrst step of applying our methodology is to write down
informally what the system is required to do. Suppose g is a
stochastic computation graph with n nodes and (to simplify
the notation) that it only takes a single parameter θ. Then
g, θ together deﬁne a distribution over the values at the n
nodes (X1, . . . , Xn). Let cost(g, X1:n) be the function that
sums the values of the leaf nodes. Our primary goal is to
write a (stochastic) backpropagation algorithm bprop such
that for any graph g,

Eg,θ [bprop(g, θ, X1:n)] = ∇θ (Eg,θ [cost(g, X1:n)])

While this equation may seem sufﬁcient to communicate
the speciﬁcation to a human with a mathematical back-
ground, more precision is needed to communicate it to a
computer. The next step is to formalize the background

mathematics, such as real numbers (tensors) and probabil-
ity distributions, so that we can state a formal analogue of
Equation 3 that the computer can understand. Although we
believe it will be possible to develop standard libraries of
mathematics that future developers can use off-the-shelf,
we needed to develop the mathematics libraries for Certi-
grad from scratch.

4.3. Designing the mathematics libraries

Whereas in traditional formal mathematics the goal is to
construct mathematics from ﬁrst principles (Gonthier et al.,
2013; Hales et al., 2015), we need not concern ourselves
with foundational issues and can simply assume that stan-
dard mathematical properties hold. For example, we can
assume that there is a type R of real numbers without need-
ing to construct them (e.g. from Cauchy sequences), and
likewise can assume there is an integration operator on the
reals (cid:82) (f : R → R) : R that satisﬁes the well-known proper-
ties without needing to construct it either (e.g. from Rie-
mann sums).

Note that axioms must be chosen with great care since even
a single false axiom (perhaps caused by a single missing
precondition) can in principle allow proving any false the-
orem and so would invalidate the property that all formal
proofs can be trusted without inspection.5 However, there
are many preconditions that appear in mathematical theo-
rems, such as integrability, that are almost always satisﬁed
in machine learning contexts and which most developers
ignore. Using axioms that omit such preconditions will
necessarily lead to proving theorems that are themselves
missing the corresponding preconditions, but in practice a
non-adversarial developer is extremely unlikely to acciden-
tally construct vacuous proofs by exploiting these axioms.
For the ﬁrst draft of our system, we purposely omitted in-
tegrability preconditions in our axioms to simplify the de-
velopment. Only later did we make our axioms sound and
propagate the additional preconditions throughout the sys-
tem so that we could fully trust our formal proofs.

Despite the convenience of axiomatizing the mathematics,
designing the libraries was still challenging for two rea-
sons. First, there were many different ways to formally rep-
resent the mathematical objects in question, and we needed
to experiment to understand the tradeoffs between the dif-
ferent representations. Second, we needed to extend sev-
eral traditional mathematical concepts to support reasoning
about executable computer programs. The rest of this sub-

(3)

5For example, the seemingly harmless axiom ∀x, x/x = 1
without the precondition x (cid:54)= 0 can be used to prove the absur-
dity (0 = 0 ∗ 1 = 0 ∗ (0/0) = (0 ∗ 0)/0 = 0/0 = 1). If a system
assumes this axiom, then a formal proof of correctness could not
be trusted without inspection since the proof may exploit this con-
tradiction.

Developing Bug-Free Machine Learning Systems With Formal Mathematics

section illustrates these challenges by considering the prob-
lem we faced of designing a representation of probability
distributions for Certigrad.

Representing probability distributions. Our challenge is to
devise a sufﬁciently abstract representation of probability
distributions that satisﬁes the following desiderata: we can
reason about the probability density functions of continu-
ous random variables, we have a way to reason about arbi-
trary deterministic functions applied to random variables,
we can execute a distribution procedurally using a pseudo-
random number generator (RNG), the mathematical and
procedural representations of a distribution are guaranteed
to correspond, and the mathematics will be recognizable to
somebody familiar with the informal math behind stochas-
tic computation graphs.

We ﬁrst deﬁne types to represent the mathematical and pro-
cedural notions of probability distribution. For mathemat-
ics, we deﬁne a Func n to be a functional that takes a real-
valued function on Rn to a scalar:
def Func (n : N) : Type := ∀ (f : Rn → R), R

The intended semantics is that if p : Func n represents a
distribution on Rn, then p f is the expected value of f over
p, i.e. Ex∼p[f (x)].

For sampling, we deﬁne an Prog n to be a procedure that
takes an RNG and returns a vector in Rn along with an
updated RNG:
def Prog (n : N) : Type := RNG → Rn × RNG

We also assume that there are primitive (continuous) distri-
butions (PrimDist := Func 1 × Prog 1) that consist of a
probability density function and a corresponding sampling
In principle, we could construct all distribu-
procedure.
tions from uniform variates, but for expediency, we treat
other well-understood distributions as primitive, such as the
Gaussian (gauss µ σ : PrimDist).

Finally, we deﬁne a type of distributions (Dist n) that ab-
stractly represents programs that may mix sampling from
primitive distributions with arbitrary deterministic compu-
tations. A Dist n can be denoted to a Func n (with the
function E) to reason about mathematically, and to an Prog
n (with the function run) to execute with an RNG.

For readers familiar with functional programming, our con-
struction is similar to a monad. We allow three ways of
constructing a Dist n, corresponding to sampling from
a primitive distribution (sample), returning a value de-
terministically (det), and composing two distributions
(compose):

sample ((pdf, prog) : PrimDist) : Dist 1
det (xs : Rn) : Dist n
compose (d1 : Dist m) (d2 : Rm → Dist n) : Dist n

Dist n : Type
E {n : N} (d : Dist n) (f : Rn → R) : R
SCG n : Type
SCG.to_dist {n : N} (g : SCG n) (θ : R) : Dist n
cost {n : N} (g : SCG n) (xs : Rn) : R

Figure 4. The basic types and functions we will need to formally
state the speciﬁcation. Dist n represents a distribution over Rn,
E is the expected value function, SCG n represents a computation
graph on n nodes, SCG.to dist is the function that samples
from an SCG n and yields a distribution over the values at the
nodes, and cost sums the values at the leaf nodes of a graph.
Curly braces around an argument indicates that it can be inferred
from context and need not be passed explicitly.

The mathematical semantics of all three constructors are
straightforward:
E (sample (pdf, prog)) f = (cid:82) (λ x, pdf x * f x)
E (det xs) f = f xs
E (compose d1 d2) f = E d1 (λ x, (E (d2 x) f))

as are the procedural semantics:

run (sample (pdf, prog)) rng = prog rng
run (det xs) rng = (xs, rng)
run (compose d1 d2) rng =
let (x, rng’) := run d1 rng in run (d2 x) rng’

We have deﬁned E and run to correspond; we consider a
stochastic program correct if we can prove the relevant the-
orems about its Func denotation, and we sample from it by
passing an RNG to its Prog denotation.

4.4. Formal speciﬁcation

With the background mathematics in place, the next step
is to write down the formal speciﬁcation itself. First, we
design types for every other object and function appearing
in the informal description. To start, we need a type SCG n
to represent stochastic computation graphs on n nodes, and
a function SCG.to_dist that takes an SCG n and a scalar
parameter θ to a distribution over n real numbers (Dist n).
We also need a function cost that takes a graph and the
values at each of its nodes and sums the values at the leaf
nodes. Figure 4 provides the full types of all objects that
will appear in the speciﬁcation.

Now we can write down a type-correct analogue of the in-
formal speciﬁcation presented in Equation 3:
def bprop_spec (bprop : ∀ {n}, SCG n → R → Rn → R)

: Prop :=

∀ (n : N) (g : SCG n) (θ : R),
E (SCG.to_dist g θ) (λ xs, bprop g θ xs)
=
∇ (λ θ, E (SCG.to_dist g θ) (λ xs, cost g xs)) θ

Given the mathematics libraries, implementing the other

Developing Bug-Free Machine Learning Systems With Formal Mathematics

objects and functions appearing in the speciﬁcation such
as SCG n and SCG.to_dist is straightforward functional
programming.

4.5. Interactive proof

While conventional wisdom is that one would write their
program before trying to prove it correct, the interactive
proof process provides so much helpful information about
what the system needs to do that we began working on the
proof immediately after drafting the speciﬁcation. We split
the proof into two steps. First, we implemented the sim-
plest possible function that satisﬁed the speciﬁcation (that
only computed the gradient for a single parameter at a time
and did not memoize at all) and proved that correct. Sec-
ond, we implemented a more performant version (that com-
puted the gradient for multiple parameters simultaneously
using memoization) and proved it equivalent to the ﬁrst
one.

For the ﬁrst step, we started with a placeholder implemen-
tation that immediately returned zero and let the interac-
tive proof process guide the implementation. Whenever
the proof seemed to require induction on a particular data
structure, we extended the program to recurse on that data
structure; whenever the proof showed that a branch of the
program needed to return a value with a given expecta-
tion, we worked backwards from that to determine what
value to return. Proving the ﬁrst step also exposed errors in
our speciﬁcation in the form of missing preconditions. For
the speciﬁcation to hold, we needed to make additional as-
sumptions about the graph, e.g. that the identiﬁer for each
node in the graph is unique, and that each leaf node is a
scalar (WellFormed g). We also needed to assume a gen-
eralization of the differentiability requirement mentioned
in Schulman et al. (2015), that a subset of the nodes deter-
mined by the structure of the graph must be differentiable
no matter the result of any stochastic choices (GradsExist
g θ).

For the second step, we wrote the memoizing implementa-
tion before starting the proof and used the process of prov-
ing to test and debug it. Although the code for memoiz-
ing was simple and short, we still managed to make two
implementation errors, one conceptual and one syntactic.
Luckily the process of proving necessarily exposes all im-
plementation errors, and in this case made it clear how to
ﬁx both of them.

We completed the main proof of correctness before proving
most of the lemmas that the proof depends on, but the lem-
mas turned out to be true (except for a few missing precon-
ditions) and so proving them did not expose any additional
implementation errors. We also completed the main proof
while our axioms were still unsound (see §4.3). When we
made our axioms sound and propagated the changes we

def bprop_spec (bprop : ∀ {n}, SCG n → R → Rn → R)

: Prop :=

∀ (n : N) (g : SCG n) (θ : R),
WellFormed g ∧ GradsExist g θ
∧ IntegralsExist g θ ∧ CanDiffUnderInts g θ →
E (SCG.to_dist g θ) (λ xs, bprop g θ xs)
=
∇ (λ θ, E (SCG.to_dist g θ) (λ xs, cost g xs)) θ

Figure 5. The ﬁnal speciﬁcation for the simpliﬁed problem with
only scalars (as opposed to tensors) and only a single parameter
θ. Our actual system supports arbitrarily-shaped tensors and dif-
ferentiating with respect to multiple parameters at once.

found that our speciﬁcation required two additional precon-
ditions: that all functions that are integrated over in the the-
orem statement are indeed integrable (IntegralsExist
g θ), and that the many preconditions needed for pushing
the gradient over each integral in the expected loss are sat-
isﬁed (CanDiffUnderInts g θ). However, tracking these
additional preconditions did not lead to any changes in our
actual implementation. Figure 5 shows the ﬁnal speciﬁca-
tion.

4.6. Optimizations

We can also use our methodology to verify optimizations
that involve mathematical reasoning. When developing
machine learning models, one often starts with an easy-
to-understand model that induces a gradient estimator with
unacceptably high variance, and does informal mathemat-
ics by hand to derive a new model that has the same objec-
tive function but that induces a better gradient estimator. In
our approach, the user can write both models and use the
process of interactive proving to conﬁrm that they induce
the same objective function. Common transformations can
be written once and proved correct so that users need only
write the ﬁrst model and the second can be derived and
proved equivalent automatically.

As part of Certigrad, we wrote a program optimization
that integrates out the KL-divergence of the multivariate
isotropic Gaussian distribution and we proved once and
for all that the optimization is sound. We also veriﬁed an
optimization that reparameterizes a model so that random
variables do not depend on parameters (and so need not
be backpropagated through). Speciﬁcally, the optimization
replaces a node that samples from N (µ, Diag(σ2)) with a
graph of three nodes that ﬁrst samples from N (0, In×n)
and then scales and shifts the result according to σ and
µ respectively. We applied these two transformations
in sequence to a na¨ıve variational-autoencoder to yield
the Auto-Encoding Variational Bayes (AEVB) estima-
tor (Kingma & Welling, 2014).

Developing Bug-Free Machine Learning Systems With Formal Mathematics

(a) Expected loss vs epoch (b) Running time vs epoch

5. Discussion

Figure 6. Results of running our certiﬁed procedure on an AEVB
model, compared to TensorFlow. Our system trains just as well,
and is slightly slower at ﬁrst but catches up over time.

at each iteration against the same model and optimization
procedure in TensorFlow, both running on 2 CPU cores.
We ﬁnd that our expected losses decrease at the same rate,
and that while Certigrad takes 25% longer for the ﬁrst few
iterations, its performance is more stable over time and it
eventually surpasses TensorFlow (Figure 6).

Our primary motivation is to develop bug-free machine
learning systems, but our approach may provide signiﬁcant
beneﬁts even when building systems that need not be per-
fect. Perhaps the greatest burden software developers must
bear is needing to fully understand how and why their sys-
tem works, and we found that by formally specifying the
system requirements we were able to relegate much of this
burden to the computer. Not only were we able to syn-
thesize some fragments of the system (§4.5), we were able
to achieve extremely high conﬁdence that our system was
bug-free without needing to think about how all the pieces
of the system ﬁt together. In our approach, the computer—
not the human—is responsible for ensuring that all the lo-
cal properties that the developer establishes imply that the
overall system is correct. Although using our methodology
to develop Certigrad imposed many new requirements and
increased the overall workload substantially, we found that
on the whole it made the development process less cogni-
tively demanding.

There are many ways that our methodology can be adopted
incrementally. For example, speciﬁcations need not cover
functional correctness, not all theorems need to be proved,
unsound axioms can be used that omit certain precon-
ditions, and more traditional code can be wrapped and
axiomatized (as we did with Eigen). When developing
Certigrad we pursued the ideal of a complete, machine-
checkable proof of functional correctness, and achieved
an extremely high level of conﬁdence that the system was
correct. However, we realized many of the beneﬁts of
our methodology—including partial synthesis and reduced
cognitive demand—early in the process before proving
most of the lemmas. Although we could not be certain
that we had found all of the bugs before we made our ax-
ioms sound and ﬁlled in the gaps in the formal proofs, in
hindsight we had eliminated all bugs early in the process
as well. While a pure version of our methodology may al-
ready be cost-effective for high-assurance applications, we
expect that pragmatic use of our methodology could yield
many of the beneﬁts for relatively little cost and could be
useful for developing a wide range of machine learning sys-
tems to varying standards of correctness.

4.7. Verifying speciﬁc models

Even though we proved that bprop satisﬁes its formal
speciﬁcation (bprop_spec), we cannot be sure that it will
compute the correct gradients for a particular model un-
less we prove that the model satisﬁes the preconditions of
the speciﬁcation. Although some of the preconditions are
technically undecidable, in practice most machine learning
models will satisfy them all for simple reasons. We wrote a
(heuristic) tactic program to prove that speciﬁc models sat-
isfy all the preconditions and used it to verify that bprop
computes the correct gradients for the AEVB model de-
rived in §4.6.

4.8. Running the system

We have proved that our system is correct in an idealized
mathematical context with inﬁnite-precision real numbers.
To actually execute the system we need to replace all real
numbers in the program with ﬂoating-point numbers. Al-
though doing so technically invalidates the speciﬁcation
and can introduce numerical instability in some cases, this
class of errors is well understood (Higham, 2002), could
be ruled out as well in principle (Harrison, 2006; Boldo
et al., 2015; Ramananandro et al., 2016) and is conceptu-
ally distinct from the algorithmic and mathematical errors
that our methodology is designed to eliminate. To improve
performance, we also replace all tensors with an optimized
tensor library (Eigen). This approximation could introduce
errors into our system if for whatever reason the Eigen
methods we use are not functionally equivalent to ones we
formally reason about; of course developers could achieve
even higher assurance by verifying their optimized tensor
code as well.

4.9. Experiments

Certigrad is efﬁcient. As an experiment, we trained an
AEVB model with a 2-layer encoding network and a 2-
layer decoding network on MNIST using the optimization
procedure ADAM (Kingma & Ba, 2014), and compared
both the expected loss and the running time of our system

Developing Bug-Free Machine Learning Systems With Formal Mathematics

Acknowledgments

We thank Jacob Steinhardt, Alexander Ratner, Cristina
White, William Hamilton, Nathaniel Thomas, and Vatsal
Sharan for providing valuable feedback on early drafts.
We also thank Leonardo de Moura, Tatsu Hashimoto, and
Joseph Helfer for helpful discussions. This work was sup-
ported by Future of Life Institute grant 2016-158712.

References

Abadi, Mart´ın, Agarwal, Ashish, Barham, Paul, Brevdo,
Eugene, Chen, Zhifeng, Citro, Craig, Corrado, Greg S.,
Davis, Andy, Dean, Jeffrey, Devin, Matthieu, Ghe-
mawat, Sanjay, Goodfellow, Ian, Harp, Andrew, Irv-
ing, Geoffrey, Isard, Michael, Jia, Yangqing, Jozefowicz,
Rafal, Kaiser, Lukasz, Kudlur, Manjunath, Levenberg,
Josh, Man´e, Dan, Monga, Rajat, Moore, Sherry, Murray,
Derek, Olah, Chris, Schuster, Mike, Shlens, Jonathon,
Steiner, Benoit, Sutskever, Ilya, Talwar, Kunal, Tucker,
Paul, Vanhoucke, Vincent, Vasudevan, Vijay, Vi´egas,
Fernanda, Vinyals, Oriol, Warden, Pete, Wattenberg,
Martin, Wicke, Martin, Yu, Yuan, and Zheng, Xiaoqiang.
TensorFlow: Large-scale machine learning on heteroge-
neous systems, 2015. URL http://tensorflow.
org/. Software available from tensorﬂow.org.

Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pas-
canu, R., Desjardins, G., Turian, J., Warde-Farley, D.,
and Bengio, Y. Theano: a CPU and GPU math expres-
sion compiler. In Python for Scientiﬁc Computing Con-
ference, 2010.

de Moura, Leonardo, Kong, Soonho, Avigad, Jeremy,
Van Doorn, Floris, and von Raumer, Jakob. The Lean
In Automated
theorem prover (system description).
Deduction-CADE-25, pp. 378–388. Springer, 2015.

Gonthier, Georges. Formal proof–the four-color theorem.

Notices of the AMS, 55(11):1382–1393, 2008.

Gonthier, Georges, Asperti, Andrea, Avigad, Jeremy,
Bertot, Yves, Cohen, Cyril, Garillot, Franc¸ois, Le Roux,
St´ephane, Mahboubi, Assia, O’Connor, Russell, Biha,
Sidi Ould, et al. A machine-checked proof of the odd or-
der theorem. In Interactive Theorem Proving, pp. 163–
179. Springer, 2013.

Gordon, Michael JC. Edinburgh lcf: a mechanised logic of

computation. 1979.

Gordon, Michael JC and Melham, Tom F.

Introduction
to hol a theorem proving environment for higher order
logic. 1993.

Guennebaud, Ga¨el, Jacob, Benoˆıt, et al.

Eigen v3.

http://eigen.tuxfamily.org, 2010.

Hales, Thomas, Adams, Mark, Bauer, Gertrud, Dang,
Dat Tat, Harrison, John, Hoang, Truong Le, Kaliszyk,
Cezary, Magron, Victor, McLaughlin, Sean, Nguyen,
Thang Tat, et al. A formal proof of the kepler conjec-
ture. arXiv preprint arXiv:1501.02155, 2015.

Harrison, John. Hol light: A tutorial introduction. In Inter-
national Conference on Formal Methods in Computer-
Aided Design, pp. 265–269. Springer, 1996.

Boldo, Sylvie, Jourdan, Jacques-Henri, Leroy, Xavier, and
Melquiond, Guillaume. Veriﬁed compilation of ﬂoating-
point computations. Journal of Automated Reasoning,
54(2):135–163, 2015.

Harrison, John. Floating-point veriﬁcation using theorem
proving. In International School on Formal Methods for
the Design of Computer, Communication and Software
Systems, pp. 211–242. Springer, 2006.

Chen, Haogang, Ziegler, Daniel, Chajed, Tej, Chlipala,
Adam, Kaashoek, M Frans, and Zeldovich, Nickolai.
Using crash hoare logic for certifying the fscq ﬁle sys-
tem. In Proceedings of the 25th Symposium on Operat-
ing Systems Principles, pp. 18–37. ACM, 2015.

Chlipala, Adam. The bedrock structured programming
system: Combining generative metaprogramming and
In ACM
hoare logic in an extensible program veriﬁer.
SIGPLAN Notices, volume 48, pp. 391–402. ACM,
2013.

Coq Development Team. The Coq proof assistant reference

manual: Version 8.5. INRIA, 2015-2016.

Coquand, Thierry and Huet, G´erard. The calculus of con-
Information and computation, 76(2-3):95–

structions.
120, 1988.

Higham, Nicholas J. Accuracy and stability of numerical

algorithms. SIAM, 2002.

Kingma, D. P. and Welling, M. Auto-encoding variational

Bayes. arXiv, 2014.

Kingma, Diederik and Ba,

Jimmy.
method for stochastic optimization.
arXiv:1412.6980, 2014.

Adam:

A
arXiv preprint

Klein, Gerwin, Elphinstone, Kevin, Heiser, Gernot, An-
dronick, June, Cock, David, Derrin, Philip, Elkaduwe,
Dhammika, Engelhardt, Kai, Kolanski, Rafal, Norrish,
Michael, et al. sel4: Formal veriﬁcation of an os kernel.
In Proceedings of the ACM SIGOPS 22nd symposium on
Operating systems principles, pp. 207–220. ACM, 2009.

Leroy, Xavier. Formal veriﬁcation of a realistic compiler.
Communications of the ACM, 52(7):107–115, 2009.

Developing Bug-Free Machine Learning Systems With Formal Mathematics

Nipkow, Tobias, Paulson, Lawrence C, and Wenzel,
Isabelle/HOL: a proof assistant for higher-

Markus.
order logic, volume 2283. Springer, 2002.

Owre, Sam, Rushby, John M, and Shankar, Natarajan.
In Automated

Pvs: A prototype veriﬁcation system.
Deduction—CADE-11, pp. 748–752. Springer, 1992.

Ramananandro, Tahina, Mountcastle, Paul, Meister,
Benoˆıt, and Lethin, Richard. A uniﬁed coq framework
for verifying c programs with ﬂoating-point computa-
In Proceedings of the 5th ACM SIGPLAN Con-
tions.
ference on Certiﬁed Programs and Proofs, pp. 15–26.
ACM, 2016.

Rudnicki, Piotr. An overview of the mizar project. In Pro-
ceedings of the 1992 Workshop on Types for Proofs and
Programs, pp. 311–330, 1992.

Schulman, John, Heess, Nicolas, Weber, Theophane, and
Abbeel, Pieter. Gradient estimation using stochastic
computation graphs. In Advances in Neural Information
Processing Systems, pp. 3528–3536, 2015.

