Prediction and Control with Temporal Segment Models

A. Appendix

Here we give a more precise description of the architec-
tures of the models we introduced in the paper. Both the
dynamics model and the latent action prior were trained
using Adam with the default parameters.

A.1. Dynamics Model

The following ﬁgure depicts the detailed encoder and de-
coder architectures for our dynamics models. The encoder
uses 1D-convolutions (across the temporal dimension) and
the ReLU activation function. The decoder is autoregres-
sive, using dilated causal 1D-convolutions and the gated
activation function described in Section 3.1.

The layer sizes indicated below correspond to the model we
trained for the basic Reacher environment. For the obsta-
cle and pushing environments, we used the same encoder
architecture. The decoder for those environments had 64
channels in all layers, and had an additional 1 × 1 convolu-
tion with 128 channels before the ﬁnal layer.

X+2 x 1 convstride 132 cEncoder, Q(x)2 x 1 convstride 216 catten, projectZ2ZZInputSampled OutputDecoder, P(x)U+UXZ32 c2 x 1 dilated convrate 132 c3 x 1 dilated convrate 232 c2 x 1 dilated convrate 41 x 1 convX+InputOutputDynamics ModelPrediction and Control with Temporal Segment Models

A.2. Latent Action Prior

The architecture for the latent action prior is quite similar
to that of our dynamics models as depicted on the previous
page. We used the same architecture for all experiments.

2 x 1 convstride 112 cEncoder, Q(u)2 x 1 convstride 212 catten, projectZ2ZZInputSampled OutputDecoder, P(u)UZ32 c2 x 1 dilated convrate 132 c3 x1 dilated convrate 232 c2 x 1 dilated convrate 41 x 1 convInputOutputLatent Action Prior