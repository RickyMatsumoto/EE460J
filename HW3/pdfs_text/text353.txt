Supplementary Material: Bayesian inference on random simple graphs
with power law degree distributions

Juho Lee 1 Creighton Heaukulani 2 Zoubin Ghahramani 2 3 Lancelot F. James 4 Seungjin Choi 1

1. Proofs

We prove Theorem 3.1 and Theorem 5.1 in the paper. First consider the following redeﬁnition of our model with slightly
different notation; let Wn be a random variable constrained on (0, Cn], with density

where C1, C2, . . . , is a sequence of positive numbers satisfying

fn(dw) =

w−α−1(1 − e−w)1{0<w≤Cn}dw,

1
Zn

lim
n→∞

Cn = ∞,

lim
n→∞

C α

n /n = 0.

f (w) =

α
Γ(1 − α)

w−α−1(1 − e−w)1{w>0},

Note that Zn → Γ(1 − α)/α as n → ∞, and so the sequence of densities fn(dw) converges pointwise to the density of
the BFRY distribution

and Wn converges in distribution to a BFRY random variable. Let Wn,1, . . . , Wn,n be n i.i.d. copies of Wn. A random
simple graph X is then deﬁned to be a collection of Bernoulli random variables as follows:
Wn,i√
Ln

P{Xij = 1 | ri,j} =

ri,j = UiUj, Ui =

ri,j
1 + ri,j

(4)

,

,

where Ln := (cid:80)n
i=1 Wn,i. We will write X | r ∼ GRG(n, r), where r := (ri,j : i < j ≤ n).
We begin with a sequence of Lemmas. Deﬁne a sequence of random variables Vs,n, for every s, n ≥ 1, by

Let Vs,n,1, . . . , Vs,n,n be n i.i.d. copies of Vs,n, and denote the empirical mean of these copies by

Vs,n :=

Wn
C s−α
n

.

¯Vs,n :=

Vs,n,i.

1
n

n
(cid:88)

i=1

The expectation of Vs,n is ﬁnite for all s, n < ∞, and is computed as

E[Vs,n] =

ws−α−1(1 − e−w)dw

(cid:90) Cn

1
ZnC s−α
n
(cid:26) 1
1
Zn

s − α

0

=

−

γ(s − α, Cn)
C s−α
n

(cid:27)

,

1Pohang University of Science and Technology (POSTECH), Pohang, South Korea 2University of Cambridge, Cambridge, United
Kingdom 3Uber AI Labs, San Francisco, CA, USA 4Hong Kong University of Science and Technology (HKUST), Clearwater Bay,
Hong Kong. Correspondence to: Juho Lee <stonecold@postech.ac.kr>.

Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, 2017. JMLR: W&CP. Copyright 2017 by
the author(s).

(1)

(2)

(3)

(5)

(6)

(7)

Supp: Power-law simple graphs

where γ(·, ·) is the lower incomplete gamma function.

P
→ denote convergence in probability. The following lemma is a standard mean convergence result:

Let
Lemma 1.1. ¯Vs,n

P
→ E[Vs,n], as n → ∞.

Proof. For all ε > 0, by Chebyshev’s inequality and the condition in Eq. (2),

P{| ¯Vs,n − E[Vs,n]| ≥ ε} ≤

Var(Vs,n)
nε2

≤

E[V 2
s,n]
nε2 =

1
Znε2

(cid:26)

C α
n
n(2s − α)

−

γ(2s − α, Cn)
nC 2s−2α
n

(cid:27)

→ 0,

The following lemma will be used to study various higher order moments in later results:

as n → ∞, as desired.

Lemma 1.2. For s ≥ 2,

Proof. We have

Ms,n :=

(cid:80)n
((cid:80)n

i=1 W s
n,i
i=1 Wn,i)s

P
→ 0,

as n → ∞.

Ms,n =

nC s−α
n
nsC s−sα
n

¯Vs,n
¯V s
1,n

=

(cid:18) C α
n
n

(cid:19)s−1 ¯Vs,n
¯V s
1,n

.

As n → ∞, the ﬁrst factor on the right hand side clearly converges to zero (c.f. Eq. (2)), and, by Lemma 1.1, the second
term converges to a constant in probability.

Recall that Dn,i := (cid:80)
j(cid:54)=i Xi,j is the degree of the i-th node in the graph X | r ∼ GRG(n, r), given by Eq. (4). The
following result will show up in later calculations involving the probability generating function (PGF) of the degree random
variables Dn,i:

Lemma 1.3. For every collection t1, . . . , tn with |ti| ≤ 1, for i ≤ n,

(cid:104) n
(cid:89)

E

i=1

tDn,i
i

| Wn,1 = w1, . . . , Wn,n = wn

=

(cid:105)

(cid:89)

i<j≤n

Ln + titjwiwj
Ln + wiwj

,

for positive w1, . . . , wn.

Proof. The proof is given by Britton et al. (2006).

The following result studies a representation of the PGF of the degree random variables and their higher order moments:

Lemma 1.4. Fix a node k ≤ n. Deﬁne

Fn,k(t; wk) :=

(cid:89)

i(cid:54)=k

Ln,−k + wk + twkWn,i
Ln,−k + wk + wkWn,i

,

for |t| ≤ 1, and wk > 0,

(12)

where Ln,−k := (cid:80)
hold:

i(cid:54)=k Wn,i. Note that the s-th derivative F (s)

n,k(t; wk) exists for all s ≥ 0. For all s ≥ 0, the following

1. F (s)
2. F (s)

n,k(t; wk) is uniformly bounded, for all n ≥ 1;
k exp{(t − 1)wk}, as n → ∞.
n,k(t; wk)

P
→ ws

(8)

(9)

(10)

(11)

Supp: Power-law simple graphs

Proof. In the case s = 0, Fn,k(t; wk) is trivially bounded by 1 since |t| ≤ 1. By the Taylor series expansion log(1 + x) =
x + O(x2), we have

Fn,k(t; wk) = exp

(t − 1)wk

(cid:26)

Ln,−k
Ln,−k + wk

(cid:18)

+ O

w2
k

(cid:80)

i(cid:54)=k W 2
n,i
(Ln,−k + wk)2

(cid:19)(cid:27)
.

By Lemma 1.1,

where ¯V1,n,−k is the empirical mean in Eq. (6) excluding the element V1,n,k. Furthermore, by Lemma 1.2,

Ln,−k
Ln,−k + wk

=

¯V1,n,−k
¯V1,n,−k + wk/(n − 1)/C 1−α

n

P
→ 1,

(cid:18)

O

w2
k

(cid:80)

i(cid:54)=k W 2
n,i
(Ln,−k + wk)2

(cid:19)

≤ O(w2

kM2,n,−k)

P
→ 0,

where Ms,n,−k is Ms,n computed without Vs,n,k. Combining, we have

Fn,k(t; wk)

P
→ exp{(t − 1)wk}.

Before proceeding for s ≥ 1, we deﬁne

for all r, n ≥ 1. One can easily see that Qr,n,k(t; wk) ≤ 1 for all r, n ≥ 1. For r = 1, we have

Qr,n,k(t; wk) :=

W r
n,i
(Ln,−k + wk + twkWn,i)r ,

(cid:88)

i(cid:54)=k

(cid:88)

i(cid:54)=k

Wn,i
Ln,−k + wk + twkCn

≤ Q1,n,k(t; wk) ≤ 1,

and

(cid:88)

i(cid:54)=k

Wn,i
Ln,−k + wk + twkCn

=

1
1 + wk/Ln,−k + twkCn/Ln,−k

(cid:26)

=

1 +

wk
(n − 1)C 1−α

n

¯V −1
s,n,−k + twk

C α
n
n

n
n − 1

¯V −1
s,n,−k

(cid:27)−1

P
→ 1.

Hence, by the squeeze theorem, Q1,n,k(t; wk)

P
→ 1. For r ≥ 2, we have

0 ≤ Qr,n,k(t; wk) ≤ Mr,n,−k

P
→ 0,

by Lemma 1.2. Hence, we have Qr,n,k(t; wk)

P
→ 0 for r ≥ 2.

Now we show that

n,k(t; wk) = wkF (s−1)
F (s)

n,k

(t; wk)Q1,n,k(t; wk) +

as,rF (s−r)
n,k

(t; wk)Qr,n,k(t; wk),

(21)

s
(cid:88)

r=2

for some constants {as,r} for all s ≥ 1 and r ≥ 2. We proceed by the mathematical induction. For s = 1,

F (1)

n,k(t; wk) =

(cid:88)

i(cid:54)=k

wkWn,i
Ln,−k + wk + wkWn,i

(cid:89)

j(cid:54)=i,k

Ln,−k + wk + twkWn,j
Ln,−k + wk + wkWn,j

= wkFn,k(t; wk)Q1,n,k(t; wk).

(22)

(13)

(14)

(15)

(16)

(17)

(18)

(19)

(20)

Now by the inductive hypothesis,

Supp: Power-law simple graphs

F (s+1)
n,k

(t; wk) = wkF (s)

n,k(t; wk)Q1,n,k(t; wk) − w2

kF (s−1)

n,k

(t; wk)Q2,n,k(t; wk)

+

s
(cid:88)

r=2

as,r(F (s+1−r)
n,k

(t; wk)Qr,n,k(t; wk) − rwkF (s−r)

n,k Qr+1,n,k(t; wk))

= wkF (s)

n,k(t; wk)Q1,n,k(t; wk) +

as+1,rF (s+1−r)
n,k

(t; wk)Qr,n,k(t; wk),

s+1
(cid:88)

r=2

where

so the inductive argument holds.

as+1,2 = as,2 − w2
k,

as+1,r = as,r − as,r−1(r − 1)wk

for r ≥ 2,

Having (21), by mathematical induction, we can easily show that F (s)
Moreover,

n,k(t; wk) is uniformly bounded for all s, n ≥ 1.

F (1)

n,k(t; wk) = wkFn,k(t; wk)Q1,n,k(t; wk)

P
→ wk exp{(t − 1)wk},

by (16) and (19). Combining this with (20), by mathematical induction, we can show that for all s ≥ 1,

F (s)

n,k(t; wk)

P
→ ws

k exp{(t − 1)wk}.

We will now use our collected results to analyze the asymptotic distribution of the degree random variables; the following
result characterizes this distribution:
Lemma 1.5. Fix a node k. Given {Wn,k = wk}, for some wk > 0, the degree Dn,k of node k converges in distribution to
a Poisson random variable with rate wk, as n → ∞.

Proof. The PGF of Dn,k is given by

E[tDn,k | Wn,k = wk] = E[Fn,k(t; wk)],

for |t| ≤ 1.

Note that these expectations are under the σ-ﬁeld generated by {Wk = wk}. For all s ≥ 0, we will derive the limit of
P{Dn,k = s | wk}, as n → ∞, which we note is given by the s-th order derivatives of the PGF in Eq. (27), evaluated at
the argument t = 0. It therefore sufﬁces to show that E[F (s)
k exp{(t − 1)wk}, as n → ∞, for all s ≥ 0.
By Lemma 1.4, we know that F (s)
k exp{(t − 1)wk}, as n → ∞.
n,k(t; wk)
Therefore, by uniform integrability,

n,k(t; wk)] → ws
n,k(t; wk) is uniformly bounded and that F (s)

P
→ ws

lim
n→∞

E[F (s)

(cid:104)
n,k(t; wk)] = E

lim
n→∞

F (s)

n,k(t; wk)

(cid:105)

= ws

k exp{(t − 1)wk}.

We are now ready to prove the main theorems in the paper.

Proof of Theorem 3.1. We will ﬁrst verify that, for y (cid:29) 1, P{Dn,k = y} → cy−1−α for every node k and for some
constant c > 0 as n → ∞. By Lemma 1.5, conditioned on {Wk = wk}, the degree Dn,k converges in distribution to a
Poisson random variable with rate wk. Then by dominated convergence,

lim
n→∞

P{Dn,k = y} = lim
n→∞
(cid:90) ∞

(cid:90) ∞

P{Dk = y|wk}pn(dwk)

0
wy
ke−wk
y!
0
αΓ(y − α)
y!Γ(1 − α)

=

=

p(dwk)

(1 − 2α−y).

(23)

(24)

(25)

(26)

(27)

(28)

(29)

By the asymptotics of the Gamma function, for y (cid:29) 1, we have

Supp: Power-law simple graphs

lim
n→∞

P{Dn,k = y} = cy−1−α,

for some constant c.

Next we show that, for any ﬁnite m, the collection of random variables Dn,1, . . . , Dn,m are asymptotically independent,
as n → ∞. We compute the (joint) probability generating function of (Dn,1, . . . , Dn,m), with |ti| ≤ 1 for i = 1, . . . , m.
By Lemma 1.3,

(cid:105)

tDn,i
i

= E

(cid:104) m
(cid:89)

m
(cid:89)

(cid:104) m
(cid:89)

E

i=1

Ln + titjWn,iWn,j
Ln + Wn,iWn,j

n
(cid:89)

j=m+1

Ln + tiWn,iWn,j
Ln + Wn,iWn,j

(cid:105)

i=1

j=i+1

(cid:104)
= E

E

(cid:104) m
(cid:89)

m
(cid:89)

i=1

j=i+1

n
(cid:89)

×

j=m+1

Ln,m+1:n + (cid:96)n,1:m + titjwiWn,j
Ln,m+1:n + (cid:96)n,1:m + wiWn,j

Ln,m+1:n + (cid:96)n,1:m + tiwiWn,j
Ln,m+1:n + (cid:96)n,1:m + wiWn,j

| Wn,1:m = w1:m

(cid:105)(cid:105)

.

Given w1:m, by a similar argument as in the proof of Lemma 1.4, one can easily show that

m
(cid:89)

j=i+1

Ln,m+1:n + (cid:96)n,1:m + titjwiWn,j
Ln,m+1:n + (cid:96)n,1:m + wiWn,j

P
→ 1,

as n → ∞,

and

n
(cid:89)

j=m+1

Ln,m+1:n + (cid:96)n,1:m + tiwiWn,j
Ln,m+1:n + (cid:96)n,1:m + wiWn,j

P
→ exp{(ti − 1)wi},

as n → ∞.

Hence, again by a similar argument as in the proof of Lemma 1.4, we have

lim
n→∞

(cid:104) m
(cid:89)

E

i=1

tDn,i
i

(cid:105)

=

m
(cid:89)

i=1

E[exp{(ti − 1)Wi}],

that is, the joint PGF asymptotically factorizes into the product of the PGFs for i.i.d. random variables, and the result
follows.

Proof of Theorem 3.2. Using the fact that the expected number of nodes En := (cid:80)n
tn =

t and obtain

√

i=1 Dn,i/2, we may take t1 = · · · =

E[tEn] = E

(cid:104) (cid:89)

Ln + tWn,iWn,j
Ln + Wn,iWn,j

(cid:105)
.

i<j≤n

We evaluate the derivative of the PGF to obtain the ﬁrst moment

E[En] =

∂E[tEn ]
∂t

(cid:12)
(cid:12)
(cid:12)t=1

(cid:104) (cid:88)

= E

i<j≤n

Wn,iWn,j
Ln + Wn,iWn,j

(cid:105)

≤

1
2

(cid:104) (cid:88)

E

(cid:105)

Wn,iWn,j
Ln

n
2

=

E[Wn].

i≤j≤n

Since

we have

E[Wn] =

1
Zn

(cid:110) C 1−α
n
1 − α

− γ(1 − α, Cn)

(cid:111)
,

E[En] = O(nC 1−α

).

n

(30)

(31)

(32)

(33)

(34)

(35)

(36)

(37)

(38)

Proof of Theorem 5.1. Recall that

Supp: Power-law simple graphs

P{X = x | r} =

(cid:89)

i<j≤n

ri,j
1 + ri,j

= G−1(r)

(cid:89)

Axi,j
i,j

U Dn,i
i

,

i<j≤n

n
(cid:89)

i=1

where A := (Ai,j)i<j≤n and

Since (cid:80)
x

P{X = x | r} = 1, we have

The joint PGF of (Dn,1, . . . , Dn,n) is then

G(r) :=

(1 + Ai,jUiUj).

(cid:89)

i<j≤n

G(r) =

(cid:88)

(cid:89)

Axi,j
i,j

uDn,i
i

.

x

i<j≤n

n
(cid:89)

i=1

(cid:104) n
(cid:89)

E

i=1

tDn,i
i

| A, Wn,1:n

=

(cid:105)

(cid:88)

P{X = x | r}

tDn,i(x)
i

x

n
(cid:89)

i=1

n
(cid:89)

i=1

= G−1(r)

(cid:88)

(cid:89)

Axi,j
i,j

(tiUi)Dn,i

x

i<j≤n
1 + Ai,jtitjUiUj
1 + Ai,jUiUj

.

(cid:89)

=

i<j≤n

(39)

(40)

(41)

(42)

The remainder of the proof follows analogously to the proof of Theorem 3.1 above.

References

Britton, T., Deijfen, M., and Martin-L¨of, A. Generating simple random graphs with prescribed degree distribution. Journal

of Statistical Physics, 124(6):1377–1397, 2006.

Kingma, D. P. and Welling, M. Auto-encoding variational Bayes. In ICLR, 2014.

Knowles, D. A.

Stochastic gradient variational Bayes for gamma approximating distributions.

arXiv preprint

arXiv:1509.01631, 2015.

Bayesian Analysis, 8(4):837–882, 2013.

Salimans, T. and Knowles, D. A. Fixed-form variational posterior approximation through stochastic linear regression.

