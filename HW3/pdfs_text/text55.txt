Improving Viterbi is Hard:
Better Runtimes Imply Faster Clique Algorithms

Arturs Backurs 1 Christos Tzamos 1

Abstract
The classic algorithm of Viterbi computes the
most likely path in a Hidden Markov Model
(HMM) that results in a given sequence of ob-
servations. It runs in time O(T n2) given a se-
quence of T observations from a HMM with n
states. Despite signiﬁcant interest in the prob-
lem and prolonged effort by different communi-
ties, no known algorithm achieves more than a
polylogarithmic speedup. In this paper, we ex-
plain this difﬁculty by providing matching condi-
tional lower bounds. Our lower bounds are based
on assumptions that the best known algorithms
for the All-Pairs Shortest Paths problem (APSP)
and for the Max-Weight k-Clique problem in
edge-weighted graphs are essentially tight. Fi-
nally, using a recent algorithm by Green Larsen
and Williams for online Boolean matrix-vector
log n) speedup for
multiplication, we get a 2Ω(
the Viterbi algorithm when there are few distinct
transition probabilities in the HMM.

√

1. Introduction

A Hidden Markov Model (HMM) is a simple model that
describes a random process for generating a sequence of
observations. A random walk is performed on an underly-
ing graph (Markov Chain) and, at each step, an observation
is drawn from a probability distribution that depends only
on the current state (the node in the graph).

HMMs are a fundamental statistical tool and one of the
most important questions in the applications of HMMs is
computing the most likely sequence of states visited by the
random walk in the HMM given the sequence of obser-
vations. Andrew Viterbi proposed an algorithm (Viterbi,
1967) for this problem that computes the solution in

Authors ordered alphabetically.

1MIT, US. Correspon-
dence to: Arturs Backurs <backurs@mit.edu>, Christos Tzamos
<tzamos@mit.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

O(T n2) time for any HMM with n states and an observa-
tion sequence of length T . This algorithm is known as the
Viterbi algorithm and the problem of computing the most
likely sequence of states is also known as the Viterbi Path
problem.

The Viterbi algorithm has found wide applicability in ma-
chine learning. It is an important tool for structured predic-
tion, used e.g., for structured perceptrons (Collins, 2002).
Other applications include speech recognition (Rabiner,
1989; Neﬁan et al., 2002; Bengio, 2003), part-of-speech
tagging (Collins, 2002), action planning (Attias, 2003),
emotion recognition (Cohen et al., 2000), human activity
classiﬁcation (Mannini & Sabatini, 2010), and waveform
classiﬁcation (Kim & Smyth, 2006). Furthermore, it is of-
ten combined with other methods. For example, a com-
bination of the Viterbi algorithm and neural networks is
used for speech recognition (Mohamed et al., 2012; Abdel-
Hamid et al., 2012; Bourlard & Morgan, 2012), hand-
writing recognition and protein secondary structure predic-
tion (Lin et al., 2005; Peng et al., 2009). It also can be com-
bined with Support Vector Machines (Altun et al., 2003).
Finally, the Viterbi algorithm is used as a module in Graph
Transformer Networks, with applications to speech recog-
nition (LeCun et al., 1998; Collobert, 2011).

The quadratic dependence of the algorithm’s runtime on
the number of states is a long-standing bottleneck that lim-
its its applicability to problems with large state spaces,
particularly when the number of observations is large. A
lot of effort has been put into improving the Viterbi algo-
rithm to lower either the time or space complexity. Many
works achieve speedups by requiring structure in the in-
put, either explicitly by considering restricted classes of
HMMs (Felzenszwalb et al., 2004; Siddiqi & Moore, 2005)
or implicitly by using heuristics that improve runtime in
certain cases (Esposito & Radicioni, 2009; Kaji et al.,
2010). For the general case, in (Lifshits et al., 2009; Mah-
mud & Schliep, 2011) it is shown how to speed up the
Viterbi algorithm by O(log n) when the number of distinct
observations is constant using the Four Russians method
or similar ideas. More recently, in (Cairo et al., 2016),
the same logarithmic speed-up was shown to be possible
for the general case. Despite signiﬁcant effort, only log-

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

Lower Bound Complexity

Alphabet size

Assumption

Theorem 1

Theorem 2

Theorem 4

T n2
T n2
T n2 when T ≤ n 1 (unary)

T
nε (for any constant ε > 0)

APSP Conjecture

k-Clique Conjecture

APSP Conjecture

Upper Bound Complexity
√

Theorem 3

T n2/2Ω(

log n)

Any

Alphabet size

√

Assumption
2δ
log n distinct
probabilities in HMM

transition

Table 1: Summary of our upper and lower bounds for the Viterbi Path problem. n is the number of states in the underlying
HMM and T is the number of observations. For a sparse HMM with m non-zero transition probabilities, we show a tight
lower bound of T m (see Theorems 6, 7 and 8 in Section 6).

arithmic improvements are known other than in very spe-
cial cases. In contrast, the memory complexity can be re-
duced to almost linear in the number of states without sig-
niﬁcant overhead in the runtime (Grice et al., 1997; Tarnas
& Hughey, 1998; Churbanov & Winters-Hilt, 2008).

In this work, we attempt to explain this apparent barrier for
faster runtimes by giving evidence of the inherent hardness
of the Viterbi Path problem. In particular, we show that get-
ting a polynomial speedup1 would imply a breakthrough
for fundamental graph problems. Our lower bounds are
based on standard hardness assumptions for the All-Pairs
Shortest Paths and the Min-Weight k-Clique problems and
apply even in cases where the number of distinct observa-
tions is small.

Before formally stating our results, let us give some back-
ground on the Min-Weight k-Clique problem. This fun-
damental graph problem asks to ﬁnd the minimum weight
k-clique in the given undirected weighted graph on n nodes
and O(n2) weighted edges. This is the parameterized ver-
sion of the NP-hard Min-Weight Clique problem (Karp,
1972). The Min-Weight k-Clique is amongst the most well-
studied problems in theoretical computer science, and it is
the canonical intractable problem in parameterized com-
plexity.

A naive algorithm solves the Min-Weight k-Clique in
O(nk) time and the best known algorithm still runs in
O(nk−o(1)) for any constant k. Obtaining a signiﬁcantly
faster algorithm for this problem is a longstanding open
question.

A conjecture in graph algorithms and parameterized com-
plexity is that it there is no O(nk−ε) algorithm for any
constant ε > 0. The special case of the conjecture with
k = 3 says that ﬁnding the minimum weight triangle
in a weighted graph cannot be solved in O(n3−δ) time
for any constant δ > 0. There are many negative re-
sults that intuitively support this conjecture: a truly sub-

cubic algorithm for Min-Weight 3-Clique implies such al-
gorithm for the All-Pairs Shortest Paths as well (Williams
& Williams, 2010). The latter is a well studied problem
and no truly subcubic algorithm is known for it despite
signiﬁcant effort (Williams, 2014). Unconditional lower
bounds for k-Clique are known for various computational
models, such as Ω(nk) for monotone circuits (Alon & Bop-
pana, 1987). The planted Clique problem has also proven
to be very challenging (e.g. (Alon et al., 2007; 1998; Hazan
& Krauthgamer, 2011; Jerrum, 1992)). Max-Clique is also
known to be hard to efﬁciently approximate within nontriv-
ial factors (Håstad, 1999).

We complement our lower bounds with an algorithm for
Viterbi Path that achieves speedup 2Ω(
log n) when there
are few distinct transition probabilities in the underlying
HMM. We summarize our results in Table 1.

√

Our results and techniques Our ﬁrst lower bound shows
that the Viterbi Path problem cannot be computed in time
O(T n2)1−ε for a constant ε > 0 unless the APSP con-
jecture is false. The APSP conjecture states that there is
no algorithm for the All-Pairs Shortest Paths problem that
runs in truly subcubic2 time in the number of vertices of the
graph. We obtain the following theorem:

Theorem 1. The VITERBI PATH problem requires
Ω(T n2)1−o(1) time assuming the APSP Conjecture.

The proof of the theorem gives a reduction from All-Pairs
Shortest Paths to the Viterbi Path problem. This is done
by encoding the weights of the graph of the APSP instance
as transition probabilities of the HMM or as probabilities
of seeing observations from different states. The proof re-
quires a large alphabet size, i.e. a large number of distinct
observations, which can be as large as the number of total
steps T .

A natural question question to ask is whether there is a
faster algorithm that solves the Viterbi Path problem when

1Getting an algorithm running in time, say O(T n1.99).

2Truly subcubic means O(n3−δ) for constant δ > 0.

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

the alphabet size is much smaller than T , say when T = n2
and the alphabet size is n. We observe that in such a case,
the input size to the Viterbi Path problem is only O(n2):
we only need to specify the transition probabilities of the
HMM, the probabilities of each observation in each state
and the sequence of observations. The Viterbi algorithm
in this setting runs in Θ(T n2) = Θ(n4) time. Showing
a matching APSP based lower bound seems difﬁcult be-
cause the runtime in this setting is quadratic in the input
size while the APSP conjecture gives only N 1.5 hardness
for input size N . To our best knowledge, all existing re-
duction techniques based on the APSP conjecture do not
achieve such an ampliﬁcation of hardness. In order to get
a lower bound for smaller alphabet sizes, we need to use a
different hardness assumption.

For this purpose, we consider the k-Clique conjecture. It
is a popular hardness assumption which states that it is
not possible to compute a minimum weight k-clique on an
edge-weighted graph with n vertices in time O(nk−ε) for
constant k and ε > 0. With this assumption, we are able
to extend Theorem 1 and get the following lower bound for
the Viterbi Path problem on very small alphabets:

Theorem 2. For any C, ε > 0, the VITERBI PATH prob-
lem on T = Θ(nC) observations from an alphabet of size
Θ(nε) requires Ω(T n2)1−o(1) time assuming the k-Clique
Conjecture for k = (cid:100) C

ε (cid:101) + 2.

To show the theorem, we perform a reduction from the
Min-Weight k-Clique problem. Given a Min-Weight k-
Clique instance, we create an HMM with two special
nodes, a start node and an end node, and enforce the fol-
lowing behavior of the optimal Viterbi path: Most of the
time it stays in the start or end node, except for a small
number of steps, during which it traverses the rest of the
graph to move from the start to the end node. The time at
which the traversal happens corresponds to a clique in the
original graph of the Min-Weight k-Clique instance. We
penalize the traversal according to the weight of the corre-
sponding k-clique and thus the optimal path will ﬁnd the
minimum weight k-clique. Transition probabilities of the
HMM and probabilities of seeing observations from differ-
ent states encode edge-weights of the Min-Weight k-Clique
instance. Further, we encode the weights of smaller cliques
into the sequence of observations according to the binary
expansion of the weights.

Our results of Theorems 1 and 2 imply that the Viterbi al-
gorithm is essentially optimal even for small alphabets. We
also study the extreme case of the Viterbi Path problem
with unary alphabet where the only information available
is the total number of steps T . We show a surprising be-
havior: when T ≤ n the Viterbi algorithm is essentially op-
timal, while there is a simple much faster algorithm when
T > n. See Section 5 for more details.

We complement our lower bounds with an algorithm for
log n) when there
Viterbi Path that achieves speedup 2Ω(
are few distinct transition probabilities in the underlying
HMM. Such a restriction is mild in applications where one
can round the transition probabilities to a small number of
distinct values.

√

log n dis-
transition probabilities for a constant ε > 0,
log n) randomized algorithm for the

Theorem 3. When there are fewer than 2ε
tinct
there is a T n2/2Ω(
VITERBI PATH problem that succeeds whp.

√

√

We achieve this result by developing an algorithm for
online (min, +) matrix-vector multiplication for the case
when the matrix has few distinct values. Our algorithm is
presented in Section 7 and is based on a recent result for on-
line Boolean matrix-vector multiplication by Green Larsen
and Williams (Larsen & Williams, 2017).

The results we presented above hold for dense HMMs. For
sparse HMMs that have at most m edges out of the n2 pos-
the transition matrix has at most m non-
sible ones, i.e.
zero probabilities, the VITERBI PATH problem can be eas-
ily solved in O(T m) time. The lower bounds that we pre-
sented above can be adapted directly for this case to show
that no faster algorithm exists that runs in time O(T m)1−ε.
See the corresponding discussion in Section 6.

2. Preliminaries

Notation For
{1, 2, . . . , m} by [m].

an integer m, we denote

the

set

Deﬁnition 1 (Hidden Markov Model). A Hidden Markov
Model (HMM) consists of a directed graph with n distinct
hidden states [n] with transition probabilities ˜A(u, v) of
going from state u to state v. In any given state, there is
a probability distribution of symbols that can be observed
and ˜B(u, s) gives the probability of seeing symbol s on
state u. The symbols come from an alphabet [σ] of size
σ. An HMM can thus be represented by a tuple ( ˜A, ˜B).

2.1. The Viterbi Path Problem

Given an HMM and a sequence of T observations, the
Viterbi algorithm (Viterbi, 1967) outputs a sequence of T
states that is most likely given the T observations. More
precisely, let S = (s1, . . . , sT ) be the given sequence of
T observations where symbol st ∈ [σ] is observed at time
t = 1, . . . , T . Let ut ∈ [n] be the state of the HMM at time
t = 1, . . . , T . The Viterbi algorithm ﬁnds a state sequence
U = (u0, u1, . . . , uT ) starting at u0 = 1 that maximizes
Pr[U |S]. The problem of ﬁnding the sequence U is known
as the Viterbi Path problem. In particular, the Viterbi Path

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

problem solves the optimization problem

2.2. Hardness assumptions

arg max
u0=1,u1,...,uT

T
(cid:89)

t=1

(cid:105)
(cid:104) ˜A(ut−1, ut) · ˜B(ut, st)

.

The Viterbi algorithm solves this problem in O(T n2) by
computing for t = 1 . . . T the best sequence of length
t that ends in a given state in a dynamic programming
fashion. When run in a word RAM model with O(log n)
bit words, this algorithm is numerically unstable because
even representing the probability of reaching a state re-
quires linear number of bits. Therefore, log probabilities
are used for numerical stability since that allows to avoid
underﬂows (Young et al., 1997; Amengual & Vidal, 1998;
Li & Tang, 2009; Lee et al., 2007; Huang et al., 2001).
To maintain numerical stability and understand the under-
lying combinatorial structure of the problem, we assume
that the input is given in the form of log-probabilities, i.e.
the input to the problem is A(u, v) = − log ˜A(u, v) and
B(u, s) = − log ˜B(u, s) and focus our attention on the
Viterbi Path problem deﬁned by matrices A and B.

Deﬁnition 2 (Viterbi Path Problem). The VITERBI PATH
problem is speciﬁed by a tuple (A, B, S) where A and B
are n × n and n × σ matrices, respectively, and S =
(s1, . . . , sT ) is a sequence of T = nΘ(1) observations
s1, . . . , sT ∈ [σ] over an alphabet of size σ. Given an in-
stance (A, B, S) of the VITERBI PATH problem, our goal
is to output a sequence of vertices u0, u1, . . . , uT ∈ [n]
with u0 = 1 that solves

arg min
u0=1,u1,...,uT

T
(cid:88)

t=1

[A(ut−1, ut) + B(ut, st)] .

We can assume that log probabilities in matrices A and B
are arbitrary positive numbers without the restriction that
the corresponding probabilities must sum to 1. See Ap-
pendix C for a discussion.

A simpler special case of the VITERBI PATH problem asks
to compute the most likely path of length T without any
observations.

Deﬁnition 3 (Shortest Walk Problem). Given an integer
T and a weighted directed graph (with possible self-loops)
on n vertices with edge weights speciﬁed by a matrix A, the
SHORTEST WALK problem asks to compute a sequence of
vertices u0 = 1, u1, . . . , uT ∈ [n] that solves

arg min
u0=1,u1,...,uT

A(ut−1, ut).

T
(cid:88)

t=1

It is easy to see that the SHORTEST WALK problem cor-
responds to the VITERBI PATH problem when σ = 1 and
B(u, 1) = 0 for all u ∈ [n].

We use the hardness assumptions of the following prob-
lems.

Deﬁnition 4 (ALL-PAIRS SHORTEST PATHS
(APSP)
problem). Given an undirected graph G = (V, E) with n
vertices and positive integer weights on the edges, ﬁnd the
shortest path between u and v for every u, v ∈ V .

APSP

conjecture
The
ALL-PAIRS SHORTEST PATHS
Ω(n3)1−o(1) time in expectation.

states
problem

that

the
requires

1

The
Conjecture
(APSP
ALL-PAIRS SHORTEST PATHS problem on a graph
with n vertices and positive integer edge-weights bounded
by nO(1) requires Ω(n3)1−o(1) time in expectation.

conjecture).

There is a long list of works showing conditional hardness
for various problems based on the All-Pairs Shortest Paths
conjecture (Roditty & Zwick, 2004; Williams & Williams,
2010; Abboud & Williams, 2014; Abboud et al., 2015b;c).

Deﬁnition 5 (MIN-WEIGHT k-CLIQUE problem). Given a
complete graph G = (V, E) with n vertices and positive in-
teger edge-weights, output the minimum total edge-weight
of a k-clique in the graph.

This is a very well studied computational problem and de-
spite serious efforts, the best known algorithm for this prob-
lem still runs in time O(nk−o(1)), which matches the run-
time of the trivial algorithm up to subpolynomial factors.
The k-Clique conjecture states that this problem requires
Ω(nk)1−o(1) time and it has served as a basis for show-
ing conditional hardness results for several problems on
sequences (Abboud et al., 2015a; 2014; Bringmann et al.,
2016) and computational geometry (Backurs et al., 2016).

2

The
(k-Clique
Conjecture
MIN-WEIGHT k-CLIQUE problem on a graph with n
vertices and positive integer edge-weights bounded by
nO(k) requires Ω(nk)1−o(1) time in expectation.

conjecture).

For k = 3, the MIN-WEIGHT 3-CLIQUE problem asks to
ﬁnd the minimum weight triangle in a graph. This prob-
lem is also known as the MINIMUM TRIANGLE problem
and under the 3-Clique conjecture it requires Ω(n3)1−o(1)
time. The latter conjecture is equivalent to the APSP con-
jecture (Williams & Williams, 2010).

often

We
MIN-WEIGHT k-CLIQUE problem:

following

use

the

variant

of

the

Deﬁnition 6 (MIN-WEIGHT k-CLIQUE problem for
k-partite graphs). Given a complete k-partite graph G =
(V1 ∪ . . . ∪ Vk, E) with |Vi| = ni and positive inte-
ger weights on the edges, output the minimum total edge-
weight of a k-clique in the graph.

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

If for all i, j we have that ni = nΘ(1)
, it can be shown that
the MIN-WEIGHT k-CLIQUE problem for k-partite graphs

j

(cid:16)(cid:81)k

(cid:17)1−o(1)

i=1 ni

requires Ω
time assuming the k-Clique
conjecture. We provide a simple proof of this statement in
the appendix.

3. Hardness of VITERBI PATH

We begin by presenting our main hardness result for the
VITERBI PATH problem.

Proof. The optimal path for the VITERBI PATH instance
begins at node 1. It must end in node 2 since otherwise
when observation ⊥F arrives we collect cost +∞. Simi-
larly, whenever an observation ⊥ arrives the path must be
either on node 1 or 2. Thus, the path ﬁrst loops in node 1
and then goes from node 1 to node 2 during three consecu-
tive observations u, u and ⊥ for some u ∈ U and stays in
node 2 until the end. Let v1 ∈ V1 and v2 ∈ V2 be the two
nodes visited when moving from node 1 to node 2. The
only two steps of non-zero cost are:

Theorem 1. The VITERBI PATH problem requires
Ω(T n2)1−o(1) time assuming the APSP Conjecture.

1. Moving from node 1 to node v1 at the ﬁrst observation

u. This costs A(1, v1) + B(v1, u) = B(v1, u).

To show APSP hardness, we will perform a reduction
from the MINIMUM TRIANGLE problem (described in Sec-
tion 2.2) to the VITERBI PATH problem.
In the instance
of the MINIMUM TRIANGLE problem, we are given a 3-
partite graph G = (V1 ∪ V2 ∪ U, E) such that |V1| =
|V2| = n, |U | = m. We want to ﬁnd a triangle of minimum
weight in the graph G. To perform the reduction, we deﬁne
a weighted directed graph G(cid:48) = ({1, 2} ∪ V1 ∪ V2, E(cid:48)).
E(cid:48) contains all the edges of G between V1 and V2, directed
from V1 towards V2, edges from 1 towards all nodes of V1
of weight 0 and edges from all nodes of V2 towards 2 of
weight 0. We also add a self-loops at nodes 1 and 2 of
weight 0.

We create an instance of the VITERBI PATH problem
(A, B, S) as described below. Figure 1 illustrates the con-
struction of the instance.

• Matrix A is the weighted adjacency matrix of G(cid:48) that
takes value +∞ (or a sufﬁciently large integer) for
non-existent edges and non-existent self-loops.

• The alphabet of the HMM is U ∪ {⊥, ⊥F } and thus
matrix B has 2n + 2 rows and σ = m + 2 columns.
For all v ∈ V1 ∪ V2 and u ∈ U , B(v, u) is equal to the
weight of the edge (v, u) in graph G. Moreover, for all
v ∈ V1 ∪ V2, B(v, ⊥) = +∞ (or a sufﬁciently large
number) and for all v ∈ V1 ∪ V2 ∪ {1}, B(v, ⊥F ) =
+∞. Finally, all remaining entries corresponding to
nodes 1 and 2 are 0.

• Sequence S of length T = 3m + 1 is generated by
appending the observations u, u and ⊥ for all u ∈ U
and adding a ⊥F observation at the end.

Given the above construction, the theorem statement fol-
lows directly from the following claim.

Claim 1. The weight of the solution to the VITERBI PATH
instance is equal to the weight of the minimum triangle in
the graph G.

2. Moving from node v1 to node v2 at the second obser-

vation u. This costs A(v1, v2) + B(v2, u).

Thus, the overall cost of the path is equal to B(v1, u) +
A(v1, v2) + B(v2, u), which is equal to the weight of the
triangle (v1, v2, u) in G. Minimizing the cost of the path in
this instance is therefore the same as ﬁnding the minimum
weight triangle in G.

4. Hardness of VITERBI PATH with small

alphabet

The proof of Theorem 1 requires a large alphabet size,
which can be as large as the number of total steps T . In
the appendix, we show how to get a lower bound for the
VITERBI PATH problem on alphabets of small size by us-
ing a different hardness assumption.

Theorem 2. For any C, ε > 0, the VITERBI PATH prob-
lem on T = Θ(nC) observations from an alphabet of size
Θ(nε) requires Ω(T n2)1−o(1) time assuming the k-Clique
Conjecture for k = (cid:100) C

ε (cid:101) + 2.

5. Complexity of VITERBI PATH for unary

alphabet

In this section, we focus on the extreme case of
VITERBI PATH with unary alphabet.

Theorem 4. The VITERBI PATH problem requires
Ω(T n2)1−o(1) time when T ≤ n even if the size of the
alphabet is σ = 1, assuming the APSP Conjecture.

The above theorem follows from APSP-hardness of the
SHORTEST WALK problem that we present next.

Theorem 5. The SHORTEST WALK problem requires
Ω(T n2)1−o(1) time when T ≤ n, assuming the APSP Con-
jecture.

Proof. We will
from the
MINIMUM TRIANGLE problem to the VITERBI PATH

perform a

reduction

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

wv1,v2

0

1

0

0
0
0

0
0
0
0

0

2

Node
1
v ∈ V1 ∪ V2
2

0

u ∈ U ⊥ ⊥F
0 ∞
wv,u ∞ ∞
0
0

0

V1

V2

(a) The graph speciﬁed by transition matrix A. Every edge (v1, v2) in V1 × V2 has
the original edge-weight as in graph G.

(b) The cost of seeing a symbol at every
node given by matrix B.

Figure 1: The construction of matrices A and B for the reduction in the proof of Theorem 1. The notation wv,u denotes
the weight of the edge (v, u) in the original graph G.

problem.
In the instance of the MINIMUM TRIANGLE
problem, we are given a 3-partite undirected graph
G = (V1 ∪ V2 ∪ U, E) with positive edge weights such
that |V1| = |V2| = n, |U | = m. We want to ﬁnd a
triangle of minimum weight in the graph G. To perform
the reduction, we deﬁne a weighted directed and acyclic
graph G(cid:48) = ({1, 2} ∪ V1 ∪ V2 ∪ U ∪ U (cid:48), E(cid:48)). Nodes
in U (cid:48) are in one-to-one correspondence with nodes in
U and |U (cid:48)| = m. E(cid:48) is deﬁned as follows. We add all
edges of G between nodes in U and V1 directed from U
towards V1 and similarly, we add all edges of G between
nodes in V1 and V2 directed from V1 towards V2. Instead
of having edges between nodes in V2 and U , we add the
corresponding edges of G between nodes in V2 and U (cid:48)
directed from V2 towards U (cid:48). Moreover, we add additional
edges of weight 0 to create a path P of m + 1 nodes,
starting from node 1 and going through all nodes in U in
some order. Finally, we create another path P (cid:48) of m + 1
nodes going through all nodes in U (cid:48) in the same order as
their counterparts on path P and ending at node 2. These
edges have weight 0 apart from the last one, entering node
2, which has weight −C (a sufﬁciently large negative
constant)3.

We create an instance of the SHORTEST WALK problem
by setting T = m + 4 and A to be the weighted adjacency
matrix of G(cid:48) that takes value +∞ (or a sufﬁciently large
integer) for non-existent edges and self-loops.

The optimal walk of the SHORTEST WALK instance must
include the edge of weight −C entering node 2 since oth-
erwise the cost will be non-negative. Moreover, the walk

3Since the deﬁnition of SHORTEST WALK doesn’t allow neg-
ative weights, we can equivalently set its weight to be 0 and add
C to all the other edge weights.

must reach node 2 exactly at the last step since otherwise
the cost will be +∞ as there are no outgoing edges from
node 2. By the choice of T , the walk leaves path P at some
node u ∈ U , then visits nodes v1 and v2 in V1 and V2, re-
spectively, and subsequently moves to node u(cid:48) ∈ U (cid:48) where
u(cid:48) is the counterpart of u on path P (cid:48). The total cost of the
walk is thus the weight of the triangle (u, v1, v2) in G, mi-
nus C. Therefore, the optimal walk has cost equal to the
weight of the minimum triangle up to the additive constant
C.

Notice that when T > n, the runtime of the Viterbi algo-
rithm is no longer optimal. We now present a faster algo-
rithm with a total running time log T · n3/2Ω(

log n).

√

As we show in Section 7,
the general VITERBI PATH
problem reduces, according to Equation 2, to computing
(min, +) matrix-vector products.
In the case of unary
alphabet, it corresponds to computing (min, +) matrix-
vector product T times as follows: A ⊕ A ⊕ ... ⊕ A ⊕ z.
This can be equivalently performed by ﬁrst computing all
(min, +) matrix-matrix products A⊕T = A ⊕ A ⊕ ... ⊕ A
using exponentiation with repeated squaring and then mul-
tiplying the resulting matrix with the vector z. This re-
quires only O(log T ) matrix (min, +)-multiplications. Us-
ing the currently best algorithm for (min, +) matrix prod-
uct (Williams, 2014), we get an algorithm with total run-
log n).
ning time log T · n3/2Ω(

√

6. Hardness for sparse HMMs

The VITERBI PATH lower-bounds we have provided apply
to the case where the HMM has all n2 possible edges.

For sparse HMMs that have at most m edges out of the

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

n2 possible ones, i.e. the transition matrix has at most m
non-zero probabilities, the VITERBI PATH problem can be
easily solved in O(T m) time. The lower bounds that we
presented in the paper can be adapted directly for this case
to show that no faster algorithm exists that runs in time
O(T m)1−ε. This can be easily seen via a padding argu-
ment. Consider a hard instance for VITERBI PATH on a
m
dense HMM with
additional states with self-loops, we obtain a sparse in-
m = O(m) edges.
stance with n states and m + n −
Thus, any algorithm that computes the optimal Viterbi Path
in O(T m)1−ε time for the resulting instance would solve
√
m)2(cid:1)1−ε
the original instance with
time contradicting the corresponding lower bound.

m states and m edges. Adding n−

m states in O (cid:0)T (

√

√

√

√

This observation directly gives the following lower bounds
for VITERBI PATH problem, parametrized by the number
m of edges in an HMM with n states.
Theorem 6. The VITERBI PATH problem requires
Ω(T m)1−o(1) time for an HMM with m edges and n
states, assuming the APSP Conjecture.

Theorem 7. For any C, ε > 0, the VITERBI PATH prob-
lem on T = Θ(mC) observations from an alphabet of size
Θ(mε) requires Ω(T m)1−o(1) time assuming the k-Clique
Conjecture for k = (cid:100) C
Theorem 8. The VITERBI PATH problem requires
Ω(T m)1−o(1) time when T ≤
m even if the size of the
alphabet is σ = 1, assuming the APSP Conjecture.

ε (cid:101) + 2.

√

7. A faster VITERBI PATH algorithm

In this section, we present a faster algorithm for the
VITERBI PATH problem, when there are only few distinct
transition probabilities in the underlying HMM.
Theorem 3. When there are fewer than 2ε
tinct
there is a T n2/2Ω(
VITERBI PATH problem that succeeds whp.

log n dis-
transition probabilities for a constant ε > 0,
log n) randomized algorithm for the

√

√

The number of distinct transition probabilities is equal to
the number of distinct entries in matrix ˜A in Deﬁnition 1.
The same is true for matrix A in the additive version of
VITERBI PATH, in Deﬁnition 2. So, from the theorem
log n
statement we can assume that matrix A has at most 2ε
different entries for some constant ε > 0.

√

To present our algorithm, we revisit
VITERBI PATH. We want
1, u1, . . . , uT that minimizes the quantity:

the deﬁnition of
to compute a path u0 =

min
u0=1,u1,...,uT

T
(cid:88)

t=1

[A(ut−1, ut) + B(ut, st)] .

(1)

Deﬁning the vectors bt = B(·, st), we note that (1) is equal

to the minimum entry in the vector obtained by a sequence
of T (min, +) matrix-vector products4 as follows:

A ⊕ (. . . (A ⊕ (A ⊕ (A ⊕ z + b1) + b2) + b3) . . .) + bT (2)

where z is a vector with entries z1 = 0 and zi = ∞ for
all i (cid:54)= 1. Vector z represents the cost of being at node i at
time 0. Vector (A ⊕ z + b1) represents the minimum cost
of reaching each node at time 1 after seeing observation
s1. After T steps, every entry i of vector (2) represents
the minimum minimum cost of a path that starts at u0 =
1 and ends at uT = i after T observations. Taking the
minimum of all entries gives the cost of the solution to the
VITERBI PATH instance.

To evaluate (2), we design an online (min, +) matrix-
vector multiplication algorithm. In the online matrix-vector
multiplication problem, we are given a matrix and a se-
quence of vectors in online fashion. We are required to
output the result of every matrix-vector product before re-
ceiving the next vector. Our algorithm for online (min, +)
matrix-vector multiplication is based on a recent algorithm
for online Boolean matrix-vector multiplication by Green
Larsen and Williams (Larsen & Williams, 2017):

Theorem 9 (Green Larsen and Williams (Larsen &
Williams, 2017)). For any matrix M ∈ {0, 1}n×n and any
log n) vectors v1, . . . , vT ∈ {0, 1}n,
sequence of T = 2ω(
online Boolean matrix-vector multiplication of M and vi
√
can be performed in n2/2Ω(
log n) amortized time whp. No
preprocessing is required.

√

We show the following theorem for online (min, +)
matrix-vector multiplication, which gives the promised
runtime for the VITERBI PATH problem5 since we are inter-
ested in the case where T and n are polynomially related,
i.e. T = nΘ(1).
Theorem 10. Let A ∈ Rn×n be a matrix with at most
log n distinct entries for a constant ε > 0. For any se-
2ε
log n) vectors v1, . . . , vT ∈ Rn, online
quence of T = 2ω(
(min, +) matrix-vector multiplication of A and vi can be
performed in n2/2Ω(
log n) amortized time whp. No pre-
processing is required.

√

√

√

√

Proof. We will show the theorem for the case where A ∈
{0, +∞}n×n. The general case where matrix A has d ≤
log n distinct values a1, ..., ad can be handled by creat-
2ε
ing d matrices A1, ..., Ad, where each matrix Ak has en-
ij = 0 if Aij = ak and +∞ otherwise. Then, vector
tries Ak

4A (min, +) product between a matrix M and a vector v
is denoted by M ⊕ v and is equal to a vector u where ui =
minj(Mi,j + vj).

5Even though computing all (min, +) products does not di-
rectly give a path for the VITERBI PATH problem, we can obtain
one at no additional cost by storing back pointers. This is standard
and we omit the details.

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

the anonymous reviewers for their careful reviews. This
work was supported in part by an IBM PhD Fellowship,
the NSF and the Simons Foundation.

√

r = A ⊕ v can be computed by computing rk = Ak ⊕ v for
i + ak). This introduces a
every k and setting ri = mink(rk
log n in amortized runtime but the ﬁnal amor-
factor of 2ε
log n) if ε > 0 is sufﬁciently
tized runtime remains n2/2Ω(
small. From now on we assume that A ∈ {0, +∞}n×n and
deﬁne the matrix ¯A ∈ {0, 1}n×n whose every entry is 1 if
the corresponding entry at matrix A is 0 and 0 otherwise.

√

For every query vector v, we perform the following:

– Sort indices i1, ..., in such that vi1 ≤ ... ≤ vin in

O(n log n) time.

– Partition the indices into p = 2α
Sk contains indices i(k−1)(cid:100) n

p (cid:101)+1, ..., ik(cid:100) n

p (cid:101).

√

log n sets, where set

– Set r = (⊥, ..., ⊥)T , where ⊥ indicates an undeﬁned

value.

– For k = 1...p ﬁll the entries of r as follows:

- Let ISk be the indicator vector of Sk that takes
value 1 at index i if i ∈ Sk and 0 otherwise.

- Compute the Boolean matrix-vector product
πk = ¯A (cid:12) ISk using the algorithm from Theo-
rem 9.

- Set rj = mini∈Sk (Aj,i + vi) for all j ∈ [n] such

that rj = ⊥ and πk

j = 1.

– Return vector r.

√

√

√

Runtime of the algorithm per query The algorithm per-
log n Boolean matrix-vector multiplica-
forms p = 2α
tions, for a total amortized cost of p · n2/2Ω(
log n) =
n2/2Ω(
log n) for a small enough constant α > 0. More-
over, to ﬁll an entry rj the algorithm requires going through
all elements in some set Sk for a total runtime of O(|Sk|) =
n/2Ω(
log n). Thus, for all entries pj the total time re-
quired is n2/2Ω(
log n). The runtime of the other steps is
dominated by these two operations so the algorithm takes
n2/2Ω(

log n) amortized time per query.

√

√

√

Correctness of the algorithm To see that the algorithm
correctly computes the (min, +) product A ⊕ v, observe
that the algorithm ﬁlls in the entries of vector r from small-
est to largest. Thus, when we set a value to entry rj we
never have to change it again. Moreover, if the value rj
gets ﬁlled at step k, it must be the case that πk(cid:48)
j = 0 for all
k(cid:48) < k. This means that for all indices i ∈ S1 ∪ ... ∪ Sk−1
the corresponding entry Aj,i was always +∞.

Acknowledgments

We thank Piotr Indyk for many helpful discussions, for
comments on an earlier version of the writeup and for sug-
gestion on how to improve the presentation. We also thank

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

References

Abboud, Amir and Williams, Virginia Vassilevska. Popu-
lar conjectures imply strong lower bounds for dynamic
problems. In Foundations of Computer Science (FOCS),
2014 IEEE 55th Annual Symposium on, pp. 434–443.
IEEE, 2014.

Amengual, Juan C and Vidal, Enrique. Efﬁcient error-
correcting viterbi parsing. Pattern Analysis and Machine
Intelligence, IEEE Transactions on, 20(10):1109–1116,
1998.

Attias, Hagai. Planning by probabilistic inference. In AIS-

TATS, 2003.

Abboud, Amir, Williams, Virginia Vassilevska, and
Weimann, Oren. Consequences of faster alignment of
sequences. In Automata, Languages, and Programming,
pp. 39–51. Springer, 2014.

Backurs, Arturs, Dikkala, Nishanth, and Tzamos, Christos.
Tight Hardness Results for Maximum Weight Rectan-
In International Colloquium on Automata, Lan-
gles.
guages, and Programming, 2016.

Abboud, Amir, Backurs, Arturs, and Williams, Vir-
ginia Vassilevska. If the Current Clique Algorithms are
Optimal, so is Valiant’s Parser. In Foundations of Com-
puter Science (FOCS), 2015 IEEE 56th Annual Sympo-
sium on, pp. 98–117. IEEE, 2015a.

Abboud, Amir, Grandoni, Fabrizio, and Williams, Vir-
ginia Vassilevska. Subcubic equivalences between graph
centrality problems, APSP and diameter. In Proceedings
of the Twenty-Sixth Annual ACM-SIAM Symposium on
Discrete Algorithms, pp. 1681–1697. SIAM, 2015b.

Abboud, Amir, Williams, Virginia Vassilevska, and Yu,
Huacheng. Matching triangles and basing hardness on
an extremely popular conjecture. In Proceedings of the
Forty-Seventh Annual ACM on Symposium on Theory of
Computing, pp. 41–50. ACM, 2015c.

Abdel-Hamid, Ossama, Mohamed, Abdel-rahman, Jiang,
Hui, and Penn, Gerald. Applying convolutional neural
networks concepts to hybrid nn-hmm model for speech
recognition. In Acoustics, Speech and Signal Processing
(ICASSP), 2012 IEEE International Conference on, pp.
4277–4280. IEEE, 2012.

Alon, Noga and Boppana, Ravi B. The monotone circuit
complexity of boolean functions. Combinatorica, 7(1):
1–22, 1987.

Alon, Noga, Krivelevich, Michael, and Sudakov, Benny.
Finding a large hidden clique in a random graph. Ran-
dom Struct. Algorithms, 13(3-4):457–466, 1998.

Alon, Noga, Andoni, Alexandr, Kaufman, Tali, Matulef,
Kevin, Rubinfeld, Ronitt, and Xie, Ning. Testing k-wise
and almost k-wise independence. In Proceedings of the
39th Annual ACM Symposium on Theory of Computing,
San Diego, California, USA, June 11-13, 2007, pp. 496–
505, 2007.

Altun, Yasemin, Tsochantaridis,

Ioannis, Hofmann,
Thomas, et al. Hidden markov support vector machines.
In ICML, volume 3, pp. 3–10, 2003.

Bengio, Samy. An asynchronous hidden markov model for
audio-visual speech recognition. Advances in Neural In-
formation Processing Systems, pp. 1237–1244, 2003.

Bourlard, Herve A and Morgan, Nelson. Connectionist
speech recognition: a hybrid approach, volume 247.
Springer Science & Business Media, 2012.

Bringmann, Karl, Grønlund, Allan,

and Larsen,
Kasper Green. A dichotomy for regular expression
membership testing. arXiv preprint arXiv:1611.00918,
2016.

Cairo, Massimo, Farina, Gabriele, and Rizzi, Romeo. De-
coding Hidden Markov Models Faster Than Viterbi Via
Online Matrix-Vector (max,+)-Multiplication. In Thirti-
eth AAAI Conference on Artiﬁcial Intelligence, 2016.

Churbanov, Alexander and Winters-Hilt, Stephen. Imple-
menting EM and Viterbi algorithms for Hidden Markov
Model in linear memory. BMC bioinformatics, 9(1):1,
2008.

Cohen, Ira, Garg, Ashutosh, Huang, Thomas S, et al. Emo-
tion recognition from facial expressions using multilevel
In Neural information processing systems, vol-
hmm.
ume 2. Citeseer, 2000.

Collins, Michael. Discriminative training methods for
hidden markov models: Theory and experiments with
In Proceedings of the ACL-02
perceptron algorithms.
conference on Empirical methods in natural language
processing-Volume 10, pp. 1–8. Association for Compu-
tational Linguistics, 2002.

Collobert, Ronan. Deep learning for efﬁcient discrimina-
tive parsing. In AISTATS, volume 15, pp. 224–232, 2011.

Esposito, Roberto and Radicioni, Daniele P. Carpediem:
Optimizing the viterbi algorithm and applications to su-
pervised sequential learning. Journal of Machine Learn-
ing Research, 10(Aug):1851–1880, 2009.

Felzenszwalb, Pedro F, Huttenlocher, Daniel P, and Klein-
Fast algorithms for large-state-space

berg, Jon M.

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

HMMs with applications to web usage analysis. Ad-
vances in NIPS, 16:409–416, 2004.

Grice, J Alicia, Hughey, Richard, and Speck, Don. Re-
duced space sequence alignment. Computer applications
in the biosciences: CABIOS, 13(1):45–53, 1997.

Håstad, Johan. Clique is hard to approximate within n1−ε.

Acta Mathematica, 182(1):105–142, 1999.

Hazan, Elad and Krauthgamer, Robert. How hard is it to
approximate the best nash equilibrium? SIAM J. Com-
put., 40(1):79–91, 2011.

Huang, Xuedong, Acero, Alex, Hon, Hsiao-Wuen, and
Foreword By-Reddy, Raj. Spoken language processing:
A guide to theory, algorithm, and system development.
Prentice Hall PTR, 2001.

Jerrum, Mark. Large cliques elude the metropolis process.

Random Struct. Algorithms, 3(4):347–360, 1992.

Kaji, Nobuhiro, Fujiwara, Yasuhiro, Yoshinaga, Naoki, and
Kitsuregawa, Masaru. Efﬁcient staggered decoding for
In Proceedings of the 48th Annual
sequence labeling.
Meeting of the Association for Computational Linguis-
tics, pp. 485–494. Association for Computational Lin-
guistics, 2010.

Karp, Richard M. Reducibility among combinatorial prob-
lems. In Complexity of computer computations, pp. 85–
103. Springer, 1972.

Kim, Seyoung and Smyth, Padhraic. Segmental hidden
markov models with random effects for waveform mod-
eling. Journal of Machine Learning Research, 7(Jun):
945–969, 2006.

Larsen, Kasper Green and Williams, Ryan. Faster on-
line matrix-vector multiplication. In Proceedings of the
Twenty-Eighth Annual ACM-SIAM Symposium on Dis-
crete Algorithms, pp. 2182–2189. SIAM, 2017.

LeCun, Yann, Bottou, Léon, Bengio, Yoshua, and Haffner,
Patrick. Gradient-based learning applied to document
recognition. Proceedings of the IEEE, 86(11):2278–
2324, 1998.

Lee, Peng, Dong, Ming, Liang, Weiqian, and Liu, Run-
sheng. Design of Speech Recognition Co-Processor for
the Embedded Implementation. In Electron Devices and
Solid-State Circuits, 2007. EDSSC 2007. IEEE Confer-
ence on, pp. 1163–1166. IEEE, 2007.

Lifshits, Yury, Mozes, Shay, Weimann, Oren, and Ziv-
Ukelson, Michal. Speeding up HMM decoding and
training by exploiting sequence repetitions. Algorith-
mica, 54(3):379–399, 2009.

Lin, Kuang, Simossis, Victor A, Taylor, Willam R, and
Heringa, Jaap. A simple and fast secondary structure
prediction method using hidden neural networks. Bioin-
formatics, 21(2):152–159, 2005.

Mahmud, Md Pavel and Schliep, Alexander. Speeding up
Bayesian HMM by the four Russians method. In Inter-
national Workshop on Algorithms in Bioinformatics, pp.
188–200. Springer, 2011.

Mannini, Andrea and Sabatini, Angelo Maria. Machine
learning methods for classifying human physical activ-
ity from on-body accelerometers. Sensors, 10(2):1154–
1175, 2010.

Mohamed, Abdel-rahman, Dahl, George E, and Hinton,
Geoffrey. Acoustic modeling using deep belief net-
works. IEEE Transactions on Audio, Speech, and Lan-
guage Processing, 20(1):14–22, 2012.

Neﬁan, Ara V, Liang, Luhong, Pi, Xiaobo, Xiaoxiang, Liu,
Mao, Crusoe, and Murphy, Kevin. A coupled hmm for
audio-visual speech recognition. In Acoustics, Speech,
and Signal Processing (ICASSP), 2002 IEEE Interna-
tional Conference on, volume 2, pp. II–2013. IEEE,
2002.

Peng, Jian, Bo, Liefeng, and Xu, Jinbo. Conditional neu-
ral ﬁelds. In Advances in neural information processing
systems, pp. 1419–1427, 2009.

Rabiner, Lawrence R. A tutorial on hidden markov mod-
els and selected applications in speech recognition. Pro-
ceedings of the IEEE, 77(2):257–286, 1989.

Roditty, Liam and Zwick, Uri. On dynamic shortest
paths problems. In Algorithms–ESA 2004, pp. 580–591.
Springer, 2004.

Siddiqi, Sajid M and Moore, Andrew W. Fast inference and
In Proceedings of
learning in large-state-space hmms.
the 22nd international conference on Machine learning,
pp. 800–807. ACM, 2005.

Tarnas, Christopher and Hughey, Richard. Reduced space
hidden Markov model training. Bioinformatics, 14(5):
401–406, 1998.

Li, Peng and Tang, Hua. Design a co-processor for Out-
put Probability Calculation in speech recognition.
In
Circuits and Systems, 2009. ISCAS 2009. IEEE Interna-
tional Symposium on, pp. 369–372. IEEE, 2009.

Viterbi, Andrew J. Error bounds for convolutional codes
and an asymptotically optimum decoding algorithm. In-
formation Theory, IEEE Transactions on, 13(2):260–
269, 1967.

Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms

Williams, Ryan. Faster all-pairs shortest paths via cir-
In Proceedings of the 46th Annual
cuit complexity.
ACM Symposium on Theory of Computing, pp. 664–673.
ACM, 2014.

Williams, Virginia Vassilevska and Williams, Ryan. Sub-
cubic equivalences between path, matrix and triangle
problems. In Foundations of Computer Science (FOCS),
2010 51st Annual IEEE Symposium on, pp. 645–654.
IEEE, 2010.

Young, Steve, Evermann, Gunnar, Gales, Mark, Hain,
Thomas, Kershaw, Dan, Liu, Xunying, Moore, Gareth,
Odell, Julian, Ollason, Dave, Povey, Dan, et al. The HTK
book, volume 2. Entropic Cambridge Research Labora-
tory Cambridge, 1997.

