Efﬁcient Online Bandit Multiclass Learning

A. Adaptive Tuning of the Exploration Rate
In Theorem 2 we have presented a tuning of γ that guarantees a regret of the order of ˜O( 1
√T ). However, this setting
η
requires to upper bound the sum of the quadratic terms with a worst case bound. In this section, we develop an adaptive
strategy for the tuning of the exploration rate γ that guarantees an optimal bound w.r.t. to the tightest sum of the quadratic
terms.

First, we make rate dependent of the time, i.e. γt. Our aim is to choose γt in each time step in order to minimize the excess
. The main result is that, adaptively setting γt’s would result in a
mistake bound E
bound within (roughly) a constant factor of that obtained by the best ﬁxed γ in hindsight. We start with a technical lemma.

T
t=1 γt + 1
η(2
−

zT
t A−

1
t zt

T
t=1

k
γt

η)

�

��

�

Lemma 4. Let c1, . . . , cT ∈
have,

[0, b] be a sequence of real numbers, a > 0, and deﬁne γt = min

b+

t
1
s=1 cs
−
t

�

, 1

. We

�

��

T

t=1 �
�

ct
γt �

≤

γt + a

(2 + 2a)√T

b +

ct + a

ct .

T

T

t=1
�

t=1
�

�
�
�
�

Proof. First, note that

T

T

γt ≤

t=1
�

�

t=1
�

b +

t
1
s=1 cs
−
t
�

T

T

b +

cs

s=1
�

t=1 �
�

1
t ≤

≤ �
�
�
�

T

cs .

2√T

b +

�
�
�
�
0, we have that

s=1
�

Second, using the elementary chain of inequalities max(a, b)

a + b,

a, b

≤

∀

≥

T

T

=

max

ct
γt

t=1
�

t=1
�
T

t=1
�

√T

≤

≤

2√T

≤

, ct

ct

T

t=1
�

+

T

ct√t
t
1
s=1 cs
−

b +





�

ct

�

b +

t
1
s=1 cs
−

√T

T

�

�

ct
t
s=1 cs

+

ct

t=1
�

T

cs +

ct,

s=1
�

t=1
�

��
b +

T

t=1
�

�
�
�
�

where the last inequality uses Lemma 3.5 of (Auer et al., 2002). Combining the two inequalities, we get the desired
result.

Built upon the lemma above, we show that, tailored to our setting, the adaptive tuning would result in a bound within a
constant factor of that achieved by the best ﬁxed γ in hindsight.

Theorem 5. Running SOBA with the adaptive setting of γt = min

, 1

and a = X 2, we have that

E[M ]

Lη(U ) + O

≤

X 2

U

�

2
F +
�

1
η

�

k(1+

s A−

1
s zs)

t
1
s=1 zT
−
t

�

��

(√dk2T ln T + dk2 ln T )

�

.

�

Proof Sketch. Following the same proof as Theorem 3, we get that

ˆMT

E

�

�

≤

Lη(U ) +

2
F
�
η

U

aη
�
2
−

+

1

−

η(2

η)

T

E[

t=1
�

k
γt

zT
t A−

1
t zt]

Meanwhile by triangle inequality,

Efﬁcient Online Bandit Multiclass Learning

E[MT ]

≤

E[ ˆMT ] + E

1[˜yt �

= ˆyt]

� ≤

E[ ˆMT ] + E

T

�

t=1
�

T

�

t=1
�

γt

.

�

Combining the two inequalities above, we get

E [MT ]

Lη(U ) +

≤

2
F
�
η

U

aη
�
2
−

+ E

η(2

�

η)

1

−

T

t=1
�

k zT

1
t zt

t A−
γt

+

T

t=1
�

γt

.

�

We take a closer look at the last term. Lemma 4 with ct = kzT

1

t A−

t zt ∈

[0, k], b = k, a = 1
η(2
−

η) , implies that

η(2

η)γt

zT
t A−

1
t zt

T

T

γt +

t=1
�

t=1
�

2 +

k

−

2

≤

�

η(2

η)

�

−

�
�
�
�

T

t=1
�

√T

k(1 +

zT
t A−

t zt) +

1

k(1 +

zT
t A−

t zt) .

1

1

−

η(2

η)

T

t=1
�

Taking the expecation of both sides and using Lemma 3, we get that the last term on the right hand side is at most
12
η (√dk2T ln T + dk2 ln T ). This completes the proof.

B. Deferred Proofs

2 such that 1
Proof of Theorem 1. Let p
an update, i.e. makes a mistake. We have:

≥

p + 1

q = 1. Denote by bt the indicator variable that multiclass Perceptron makes

eˆyT )

xT �

⊗

+ 2b2

xT �

t �

2
2

WT +1, U

�

�
WT +1�F �
U

�F

�F

�
�

�
�

U

�F
2 + 2bt�
WT �
2
F + 2b2
WT �

WT , (eyT −
xT �

2
2

t �

≤ �
=

�

U

≤ �

≤ · · ·

U

≤ �

U

≤ �

T

t=1
�

2

�F �
�
�
�
�F X√2

b2
t �

xt�

2
2

b2
t

bt

T

�
�
�
�

�
�
�
�

t=1
�
T

t=1
�

=

U

�

�F X√2

Also, we have, that

Efﬁcient Online Bandit Multiclass Learning

WT +1, U

=

�

�

bt�

U , (eyt −

eˆyt )

xt�

⊗

T

t=1
�
T

t=1
�
T

t=1
�
T

t=1
�
T

t=1
�
T

t=1
�

=

≥

≥

≥

=

bt[1

(1

U , (eyt −

− �

−

eˆyt )

)]

xt�

⊗

bt[1

1

− |

− �

U , (eyt −

eˆyt )

xt�|+]

⊗

bt −

T

t=1
�
T

(

bt −

(

bt −

t=1
�
T

t=1
�

bt�(U , (xt, yt))

bp
t )

1
p (

�(U , (xt, yt))q)

1
q

bt)

1
p (

�(U , (xt, yt))q)

1
q .

T

t=1
�
T

t=1
�

Putting all together we have

U

�F X√2

�

T

T

T

1
p

bt ≥

bt − �

bt

�

t=1
�

t=1
�

�
�
�
�

t=1
�

LMH,q(U )

1

q .

Noting that

T
t=1 bt is equal to number of mistake MT , we get the stated bound.

�

∈

≤

Lemma 5. Suppose we are given positive real numbers L, T, H, U and function F (γ) = min(T, L+γT + U H
where γ

[0, 1]. Then:

γ +

�

U HL
γ

),

1. If L

(U + 1)√HT , then taking γ∗ = min(

H
T , 1) gives that F (γ∗)

L + 3(U + 1)√HT .

2. If L > (U + 1)√HT , then taking γ∗ = min(( HL
T 2 )

1

3 , 1) gives that F (γ∗)

L + 2(√U + 1)(HLT )

1

3 .

�

≤

≤

Proof. We prove the two cases separately.

1. If T

H, then γ∗ = 1, F (γ∗)

≤

≤
Otherwise, T > H. In this case, γ∗ =

≤

T

L + 3(U + 1)√HT .

H
T . We have that

�

F (γ∗)

= L + γ∗T +

U H
γ∗

U HL
γ∗

+

�

= L + √HT + U √HT +

U L√HT

L + (U + 1)√HT + L + U √HT
L + 3(U + 1)√HT .

�

≤

≤

where the ﬁrst inequality is from that arithmetic mean-geometric mean inequality, the second inequality is by the
assumption on L.

Efﬁcient Online Bandit Multiclass Learning

2. If HL > T 2, then γ∗ = 1, F (γ∗)

T

≤

≤

(HLT )

1
3 .

Otherwise, HL

T 2. In this case, γ∗ = ( HL
T 2 )

1
3 . We have that

≤

F (γ∗) = L + γ∗T +

U H
γ∗

+

∗

U HL
γ

�
2
3 T

= L + (HLT )

1
3 + U H

1

2

3 L−

3 + √U (HLT )

1
3

L + (√U + U
L + 2(√U + 1)(HLT )

1
3 + 1)(HLT )

1
3 .

1
3

≤

≤

where the ﬁrst inequality is from algebra and the condition on L, implying U H
U

3 , the second inequality is from that U

1
3 (HLT )

√U + 1.

1
3

1

2
3 T

2

3 L−

1
3

(HLT )

1

3 U ( HT
L2 )

1
3

≤

≤

≤

C. Per-Step Analysis of Online Least Squares

For completeness, we present a technical lemma in online least squares, which has appeared in (e.g., Orabona et al., 2012).
s , wt =

Lemma 6. Suppose zt’s are vectors, and αt’s are scalars. For all t

1, deﬁne At =

t
s=1 zszT

1
1

A−
t
−

−

1

t
s=1 αszs. Then for any vector u, we have:
−

≥

�

�

1
2

(

wt , zt�

�

+ αt)2(1

zT
t A−

1
t zt)

−

1
2

−

(

u , zt�

�

+ αt)2

1
2 �

u

≤

2
At

wt�

−

1 −

−

1
2 �

u

wt+1�

−

2
At .

Proof. Observe that wt’s have the following recurrence:

Since At = At

1 + ztzT

t , we have

−

wt+1 = A−

1
t (At

1wt −

−

αtzt)

Atwt+1 = Atwt −

(wT

t zt + αt)zt

Now, by standard online mirror descent analysis (See e.g. Cesa-Bianchi & Lugosi, 2006, proof of Theorem 11.1), we have

u , (wT

t zt + αt)zt

wt −

�

1
2 �
1
2 �

u

u

2
At −
2
At

wt�
wt�

−

−

1 −

−

u

1
2 �
1
2 �

−

u

wt+1�

2
At +

1
2

wt+1�

−

2
At +

1
2

�

≤

≤

(wT

t zt + αt)2zT

t A−

1
t zt

(wT

t zt + αt)2zT

t A−

t zt +

1

1
2

(uT zt −

wT

t zt)2

Now, move the last term on the RHS to the LHS, we get

(wT

t zt −

uT zt)

1
2

·

(wT

t zt + uT zt + 2αt)

1
2 �

u

≤

2
At

wt�

−

1 −

−

1
2 �

u

wt+1�

−

2
At +

1
2

(wT

t zt + αt)2zT

t A−

1
t zt

i.e.

1
2

+ αt)2

(

wt , zt�

u , zt�
�
Now moving the last term on the RHS to the LHS, the lemma follows.

wt�

1 −

≤

−

−

u

(

�

−

+ αt)2

2
At

1
2 �

1
2

1
2 �

u

wt+1�

−

2
At +

1
2

(wT

t zt + αt)2zT

t A−

1
t zt .

