On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Xueyu Mao 1 Purnamrita Sarkar 2 Deepayan Chakrabarti 3

Abstract

The problem of ﬁnding overlapping communi-
ties in networks has gained much attention re-
cently. Optimization-based approaches use non-
negative matrix factorization (NMF) or variants,
but the global optimum cannot be provably at-
tained in general. Model-based approaches,
such as the popular mixed membership stochastic
blockmodel or MMSB (Airoldi et al., 2008), use
parameters for each node to specify the overlap-
ping communities, but standard inference tech-
niques cannot guarantee consistency. We link
the two approaches, by (a) establishing sufﬁcient
conditions for the symmetric NMF optimization
to have a unique solution under MMSB, and (b)
proposing a computationally efﬁcient algorithm
called GeoNMF that is provably optimal and
hence consistent for a broad parameter regime.
We demonstrate its accuracy on both simulated
and real-world datasets.

1. Introduction

Community detection is a fundamental problem in net-
work analysis.
It has been widely used in a diverse
set of applications ranging from link prediction in so-
cial networks (Soundarajan & Hopcroft, 2012), predicting
protein-protein or protein-DNA interactions in biological
networks (Chen & Yuan, 2006), to network protocol de-
sign such as data forwarding in delay tolerant networks (Lu
et al., 2015).

Traditional community detection assumes that every node
in the network belongs to exactly one community, but
many practical settings call for greater ﬂexibility. For

1Department of Computer Science. 2Department of Statistics
and Data Sciences. 3Department of Information, Risk, and Opera-
tions Management. The University of Texas at Austin, TX, USA.
Correspondence to: Xueyu Mao <xmao@cs.utexas.edu>, Pur-
namrita Sarkar <purna.sarkar@austin.utexas.edu>, Deepayan
Chakrabarti <deepay@utexas.edu>.

instance, individuals in a social network may have mul-
tiple interests, and hence are best described as mem-
bers of multiple interest-based communities. We focus
on the popular mixed membership stochastic blockmodel
[n]
(MMSB) (Airoldi et al., 2008) where each node i, i
has a discrete probability distribution θi = (θi1, . . . , θiK)
over K communities. The probability of linkage between
nodes i and j depends on the degree of overlap between
their communities:

∈

∼

Dirichlet(α)

θi
P = ρΘBΘT
Aij = Aji = Bernoulli(Pij)

i

[n]

∈

i, j

[n]

∈

∈

where θi is the i-th row of Θ, A represents the adja-
RK×K
cency matrix of the generated graph, and B
is the community-community interaction matrix. The pa-
rameter ρ controls the sparsity of the graph, so WLOG,
the largest entry of B can be set to 1. The parameter
α0 = (cid:80)
i αi controls the amount of overlap. In particular,
0, MMSB reduces to the well known stochas-
when α0
tic blockmodel, where every node belongs to exactly one
community. Larger α0 leads to more overlap. Since we
only observe A, a natural question is: how can
and B
be recovered from A in a way that is provably consistent?

θi
{

→

}

1.1. Prior work

We categorize existing approaches broadly into three
groups: model-based parameter inference methods, spe-
cialized algorithms that offer provable guarantees, and
optimization-based methods using non-negative matrix
factorization.

Model-based methods: These apply standard techniques
for inference of hidden variables to the MMSB model. Ex-
amples include MCMC techniques (Chang, 2012) and vari-
ational methods (Gopalan & Blei, 2013). While these often
work well in practice, there are no proofs of consistency for
these methods. The MCMC methods are difﬁcult to scale
to large graphs, so we compare against the faster variational
inference methods in our experiments.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

Algorithms with provable guarantees: There has been
work on provably consistent estimation on models similar
to MMSB. Zhang et al. (2014) propose a spectral method

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

(OCCAM) for a model where the θi has unit (cid:96)2 norm (un-
like MMSB, where they have unit (cid:96)1 norm). In addition to
the standard assumptions regarding the existence of “pure”
nodes1 (which only belong to a single community) and a
positive-deﬁnite B, they also require B to have equal di-
agonal entries, and assume that the ground truth commu-
nities has a unique optimum of a special loss function,
and there is curvature around the optimum. Such assump-
tions may be hard to verify. Ray et al. (2015) and Kauf-
mann et al. (2016) consider models with binary commu-
nity memberships. Kaufmann et al. (2016) show that the
global optimum of a special loss function is consistent.
However, achieving the global optimum is computationally
intractable, and the scalable algorithm proposed by them
(SAAC) is not provably consistent. Anandkumar et al.
(2014) propose a tensor based approach for MMSB. De-
spite their elegant solution the computational complexity is
O(n2K), which can be prohibitive for large graphs.

Optimization-based methods: If B is positive-deﬁnite,
the MMSB probability matrix P can be written as
P = WWT , where the W matrix has only non-negative
entries. In other words, W is the solution to a Symmet-
ric Non-negative Matrix Factorization (SNMF) problem:
W = arg minX≥0 loss(P, XXT ) for some loss function
that measure the “difference” between P and its factoriza-
tion. SNMF has been widely studied and successfully used
for community detection (Kuang et al., 2015; Wang et al.,
2011; 2016; Psorakis et al., 2011), but typically lacks the
guarantees we desire. Our paper attempts to address these
issues.

We note that Arora et al. (2012; 2013) used NMF to con-
sistently estimate parameters of a topic model. However,
their results cannot be easily applied to the MMSB infer-
ence problem. In particular, for topic models, the columns
of the word-by-topic matrix specifying the probability dis-
tribution of words in a topic sum to 1. For MMSB, the rows
of the node membership matrix sum to 1. The relationship
of this work to the MMSB problem is unclear.

1.2. Problem Statement and Contributions

We seek to answer two problems.

Problem 1: Given P, when does the solution to the SNMF
optimization yield the correct W?

The difﬁculty stems from the fact that (a) the MMSB model
may not always be identiﬁable, and (b) even if it is, the cor-
responding SNMF problem may not have a unique solution

1This is a common assumption even for NMF methods for
topic modeling, where each topic is assumed to have an anchor
word (words belonging to only one topic). Huang et al. (2016)
introduced a special optimization criterion to relax the presence
of anchor words, but the optimization criterion is non-convex.

(even after allowing for permutation of communities).

Even when the conditions for Problem 1 are met, we may
be unable to ﬁnd a good solution in practice. This is due
to two reasons. First, we only know the adjacency matrix
A, and not the probability matrix P. Second, the general
SNMF problem is non-convex, and SNMF algorithms can
get stuck at local optima. Hence, it is unclear if an algo-
rithm can consistently recover the MMSB parameters. This
leads to our next question.

Problem 2: Given A generated from a MMSB model, can
we develop a fast and provably consistent algorithm to infer
the parameters?

Our goal is to develop a fast algorithm that provably solves
SNMF for an identiﬁable MMSB model. Note that generic
SNMF algorithms typically do not have any provable guar-
antees.

Our contributions are as follows.

Identiﬁability: We show conditions that are sufﬁcient for
MMSB to be identiﬁable; speciﬁcally, there must be at least
one “pure” exemplar of each of the K clusters (i.e., a node
that belongs to that community with probability 1), and B
must be full rank.

Uniqueness under SNMF: We provide sufﬁcient condi-
tions under which an identiﬁable MMSB model is the
unique solution for the SNMF problem; speciﬁcally, the
MMSB probability matrix P has a unique SNMF solution
if B is diagonal. It is important to note that MMSB with
a diagonal B still allows for interactions between different
communities via members who belong to both.

Recovery algorithm: We present a new algorithm, called
and B given
GeoNMF, for recovering the parameters
only the observed adjacency matrix A. The only compute-
intensive part of the algorithm is the calculation of the top-
K eigenvalues and eigenvectors of A, for which highly op-
timized algorithms exist (Press et al., 1992).

θi
{

}

Provable guarantees: Under the common assumption that
θi are generated from a Dirichlet(α) prior, we prove the
consistency of GeoNMF when B is diagonal and there
are “pure” nodes for each cluster (exactly the conditions
needed for uniqueness of SNMF). We allow the sparsity
parameter ρ to decay with the graph size n. All proofs are
deferred to the appendix.

Empirical validation: On simulated networks, we com-
pare GeoNMF against variational methods (SVI) (Gopalan
& Blei, 2013). Since OCCAM, SAAC, and BSNMF (a
Bayesian variant of SNMF (Psorakis et al., 2011)) are
formed under different model assumptions, we exclude
these for the simulation experiments for fairness. We
also run experiments on Facebook and Google Plus ego

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

networks collected by Mcauley & Leskovec (2014); co-
authorship datasets constructed by us from DBLP (Ley,
2002) and the Microsoft academic graph (MAG) (Sinha
et al., 2015). These networks can have up to 150,000
nodes. On these graphs we compare GeoNMF against SVI,
SAAC, OCCAM and BSNMF. We see that GeoNMF is
consistently among the top, while also being one of the
fastest. This establishes that GeoNMF achieves excellent
accuracy and is computationally efﬁcient in addition to be-
ing provably consistent.

2. Identiﬁability and Uniqueness

In order to present our results, we will now introduce some
key deﬁnitions. Similar deﬁnitions appear in (Zhang et al.,
2014).

Deﬁnition 2.1. A node i

[K] such that θij = 1 and θi(cid:96) = 0 for all (cid:96)

∈

[n] is called a “pure” node if
[K],

∈

j
∈
= j.

∃
(cid:96)

Identiﬁability of MMSB. MMSB is not identiﬁable in
general. Consider the following counter example.

M1 =





0.5 0.5
0.5
0
0
0.5



0
0.5
0.5

 M2 =





0.25 0.25
0.5
0.25
0.25
0.5
0.5
0.25 0.25





It can be easily checked that
the probability matrices
P generated by the parameter set (Θ(1), B(1), ρ(1)) =
(M1, I3×3, 1) is exactly the same as that generated by
(Θ(2), B(2), ρ(2)) = (I3×3, 2M2, 0.5), where I3×3 is the
identity matrix. This example can be extended to arbitrar-
ily large n: for every new row θ(2)
added to Θ(2), add the
row θ(1)
i M1 to Θ(1). The new rows are still non-
negative and sum to 1; it can be veriﬁed that P(1) = P(2)
even after these new node additions.

i = θ(2)

i

Thus, while MMSB is not identiﬁable in general, we can
prove identiﬁability under certain conditions.

Theorem 2.1 (Sufﬁcient conditions for MMSB identiﬁabil-
ity). Suppose parameters Θ, B of the MMSB model satisfy
the following conditions: (a) there is at least one pure node
for each community, and (b) B has full rank. Then, MMSB
is identiﬁable up to a permutation.

Since identiﬁability is a necessary condition for consistent
recovery of parameters, we will assume these conditions
from now on.

Uniqueness of SNMF for MMSB model. Even when the
MMSB model is identiﬁable, the SNMF optimization may
not have a unique solution. In other words, given an MMSB
probability matrix P, there might be multiple matrices X
such that P = XXT , even if P corresponds to a unique
parameter setting (Θ, B, ρ) under MMSB. For SNMF to

work, W = √ρΘB1/2 must the the unique SNMF solu-
tion. When does this happen?

In general, SNMF is not unique because W can be per-
muted, so we consider the following deﬁnition of unique-
ness.

Deﬁnition 2.2.
(Uniqueness of SNMF (Huang et al.,
2014)) The Symmetric NMF of P = WWT is said to
be (essentially) unique if P = ˜W ˜WT implies ˜W = WZ,
where Z is a permutation matrix.

Theorem 2.2 (Uniqueness of SNMF for MMSB). Con-
sider an identiﬁable MMSB model where B is diago-
nal. Then, its Symmetric NMF W is unique and equals
√ρΘB1/2 .

The above results establish that if we ﬁnd a W that is the
symmetric NMF solution of P then it is at least unique.
two practical questions are still unanswered.
However,
First, given the non-convex nature of SNMF, how can we
guarantee that we ﬁnd the correct W given P? Second, in
practice we are given not P but the noisy adjacency matrix
A. Typical algorithms for SNMF do not provide guaran-
tees even for the ﬁrst question.

3. Provably consistent inference for MMSB

To achieve consistent inference, we turn to the speciﬁc
structure of the MMSB model. We motivate our approach
in three stages. First, note that under the conditions of The-
orem 2.2, the rows of W form a simplex whose corners
are formed by the pure nodes for each cluster. In addition,
these corners are aligned along different axes, and hence
are orthogonal to each other. Thus, if we can detect the
corners of the simplex, we can recover the MMSB param-
eters. So the goal is to ﬁnd the pure nodes from different
clusters, since they deﬁne the corners.

While our goal is to get W, note that it is easy to com-
pute VE1/2 where V, E are the eigenvectors and eigen-
i.e., P = VEVT . Thus, WWT =
values of P,
(VE1/2)(VE1/2)T . This implies that W = VE1/2Q
for some orthogonal matrix Q (Lemma A.1 of (Tang et al.,
2013)). Essentially we should be able to identify the pure
nodes by ﬁnding the corners of the simplex based on V and
E.

Once we have found the pure nodes, it is easy to ﬁnd the
rotation matrix Q modulo a permutaion of classes, because
we know that the pure nodes are on the axis for the simplex
of ΘB1/2.

Now, we note something rather striking. Let D denote
the diagonal matrix with expected degrees on the diago-
nal. Consider the population Laplacian D−1/2PD−1/2.
Its square root is given by D−1/2VE1/2, which has the
following interesting property for equal Dirichlet parame-

(cid:54)
On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

ters αa = α0/K. We show in Lemma 4.1 that while the
resulting rows no longer fall on a simplex, the rows with
the largest norm are precisely the pure nodes, for whom the
norm concentrates around (cid:112)K/n. Thus, picking the rows
with the largest norm of the square root gives us the pure
nodes. From this, Q, θi for other rows and the parameters
ρ and B can again be easily extracted.

Needless to say, this only answers the question for the ex-
pectation matrix P. In reality, we have a noisy adjacency
matrix. Let ˆV and ˆE denote the matrices of eigenvectors
and eigenvalues of A. We also establish in this paper that
the rows of ˆV ˆE1/2 concentrate around its population coun-
terpart (corresponding row of VE1/2O for some rotation
matrix O). While there are eigenvector deviation results
in random matrix theory, e.g.
the Davis-Kahan Theorem
(Davis & Kahan, 1970), these typically provide deviation
results for the whole ˆV matrix, not its rows. In a nutshell,
this crucial result lets us carefully bound the errors of each
step of the same basic idea executed on A, the noisy proxy
for P.

Algorithm 1 GeoNMF
Input: Adjacency matrix A; number of communities K;

a constant (cid:15)0

Output: Estimated node-community distribution matrix
ˆΘ, Community-community interaction matrix ˆB,
sparsity-control parameter ˆρ;

1: Randomly split the set of nodes [n] into two equal-

sized parts

and ¯
.
S

S

S

S

2: Obtain the top K eigen-decomposition of A(

,

) as

(cid:107)

S

F

≥

S
1

, ¯
S

(cid:15)0) maxj

ˆV1 ˆE1 ˆVT

ˆX(i, :)
2
(cid:107)

) as ˆV2 ˆE2 ˆVT
2 .

1 and of A( ¯
S

p = PartitionPureNodes
p, :)

, ¯
S
3: Calculate degree matrices D2, D12 and D21 for the
) and A( ¯
, ¯
) respectively.
,
), A(
S
S
S
21 A21 ˆV1 ˆE−1/2
, where A21 = A( ¯
,
).
S
S
(cid:111)
ˆX(j, :)
(1
i :
2
(cid:107)
(cid:107)
−
(cid:113) K
(cid:16) ˆX(F, :),
mini∈F D2(i,i)
maxi∈F D2(i,i)
4n

rows of A( ¯
S
4: ˆX = D−1/2
(cid:110)
=
5:

6:
7: ˆXp = ˆX(
S
8: Get ˆβ, where ˆβi =
9: ˆB = diag( ˆβ)
10: ˆρ = maxi ˆBii
11: ˆB = ˆB/ˆρ
p D−1/2
12: ˆΘ( ¯
21
S
13: Repeat steps with D12, A12, ˆV2, and ˆE2 to obtain pa-
rameter estimates for the remaining bipartition.

, :) = D1/2
21

p) ˆXp
S

i D1/2
21 (

ˆX ˆX−1

(cid:13)
(cid:13)
(cid:13)eT

(cid:13)
2
(cid:13)
(cid:13)
2

(
S

[K]

p)

, i

p,

p,

∈

S

S

(cid:17)

Algorithm 1 shows our NMF algorithm based on these ge-
ometric intuitions for inference under MMSB (henceforth,
GeoNMF). The complexity of GeoNMF is dominated by
the one-time eigen-decomposition in step 2. Thus this al-
gorithm is fast and scalable. The consistency of parameters

inferred under GeoNMF is shown in the next section.

Algorithm 2 PartitionPureNodes

Input: Matrix M

Rm×K, where each row represents a

pure node; a constant τ

∈

Output: A set S consisting of one pure node from each

cluster.

.

, C =

{}
= [m] do

1: S =
{}
2: while C
Randomly pick one index from [m]
3:
S = S
4:
C = C
5:
6: end while

M(s, :)
(cid:107)

s
}
i
∈

∪ {
∪ {

[m]

C :

\

\

−

C, say s

M(i, :)

τ

(cid:107) ≤

}

S

and ¯
S

Remark 3.1. Note that Algorithm 1 produces two sets of
parameters for the two partitions of the graph
. In
practice one may need to have parameter estimates of the
entire graph. While there are many ways of doing this,
the most intuitive way would be to look at the set of pure
nodes in
p). If
one looks at the subgraph induced by the union of all these
pure nodes, then with high probability, there should be K
connected components, which will allow us to match the
communities.

p) and those in ¯
S
S

(call this ¯
S

(call this

S

= K clusters.
Also note that Algorithm 2 may return k
However, we show in Lemma 4.4 that the pure nodes ex-
tracted by our algorithm will be highly separated and with
high probability we will have k = K for an appropriately
chosen τ .

Finally, we note that, in our implementation, we construct
the candidate pure node set
(step 5 of Algorithm 1) by
F
ﬁnding all nodes with norm within (cid:15)0 multiplicative error
of the largest norm. We increase (cid:15)0 from a small value,
until ˆXp has condition number close to one. This is helpful
when n is small, where asymptotic results do not hold.

4. Analysis
We want to prove that the sample-based estimates ˆΘ, ˆB
and ˆρ concentrate around the corresponding population pa-
rameters Θ, B, and ρ after appropriate normalization. We
will show this in several steps, which follow the steps of
GeoNMF.

, :), where ¯
S

For the following statements, denote βmin = mina Baa,
Θ2 = Θ( ¯
is one of the random bipartitions
S
of [n]. Let D21 be the population version of D21 deﬁned in
Algorithm 1. Also let ˆXi = eT
and
1
21 Θ2B1/2 for
its population version Xi = √ρ
i

21 A21 ˆV1 ˆE−1/2
i D−1/2
i D−1/2
eT

·

[ n
2 ].

∈

First we show the pure nodes have the largest row norm of
the population version of ˆX.

(cid:54)
(cid:54)
On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Lemma 4.1. Recall that X
with αi = α0/K, then

2 ×K. If Θ

Dirichlet(α)

∼

R n
∈
[ n
2 ],

i
∀

∈
(cid:32)

Xi

(cid:107)

2
2 ≤

(cid:107)

2K
n

max
a

θia

1 + OP

(cid:32)(cid:114)

(cid:33)(cid:33)

K log n
n

F

with probability larger than 1
In particular, if node i of subgraph A( ¯
S
(maxa θia = 1),

O(1/n3).
, ¯
S

−

) is a pure node

Xi

(cid:107)

2
2 ∈

(cid:107)

(cid:34)
1

2K
n

OP

−

(cid:32)(cid:114)

(cid:33)

K log n
n

, 1 + OP

(cid:32)(cid:114)

(cid:33)(cid:35)

.

K log n
n

Concentration of rows of ˆX. We must show that the rows
of the sample ˆX matrix concentrate around a suitably ro-
tated population version. While it is known that ˆV concen-
trates around suitably rotated V (see the variant of Davis-
Kahan Theorem presented in (Yu et al., 2015)), these re-
sults are for columns of the V matrix, not for each row. The
trivial bound for row-wise error would be to upper bound it
by the total error, which is too crude for our purposes. To
get row-wise convergence, we use sample-splitting (similar
ideas can be found in (McSherry, 2001; Chaudhuri et al.,
2012)), as detailed in steps 1 to 4 of GeoNMF. The key
idea is to split the graph in two parts and project the adja-
cency matrix of one part onto eigenvectors of another part.
Due to independence of these two parts, one can show con-
centration.
Theorem 4.2. Consider an adjacency matrix A gener-
ated from MMSB(Θ, B, ρ), where Θ
Dirichlet(α) with
αi = α0/K, whose parameters satisfy the conditions of
Theorem 2.2. If ρn = Ω(log n), then
orthogonal matrix
i
O

RK×K that

∼

∃

[ n
2 ],

∈

∀

∈

XiO

ˆXi
(cid:107)

2
(cid:107)

= OP

−
Xi
(cid:107)
with probability larger than 1

(cid:107)2

(cid:32)

(cid:33)

K 2√log n
β5/2
minρ√n

O(K 2/n2).

−

Thus, the sample-based quantity for each row i converges
to its population variant.

Selection of pure nodes. GeoNMF selects the nodes with
(almost) the highest norm. We prove that this only selects

nearly pure nodes. Let (cid:15)(cid:48) = OP

K2√
β5/2
minρ
row-wise error term from Theorem 4.2.

log n
√
n

(cid:18)

(cid:19)

represent the

∃

Lemma 4.3. Let
ˆXi
(1

F
(cid:15)0) maxj

2

(cid:107)

(cid:107)

≥

−

be
ˆXj
(cid:107)

the
2. Then
(cid:107)

set of nodes with
,

i
∀

∈ F

max
a

θia

1

≥

−

OP ((cid:15)0 + (cid:15)(cid:48))

with probability larger than 1

O(K 2/n2).

−

We choose (cid:15)0 = OP ((cid:15)(cid:48)) and it is straightforward to show
2(cid:15)(cid:48), then
by Lemmas 4.1, 4.3, and Theorem 4.2 that if (cid:15)0

includes all pure nodes from all K communities.

≥

Clustering of pure nodes. Once the (nearly) pure nodes
have been selected, we run PartitionPureNodes (Algo-
rithm 2) on them. We show that these nodes can form ex-
actly K well separated clusters and each cluster only con-
tains nodes whose θ are peaked on the same element, and
PartitionPureNodes can select exactly one node from each
of the K communities.

(cid:113) K
Lemma 4.4. Let τ =
is
4n
deﬁned in step 5 of Algorithm 1. If all conditions in Theo-
rem 4.2 are satisﬁed, then PartitionPureNodes ( ˆX(
, :), τ )
F
returns one (nearly) pure node from each of the underlying
O(K 2/n2).
K communities with probability larger than 1

mini∈F D2(i,i)
maxi∈F D2(i,i) , where

F

−

Concentration of ( ˆΘ, ˆB, ˆρ). GeoNMF recovers Θ using
D, ˆX, and its pure portion ˆXp (via the inverse ˆX−1
p ). We
ﬁrst prove that ˆX−1
p
Theorem 4.5. Let
p be the set of of pure nodes extracted
using our algorithm. Let ˆXp denote the rows of ˆX indexed
p. Then, for the orthogonal matrix O from Theorem
by
S
4.2,

concentrates around its expectation.

S

ˆX−1
(cid:107)

(XpO)−1
p −
X−1
p
(cid:107)

(cid:107)

F

F
(cid:107)

= OP

(cid:32)

(cid:33)

K 5/2√log n
β5/2
minρ√n

with probability larger than 1

O(K 2/n2).

−

Next, we shall prove consistency for ˆΘ2 := ˆΘ( ¯
S
proof for ˆΘ(
S
S
Theorem 4.6. Let ˆΘ2 = D1/2
ˆX ˆX−1
21p , then
21
RK×K such that
mutation matrix Π

, :) is similar. Let D21p = D21(
p D−1/2

p,

S

∃

, :); the
p).

a per-

ˆΘ2

∈
Θ2Π
F
(cid:107)

(cid:107)

−
Θ2
(cid:107)
with probability larger than 1

F
(cid:107)

= OP

(cid:19)

(cid:18) K 3√log n
β3
minρ√n

O(K 2/n2).

−
Recall that B and ˆB are both diagonal matrices, with diag-
ˆβa
and
onal components
}
{
a D1/2
Theorem 4.7. Let ˆρ ˆβa =
eT
21 (
S
RK×K such that
a permutation matrix Π

2
2. Then,
[K],

respectively.

βa
{

p,

}

(cid:107)
∈

(cid:34)

(cid:32)

ˆρ ˆβa

∈

ρβa(cid:48)

1

OP

−

(cid:33)

K 5/2 log n
β5/2
minρ√n

, 1 + OP

(cid:33)(cid:35)

K 5/2 log n
β5/2
minρ√n

p) ˆXp
(cid:107)
S
a
∈

∀

(cid:32)

for some a(cid:48) such that Πa(cid:48)a = 1, with probability larger
than 1

O(K 2/n2).

Remark 4.1. While the details of our algorithms were de-
signed for obtaining rigorous theoretical guarantees, many

−

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

of these can be relaxed in practice. For instance, while
we require the Dirichlet parameters to be equal, leading
to balanced cluster sizes, real data experiments show that
our algorithm works well for unbalanced settings as well.
Similarly, the algorithm assumes a diagonal B (which is
sufﬁcient for uniqueness), but empirically works well even
in the presence of off-diagonal noise. Finally, splitting the
nodes into

is not needed in practice.

and ¯
S

S

5. Experiments

We present results on simulated and real-world datasets.
Via simulations, we evaluate the sensitivity of GeoNMF to
the various MMSB parameters: the skewness of the diag-
onal elements of B and off-diagonal noise, the Dirichlet
parameter α that controls the degree of overlap, the spar-
sity parameter ρ, and the number of communities K. Then,
we evaluate GeoNMF on Facebook and Google Plus ego
networks, and co-authorship networks with upto 150,000
nodes constructed from DBLP and the Microsoft Academic
Network.

Baseline methods: For the real-world networks, we com-
pare GeoNMF against the following methods2:

Stochastic variational
(Gopalan & Blei, 2013),

inference (SVI) for MMSB

a Bayesian variant of SNMF for overlapping commu-
nity detection (BSNMF) (Psorakis et al., 2011),

the OCCAM algorithm (Zhang et al., 2014) for recov-
ering mixed memberships, and

the SAAC algorithm (Kaufmann et al., 2016).

•

•

•

•

the simulation experiments, we only compare
For
GeoNMF against SVI, since these are the only two meth-
ods based speciﬁcally on the MMSB model. BSNMF has a
completely different underlying model, OCCAM requires
rows of Θ to have unit (cid:96)2 norm and B to have equal diago-
nal elements, and SAAC requires Θ to be a binary matrix,
while MMSB requires rows of Θ to have unit (cid:96)1 norm.

Since the community identities can only be recovered up-to
a permutation, in both simulated and real data experiments,
we ﬁgure out the order of the communities using the well
known Munkres algorithm in (Munkres, 1957).

5.1. Simulated data

Our simulations with the MMSB model are shown in Fig-
ure 1. We use αi = α0/K for i
[K]. While this leads to

∈

2We were not to run Anandkumar et al. (2014)’s main (GPU)
implementation of their algorithm because a required library
CULA is no longer open source, and a complementary CPU im-
plementation did not yield good results with default settings.

balanced clusters, note that the real datasets have clusters
of different sizes and we will show that GeoNMF works
consistently well even for those networks (see Section 5.2).
Unless otherwise stated, we set n = 5000, K = 3, and
α0 = 1.

Evaluation Metric: Since we have ground truth Θ, we
report the relative error of the inferred MMSB parameters

ˆΘ−ΘΠ
(cid:107)
(cid:107)Θ(cid:107)F

(cid:107)F

Θ deﬁned as min
. Here the minimum is taken
Π
K permutation matrices. For each experi-
over all K
ment, we report the average and the standard deviation over
10 random samples. Since all the baseline algorithms only
return ˆΘ, we only report relative error of that.

×

Sensitivity to skewness of the diagonal of B: Let β =
diag(B). For skewed β, different communities have dif-
ferent strengths of connection. We use β = (0.5
−
(cid:15)B, 0.5, 0.5 + (cid:15)B) and plot the relative error against vary-
ing (cid:15)B. Figure 1(a) shows that GeoNMF has much smaller
error than SVI, and is robust to β over a wide range.

Sensitivity to off-diagonal element B: While SNMF is
identiﬁable only for diagonal B, we still test GeoNMF in
the setting where all off-diagonal entries of B have noise
(cid:15). Figure 1(b) shows once again that GeoNMF is robust to
such noise, and is much more accurate than SVI.

Sensitivity to α0: In Figure 1(c), the relative error is plot-
ted against increasing α0; larger values corresponding to
larger overlap between communities. Accuracy degrades
with increasing overlap, as expected, but GeoNMF is much
less affected than SVI.

Sensitivity to ρ: Figure 1(d) shows relative error against
increasing ρ. For dense networks, both GeoNMF and SVI
perform similarly, but the error of SVI increases drastically
in the sparse regime (small ρ).

Scalability: Figure 1(f) shows the wall-clock time for net-
works of different sizes. Both GeoNMF and SVI scale lin-
early with the number of nodes, but SVI is about 100 times
slower than GeoNMF.

5.2. Real-world data

Datasets: For real-data experiments, we use two kinds of
networks:

•

•

Ego networks: We use the Facebook and Google
Plus (G-plus) ego networks, where each node can be
part of multiple “circles” or “communities.”
Co-authorship networks3: We construct co-authorship
networks from DBLP (each community is a group

3Available at http://www.cs.utexas.edu/˜xmao/

coauthorship

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

(a) ρ = 1, B = diag(β/ maxi βi),
β = (0.5 − (cid:15)B, 0.5, 0.5 + (cid:15)B)

(b) B = diag(β − (cid:15) · 1K ) + (cid:15) · 1K 1T
K ,

β = (0.6, 0.8, 1), ρ = 1

(c) ρ = 0.7, B = diag(β),
β = (0.4, 0.7, 1)

(d) B = diag(β),

β = (1, 1, 1), ρ = 1

(e) B = diag(0.35 · 1K + 0.65 · rK ),

(f) B = diag(0.5 · 1K + 0.5 · rK ),

rK = rand(K, 1), ρ = 1

rK = rand(K, 1), ρ = 1

Figure 1. (a)-(e) Simulation results for varying parameters. (f) Running time.

of conferences), and from the Microsoft Academic
Graph (each community is denoted by a “ﬁeld of
study” (FOS) tag). Each author’s θ vector is con-
structed by normalizing the number of papers he/she
has published in conferences in a subﬁeld (or papers
that have the FOS tag).

We preprocessed the networks by recursively removing
isolated nodes, communities without any pure nodes, and
nodes with no community assignments. For the ego net-
works we pick networks with at least 200 nodes and the
average number of nodes per community (n/K) is at least
100, giving us 3 Facebook and and 40 G-plus networks. For
the co-authorship networks, all communities have enough
pure nodes, and after removing isolated nodes, the net-
works have more than 200 nodes and n/K is larger than
100. The statistics of the networks (number of nodes, av-
erage degree, number of clusters, degree of overlap etc.)
are shown in Table 1. The overlap ratio is the number of
overlapping nodes divided by the number of nodes. The
different networks have the following subﬁelds:

DBLP1: Machine Learning, Theoretical Computer
Science, Data Mining, Computer Vision, Artiﬁcial In-
telligence, Natural Language Processing

DBLP2: Networking and Communications, Systems,

•

•

Information Theory

•

•

•

•

•

DBLP3: Databases, Data Mining, World Web Wide

DBLP4: Programming Languages, Software Engi-
neering, Formal Methods

DBLP5: Computer Architecture, Computer Hard-
ware, Real-time and Embedded Systems, Computer-
aided Design

MAG1: Computational Biology and Bioinformatics,
Organic Chemistry, Genetics

MAG2: Machine Learning, Artiﬁcial Intelligence,
Mathematical Optimization

Evaluation Metric: For real data experiments, we con-
struct Θ as follows. For the ego-networks every node has
a binary vector which indicates which circle (community)
each node belongs to. We normalize this to construct Θ.
For the DBLP and Microsoft Academic networks we con-
struct a row of Θ by normalizing the number of papers an
author has in different conferences (ground truth commu-
nities). We present the averaged Spearman rank correlation
[K] and ˆΘ(:, σ(a)),
coefﬁcients (RC) between Θ(:, a), a

∈

0.100.150.200.250.300.350.400.45ǫB0.10.20.30.40.50.60.7ˆΘRelativeErrorSkewedBGeoNMFSVI10−310−210−1ǫ0.10.20.30.40.50.60.70.80.9ˆΘRelativeErrorNoisyoff-diaginBGeoNMFSVI0.51.01.52.02.53.0α00.00.10.20.30.40.50.60.7ˆΘRelativeErrorVaryingα0GeoNMFSVI20306090150300500Averagedegree0.00.10.20.30.40.50.60.70.80.9ˆΘRelativeErrorVaryingsparsityGeoNMFSVI246810121416K−0.050.000.050.100.150.200.250.300.35ˆΘRelativeErrorNum.communitiesGeoNMFSVI5000100001500020000250003000035000Numberofnodesn10−1100101102103104RunningTime/sWall-clocktime(logscale)GeoNMFSVIOn Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Dataset
# nodes n
# communities K
Average Degree
Overlap %

Facebook
362.0 (± 148.5)
2.3 (±0.58)
56.8 (±32.3)
19.3(±29.8)

G-plus
656.2 (± 422.0)
2.8 (±1.74)
103.4 (±74.9)
26.5 (±32.4)

DBLP1 DBLP2 DBLP3 DBLP4 DBLP5 MAG1
142,788
30,566
3
6
12.4
8.9
3.3
18.2

13,315
3
8.5
21.1

16,817
3
7.6
14.9

25,481
3
5.2
14.4

42,351
4
6.8
18.5

MAG2
108,064
3
16.0
3.8

Table 1. Network statistics

GeoNMF

SVI

BSNMF

OCCAM SAAC

Facebook

G-plus

DBLP1

DBLP2

DBLP3

DBLP4

DBLP5

MAG1

MAG2

g
v
a
C
R

0.5

1

0

102

101

100

10−1

s
/

e
m

i
t

g
n
i
n
n
u
R

(a)

(d)

0.3

g
v
a
C
R

0.2

0.1

0

s
/

e
m

i
t

g
n
i
n
n
u
R

104

102

100

(b)

(e)

0.15

g
v
a
C
R

0.1

0.05

s
/

e
m

i
t

g
n
i
n
n
u
R

102

101

(c)

(f)

Facebook

G-plus

DBLP1

DBLP2

DBLP3

DBLP4

DBLP5

MAG1

MAG2

Figure 2. RCavg and running time (log scale) for real datasets.

where σ is a permutation of [K]. The formal deﬁnition is:

RCavg( ˆΘ, Θ) =

RC( ˆΘ(:, i), Θ(:, σ(i))).

1
K

max
σ

K
(cid:88)

i=1

It is easy to see that RCavg( ˆΘ, Θ) takes value from -1 to
1, and higher is better. Since SAAC returns binary assign-
ment, we compute its RCavg against the binary ground truth.

Performance: We report the RCavg score in Figure 2(a)
averaged over different Faceboook and G-plus networks;
in Figure 2(b) for ﬁve DBLP networks, and in Figure 2(c)
for two MAG networks. We show the time in seconds (log-
scale) in Figure 2(d) averaged over Facebook and G-plus
networks; in Figure 2(e) for DBLP networks and in Fig-
ure 2(f) for MAG networks. We averaged over the Face-
book and G-plus networks because all the performances
were similar.

•

•

For small networks like Facebook and G-plus, all al-
gorithms perform equally well both in speed and ac-
curacy, although GeoNMF is fast even for relatively
larger G-plus networks.

DBLP is sparser, and as a result the overall rank cor-
relation decreases. However, GeoNMF consistently
performs well . While for some networks, BSNMF
and OCCAM have comparable RCavg, they are much
slower than GeoNMF.

•

MAG is larger (hundreds of thousands of nodes) than
DBLP. For these networks we could not even run
BSNMF because of memory issues. Again, GeoNMF
performs consistently well while outperforming oth-
ers in speed.

Estimating K: While we assume that K is known apriori,
K can be estimated using the USVT estimator (Chatterjee
et al., 2015). For the simulated graphs, when average de-
gree is above ten, USVT estimates K correctly. However
for the real graphs, which are often sparse, it typically over-
estimates the true number of clusters.

6. Conclusions

This paper explored the applicability of symmetric NMF
algorithms for inference of MMSB parameters. We showed
broad conditions that ensure identiﬁability of MMSB, and
then proved sufﬁciency conditions for the MMSB param-
eters to be uniquely determined by a general symmetric
NMF algorithm. Since general-purpose symmetric NMF
algorithms do not have optimality guarantees, we propose
a new algorithm, called GeoNMF, that adapts symmetric
NMF speciﬁcally to MMSB. GeoNMF is not only provably
consistent, but also shows good accuracy in simulated and
real-world experiments, while also being among the fastest
approaches.

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

References

Airoldi, Edoardo M, Blei, David M, Fienberg, Stephen E,
and Xing, Eric P. Mixed membership stochastic block-
Journal of Machine Learning Research, 9:
models.
1981–2014, 2008.

Anandkumar, Animashree, Ge, Rong, Hsu, Daniel J, and
Kakade, Sham M. A tensor approach to learning mixed
membership community models. Journal of Machine
Learning Research, 15(1):2239–2312, 2014.

Kaufmann, Emilie, Bonald, Thomas, and Lelarge, Marc. A
spectral algorithm with additive clustering for the recov-
ery of overlapping communities in networks. In Interna-
tional Conference on Algorithmic Learning Theory, pp.
355–370. Springer, 2016.

Kuang, Da, Yun, Sangwoon, and Park, Haesun. Symnmf:
nonnegative low-rank approximation of a similarity ma-
trix for graph clustering. Journal of Global Optimiza-
tion, 62(3):545–574, 2015.

Arora, Sanjeev, Ge, Rong, and Moitra, Ankur. Learning
topic models–going beyond svd. In Foundations of Com-
puter Science (FOCS), 2012 IEEE 53rd Annual Sympo-
sium on, pp. 1–10. IEEE, 2012.

Ley, Michael. The dblp computer science bibliography:
In Interna-
Evolution, research issues, perspectives.
tional symposium on string processing and information
retrieval, pp. 1–10. Springer, 2002.

Arora, Sanjeev, Ge, Rong, Halpern, Yonatan, Mimno,
David M, Moitra, Ankur, Sontag, David, Wu, Yichen,
and Zhu, Michael. A practical algorithm for topic mod-
eling with provable guarantees. In ICML, pp. 280–288,
2013.

Chang,

Jonathan.
LDA: Collapsed gibbs
topic models, 2012.
pling methods
http://cran.r-project.org/web/
packages/lda/index.html.

for

sam-
URL

Lu, Zongqing, Sun, Xiao, Wen, Yonggang, Cao, Guohong,
and La Porta, Thomas. Algorithms and applications for
community detection in weighted networks. Parallel
and Distributed Systems, IEEE Transactions on, 26(11):
2916–2926, 2015.

Mcauley, Julian and Leskovec, Jure. Discovering social cir-
cles in ego networks. ACM Transactions on Knowledge
Discovery from Data (TKDD), 8(1):4, 2014.

Chatterjee, Sourav et al. Matrix estimation by universal
singular value thresholding. The Annals of Statistics, 43
(1):177–214, 2015.

McSherry, Frank. Spectral partitioning of random graphs.
In Foundations of Computer Science, 2001. Proceedings.
42nd IEEE Symposium on, pp. 529–537. IEEE, 2001.

Chaudhuri, Kamalika, Graham, Fan Chung, and Tsiatas,
Alexander. Spectral clustering of graphs with general de-
grees in the extended planted partition model. In COLT,
volume 23, pp. 35–1, 2012.

Chen, Jingchun and Yuan, Bo. Detecting functional mod-
ules in the yeast protein–protein interaction network.
Bioinformatics, 22(18):2283–2290, 2006.

Davis, Chandler and Kahan, William Morton. The rotation
of eigenvectors by a perturbation. iii. SIAM Journal on
Numerical Analysis, 7(1):1–46, 1970.

Gopalan, Prem K and Blei, David M. Efﬁcient discovery
of overlapping communities in massive networks. Pro-
ceedings of the National Academy of Sciences, 110(36):
14534–14539, 2013.

Huang, Kejun, Sidiropoulos, Nicholas, and Swami, Anan-
thram. Non-negative matrix factorization revisited:
Uniqueness and algorithm for symmetric decomposition.
Signal Processing, IEEE Transactions on, 62(1):211–
224, 2014.

Huang, Kejun, Fu, Xiao, and Sidiropoulos, Nikolaos D.
Anchor-free correlated topic modeling:
Identiﬁability
and algorithm. In Advances in Neural Information Pro-
cessing Systems, pp. 1786–1794, 2016.

Munkres, James. Algorithms for the assignment and trans-
portation problems. Journal of the society for industrial
and applied mathematics, 5(1):32–38, 1957.

Press, William H., Teukolsky, Saul A., Vetterling,
William T., and Flannery, Brian P. Numerical Recipes
in C. Cambridge University Press, 2nd edition, 1992.

Psorakis, Ioannis, Roberts, Stephen, Ebden, Mark, and
Sheldon, Ben. Overlapping community detection using
bayesian non-negative matrix factorization. Phys. Rev.
E, 83:066114, Jun 2011.

Ray, A., Ghaderi, J., Sanghavi, S., and Shakkottai, S. Over-
In 2014
lap graph clustering via successive removal.
52nd Annual Allerton Conference on Communication,
Control, and Computing, Allerton 2014, pp. 278–285,
United States, 1 2015. Institute of Electrical and Elec-
tronics Engineers Inc. doi: 10.1109/ALLERTON.2014.
7028467.

Sinha, Arnab, Shen, Zhihong, Song, Yang, Ma, Hao, Eide,
Darrin, Hsu, Bo-june Paul, and Wang, Kuansan. An
overview of microsoft academic service (mas) and ap-
plications. In Proceedings of the 24th international con-
ference on world wide web, pp. 243–246. ACM, 2015.

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Soundarajan, Sucheta and Hopcroft, John. Using commu-
nity information to improve the precision of link predic-
tion methods. In Proceedings of the 21st international
conference companion on World Wide Web, pp. 607–608.
ACM, 2012.

Tang, Minh, Sussman, Daniel L, Priebe, Carey E, et al.
Universally consistent vertex classiﬁcation for latent po-
sitions graphs. The Annals of Statistics, 41(3):1406–
1430, 2013.

Wang, Fei, Li, Tao, Wang, Xin, Zhu, Shenghuo, and Ding,
Chris. Community discovery using nonnegative matrix
factorization. Data Mining and Knowledge Discovery,
22(3):493–521, 2011.

Wang, Xiao, Cao, Xiaochun, Jin, Di, Cao, Yixin, and He,
Dongxiao. The (un) supervised nmf methods for dis-
covering overlapping communities as well as hubs and
outliers in networks. Physica A: Statistical Mechanics
and its Applications, 446:22–34, 2016.

Yu, Yi, Wang, Tengyao, Samworth, Richard J, et al. A use-
ful variant of the davis–kahan theorem for statisticians.
Biometrika, 102(2):315–323, 2015.

Zhang, Yuan, Levina, Elizaveta, and Zhu, Ji. Detect-
ing overlapping communities in networks using spectral
methods. arXiv preprint arXiv:1412.3432, 2014.

