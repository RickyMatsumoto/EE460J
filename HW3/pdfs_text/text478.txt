Prediction under Uncertainty in Sparse Spectrum Gaussian Processes
with Applications to Filtering and Control

Yunpeng Pan 1 2 Xinyan Yan 1 3 Evangelos A. Theodorou 1 2 Byron Boots 1 3

Abstract

ization,

Sparse Spectrum Gaussian Processes (SSGPs)
are a powerful tool for scaling Gaussian pro-
cesses (GPs) to large datasets. Existing SSGP
algorithms for regression assume deterministic
inputs, precluding their use in many real-world
robotics and engineering applications where ac-
counting for input uncertainty is crucial. We
address this problem by proposing two analytic
moment-based approaches with closed-form ex-
pressions for SSGP regression with uncertain in-
puts. Our methods are more general and scal-
able than their standard GP counterparts, and are
naturally applicable to multi-step prediction or
uncertainty propagation. We show that efﬁcient
algorithms for Bayesian ﬁltering and stochastic
model predictive control can use these methods,
and we evaluate our algorithms with comparative
analyses and both real-world and simulated ex-
periments.

1. Introduction

The problem of prediction under uncertainty, appears in
many ﬁelds of science and engineering that involve se-
quential prediction including state estimation (Ko & Fox,
2009; Deisenroth et al., 2012), time series prediction (Gi-
rard et al., 2003), stochastic process approximation (Ar-
chambeau et al., 2007), and planning and control (Deisen-
roth et al., 2015; Pan et al., 2015). In these problems, un-
certainty can be found in both the predictive models and the
model’s inputs. Formally, we are often interested in ﬁnding
the probability density of a prediction y, given a distribu-
tion p(x) and a probabilistic model p(y|x). By marginal-

1Georgia

USA 2School of Aerospace Engineering 3School of
teractive Computing.
<ypan37@gatech.edu>.

Institute of Technology, Atlanta, Georgia,
In-
Correspondence to: Yunpeng Pan

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

(cid:90)

p(y) =

p(y|x)p(x) dx.

(1)

Unfortunately, computing this integral exactly is often in-
tractable. In this paper, we tackle a subfamily of (1) where:
1) the probabilistic model is learned from data and speci-
ﬁed by a sparse spectrum representation of a Gaussian pro-
cess (SSGP); and 2) the input x is normally distributed. We
show that analytic expressions of the moments of p(y) can
be derived and that these are directly applicable to sequen-
tial prediction problems like ﬁltering and control.

1.1. Related work

Gaussian Process (GP) regression with uncertain inputs
has been addressed by Candela et al. (2003); Girard et al.
(2003), and extended to the multivariate outputs by Kuss
(2006). These methods have led to the development of
many algorithms in reinforcement learning (Rasmussen &
Kuss, 2004; Deisenroth et al., 2015), Bayesian ﬁltering
(Ko & Fox, 2009; Deisenroth et al., 2009), and smoothing
(Deisenroth et al., 2012). However, these approaches have
two major limitations: 1) they are not directly applicable
to large datasets, due to the polynomial time complexity
for exact inference (Williams & Rasmussen, 2006); and 2)
analytic moment expressions, when used, are restricted to
squared exponential (SE) kernels (Kuss, 2006) and cannot
be generalized to other kernels in a straightforward way.

A common method for approximating large-scale kernel
machines is through random Fourier features (Rahimi &
Recht, 2007). The key idea is to map the input to a low-
dimensional feature space yielding fast linear methods. In
the context of GP regression (GPR), this idea leads to the
sparse spectrum GPR (SSGPR) algorithm (L´azaro-Gredilla
et al., 2010). SSGP has been extended in a number of ways
for, e.g.
incremental model learning (Gijsberts & Metta,
2013), and large-scale GPR (Dai et al., 2014; Yan et al.,
2015). However, to the best of our knowledge, prediction
under uncertainty for SSGPs has not been explored. Al-
though there are several alternative approximations to exact
GP inference including approximating the posterior distri-
bution using inducing points, e.g., (Snelson & Ghahramani,
2006; Titsias, 2009; Cheng & Boots, 2016), comparing dif-
ferent GP approximations is not the focus of this paper.

Prediction under Uncertainty in Sparse Spectrum Gaussian Processes

1.2. Applications

We consider two key problems that are widely encountered
in robotics and engineering: Bayesian ﬁltering and stochas-
tic model predictive control.

The goal of Bayesian ﬁltering is to infer a hidden sys-
tem state through the recursive application of Bayes’ rule.
Well-known frameworks for Bayesian ﬁltering include un-
scented Kalman Filtering (UKF), particle ﬁltering (PF), ex-
tended Kalman ﬁltering (EKF), and assumed density ﬁlter-
ing (ADF). GP-based Bayesian ﬁltering with SE kernels
has been developed for these frameworks by (Ko & Fox,
2009; Deisenroth et al., 2009). We extend this work with
highly efﬁcient SSGP-based EKF and ADF algorithms.

The goal of stochastic model predictive control (MPC) is
to ﬁnd ﬁnite horizon optimal control at each time instant.
Due to the high computational cost of GP inference and
real-time optimization requirements in MPC, most GP-
based control methods (Deisenroth et al., 2015; Pan &
Theodorou, 2014; Kupcsik et al., 2014) are restricted to
episodic reinforcement learning tasks. To cope with this
challenge, we present an SSGP-based MPC algorithm that
is fast enough to perform probabilistic trajectory optimiza-
tion and model adaptation on-the-ﬂy.

1.3. Our contributions

• We propose two approaches to prediction under un-
certainty in SSGPs with closed-form expressions for
the predictive distribution. Compared to previous GP
counterparts, our methods: 1) are more scalable, and
2) can be generalized to any continuous shift-invariant
kernels with a Fourier feature representation.

• We demonstrate successful applications of the pro-
posed approaches by presenting scalable algorithms
for 1) recursive Bayesian ﬁltering and 2) stochastic
model predictive control via probabilistic trajectory
optimization.

The rest of the paper is organized as follows. In §2, we give
an introduction to SSGPs, which serves as our probabilis-
tic model. Derivation and expressions of the two proposed
prediction methods are detailed in §3. Applications to ﬁl-
tering and control, and experimental results are presented
in §4 and §5 respectively. Finally §6 concludes the paper.

2. Sparse Spectral Representation of GPs
Consider the task of learning the function f : Rd → R,
given IID data D = {xi, yi}n
i=1, with each pair related by
n),
(2)

(cid:15) ∼ N (0, σ2

y = f (x) + (cid:15),

where (cid:15) is IID additive Gaussian noise. Gaussian pro-
cess regression (GPR) is a principled way of performing
Bayesian inference in function space, assuming that func-
tion f has a prior distribution f ∼ GP(m, k), with mean

function m : Rd → R and kernel k : Rd × Rd → R.
Without loss of generality, we assume m(x) = 0. Ex-
act GPR is challenging for large datasets due to its O(n3)
time and O(n2) space complexity (Williams & Rasmussen,
2006), which is a direct consequence of having to store and
invert an n × n Gram matrix.

Random features can be used to form an unbiased approx-
imation of continuous shift-invariant kernel functions, and
are proposed as a general mechanism to accelerate large-
scale kernel machines (Rahimi & Recht, 2007), via ex-
plicitly mapping inputs to low-dimensional feature space.
Based on Bochner’s theorem, the Fourier transform of a
continuous shift-invariant positive deﬁnite kernel k(x, x(cid:48))
is a proper probability distribution p(ω), assuming k(x, x(cid:48))
is properly scaled (Rahimi & Recht, 2007):

(cid:90)

k(x, x(cid:48)) =

p(ω)ejωT (x−x(cid:48)) dω

= E(φω(x)φω(x(cid:48))∗), ω ∼ p(ω),

(3)

where φω(x) = ejωT x, and we can see that k(x, x(cid:48)) only
depends on the lag vector separating x and x(cid:48): x−x(cid:48). Equa-
tion (3) leads to an unbiased ﬁnite sample approximation
(cid:80) φωi(x)φωi(x(cid:48))∗, where random fre-
of k: k(x, x(cid:48)) ≈ 1
m
quencies {ωi}m
i=1 are drawn IID from p(ω). Utilizing the
fact that φω can be replaced by sinusoidal functions since
both p(ω) and k(x, x(cid:48)) are reals, and concatenating features
{φωi}m
i=1 into a succinct vector form, an approximation for
k(x, x(cid:48)) is expressed as

k(x, x(cid:48)) ≈ φ(x)T φ(x(cid:48)), φ(x) =

(cid:21)
(cid:20)φc(x)
φs(x)

,

(4)

i (x) = σk cos(ωT
φc

i x), φs

i (x) = σk sin(ωT

i x), ωi ∼ p(ω),

where σk is a scaling coefﬁcient. For the commonly
k(x, x(cid:48)) =
used Squared Exponential
f exp(− 1
Λ−1), p(ω) = N (0, Λ−1) and σk =
σ2
σf√
m , where the coefﬁcient σf and the diagonal matrix Λ are
the hyperparameters, examples of kernels and correspond-
ing spectral densities can be found in Table 1.

2 (cid:107)x − x(cid:48)(cid:107)2

(SE) kernel:

In accordance with this feature map (4), Sparse Spectrum
GPs are deﬁned as follows
Deﬁnition 1. Sparse Spectrum GPs (SSGPs) are GPs with
kernels deﬁned on the ﬁnite-dimensional and randomized
feature map φ (4):

k(x, x(cid:48)) = φ(x)T φ(x(cid:48)) + σ2

nδ(x − x(cid:48)),

(5)

where the function δ is the Kronecker delta function.

The second term in (5) accounts for the additive zero mean
Gaussian noise in (2), if the goal is to learn the correla-
tion between x and y directly as in our case of learning the
probabilistic model p(y|x), instead of learning the latent
function f .

Prediction under Uncertainty in Sparse Spectrum Gaussian Processes

Because of the explicit ﬁnite-dimensional feature map (4),
each SSGP is equivalent to a Gaussian distribution over the
weights of features w ∈ R2m. Assuming that prior dis-
tribution of weights w is N (0, I) 1 and the feature map is
ﬁxed, after conditioning on the data D = {xi, yi}n
i=1, the
posterior distribution of w is 2

ditionally independent scalar models for each output di-
mension, i.e., assuming for outputs in different dimension
ya and yb, p(ya, yb|x) = p(ya|x)p(yb|x). Discussions on
this assumption can be found in Appendix §6.1. For nota-
tional simplicity, we suppress the dependency of φ(x) on
x, and treat y as a scalar by default.

w ∼ N (α, σ2

nA−1),

α = A−1ΦY, A = ΦΦT + σ2

nI,

(6)

3.1. Exact moment matching (SSGP-EMM)

which can be derived through Bayesian linear regres-
In (6), the column vector Y and the matrix Φ are
sion.
speciﬁed by the data D: Y = (cid:2)y1
, Φ =
. . . φ(xn)(cid:3). Consequently, the posterior distri-
(cid:2)φ(x1)
bution over the output y in (2) at a test point x is exactly
Gaussian, in which the posterior variance explicitly cap-
tures the model uncertainty in prediction with input x:

. . .

yn

(cid:3)T

p(y|x) = N (αT φ(x), σ2

n + σ2

n(cid:107)φ(x)(cid:107)2

A−1 ).

(7)

This Bayesian linear regression method for SSGP is pro-
posed in L´azaro-Gredilla et al. (2010). Its time complexity
is O(nm2 + m3), which is signiﬁcantly more efﬁcient than
standard GPR’s O(n3) when m (cid:28) n.

Remark It’s worth noting that the methods proposed in
this paper are not tied to speciﬁc algorithms for SSGP
regression such as Bayesian linear regression (L´azaro-
Gredilla et al., 2010), but able to account for any SSGP
with speciﬁed feature weights distribution (6), where poste-
rior α and A can be computed by any means. Variations on
A include sparse approximations by a low rank plus diag-
onal matrix, or iterative solutions by optimization methods
like doubly stochastic gradient descent (Dai et al., 2014).

3. Prediction under Uncertainty

Two methods for prediction under uncertainty are pre-
sented under two conditions: 1) the uncertain input is nor-
mally distributed: x ∼ N (µ, Σ), and 2) probabilistic mod-
els are in the form of (7) speciﬁed by SSGPs. Despite
these conditions, evaluating the integral in (1) is still in-
tractable.
In this work, we approximate the true predic-
tive distribution p(y) by a Gaussian distribution with mo-
ments that are analytically computed through: 1) exact mo-
ment matching, and 2) linearization of posterior mean func-
tion. Closed-form expressions for predictive mean, vari-
ance, covariance, and input-prediction cross-covariance are
derived. We consider multivariate outputs by utilizing con-

1I is the identity matrix with proper size. The prior covari-
ance is identity since E (f (x)f (x)) = E (cid:0)φ(x)T wwT φ(x(cid:48))(cid:1) =
φ(x)T E(wwT )φ(x(cid:48)), and E (f (x)f (x(cid:48))) = φ(x)T φ(x(cid:48)) (see
§2.2 in Rasmussen & Kuss (2004) for details.)

2Conditioning on data D is omitted, e.g., in w|D, for simplic-

ity in notation.

We derive the closed-form expressions for exact moments:
1) the predictive mean E y, 2) the predictive variance Var y
and covariance Cov(ya, yb), which in the multivariate case
correspond to the diagonal and off-diagonal entries of the
predictive covariance matrix, and 3) the cross-covariance
between input and prediction Cov(x, y).

Using the expressions for SSGP (4), (7), and the law of
total expectation, the predictive mean becomes

E y = E E(y|x) = E (cid:0)αT φ(cid:1) = αT E

(cid:21)

(cid:20)φc
φs

,

(8)

E φc

i = σk E cos(ωT

i x), E φs

i = σk E sin(ωT

i x),

where i = 1, . . . , m, and in the nested expectation
E E(y|x), the outer expectation is over the input distribu-
tion p(x) = N (µ, Σ), and the inner expectation is over the
conditional distribution p(y|x) (7).

By observing (8), we see that the expectation of sinusoids
under the Gaussian distribution is the key to computing the
predictive mean. Thus, we state the following proposition:
Proposition 1. The expectation of sinusoids over multi-
variate Gaussian distributions: x ∼ N (µ, Σ), x ∈ Rd,
i.e., p(x) = (2π)− d
Σ−1 ), can
be computed analytically:

2 (cid:107)x − µ(cid:107)2

2 (det Σ)− 1

2 exp(− 1

E cos(ωT x) = exp(−

(cid:107)ω(cid:107)2

Σ) cos(ωT µ),

E sin(ωT x) = exp(−

(cid:107)ω(cid:107)2

Σ) sin(ωT µ).

1
2
1
2

To prove it, we invoke Euler’s formula to transform the left-
hand-side to complex domain, apply identities involving
quadratic exponentials, and then convert back to real num-
bers (see Appendix §3.2 for details). In Proposition 1, the
expectations depend on the mean and variance of the input
Gaussian distribution. Intuitively, after passing a Gaussian
distributed input through a sinusoidal function, the expec-
tation of the output is equal to passing the mean of the in-
put through the sinusoid, and then scaling it by a constant
exp(− 1
Σ), which depends on the variance of the input.
Expectations are smaller with larger input variance due to
the periodicity of sinusoids.

2 (cid:107)ω(cid:107)2

The exact moments are then derived using Proposition 1.
By the law of total variance, the predictive variance is

Var y = E Var(y|x) + Var E(y|x)

= σ2

n + σ2

n Tr (cid:0)A−1Ψ(cid:1) + αT Ψα − (E y)2,

(9)

Prediction under Uncertainty in Sparse Spectrum Gaussian Processes

where Ψ is deﬁned as the expectation of the outer product
of feature vectors over input distribution p(x). Speciﬁcally,
we compute Ψ by applying the product-to-sum trigonomet-
ric identities:

E (cid:0)φφT (cid:1) = Ψ =

(cid:21)

(cid:20)Ψcc Ψcs
Ψsc Ψss

,

Ψcc

ij =

Ψss

ij =

Ψcs

ij =

σ2
k
2
σ2
k
2
σ2
k
2

(cid:0)E (cid:0)cos(ωi + ωj)T x(cid:1) + E (cid:0)cos(ωi − ωj)T x(cid:1)(cid:1) ,

(cid:0)E (cid:0)cos(ωi − ωj)T x(cid:1) − E (cid:0)cos(ωi + ωj)T x(cid:1)(cid:1) ,

(cid:0)E (cid:0)sin(ωi + ωj)T x(cid:1) − E (cid:0)sin(ωi − ωj)T x(cid:1)(cid:1) ,

where Ψcc, Ψss, Ψcs are m × m matrices, and i, j =
1, . . . , m, on whose terms Proposition 1 can be directly ap-
plied.

Next, we derive the covariance for different output dimen-
sions for multivariate prediction. These correspond to the
off-diagonal entries of the predictive covariance matrix.
We show that, despite the conditional independence as-
sumption for different outputs given a deterministic input,
outputs become coupled with uncertain inputs. Using the
law of total covariance, the covariance is

Cov(ya, yb) = Cov (E(ya|x), E(yb|x))

= E (E(ya|x), E(yb|x))−(E ya)(E yb)
= αT

a Ψabαb − (αT

a E φa)(αT

b E φb),

(10)

where matrix Ψab is the expectation of the outer product
of feature vectors corresponding to different feature maps
φa, φb for outputs ya, yb, computed similarly as in (3.1)
with corresponding random frequencies {ωi}, and the scal-
ing coefﬁcient σk (4). Vectors αa and αb are the corre-
sponding weight vectors for ya and yb (7). Compared to
the expression for the variance of a single output in (9), the
term E (Cov(ya|x) Cov(yb|x)) that is included in the law
of total covariance is neglected due to the assumption of
conditional independence of different outputs (§2), so (10)
does not have the corresponding ﬁrst two terms in (9).

Finally, we compute the cross-covariance between input
and each output dimension. Invoking the law of total co-
variance:

Cov(x, y) = Cov(x, E(y|x))

= E (x E(y|x)) − (E x)(E y)

(11)

= Υα − (E y)µ,

where matrix Υ is the expectation of the outer product of
the input x and the feature vector φ(x) over input distribu-
tion x ∼ N (µ, Σ):

E(xφT ) = Υ = (cid:2)Υc
i = σk E (cid:0)cos(ωT
Υc

. . . Υc
i x)x(cid:1) , Υs

m Υs
1
i = σk E (cid:0)cos(ωT

. . . Υs
m

(cid:3) ,
i x)x(cid:1) ,

1

Kernel
Gaussian
Laplacian

exp(− 1

k(x, x(cid:48))
2 (cid:107)x − x(cid:48)(cid:107)2
exp(−(cid:107)x − x(cid:48)(cid:107)1)
21−ν
Γ(ν) rν Kν (r)

Λ−1 )

p(ω)
N (0, Λ−1)

(cid:81)d

i=1

1
π(1+ωi)
(cid:96)2 + 4π2(cid:107)ω(cid:107)2

h( 2ν

Mat´ern

2)ν+ d
Table 1: Examples of continuous shift-invariant positive-
deﬁnite kernels and their corresponding spectral densities,
where r =
, Kν is a modiﬁed Bessel function,
and h = 2dπ

2ν(cid:107)x−x(cid:48)(cid:107)2
(cid:96)
d
2 Γ(ν+ d
Γ(ν)(cid:96)2ν

2 )(2ν)ν

√

.

2

where i = 1, . . . , m. We state the following proposition
to compute each column in Υ consisting of expectations of
the product sinusoidal functions and inputs.

Proposition 2. The expectation of the multiplication of si-
nusoids and linear functions over multivariate Gaussian
distributions: x ∼ N (µ, Σ), can be computed analytically:

E (cid:0)cos(ωT x)x(cid:1) = (cid:0)E cos(ωT x)(cid:1) µ − (E(sin(ωT x))Σω,
E (cid:0)sin(ωT x)x(cid:1) = (cid:0)E sin(ωT x)(cid:1) µ + (cid:0)E cos(ωT x)(cid:1) Σω,

where the right-hand-side expectations have analytical ex-
pressions (Proposition 1).

To prove it, we ﬁnd an expression for E (cid:0)aT x cos(ωT x)(cid:1),
for any a,
through the complex domain trick used to
prove Proposition 1. Next,
is extended to
E (cid:0)x cos(ωT x)(cid:1), by setting a to consist of indicator vec-
tors (see Appendix §3.3 for details). Applying Proposition
1 and 2, we complete the derivation of Cov(x, y) in (11).

the result

Remark In summary, SSGP-EMM computes the exact
posterior moments. This is equivalent to expectation prop-
agation (Minka, 2001) by minimizing the Kullback-Leibler
divergence between the true distribution and its Gaus-
sian approximation with respect to the natural parameters.
SSGP-EMM’s computation complexity is O (cid:0)m2k2d2(cid:1),
where m is the number of features, k is the output dimen-
sion, and d is the input dimension. The most computation-
ally demanding part is constructing matrices Ψab (10) for
each output pair, where each requires O (cid:0)m2d2(cid:1).

Compared to the multivariate moment-matching approach
for GPs (GP-EMM) (Girard et al., 2003; Kuss, 2006) with
O (cid:0)n2k2d2(cid:1) time complexity, SSGP-EMM is more efﬁ-
cient when m (cid:28) n. Moreover, our approach is applica-
ble to any positive-deﬁnite continuous shift-invariant ker-
nel with different spectral densities (see examples in Table
1), while previous approaches like GP-EMM (Kuss, 2006)
are only derived for squared exponential (SE) or polyno-
mial kernels. Next we introduce a more computationally
efﬁcient but less accurate approach that avoids the compu-
tation of Ψab’s.

Prediction under Uncertainty in Sparse Spectrum Gaussian Processes

3.2. Linearization (SSGP-Lin)

An alternative approach to computing the exact moments
of the predictive distribution is based on the linearization
of the posterior mean function in (7) at the input mean µ:

m(x) = αT φ(x) ≈ m(µ) + αT Dφ(µ)
(cid:124) (cid:123)(cid:122) (cid:125)
M

(x − µ),

(12)

where Dφ(µ) denotes taking the derivative of function φ
at µ. Given the deﬁnition of φ in (4), Dφ can be found
by chain rule: Dφc
i (x) = −σk sin(ωT
i (x) =
σk cos(ωT

i , Dφs

i x)ωT

i x)ωT
i .

Utilizing the linearized posterior mean function (12), the
predictive moments can be approximated. The predictive
mean approximation is

E y = E E(y|x) ≈ m(µ),

(13)

and the predictive variance approximation is
Var y = E Var(y|x) + Var E(y|x)
≈ Var(y|µ) + Var(αT M x)
n(cid:107)φ(µ)(cid:107)2
= σ2

n + σ2

A−1 + αT M ΣM T α.

(14)

and the approximate covariance between output dimension
a and b is

Cov(ya, yb) = Cov (E(ya|x), E(yb|x))

a Ma(x − µ)(x − µ)T M T

b αb

(cid:1)

(15)

= E (cid:0)αT
≈ αT

a MaΣM T

b αb,

where Ma and Mb are deﬁned as M in (12), except that
they correspond to feature maps φa and φb. Notice that the
assumption of conditional independence between different
outputs is invoked here again, cf., (10).

Finally, the cross-covariance between the input and output
can be approximated as

Cov(x, y) = Cov(x, E(y|x))

≈ E (cid:0)(x − µ)(αT M (x − µ))(cid:1)
= αT M Σ

(16)

Unlike SSGP-EMM, which computes exact moments
(§3.1), this linearization-based approach SSGP-Lin com-
putes an approximation of the predictive moments.
In
contrast to SSGP-EMM’s O(cid:0)m2k2d(cid:1) computational com-
plexity, the computation time of SSGP-Lin is reduced to
O(cid:0)m2kd(cid:1), as a direct consequence of avoiding the con-
struction of Ψ (3.1) in SSGP-EMM (10), which makes
SSGP-Lin more efﬁcient
than SSGP-EMM, especially
when the output dimension is high.

Both SSGP-EMM and SSGP-Lin are applicable to a gen-
eral family of kernels. See Table 2 for a comparison be-
tween our methods and GP-EMM (Girard et al., 2003;
Kuss, 2006).
In the next section, we compare these ap-
proaches in applications of ﬁltering and control.

SSGP-Lin

Method
Time
Applicable
kernels

SSGP-EMM
O(m2k2d2) O(m2k + mk2d)
continuous shift-
invariant kernels

GP-EMM
O(n2k2d2)
SE or polyno-
mial kernels
Table 2: Comparison of our proposed methods and GP-
EMM (Girard et al., 2003; Kuss, 2006) in terms of compu-
tational complexity and generalizability.

continuous shift-
invariant kernels

4. Applications

We focus on the application of the proposed methods to
Bayesian ﬁltering and predictive control. We begin by in-
troducing Gauss-Markov models, which can be expressed
by the following discrete-time nonlinear dynamical system:

xt+1 = f (xt, ut) + (cid:15)x
t ,
yt = g(xt) + (cid:15)y
t ,

(cid:15)x
t ∼ N (0, Σ(cid:15)x ),
(cid:15)y
t ∼ N (0, Σ(cid:15)y ),

(17)

(18)

where xt ∈ Rd is state, ut ∈ Rr is control, yt ∈ Rk is
t ∈ Rd is IID process noise,
observation or measurement, (cid:15)x
(cid:15)y
t ∈ Rk is IID measurement noise, and subscript t denotes
discrete time index. We call the probabilistic models (17)
and (18) the dynamics and observation models, and the cor-
responding deterministic functions f and g the dynamics
and observation functions.

t=1

t=1 , {xt, yt}n

We consider scenarios where f and g are unknown but
a dataset D = (cid:0){(xt, ut), xt+1}n−1
(cid:1) is pro-
vided. The probabilistic models speciﬁed by SSGPs can
be learned from the dataset, and then used to model the
dynamics and observation (17) (18). More concretely, the
dynamics model p(xt+1|xt, ut) is learned using state tran-
sition pairs {(xt, ut), xt+1}n−1
t=1 , and the observation model
p(yt|xt) is learned separately from state-observation pairs
{xt, yt}n

t=1.

4.1. Bayesian ﬁltering

The task of Bayesian ﬁltering is to infer the posterior dis-
tribution of the current state of a dynamical system based
on the current and past noisy observations, i.e., ﬁnding
p(xt|t), where the notation xt|s denotes the random vari-
able xt|y0, . . . , ys. Due to the Markov property of the pro-
cess x, i.e., xt|x0, . . . , xt−1 = xt|xt−1, in Gauss-Markov
models, p(xt|t) can be computed recursively through alter-
nating prediction step and correction step.

4.1.1. PREDICTION STEP (xt−1|t−1 → xt|t−1)
In the prediction step, xt−1|t−1 is propagated through the
dynamics model p(xt|xt−1, ut−1):
(cid:90)

p(xt|t−1) =

p(xt|xt−1, ut−1)p(xt−1|t−1) dxt−1,

which can be viewed as prediction under uncertainty
(1). Suppose that p(xt−1|t−1) = N (ˆµt−1|t−1, ˆΣt−1|t−1),
the dynamics,
with learned SSGP representation for
Gaussian approximations of the output: p(xt|t−1) ≈
N (ˆµt|t−1, ˆΣt|t−1) can be obtained by either SSGP-EMM

Prediction under Uncertainty in Sparse Spectrum Gaussian Processes

(§3.1) using (8), (9) and (10), or SSGP-Lin (§3.2) using
(13), (14) and (15).

4.1.2. CORRECTION STEP (xt|t−1 → xt|t)
The correction step conditions xt|t−1 on the current obser-
vation yt using Bayes’ rule:

p(xt|t) =

p(yt|xt|t−1)p(xt|t−1)
(cid:82) p(yt|xt|t−1)p(xt|t−1) dxt

.

(19)

In the preceding prediction step, we obtain p(xt|t−1) ≈
N (ˆµt|t−1, ˆΣt−1|t−1), which serves as a prior on xt in this
correction step. Due to the intractability of the integral in
the denominator, to apply Bayes’ rule we ﬁrst seek Gaus-
sian approximations for the joint distribution, as in the pre-
vious work on Bayesian ﬁltering relying on GPs (Deisen-
roth et al., 2009; Ko & Fox, 2009):

(cid:21)

(cid:20)xt|t−1
yt|t−1

∼ N

(cid:21)

(cid:18)(cid:20)ˆµt|t−1
ˆµy

,

(cid:20) ˆΣt|t−1
ˆΣT
xy

(cid:21)(cid:19)

ˆΣxy
ˆΣy

,

(20)

Invoking p(yt|t−1) = (cid:82) p(yt|xt|t−1)p(xt|t−1) dxt, the mo-
ments ˆµy, ˆΣy, and ˆΣxy in the joint Gaussian approximation
can be computed as the predictive mean, predictive covari-
ance, and input-prediction cross-covariance, for the obser-
vation model p(yt|xt) with input p(xt|t−1), using SSGP-
EMM or SSGP-Lin. Having all terms in (20) determined,
we condition xt|t−1 exactly on current observation yt:

ˆµt|t = ˆµt|t−1 + ˆΣxy ˆΣ−1
ˆΣt|t = ˆΣt|t−1 − ˆΣxy ˆΣ−1
y

y (y − ˆµy),
ˆΣxy.

(21)

This Gaussian approximation p(xt|t) ≈ N (ˆµt|t, ˆΣt|t) is
then used as input to the prediction step. Thus, we have
shown that starting from p(x0) = N (µ0, Σ0), by consec-
utively applying prediction and correction steps presented
above, we recursively obtain state estimates for xt|t−1 and
xt|t. Rather than using a ﬁnite sample-based approximation
such as in the GP-UKF (Ko & Fox, 2009), the Gaussian ap-
proximations of the full densities p(xt|t) and p(xt|t−1) are
propagated.

Algorithm 1 SSGP-ADF and SSGP-EKF
1: Model learning: collect dataset D, and learn SSGP dy-

namics and observations models (§2.)

2: Initialization: set prior p(x0).
3: for t = 1, . . . do
4:

Prediction: compute ˆµt|t−1 and ˆΣt|t−1 . by either
SSGP-EMM (§3.1) or SSGP-Lin (§3.2).
5: Measurement: make an observation yt.
6:

Correction: compute ˆµt|t and ˆΣt|t according to (21)
by either SSGP-EMM (§3.1) or SSGP-Lin (§3.2).

7: end for

We summarize the resulting ﬁltering algorithm SSGP-
ADF (assumed density ﬁltering) and SSGP-EKF (extended
Kalman ﬁltering), based on SSGP-EMM and SSGP-Lin,
respectively, in Algorithm 1. These are analogs of GP-ADF
(Deisenroth et al., 2009) and GP-EKF (Ko & Fox, 2009).

4.2. Stochastic Model Predictive Control

The stochastic model predictive control (MPC) problem is
to choose a control sequence that minimizes the expected
cost, provided p(xt):

u(cid:63)
t+1:t+T = argmin
ut+1:t+T

E (cid:0)h(xt+T ) +

l(xt+i, ut+i)(cid:1),

i+T
(cid:88)

i

at each time step, subject to stochastic system dynamics
(17), where function h : Rd → R and l : Rd × Rr → R
are the ﬁnal and running cost respectively. There are two
main challenges to applying MPC in practice: 1) MPC re-
quires an accurate dynamics model for multi-step predic-
tion, and 2) online optimization is very computationally ex-
pensive. For clarity in presentation, we will assume that the
state is fully observable henceforth.

Algorithm 2 MPC via probabilistic trajectory optimization
(1-3: ofﬂine optimization, 4-8: online optimization)

1: Model learning: collect dataset D, and learn SSGP dy-

namics model (§2).

2: Initialization: set t = 0, and estimate p(x0).
3: Trajectory optimization: perform trajectory optimiza-

tion in belief space, obtain u(cid:63)

t+1:t+T .

4: repeat
5:

Policy execution: apply one-step control u(cid:63)
t+1 to the
system and move one step forward, update t = t+1.
6: Model adaptation: incorporate new data and update

7:

SSGP dynamics model.
Trajectory optimization: perform re-optimization
Initialize with the previ-
with the updated model.
ously optimized trajectory and obtain new u(cid:63)
t+1:t+T .

8: until Task terminated

4.2.1. MPC VIA PROBABILISTIC TRAJECTORY

OPTIMIZATION

We address the aforementioned challenges by employing
a combination of prediction under uncertainty and trajec-
tory optimization. More precisely, we use SSGP-EMM or
SSGP-Lin to efﬁciently obtain approximate Gaussian dis-
tribution over trajectory of states and perform trajectory op-
timization in the resultant Gaussian belief space based on
differential dynamic programming (DDP) (Abbeel et al.,
2007; Tassa et al., 2007). Note that DDP-related methods
require computation of ﬁrst and second order derivatives of
the dynamics and cost. Our analytic moment expressions
provide a robust and efﬁcient way to compute these deriva-
tives. Details are omitted due to space limit, but they can
be found in Appendix §4.

Within the SSGP framework, we may incrementally up-
date the posterior distribution over the feature weights w
(6) given a new sample without storing or inverting the
matrix A explicitly, Instead we keep track of its upper tri-
angular Cholesky factor A = RT R (Gijsberts & Metta,
2013). Given a new sample, a rank-1 update is applied to

Prediction under Uncertainty in Sparse Spectrum Gaussian Processes

Method
N Lx
RM SE

SSGP-ADF
2.5003
4.6822

SSGP-EKF GP-ADF
2.489385
3.415467
4.6854
5.1451

GP-EKF
3.396343
5.1012

Table 3: Comparison of our methods with GP-ADF
(Deisenroth et al., 2009) and GP-EKF (Ko & Fox, 2009)
in terms of average N Lx (negative log-likelihood) of the
ground truth states given estimates and RMSE (root-mean-
square error). Lower values are better. The results corre-
spond to the ﬁltering task in sec 5.1.1.

the Cholesky factor R, which requires O(m2) time. To
cope with time-varying systems and to make the method
more adaptive, we employ a forgetting factor λ ∈ (0, 1),
such that the impact of the previous samples decays expo-
nentially in time (Ljung, 1998).

Our proposed MPC algorithm, summarized in Algorithm
2, is related to several algorithms and differs in both model
and controller learning. First, SSGPs are more robust to
modeling error than Locally Weighted Projection Regres-
sion (LWPR) used in iLQG-LD (Mitrovic et al., 2010). See
a numerical comparison in (Gijsberts & Metta, 2013). Sec-
ond, we efﬁciently propagate uncertainty in multi-step pre-
diction which is crucial in MPC. In contrast, AGP-iLQR
(Boedecker et al., 2014) drops the input uncertainty and
uses subset of regressors (SoR-GP) which lacks a princi-
pled way to select reference points. In addition, PDDP (Pan
& Theodorou, 2014) uses GPs which are computationally
expensive for online optimization. Two deep neural net-
works are used for modeling in (Yamaguchi & Atkeson,
2016), which make it difﬁcult to perform online incremen-
tal learning, as we do here.

5. Experimental Results
5.1. Bayesian ﬁltering
5.1.1. 1D ONE-STEP FILTERING
We consider a synthetic dynamical system with ground-
2 x + 25x
truth dynamics f (x) = 1
1+x2 and observation g(x) =
6 sin(2x) with Σ(cid:15)x = 1.52 and Σ(cid:15)y = 1 in (17,18), in a
similar setting to Deisenroth et al. (2009). We compare the
performance of four ﬁlters, SSGP-ADF, SSGP-EKF, GP-
ADF (Deisenroth et al., 2009) and GP-EKF (Ko & Fox,
2009). All models are trained using 800 samples. How-
ever, for SSGP models, only 10 random Fourier features
of a SE kernel are used. Figure 1 illustrates the compar-
ison of ﬁltered state distribution of a typical realization.
We evaluate the methods by computing N Lx (the negative
log-likelihood of the ground truth samples in the ﬁltered
distribution) and RMSE (root-mean-square error between
ﬁltered mean and ground truth samples). See Table 3 for a
detailed comparison. Our methods SSGP-ADF and SSGP-
EKF are able to offer close performance with their full GP
counterparts but with greatly reduced computational cost.
See Appendix §6.2 for further discussions on the compari-
son between SSGP-ADF and SSGP-EKF.

5.1.2. RECURSIVE FILTERING
We next consider a state estimation task in high-speed au-
tonomous driving on a dirt track (Figure 2a). The goal is
to recursively estimate the state of an autonomous rallycar
given noisy measurements. The vehicle state consists of
linear velocities (x and y), heading rate, and roll angle, in
body frame. Controls are steering and throttle. Measure-
ments are collected by wheel speed sensors. This ﬁltering
task is challenging because of the complex nonlinear dy-
namics and the amount of noise in the measurements. We
do not use any prior model of the car, but learn the model
from ground truth estimates of vehicle state generated by
integrating GPS and IMU data via iSAM2 (Kaess et al.,
2012). 50,000 samples are collected from wheel speed sen-
sors and ground truth state estimates from iSAM2 for train-
ing. Because of the sample size, it is too computationally
expensive to use GP-based ﬁlter such as GP-ADF (Deisen-
roth et al., 2009). Instead, we use SSGP-ADF to perform
1,200 recursive ﬁltering steps which correspond to 30 sec-
onds of high-speed driving. Filtered distributions using 80
features are shown in Figure 2b, and Figure 2c shows the
mean and twice the standard deviation of N Lx over six 30
seconds driving with different number of features. Surpris-
ingly, only need a small number of features is necessary for
satisfactory results.

5.2. Model Predictive Control

5.2.1. TRACKING A MOVING TARGET

We consider the Puma-560 robotic arm and quadrotor sys-
tems with dynamics model speciﬁed by SSGPs. For both
tasks the goal is to track a moving target. In addition, the
true system dynamics vary online, which necessitates both
online optimization and model update, as we do here. See
Appendix §5.2 for detailed task descriptions. Results in
terms of cost l(xt, ut) are shown in Figure 4. Figure 4a
shows that our methods outperform iLQG-LD (Mitrovic
et al., 2010) and AGP-iLQR (Boedecker et al., 2014). The
similarities and differences between these methods have
been discussed in §4.2. Figure 4b shows that model update
is necessary and more features could improve performance.

5.2.2. AUTONOMOUS DRIFTING

We study the control of an autonomous car during extreme
operating conditions (powerslide). The task is to stabilize
the vehicle to a speciﬁed steady-state using purely longi-
tudinal control during high-speed cornering. This problem
has been studied in Velenis et al. (2010) where the authors
developed a LQR control scheme based on a physics-based
dynamics model. We apply our MPC algorithm to this task
without any prior model knowledge and 2,500 data points
generated by the model in Velenis et al. (2010). SSGP-Lin
is used for multi-step prediction. Results and comparison
to Velenis et al. (2010) are illustrated in Figure 3.

Prediction under Uncertainty in Sparse Spectrum Gaussian Processes

(a) GP-ADF (800 data points)

(b) SSGP-ADF (10 features)

(c) GP-EKF (800 data points)

(d) SSGP-EKF (10 features)

Figure 1: Black points are ground truth states, red areas are ﬁlter distributions for (a) GP-ADF (Deisenroth et al., 2009),
(c) GP-EKF (Ko & Fox, 2009), our proposed methods (b) SSGP-ADF and (d) SSGP-EKF. The x-axis is the mean of initial
belief p(x0), which is randomly distributed in [−10, 10] and y-axis shows the mean and twice the standard deviation of
ﬁltered distribution p(x1|y1) after observing y1.

(a) Autonomous driving task

(b) Filtered distribution vs. ground truth

(c) N Lx vs. # of features

Figure 2: Recursive ﬁltering task for high-speed autonomous driving. Figure (b) shows trajectories of all the states of a 30
seconds continuous driving (1,200 steps), where blue lines are the ground truth, and red lines and red areas are the mean
and twice the standard deviation of the ﬁltered distributions respectively. In (c), the red line and area are the mean and
twice the standard deviation of N Lx over six 30 seconds driving with varying number of features.

6. Discussion and Conclusion
We introduced two analytic moment-based approaches to
prediction under uncertainty in sparse spectrum Gaussian
processes (SSGPs). Compared to their full GP counter-
parts, our methods are more general: they are applicable
to any continuous shift-invariant kernel. They also scale
to larger datasets by leveraging random features with fre-
quencies sampled from the spectral density of a given ker-
nel (see Table 1, 2). Although we adopt the name SSGP,
our proposed methods are not tied to speciﬁc model learn-
ing methods such as linear Bayesian regression (L´azaro-
Gredilla et al., 2010). They can be applied to any SSGP
with a speciﬁed feature weight distribution (6), and α and
A can be computed via different approaches. For exam-
ple, A can be iteratively computed by methods like doubly
stochastic gradient descent (Dai et al., 2014). We studied
the application of the proposed methods to Bayesian ﬁl-
tering and model predictive control. Our methods directly
address the challenging aspects of these problems: model
uncertainty and real-time execution constraints. We evalu-
ated our algorithms on real-world and simulated examples
and showed that SSGP-EMM (§3.1) and SSGP-Lin (§3.2)
are accurate alternatives to their full GP counterparts when
learning from large amounts of data.

Acknowledgements
This work was supported by NSF NRI awards 1637758 and
1426945.

Figure 3: Comparison of the drifting performance using 50
(left), 150 (middle) and 400 (right) random features. Blue
lines are the solution provided in Velenis et al. (2010). Per-
formance improves with a larger number of features, and
with a moderate number of features, MPC with SSGP-Lin
behaves very closely to the ground truth solution.

(a) Robotic arm task cost

(b) Quadrotor task cost

Figure 4: Cost comparison for arm and quadrotor tasks.

-10-50510-30-20-100102030GP-ADF-10-50510-30-20-100102030SSGP-ADF-10-50510-30-20-100102030GP-EKF-10-50510-30-20-100102030SSGP-EKF-20-15-10-505-10-50510Start-20-15-10-505-10-50510Start01002003004005006789V0100200300400500-60-50-40-3001002003004005000.511.52V/R-20-15-10-505-10-50510Start01002003004005006789V0100200300400500-60-50-40-3001002003004005000.511.52V/Rββ01002003004005006789V0100200300400500-60-50-40-3001002003004005000.511.52V/Rβ100200300400500600700800Time step100101102103104CostOur method (SSGP-EMM)Our method (SSGP-Lin)iLQG-LD (LWPR)AGP-iLQR (SoR-GP)100200300400Time step510152025CostWith model adaptation (400 feat)With model adaptation (100 feat)Without model adaptation (100 feat)RH-DDP with known modelPrediction under Uncertainty in Sparse Spectrum Gaussian Processes

References

Abbeel, P., Coates, A., Quigley, M., and Ng, A. Y. An application
of reinforcement learning to aerobatic helicopter ﬂight. NIPS,
19:1, 2007.

Archambeau, Cedric, Cornford, Dan, Opper, Manfred, and
Shawe-Taylor, John. Gaussian process approximations of
stochastic differential equations. Gaussian Processes in Prac-
tice, 1:1–16, 2007.

Kuss, Malte. Gaussian process models for robust regression, clas-
siﬁcation, and reinforcement learning. PhD thesis, Technische
Universit¨at, 2006.

L´azaro-Gredilla, M., Qui˜nonero-Candela, J., Rasmussen, C. E.,
and Figueiras-Vidal, A. R. Sparse spectrum Gaussian process
regression. The Journal of Machine Learning Research, 99:
1865–1881, 2010.

Ljung, Lennart. System identiﬁcation. Springer, 1998.

Boedecker, J., Springenberg, JT., Wulﬁng, J., and Riedmiller, M.
Approximate real-time optimal control based on sparse Gaus-
sian process models. In ADPRL 2014, pp. 1–8. IEEE, 2014.

Minka, Thomas P. A family of algorithms for approximate
Bayesian inference. PhD thesis, Massachusetts Institute of
Technology, 2001.

Candela, J. Quinonero, Girard, A., Larsen, J., and Rasmussen,
C. E. Propagation of uncertainty in Bayesian kernel models-
application to multiple-step ahead forecasting. In IEEE Inter-
national Conference on Acoustics, Speech, and Signal Process-
ing. IEEE, 2003.

Incremental variational
Cheng, Ching-An and Boots, Byron.
In Proceedings of Ad-
sparse Gaussian process regression.
vances in Neural Information Processing Systems 30 (NIPS),
2016.

Dai, Bo, Xie, Bo, He, Niao, Liang, Yingyu, Raj, Anant, Balcan,
Maria-Florina F, and Song, Le. Scalable kernel methods via
doubly stochastic gradients. In Advances in Neural Informa-
tion Processing Systems, pp. 3041–3049, 2014.

Deisenroth, M., Fox, D., and Rasmussen, C. Gaussian processes
for data-efﬁcient learning in robotics and control. IEEE Transs-
actions on Pattern Analysis and Machine Intelligence, 27:75–
90, 2015.

Deisenroth, Marc Peter, Huber, Marco F, and Hanebeck, Uwe D.
In Pro-
Analytic moment-based Gaussian process ﬁltering.
ceedings of the 26th annual international conference on ma-
chine learning, pp. 225–232. ACM, 2009.

Deisenroth, Marc Peter, Turner, Ryan Darby, Huber, Marco F,
Hanebeck, Uwe D, and Rasmussen, Carl Edward. Robust ﬁl-
tering and smoothing with Gaussian processes. IEEE Transac-
tions on Automatic Control, 57(7):1865–1871, 2012.

Gijsberts, A. and Metta, G. Real-time model learning using incre-
mental sparse spectrum Gaussian process regression. Neural
Networks, 41:59–69, 2013.

Girard, A., Rasmussen, C.E., Quinonero-Candela, J., and Murray-
Smith, R. Gaussian process priors with uncertain inputs appli-
cation to multiple-step ahead time series forecasting. In NIPS,
2003.

Kaess, Michael, Johannsson, Hordur, Roberts, Richard, Ila,
Viorela, Leonard, John J, and Dellaert, Frank.
isam2: Incre-
mental smoothing and mapping using the bayes tree. The Inter-
national Journal of Robotics Research, 31(2):216–235, 2012.

Ko, J. and Fox, D. Gp-bayesﬁlters: Bayesian ﬁltering using gaus-
sian process prediction and observation models. Autonomous
Robots, 27(1):75–90, 2009.

Kupcsik, A., Deisenroth, M.P., Peters, J., Loh, AP, Vadakkepat,
P., and Neumann, G. Model-based contextual policy search for
data-efﬁcient generalization of robot skills. Artiﬁcial Intelli-
gence, 2014.

Mitrovic, D., Klanke, S., and Vijayakumar, S. Adaptive optimal
feedback control with learned internal dynamics models.
In
From Motor Learning to Interaction Learning in Robots, pp.
65–84. Springer, 2010.

Pan, Y. and Theodorou, E. Probabilistic differential dynamic pro-
gramming. In Advances in Neural Information Processing Sys-
tems (NIPS), pp. 1907–1915, 2014.

Pan, Yunpeng, Theodorou, Evangelos, and Kontitsis, Michail.
Sample efﬁcient path integral control under uncertainty. In Ad-
vances in Neural Information Processing Systems, pp. 2314–
2322, 2015.

Rahimi, A. and Recht, B. Random features for large-scale ker-
nel machines. In Advances in neural information processing
systems, pp. 1177–1184, 2007.

Rasmussen, C. and Kuss, M. Gaussian processes in reinforcement

learning. In NIPS, volume 4, pp. 1, 2004.

Snelson, E. and Ghahramani, Z. Sparse Gaussian processes using

pseudo-inputs. NIPS, 18:1257, 2006.

Tassa, Y., Erez, T., and Smart, W. D. Receding horizon differential

dynamic programming. In NIPS, 2007.

Titsias, Michalis K. Variational learning of inducing variables in
In AISTATS, volume 5, pp. 567–

sparse gaussian processes.
574, 2009.

Velenis, E., Frazzoli, E., and Tsiotras, P. Steady-state cornering
equilibria and stabilisation for a vehicle during extreme oper-
ating conditions. International Journal of Vehicle Autonomous
Systems, 8(2-4):217–241, 2010.

Williams, C.K.I and Rasmussen, C.E. Gaussian processes for

machine learning. MIT Press, 2006.

Yamaguchi, Akihiko and Atkeson, Christopher G. Neural net-
works and differential dynamic programming for reinforce-
In 2016 IEEE International Con-
ment learning problems.
ference on Robotics and Automation (ICRA), pp. 5434–5441.
IEEE, 2016.

Yan, Xinyan, Xie, Bo, Song, Le, and Boots, Byron. Large-scale
Gaussian process regression via doubly stochastic gradient de-
scent. The ICML Workshop on Large-Scale Kernel Learning,
2015.

