Strongly-Typed Agents are Guaranteed to Interact Safely

David Balduzzi 1

Abstract

As artiﬁcial agents proliferate, it is becoming in-
creasingly important to ensure that their interac-
tions with one another are well-behaved. In this
paper, we formalize a common-sense notion of
when algorithms are well-behaved: an algorithm
is safe if it does no harm. Motivated by recent
progress in deep learning, we focus on the spe-
ciﬁc case where agents update their actions ac-
cording to gradient descent. The paper shows
that that gradient descent converges to a Nash
equilibrium in safe games. The main contribu-
tion is to deﬁne strongly-typed agents and show
they are guaranteed to interact safely, thereby
providing sufﬁcient conditions to guarantee safe
interactions. A series of examples show that
strong-typing generalizes certain key features of
convexity, is closely related to blind source sepa-
ration, and introduces a new perspective on clas-
sical multilinear games based on tensor decom-
position.

1. Introduction

“First, do no harm”

Recent years have seen rapid progress on core problems
in artiﬁcial intelligence such as object and voice recog-
nition (Hinton & et al, 2012; Krizhevsky et al., 2012),
playing video and board games (Mnih et al., 2015; Sil-
ver et al., 2016), and driving autonomous vehicles (Zhang
et al., 2016). As artiﬁcial agents proliferate, it is increas-
ingly important to ensure their interactions with one an-
other, with humans, and with their environment are safe.

Concretely, the number of neural networks being trained
and used is growing rapidly. There are enormous and in-
creasing economies of scale that can likely be derived from
treating them as populations – rather than as isolated algo-
rithms. How to ensure interacting neural networks cooper-
ate effectively? When can weights trained on one problem

1Victoria University of Wellington, New Zealand. Correspon-

dence to: David Balduzzi <dbalduzzi@gmail.com>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

be adapted to another without adverse effects? The prob-
lems fall under mechanism design, a branch of game theory
(Nisan et al., 2007). However, neural nets differ from hu-
mans in that they optimize clear objectives using gradient
descent. The setting is thus more structured than traditional
mechanism design.

Safety. The ﬁrst contribution of the paper is formalize
safety as a criterion on how agents interact. We propose
a basic notion of safety based on the common-sense prin-
ciple that agents should do no harm to one another. More
formally, each agent optimizes an objective whose value
depends on the actions of the agent and the actions of the
rest of the population. A game is safe if the actions chosen
by each agent do no (inﬁnitesimal) harm to any other agent,
where harm is measured as increased loss.

The key simplifying assumption in the paper is to take gra-
dient descent as a computational primitive (Balduzzi,
2016). Questions about mechanism design are sharp-
ened under the assumption that agents use gradient de-
scent. The assumption holds broadly since the key driver
of progress in artiﬁcial intelligence is deep learning, which
uses gradient descent to optimize complicated objective
functions composed from simple differentiable modules
(LeCun et al., 2015).

A weakness of the approach is that it conceives safety more
narrowly than, for example, Amodei et al. (2016) which is
concerned with societal risks arising from artiﬁcial intelli-
gence. We argue that a necessary foundational component
of the broader AI-safety project is to clarify exactly what
safety entails when the objectives of the agents and the al-
gorithms they employ are precisely speciﬁed.

Strongly-typed games. The second contribution is to in-
troduce type systems suited to multi-agent optimization
problems (that is, games). We build on the typed linear
algebra introduced in Balduzzi & Ghifary (2016). The
nomenclature is motivated by an analogy with types in the
theory of programming. Type systems are used to prevent
untrapped errors (errors that go unnoticed and cause arbi-
trary behavior later on) when running a program (Cardelli,
1997). A program is safe if it does not cause untrapped er-
rors. Type systems can enforce safety by statically rejecting
all programs that are potentially unsafe.

Strongly-Typed Agents are Guaranteed to Interact Safely

The idea underlying types in programming is that “like
should interact with like”. Typed linear algebra, deﬁni-
tion 1, formalizes “like interacts with like” in the simplest
possible way – by ﬁxing an orthogonal basis. Section 2 in-
troduces a wider class of games than in the literature and
deﬁnes safety. Theorem 1 shows that gradient descent con-
verges to a Nash equilibrium in safe games. Section 3 ex-
tracts the key ingredients required for safe gradients from
two warmup examples. The ingredients are simultaneous
diagonalization, i.e.
the existence of a shared latent or-
thogonal basis, and monotonic covariation, i.e.
that the
derivatives of the objectives have the same sign in the la-
tent coordinate system. The main result, theorem 2, is that
strongly-typed games are guaranteed to be safe.

Implications. Safety and strong-typing generalize key
properties of convexity. Convexity is of course the gold
standard for well-behaved gradients. We uncover latent
types and demonstrate safety of Newton’s method, natural
gradient and mirror descent; see sections 3.2, A2 and A3.

The main theme of sections 4 and 5 is disentangling latent
factors. We show that strong-typing in quadratic games is
closely related to blind source separation. Section 5 ana-
lyzes classical N -player games. The analysis yields a new
perspective on classical games based on tensor-SVD that is
closely related to independent component analysis.

Sections 6 and A6 switch to neural networks and ana-
lyze two biologically plausible variants of backpropagation
(Balduzzi et al., 2015; Lillicrap et al., 2016). We show that
the main results of the papers are to prove the respective
algorithms are safe.

Scope and related work. This paper lays the foundations
of safety in gradient-based optimization. Applications are
deferred to future work.

The literature on safety is mostly focused on problems aris-
ing in reinforcement learning, for example ensuring agents
avoid dangerous outcomes (Turchetta et al., 2016; Amodei
et al., 2016; Berkenkamp et al., 2016). Gradients are typi-
cally not available in reinforcement learning problems. We
study interactions between algorithms with clearly deﬁned
objectives that utilize gradient-based optimization, which
gives a more technical perspective.

The idea of a population of neural networks solving mul-
tiple related tasks is developed in Fernando et al. (2017),
which uses genetic algorithms to adapt components to new
tasks. However, they repeatedly reinitialize components to
undo the damage done by the genetic algorithm. Our work
is intended, ultimately, to help design algorithms that detect
and avoid damaging updates. A recent survey paper argues
the brain optimizes a family of complementary loss func-
tions (Marblestone et al., 2016) without considering how

the complementarity of the loss functions could be checked
or enforced.

The idea of investigating game-theoretic and mechanism
design questions speciﬁc to certain classes of algorithms is
introduced in Rakhlin & Sridharan (2013); Syrgkanis et al.
(2015). The papers consider how convergence in games can
be accelerated if the players use variants of mirror descent.

If ↵

0 then ↵ is positive; if ↵> 0 then it
Terminology.
is strictly positive. A (not necessarily square) matrix D is
= j and similarly for tensors.
diagonal if dij = 0 for all i
= v|w.
Vectors are columns. The inner product is

v, w

 

h

i

2. Safety

2.1. Types and orthogonal projections

Let us recall some basic facts about orthogonal projections.
Let (V,
) be a vector space equipped with an inner
product. An orthogonal projection is a linear transform
⇡ : V

V that is

h•

•i

,

!

O1. idempotent, ⇡2 = ⇡, and

V .

O2. self-adjoint,

⇡v, v0

=

v, ⇡v0

for any v, v0

i

h

h
Lemma 1. Let P denote an (n
nal columns p1, . . . , pk. Then the (n
=

k
i=1 pip|

pi,

k

⇥

k)-matrix with orthogo-
n)-matrix PP| =
i is an (orthogonal) projec-

⇥

2

i

tion.
P
Lemma 2. If two orthogonal projections ⇡ and ⌧ commute
then their product is an orthogonal projection.

P

i=1 pih

•i

Proof. Let q := ⇡⌧ . If ⇡⌧ = ⌧ ⇡ then

q2 = ⇡⌧

⇡⌧ = ⇡⇡

⌧ ⌧ = ⇡⌧ = q.

·

·

Checking self-adjointness is an exercise.

,

V,

is a D-
TV =
Deﬁnition 1. A type
dimensional vector space with an inner product and or-
 
V such that ⇡r⇡s = 0
thogonal projections ⇡r : V
for r
TV has
dimension D and rank R.

R
r=1 ⇡r = IV is the identity. Type

⇡r}
{

= s and

!

h•

•i

 

,

R
r=1

P

A full rank type, D = R, is equivalent to a vector space
equipped with an orthogonal basis. Lower rank types are
less rigid, and can be thought of as vector spaces equipped
with generalized orthogonal coordinates.

2.2. Safe games

Deﬁnition 2. A game consists of a type

V , players [N ] :=

H⇢
{
and an assignment ⇢ : [N ]

1, . . . , N

TV , feasible set
R,
H!
[R] of players to projections.

, losses `n :
}

!

6
6
Strongly-Typed Agents are Guaranteed to Interact Safely

The type structure and assignments specify the coordinates
controlled by each player. On round t, player n chooses
⇠t
n 2

V and updates the joint action via

wt+1 = wt

⇡⇢(n)(⇠t

n) where wt, wt+1

 

.

2H

Updates leaving the feasible set can be mapped back into
it, see section A1. The projection ⇡⇢(n) speciﬁes the coor-
dinates of the joint-action vector that player n can modify.
N
n=1 RDn
Example 1. In a block game actions w
decompose as w = (w1, . . . , wN ) where the nth player
can modify the coordinates in wn. The orthogonal pro-
jections ⇡n(w) = (0, . . . , wn, . . . , 0) form a rank-N type
[N ].
with ⇢(n) = n for all n
2
Example 2. In an open game the type has rank(
TV ) = 1
so the single projection is the identity and ⇢(n) = 1 for all
n. Every player can modify all the coordinates.

V =

Q

2

Block games coincide with the standard deﬁnition of a
game in the literature. Open games arise below when con-
sidering Newton’s method, natural gradients, mirror de-
scent and neural networks.

The goal of each player is to minimize its loss. Safety is the
condition that no player’s updates harm any other player.
Deﬁnition 3. It is safe for player m to choose ⇠t
it does no inﬁnitesimal harm to any player

m 2

V if

 

↵

⇡⇢(m)(⇠t

m),

`n(wt)

r

0 for all n

[N ].

2

⌦

m :=

A game is safe if it is safe for players to use gradient de-
scent: i.e. if choosing ⇠t

`m(wt) is safe for all m.

r
It is worth getting a degenerate case out of the way. A block
game is decomposable if player m’s loss only depends on
the actions it controls. Intuitively, a decomposable game is
N independent optimization problems. More formally:
Lemma 3. A block game is decomposable if `m(w) =
`m(⇡mw) for all w and m. Decomposable games are safe.

Proof. Since ⇡m is self-adjoint, we have that
h
. Decomposability implies ⇡m(
⇡m⇠, ⇡m⌘
h
r
when m

i
= n, so

⇡m⇠, ⌘

=
`n) = 0

i

⇡m(
k
0

r

(

`m)

2
2
k

if m = n
else

⇡m(

`m), ⇡m(

`n)

=

r

r

⌦
↵
which is always positive.

2.3. Convergence

is compact
A block game is convex if the feasible set
and convex and the losses `n :
R are convex in
the coordinates controlled by the respective players. Nash
equilibria are guaranteed to exist in convex block games
(Nash, 1950). However, ﬁnding them is often intractable

H!

H

(Daskalakis et al., 2009). We show gradient descent con-
verges to a Nash equilibrium in safe convex games.

Theorem 1. Gradient descent converges to a Nash equi-
librium in safe convex games with smooth losses.

Proof. Introduce potential function  (w) =
`n(w) where ↵n > 0 are strictly positive. Then

N

n=1 ↵n ·

P

N

⇡m(

 ),

h

r

`mi

r

=

↵n

⇡m(

`n),

`m

(1)

r

r

k

 

r

`m)

E
0

2
2  

D
⇡m(

n=1
X
↵m ·k
since safety implies the cross-terms are nonnegative. The
players’ updates therefore converge to either a critical point
of   or to the boundary of the feasible set. Suppose gradi-
ent descent converges to the interior of
. Eq (1) implies
`m) = 0 for all m. By convex-
that if
ity of the losses, the critical point is a minimizer of each
loss with respect to that player’s actions, implying it is a
Nash equilibrium. A similar argument holds if gradient de-
scent converges to the boundary, see section A1.

 = 0 then ⇡m(

H

r

r

Example 3 (convergence in a safe constrained game). Con-
sider a two-player block game with `1(x, y) = x + 2y and
`2(x, y) = 2x + y where player-1 controls x and player-
R2 :
2 controls y. Introduce feasible set
H
x2 + y2
1
. The game is convex and safe. The set of
}
Nash equilibria is the bottom-left quadrant of the bound-
: x, y
. Gradient
ary
descent with positive combinations of ⇡1(
@x and
⇡2(

@y always converges to a Nash equilibrium.

0 and x2 + y2 = 1
}

(x, y)
{

`1) = @

`2) = @

(x, y)

2H

r



=



2

{

r

A simple game that does not converge is the following zero-
sum game, which is related to generative adversarial net-
works (Goodfellow, 2017).
Example 4 (convergence requires positivity). Consider the
two-player block game `1(x, y) = xy and `2(x, y) =
xy
where player-1 controls x and player-2 controls y. The
Nash equilibrium is the origin (x, y) = (0, 0). However,
`1 =
gradient descent does not converge. Observe that
r
`1) = y @
y @
@x + x @
@x
and ⇡2(
`2)
rotates around the origin. No positive combination of
⇡1(

@x  
@y . The ﬂow ⇡1(

`2) converges to the origin.

@y and
`2) =

`1) and ⇡2(

@y so ⇡1(

`2 =
x @

`1) + ⇡2(

x @

y @

r

r

r

r

r

 

 

 

r

r

3. Strongly-Typed Games

Strong-typing is based two key ideas: diagonalization and
positivity. Diagonalization is an important tool in applied
mathematics. The Fourier transform simultaneously diag-
onalizes differentiation and convolution:

df
dx

F

⇣

⌘

= 2⇡i!

(f )

and

(f

g) =

(f )

(g)

F

⇤

F

· F

F

6
Strongly-Typed Agents are Guaranteed to Interact Safely

The SVD diagonalizes any matrix: Q|MP = D. Finally,
the Legendre transform f ⇤(⌘) = max✓{
di-
agonalizes the inﬁmal convolution

f (✓)

⌘|✓

 

}

We therefore restrict to when A|B and BA| are symmet-
ric. Recalling (2), we further suppose that A and B are
simultaneously diagonalizable and obtain:

(f ⇤g)⇤ = f ⇤+g⇤ for (f ⇤g)(✓) = min
# {

f (#)+g(✓

#)

.

 

}

Diagonalization ﬁnds a latent orthogonal basis that is more
mathematically amenable than the naturally occurring co-
ordinate system. Strong-typing is based on an extension of
diagonalization to nonlinear functions. Before diving in,
we recall the basics of simultaneous diagonalization.

Symmetric matrices. Any symmetric matrix A factor-
izes as A = P|DP where P is orthogonal and D is di-
agonal. A collection A1, . . . , AN of symmetric matrices
is simultaneously diagonalizable iff the matrices commute,
in which case Ai = P|DiP where Di is diagonal and P
determines a common latent coordinate system (or type).

m) and (n

Arbitrary matrices. The diagonalization of an (m
n)-
matrix A is A = PDQ| where P and Q are orthogonal
n) matrices and D is positive diagonal.
(m
A collection of matrices is simultaneously diagonalizable
if Ai = PDiQ| for all i. A necessary condition for simul-
taneous diagonalizability is that

⇥

⇥

⇥

A|

i Aj and AiA|

j are symmetric for all i, j.

(2)

Next, we work through two examples where diagonaliza-
tion and a positivity condition imply safety.

3.1. Warmup: When are two-player games safe?

To orient the reader, we consider a minimal example which
illustrates most of the main ideas of the paper: two-player
bilinear games (von Neumann & Morgenstern, 1944). Con-
sider a two-player block game with loss functions

`1(v, w) = v|Aw and

`2(v, w) = v|Bw

and projections ⇡1/2(v, w) = (v, 0) and (0, w). The
) =
gradients are
`2 = (w|B|, v|B). The game is
(w|A|, v|A) and
safe if

ij(wjAij

+ viAij

`1 =

@
@wj

@
@vi

P

r

r

h

⇡1(

`1),
r
`1, ⇡2(

hr

r

`2i
`2)
i

r

= w|A|Bw

0

= v|BA|v

 
0

 

and
for all v and w.

Safety requires that A|B and BA| are positive semidef-
inite. Any square matrix decomposes into symmetric and
antisymmetric components M = Ms + Ma = 1
2 (M +
M|) + 1
M|) where w|Maw = 0 for all w. Thus,
a square matrix is positive semideﬁnite iff its symmetric
component is positive semideﬁnite.

2 (M

 

Lemma 4. A two-player game is safe if A = PDQ| and
B = PEQ| where P and Q are orthogonal matrices, D
and E are diagonal, and DE

0.

 

Proof. The assumptions imply that

⇡1 r

h

and

hr

`1,

`2i
r
`1, ⇡2 r

`2i

= w|A|Bw = w|Q(D|E)Q|w

0

 

= w|P(E|D)P|w

0.

 

3.2. Warmup: When is Newton’s method safe?

It was observed in Dauphin et al. (2014) that applying New-
ton’s method to neural networks is problematic because it
is attracted to saddle points and can increase the loss on
nonconvex problems. We reformulate their observation in
the language of safety.

Consider a single player open game with twice differen-
R and projection ⇡ = IV . Newton’s
tiable loss ` : V
!
method optimizes ` via weight updates

wt+1 = wt

⇠t with ⇠t = ⌘t

H 

1(wt)

`(wt),

 

·

·r

where Hij(w) = @2`
Lemma 5. If ` is strictly convex then Newton’s method is
safe, i.e.

(w) is the Hessian and ⌘t > 0.

0 for all w.

@wi@wj

H 

`,

`

1

h

r

r

i  

Proof. Factorize the Hessian at wt as H = PDP|. If ` is
strictly convex then D > 0 and so

1

H 

h

`,

`

i

r

r

h

=

D 

1P|

`, P|

`

0

r

i  

r

as required.

Two features are noteworthy: (i) the transform ⌘ = P|⇠
diagonalizes the second-order Taylor expansion of `,

compare `(w + ⇠) = `(w) + ⇠|

` +

⇠|H⇠

with `(w + P⌘) = `(w) + ⌘|(P|

`) +

⌘|D⌘,

1
2

·r

1
2

r

and (ii) the proof hinges on the positivity of D. Sections A2
and A3 extend the approach to show the natural gradient
(Amari, 1998) and mirror descent (Raskutti & Mukherjee,
2015) are safe using the Legendre transform.

3.3. Strongly-typed games are safe

We apply the lessons from the warmups to deﬁne a factor-
ization of nonlinear functions.

Strongly-Typed Agents are Guaranteed to Interact Safely

Deﬁnition 4. The functions
ously factorize if there is a triple

`n : V
{

R

N
n=1 simultane-
}

!

Pl}
{
satisfying

⇣

L
l=1,

pl

fl : R
{

R

L
l=1,
}

gn : R
{

L

R

N
n=1
}

!

!

,

⌘

`n(w) = gn

f1(P|

1 w), . . . , fL(P|

Lw)

for all n

⇣
pl)-matrices whose columns jointly form
where Pl are (D
an orthogonal basis of V and fl and gn are differentiable,
and the gn’s co-vary monotonically: @gm
@fl

⇥

0.

⌘

@gn
@fl  

The projections ⌧l = PlP|
l deﬁne a type structure on V .
Intuitively, the outputs zl = fl(P|
l w) are latent factors
computed from the inputs w such that each zl is indepen-
dent of the others – independence is enforced by the pro-
jections ⌧l. Monotonic covariation of the functions gn with
respect to the factors zl plays the same role as positivity in
two-player games and Newton’s method.
N
Deﬁnition 5. Game (
n=1) is strongly-typed if the
`n}
TV ,
{
loss functions admit a simultaneous factorization whose
L
⌧ l = PlP|
l=1 commute with
projections
l }
{
Theorem 2. Strongly-typed games are safe.

⇡n}

N
n=1.

{

D
i=1 for
⇡n}
{
. Express elements of V as (v1, . . . , vD) in the

ei}
Proof. Commutativity implies there is a basis
V that simultaneously diagonalizes the projections
and
basis. Safety then reduces to showing

⌧ l}
{

{

⇡m(

`m),

h

r

`ni

r

=

i:⇡m(ei)
X{

=0

}

@gm
@vi

@gn
@vi  

·

0.

Observe that @fk
@vi
tions of orthogonal coordinates. It follows that

= 0 if k

@fl
@vi

= l since fk and fl are func-

@gm
@vi

@gn
@vi

·

@gm
@fk

@fk
@vi ! ·  

@gn
@fl

@fl
@vi !

L

Xl=1
2

@gm
@fl

@gn
@fl ·

@fl
@vi ◆

✓

0

 

=

=

L

 

Xk=1
L

Xl=1

since the gn’s co-vary monotonically.

Strong-typing is a sufﬁcient but not necessary condition for
safety. More general deﬁnitions can be proposed according
to taste. Deﬁnition 5 is easy to check, covers the basic ex-
amples below, and incorporates the concrete intuition de-
veloped in the warmups.

3.4. Comparison with potential games

notation, a block game is a weighted potential game if there
exists a potential function   and scalar weights ↵n > 0
satisfying

`n(w)

 

for all w, v

`n(w + ⇡nv) = ↵n ·
[N ].

V and n

⇣

2

2

 (w)

 (w + ⇡nv)

 

⌘

We provide two counter-examples to show that strongly-
typed games are distinct from potential games.
Example 5 (a strongly-typed game that is not a potential
game). Let `1(x, y) = x1y1 + 2x2y2 and `2(x, y) =
3x1y1 + 4x2y2. The block game with projections onto
x and y is strongly-typed but is not a weighted potential
game.
is not safe). Let
Example 6 (a potential game that
`1(x, y) = xy and `2(x, y) = xy
9x, with projections
onto x and y. The game is a potential game but is not safe
because

 

⇡1(

`1),

h

r

`2i

r

h

=

(y, 0), (y

9, x)

= y2

 

i

9y

 

can be negative.

4. Quadratic Games

Given a collection of (D
b(n)
vectors
{
functions

}

N
n=1 and D-
}
the corresponding quadratic game has loss

D)-matrices

A(n)
{

⇥

`n(w) =

w|A(n)w + w|b(n).

1
2

We assume the matrices A(n) are symmetric without loss
of generality.

4.1. Open quadratic games

In an open quadratic game, each player updates the entire
joint action.

Corollary 1. An open quadratic game is safe if there is
D)-matrix P, diagonal matrices D(n)
an orthogonal (D
⇥
such that D(m)D(n)

0, and D-vector b such that

 

A(n) = PD(n)P|

and b(n) = A(n)b.

We derive corollaries 1 and 2 from theorem 2. Alternate,
direct proofs are provided in appendix A4.

Proof. Let fi(x) = x( x
Then

2  

bi) and gn(z) =

D

i=1 d(n)

i

zi.

·

`n(w) = gn

f1(p|

1 w), . . . , fD(p|

P
Dw)

,

The proof of theorem 1 suggests that safe games are related
In our
to potential games (Monderer & Shapley, 1996).

⌘
where pi are the columns of P, is strongly-typed.

⇣

6
6
Strongly-Typed Agents are Guaranteed to Interact Safely

The Hessian of `n is H`n = A(n). The conditions of corol-
lary 1 can be reformulated as (i) the Hessians of the losses
commute H`mH`n = H`n H`m for all m and n, and (ii)
the Newton steps for the losses coincide (when the Hes-
sians are nonsingular):

1
H 
`n

(

r
Newton step

`n)

= (A(n)) 

1A(n)(w

b) = w

b.

 

 

|

{z

}

Example: Disentangling latent factors. An important
problem in machine learning is disentangling latent factors
(Bengio, 2013). Basic methods for tackling the problem
include PCA, canonical correlation analysis (CCA) and in-
dependent component analysis (ICA). We show how the
factorization in corollary 1 can arise “in nature” as a vari-
ant of blind source separation.

Suppose a signal on D channels is recorded for T time-
T )-matrix X. Assume the observations
points giving (D
combine L independent latent signals: X = MS where S
is an (L
T )-matrix representing the latent signal and M
⇥
is a mixing matrix.

⇥

Blind source separation is concerned with recovering the
latent signals. The covariance of the signal is A = XX|.
Factorize A = PDP| and let ˜S = P|X. Although this
may not recover the original signal, i.e. ˜S
= S in general,
it does disentangle X into uncorrelated factors:

˜S˜S| = P|XX|P = D.

Finally, recall that ﬁnding the ﬁrst principal component can
be formulated as the constrained maximization problem:

}

w|Aw.

{
k
there
generated

argmax
k2=1
w
w:
are N sets of observations
Now suppose
X(1), . . . , X(N )
orthogonal
single
mixing matrix acting on different sets of (potentially
rescaled) latent signals: X(n) = PS(n). Finding the ﬁrst
principle components of the signals reduces to solving the
constrained optimization problems

by

a

argmax
k2=1
w
w:

k

}

(

{

w|X(n)(X(n))|w

(3)

N

)

n=1

Corollary 1 implies that (3) is a safe. Note the corollary im-
plies the optimization problems have compatible gradients,
not that they share a common solution. In general there are
many Nash equilibria, analogous to example 3.

Quadratic games and linear regression. The blind
source separation example assumes that the linear terms
b(n) in the loss are zero.
If the linear term is nonzero
then linear regression is a special case of minimizing the
quadratic loss. Safety then relates to searching for weights
that simultaneously solve linear regression problems on
multiple datasets.

4.2. Block Quadratic Games

The block quadratic game has losses as above; however
the action space decomposes into (w1, . . . , wN ) with cor-
responding projections. Block decompose the components
of the loss as

1

C
C
A

•

A(n) = 0

and b(n) = 0

A(n)
11
...
A(n)
N 1

B
B
@

· · ·

· · ·

A(n)
1N
...
A(n)
N N

b(n)
1
...
b(n)
N

1

.

C
C
A

B
B
@

Corollary 2. A block quadratic game is safe if there are:

(i) (D

D)-orthogonal P with Pmn = 0 for m

= n;

⇥

(ii) (D

L) matrix R with Rn

diagonal for all n;

⇥
(iii) diagonal (L

⇥

(iv) and a D-vector b

L)-matrices D(n) with D(m)D(n)

0;

 

such that A(n) = PRD(n)R|P|

and

b(n) = A(n)b for all n.

The notation Pmn and R
columns of P and columns of R.

•

n refers to blocks in the rows and

l

L

l=1 d(n)

Proof. Let pi denote the columns of P and gn(z) =
zl. Given l, construct Pl by concatenating the
columns pi of P for which the corresponding entries of Ril
P
are nonzero and let rl be the vector containing the nonzero
l xl). Then
entries of R

l. Deﬁne fl(xl) = r|

l ( xl

bl)

(r|

·

•

`n(w) = gn

f1(P|

2  

·
1 w), . . . , fL(P|

Lw)

.

It is an exercise to check the game is strongly-typed.

⇣

⌘

Example: Disentangling latent factors. We continue
the discussion of blind source separation and safety. Sup-
pose that the mixing matrix decomposes into blocks

M = 0

1

M1
•...
MN

B
@
The blocks generate multiple views on a single latent signal,
(Kakade & Foster, 2007; McWilliams et al., 2013; Benton
et al., 2017). The nth view is Mn

C
A

S.

•

•

As in the example in section 4.1, now suppose there are N
sets of observed signals generated from N sets of latent sig-
nals. Each agent attempts to ﬁnd the principal component
speciﬁc to its view on its set of observations. Corollary 2
implies that the problems

argmax

w|X(n)(X(n))|w

(

{

wn:

wnk2=1

k

}

N

)

n=1

6
6
Strongly-Typed Agents are Guaranteed to Interact Safely

can be safely optimized using gradient descent if the mix-
ing matrix has the block form

Mn

= Pnn ·

•

Rn

•

L

l=1 d(n)

l zl and fl(x) =
n xn. De-
Proof. Let gn(z) =
N )-matrix whose nth column is un
ﬁne Pl as the (D
in
l
P
the block of rows corresponding to wn and zero elsewhere.
Then

Q

⇥

where Pnn is orthogonal and Rn
In
other words, if the views are generated by rescaling and
changing-the-basis of the latent signals.

is diagonal.

•

`n(w) = gn

f1(P|

1 w), . . . , fL(P|

Lw)

and the game is strongly-typed.

 

 

The open and block settings share a common theme: Safe
disentangling requires observed signals that are generated
by a single (structured) mixing process applied to (arbi-
trary) sets of independent latent signals. The same phe-
nomenon arises in multi-player games, resulting in tensor
decompositions that generalize ICA.

5. Multi-Player Games and Tensor-SVD

A classic N -player strategic game consists in ﬁnite action-
sets An and losses `n : A =
R. Enumerate
the elements of each set as An = [Dn], and encode the
Q
losses as (D1, . . . , DN )-tensors

n=1 An !

N

Not all tensors admit a tensor-SVD. However, all tensors
do admit a higher-order SVD (de Lathauwer et al., 2000).
Section A5 explains why simultaneous HOSVD does not
guarantee safety and the stronger tensor-SVD is required.

Example: Disentangling latent factors Suppose S is a
latent signal with independent non-Gaussian coordinates.
We observe X = PS + ✏ where P is a (D
L) mixing
matrix and ✏ is Gaussian noise. By whitening the signal
as a preprocessing step, one can ensure the columns of P
are orthogonal. ICA recovers S from the cumulants of X,
see Hyv¨arinen et al. (2001). The main insight is that the
4th-order cumulant tensor admits a tensor-SVD:

⇥

An[↵1, . . . ,↵ N ] := `n(↵1, . . . ,↵ N ) where ↵n 2

[Dn].

[i, j, k, l] = cum(xi, xj, xk, xl)

A

Given a collection of N such tensors, deﬁne the corre-
sponding multilinear game1 as

`n(w1, . . . , wN ) =
D1,...,DN

An ⇥1 w1 ⇥· · ·⇥ N wN

:=

↵1,...,↵N =1
X

[↵1, . . . ,↵ N ]

w1[↵1]

wN [↵N ].

·

· · ·

A

The classic example is when actions are drawn from the
Dn
↵=1 wn[↵] =
wn 2
Dn-simplex
{
1 and wn[↵]
.
}

Dn =
0 for all ↵

RDn :

4
 

P

We now recall the orthogonal tensor decomposition or ten-
sor SVD (Zhang & Golub, 2001; Chen & Saad, 2009). A
tensor admits a tensor-SVD if it can be written in the form

L

Xl=1

D

=

A

u1

dl ·

l ⌦· · ·⌦

uN

l =

D ⇥1 U1

⇥· · ·⇥ N UN

where Un is a (Dn ⇥
and

is a diagonal (L, . . . , L)-tensor.

L)-matrix with orthogonal columns

Corollary 3. A multilinear game is safe if it admits a si-
multaneous tensor-SVD

(n) =

(n)

⇥1 U1 ⇥· · ·⇥ N UN

D

A

PioPjpPkqPlr ·

cum(so, sp, sq, sr)

PirPjrPkrPlr ·

kurt(sr)

=

=

o,p,q,r
X

r
X

since cum(so, sp, sq, sr) = 0 unless o = p = s = r be-
cause the signals are independent. The expression can be
⇥4P where diagonal tensor
⇥3P
written
speciﬁes the kurtosis of the latent signal. In other words,
K
computing the tensor-SVD recovers the mixing matrix and
allows to recover the latent signal up to basic symmetries.

K⇥1P

⇥2P

A

=

Following the same prescription as the examples above, if
there are N sets of observations generated from N latent
signals by the same mixing matrix, then the resulting cu-
mulant tensors satisfy corollary 3.

6. Biologically Plausible Backpropagation

Our ultimate goal is to apply strong-typing to safely opti-
mize neural nets with multiple loss functions (Marblestone
et al., 2016). Doing so requires constructing variants of
backprop that allow the propagation of multiple error sig-
nals. First steps in this direction have been taken with bio-
logically plausible models of backprop that introduce addi-
tional degrees of freedom into the algorithm.

where the diagonals have the same sign coordinatewise.

1We use the n-mode product notation

n, see de Lathauwer

⇥

et al. (2000).

is a recent algorithm with compa-
Feedback alignment
rable empirical performance to backprop. It is also more
biologically plausible since it loosens backprop’s require-
ment that forward- and back- propagating weights are sym-

Strongly-Typed Agents are Guaranteed to Interact Safely

metric (Lillicrap et al., 2016). The main theoretical result
of the paper, see their supplementary information, is
Theorem. Let  BP = W|e denote the error backpropa-
gated one layer of the neural network. Under certain con-
ditions, the error signal computed by feedback alignment,
 F A = Be, satisﬁes

 F A = ↵

W†e where ↵> 0

·

and W† is the pseudoinverse of W.

Proof. See theorem 2 of Lillicrap et al. (2016).

Corollary 4. Under the same conditions, feedback align-
ment is safe.

Proof. We require to check
the theorem obtains

 F A,  BP i  

h

0. Applying

 F A,  BP i

h

·h

= ↵

W†e, W|e

= ↵

WW†e, e

.

i

·h

i

Observe that WW† is an orthogonal projection by stan-
dard properties of the pseudoinverse so

 F A,  BP i

h

·h

= ↵

WW†e, WW†e

0

i  

as required.

In fact, Lillicrap et al. (2016) provide experimental and the-
oretical evidence that feedback alignment learns to align
the feedforward weights with the pseudoinverse of the
backconnections. In other words, they argue that feedback
alignment learns safe gradients.

Another variant of backprop is kickback, which loosens
backprop’s requirement that there are distinct forward- and
backward signals (Balduzzi et al., 2015). Kickback trun-
cates backprop’s error signals so that the network learns
from just the feedforward sweep together with scalar error
signals. One of the main results of Balduzzi et al. (2015) is
that kickback is safe, see section A6.

7. Conclusion

Backprop provides a general-purpose tool to train conﬁg-
urations of differentiable modules that share a single ob-
jective. However, effectively training populations of neural
networks on potentially conﬂicting tasks, such that they au-
tomatically exploit synergies and avoid damaging incom-
patibilities (such as unlearning old features that are not use-
ful on a new task) requires fundamentally new ideas.

A key piece of the puzzle is to develop type systems that
can be used to (i) guarantee when certain optimizations can
be safely performed jointly and (ii) ﬂag potential conﬂicts
so that the incompatible optimization problems can be sep-
arated. The paper provides a ﬁrst step in this direction.

From a different perspective, convex methods have played
an enormous role in optimization yet their relevance to
deep learning is limited. The approach to strong-typing
developed here is inspired by and extends certain features
of convexity. One of the goals of this paper is to carve
out some of the key concepts underlying convex geometry
and reassemble them into a more ﬂexible, but still power-
ful framework. The proposed deﬁnition of strong-typing
should be considered a ﬁrst and far from ﬁnal attempt.

A large class of natural examples is generated by imposing
strong-typing on simple quadratic and multilinear games.
It turns out that, in these settings, strong-typing yields
the same matrix and tensor decompositions that arise in
blind source separation and independent component anal-
ysis, where multiple latent signals are mixed by the same
structured process. An important future direction is to dis-
entangle nonlinear latent factors.

Strong-typing and safety in neural nets. We conclude
by discussing the relevance of the framework to neural net-
works. Firstly, neural nets and strong-typing have many of
the same ingredients: neural nets combine linear algebra
(matrix multiplications and convolutions) with monotonic
functions (sigmoids,
tanhs, rectiﬁers, and max-pooling
amongst others). Rectiﬁers and sigmoids have the addi-
tional feature that their outputs are always positive.



l x

Secondly, there is a deeper connection between rectiﬁers
and strong-typing. Rectiﬁers are orthogonal projections
on weights: ⇢(W|x) zeroes out the columns wl of W for
which w|
0. Rectiﬁers are more sophisticated projec-
tions than we have previously considered because they are
context-dependent. The columns that are zeroed out de-
pend on W and x: the rectiﬁer-projection takes W and x
as parameters, compare remarks 1 and 2 in the appendix.
Representation learning in rectiﬁer networks can thus be
recast as learning parameterized type structures. An inter-
esting future direction is to consider tensor-switching net-
works (Tsai et al., 2016), which decouple a neuron’s deci-
sion to activate from the information it passes along (for a
rectiﬁer, both depend on W|x).

Finally, it has long been known that the brain does not use
backprop (Crick, 1989). One possibility is that backprop is
the optimal deep learning algorithm which, unfortunately,
evolution failed to stumble upon. Another is that there are
evolutionary advantages to not using backpropagation. For
example, it has been argued that the brain optimizes multi-
ple loss functions (Marblestone et al., 2016). Does jointly
optimizing or satisﬁcing multiple objectives require learn-
ing mechanisms with more degrees of freedom than back-
prop (Balduzzi et al., 2015; Lillicrap et al., 2016)? Safety
and strong-typing provide the tools needed to frame and
investigate the question.

Strongly-Typed Agents are Guaranteed to Interact Safely

Acknowledgements

I am grateful to Stephen Marsland and James Benn for use-
ful discussions.

References
Amari, S. Natural Gradient Works Efﬁciently in Learning. Neural

Comp, 10:251–276, 1998.

Amari, S. Information Geometry and Its Applications: Convex
In Nielsen, Frank (ed.),

Function and Dually Flat Manifold.
Emerging Trends in Visual Computing, 2009.

Amodei, Dario, Olah, Chris, Steinhardt, Jacob, Christiano, Paul,
Schulman, John, and Man´e, Dan. Concrete Problems in AI
Safety. In arXiv:1606.06565, 2016.

Balduzzi, D, Vanchinathan, H, and Buhmann, J. Kickback cuts
Backprop’s red-tape: Biologically plausible credit assignment
in neural networks. In AAAI, 2015.

Balduzzi, David. Grammars for Games: A Gradient-Based,
Game-Theoretic Framework for Optimization in Deep Learn-
ing. Frontiers in Robotics and AI, 2(39), 2016.

Balduzzi, David and Ghifary, Muhammad. Strongly-Typed Re-

current Neural Networks. In ICML, 2016.

Bengio, Yoshua. Deep Learning of Representations: Look-
In Dediu, Adrian-Horia, Mart´ın-Vide, Carlos,
ing Forward.
Mitkov, Ruslan, and Truthe, Bianca (eds.), Statistical Lan-
guage and Speech Processing. Springer, 2013.

Benton, Adrian, Khayrallah, Huda, Gujral, Biman, Reisinger,
Drew, Zhang, Sheng, and Arora, Raman. Deep Generalized
Canonical Correlation Analysis. In arXiv:1702.02519, 2017.

Berkenkamp, F, Moriconi, R, Schoellig, A, and Krause, A. Safe
learning of regions of attraction for uncertain, nonlinear sys-
tems with gaussian processes. In IEEE CDC, 2016.

Bubeck, S´ebastien. Convex Optimization: Algorithms and Com-
plexity. Foundations and Trends in Machine Learning, 8(3-4):
231–358, 2015.

Chen, Jie and Saad, Yousef. On the tensor SVD and the optimal
low rank orthogonal approximation of tensors. SIAM J. Matrix
Anal. Appl., 30(4):1709–1734, 2009.

Crick, Francis. The recent excitement about neural networks. Na-

ture, 337(12):129–132, 1989.

Daskalakis, Constantinos, Goldberg, Paul W, and Papadimitriou,
Christos. The Complexity of Computing a Nash Equilibrium.
SIAM J. Computing, 39(1):195–259, 2009.

Dauphin, Yann, Pascanu, Razvan, Gulcehre, Caglar, Cho,
Kyunghyun, Ganguli, Surya, and Bengio, Yoshua.
Identify-
ing and attacking the saddle point problem in high-dimensional
non-convex optimization. In NIPS, 2014.

de Lathauwer, Lieven, de Moor, Bart, and Vandewalle, Joos.
A multilinear singular value decomposition. SIAM J. Matrix
Anal. Appl., 21(4):1253–1278, 2000.

Fernando, C, Banarse, D, Blundell, C, Zwols, Y, Ha, D, Rusu, A,
Pritzel, A, and Wierstra, D. PathNet: Evolution Channels Gra-
dient Descent in Super Neural Networks. In arXiv:1701.08734,
2017.

Goodfellow, Ian J. NIPS 2016 Tutorial: Generative Adversarial

Networks. In arXiv:1701.00160, 2017.

Hinton, G and et al. Deep Neural Networks for Acoustic Mod-
eling in Speech Recognition: The Shared Views of Four Re-
search Groups. IEEE Signal Proc Magazine, 29:82–97, 2012.

Hyv¨arinen, Aapo, Karhunen, Juha, and Oja, Erkki. Independent

Component Analysis. John Wiley & Sons, 2001.

Kakade, Sham and Foster, Dean P. Multi-view Regression Via

Canonical Correlation Analysis. In COLT, 2007.

Krizhevsky, A, Sutskever, I, and Hinton, G E. Imagenet classiﬁ-
cation with deep convolutional neural networks. In Advances
in Neural Information Processing Systems (NIPS), 2012.

LeCun, Yann, Bengio, Yoshua, and Hinton, Geoffrey. Deep learn-

ing. Nature, 521:436–444, 2015.

Lillicrap, Timothy P, Cownden, Daniel, Tweed, Douglas B, and
Ackerman, Colin J. Random feedback weights support error
backpropagation for deep learning. Nature Communications, 7
(13276), 2016.

Marblestone, Adam H, Wayne, Greg, and Kording, Konrad P.
Towards an Integration of Deep Learning and Neuroscience.
Front. Comput. Neurosci., 10(94), 2016.

McWilliams, Brian, Balduzzi, David, and Buhmann, Joachim.
Correlated random features for fast semi-supervised learning.
In NIPS, 2013.

Mnih, Volodymyr, Kavukcuoglu, Koray, Silver, David, and et al.
Human-level control through deep reinforcement learning. Na-
ture, 518(7540):529–533, 02 2015.

Monderer, Dov and Shapley, Lloyd S. Potential Games. Games

and Economic Behavior, 14:124–143, 1996.

Nash, John F. Equilibrium Points in n-Person Games. Proc Natl

Nisan, Noam, Roughgarden, Tim, Tardos, ´Eva, and Vazirani, Vi-
jay (eds.). Algorithmic Game Theory, 2007. Cambridge Uni-
versity Press, Cambridge.

Rakhlin, Alexander and Sridharan, Karthik. Optimization, learn-
ing, and games with predictable sequences. In NIPS, 2013.

Raskutti, G and Mukherjee, S. The Information Geometry of Mir-
ror Descent. IEEE Trans. Inf. Theory, 61(3):1451–1457, 2015.

Silver, David, Huang, Aja, and et al. Mastering the game of go
with deep neural networks and tree search. Nature, 529(7587):
484–489, 01 2016.

Syrgkanis, Vasilis, Agarwal, Alekh, Luo, Haipeng, and Schapire,
Robert. Fast Convergence of Regularized Learning in Games.
In NIPS, 2015.

Tsai, Chuan-Yung, Saxe, Andrew, and Cox, David. Tensor

Switching Networks. In NIPS, 2016.

Cardelli, Luca. Type Systems. In Handbook of Computer Science

Acad Sci U S A, 36(1):48–49, 1950.

and Engineering. CRC Press, 1997.

Strongly-Typed Agents are Guaranteed to Interact Safely

Turchetta, Matteo, Berkenkamp, Felix, and Krause, Andreas. Safe
Exploration in Finite Markov Decision Processes with Gaus-
sian Processes. In NIPS, 2016.

von Neumann, John and Morgenstern, Oskar. Theory of Games
and Economic Behavior. Princeton University Press, Princeton
NJ, 1944.

Zhang, T, Kahn, G, Levine, S, and Abbeel, P. Learning deep con-
trol policies for autonomous aerial vehicles with mpc-guided
policy search. In ICRA, 2016.

Zhang, Tong and Golub, Gene H. Rank-one approximation to
higher order tensors. SIAM J. Matrix Anal. Appl., 23(2):534–
550, 2001.

