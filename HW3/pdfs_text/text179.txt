Supplementary Material for RobustFill: Neural
Program Learning under Noisy I/O

A. Attention Formulas

The formula ci = Attention(hi−1, xi, S) is as follows:

ti = tanh(W [hi−1; xi])
dij = sj · ti
edij
k edik
αijsj

ci =

αij =

(cid:88)

(cid:80)

j

i = tanh(W [hi−1; xi; cA
tB

i ])

Where i is the current timestep, hi1 is the previous hidden state, xi is the current input, S = s1, ..., sN are the vectors being
attended to, and W is a learned parameter matrix. The interpolated context vector ci is concatenated into the input and fed
into the LSTM. In the case of double attention, the output of the ﬁrst attention mechanism C A
is concatenated to the input
i
of the second attention, i.e.:

where the remaining steps are identical.

B. DSL Extended Description

Section 3.2 of the paper provides the grammar of our domain speciﬁc language, which both deﬁnes the space of possible
programs, and allows us to easily sample programs. The formal semantics of this language are deﬁned below in Figure 1.
The program takes as input a string v and produces a string as output (result of Concat operator).

As an implementational detail, we note that after sampling a program from the grammar, we ﬂatten calls to nesting functions
(as deﬁned in Figure 2 of the paper) into a single token. For example, the function GetToken(t, i) would be tokenized
as a single token GetTokent,i rather than 3 separate tokens. This is possible because for nesting functions, the size of the
total parameter space is small. For all other functions, the parameter space is too large for us to ﬂatten function calls
without dramatically increasing the vocabulary size, so we treat parameters as separate tokens.

(cid:74)

Concat(e1, e2, e3, ...)
(cid:75)
n1(n2)
(cid:75)
n(f )
(cid:75)
ConstStr(c)
(cid:74)
(cid:75)
SubStr(k1, k2)
(cid:75)
(cid:74)

(cid:74)

(cid:74)

(cid:74)

v,

e2
e1
(cid:75)
(cid:75)
v1 , where v1 =
(cid:75)
v1, where v1 =

v = Concat(
(cid:74)
v =
n1
(cid:74)
v =
n
(cid:74)
v = c
v = v[p1..p2], where

(cid:75)

(cid:74)

v,
(cid:74)
n2
(cid:74)
f

v
(cid:75)

e3

v, ...)

(cid:75)
v

(cid:75)

p1 = k1 > 0 ? k1 : len(v) + k1
p2 = k2 > 0 ? k2 : len(v) + k2

GetSpan(r1, i1, y1, r2, i2, y2)
(cid:75)
(cid:74)

v = v[p1..p2] ,where

p1 = y1(Start or End) of |i1|th match of r1 in v from beginning (end if ii < 0)
p2 = y2(Start or End) of |i2|th match of r2 in v from beginning (end if i2 < 0)

GetToken(t, i)
GetUpto(r)
(cid:74)
GetFrom(r)
(cid:74)

GetFirst(t, i)

(cid:74)

(cid:74)

(cid:75)

(cid:74)

GetAll(t)
ToCase(s)
Trim()
(cid:75)
(cid:74)
Replace(δ1, δ2)
(cid:75)

(cid:74)

(cid:75)

(cid:74)

(cid:75)

(cid:75)

(cid:75)

(cid:75)

v = |i|th match of t in v from beginning (end if i < 0)
v = v[0..i], where i is the index of end of ﬁrst match of r in v from beginning
v = v[j..len(v)], where j is the end of last match of r in v from end
v = Concat(s1, · · · , si), where sj denotes the jth match of t in v
v = Concat(s1, · · · , sm), where si denotes the ith match of t in v and m denotes the total matches
v = ToCase(s, v)
v = Trim(v)
v = Replace(v, δ1, δ2)

Figure 1. The semantics of the DSL for string transformations.

C. Synthetic Training Data Generation

Since there are only a few hundred real-world FlashFill benchmarks, we use synthetically generated training data to train
our neural models. The key idea in data generation is to uniformly sample programs from the DSL, and then for each
sampled program, generate a set of input-output examples that are consistent with it. We now describe the key steps in the
data generation process in more detail.

First, programs are sampled randomly from the DSL. We treat the DSL as a probabilistic context free grammar (PCFG)
where the probability of expanding to any child node is uniformly random. Even though the top-level concat operator
can take an arbitrary number of expressions e, in practice, we limit it to have at most k expressions, where k is randomly
sampled from 1 to 10.

Next, the input strings are sampled from the space of all random ASCII strings with lengths between 1 and 100, using
some simple heuristics that are extracted from the sampled programs preconditions. For example, if the program contained
GetToken(Word, 2) and GetFrom(Space, 4) as sub-expressions, then we would ﬁrst generate 2 words and 4 spaces, then
shufﬂe these and add other random ASCII characters. In this case, words are deﬁned as random ASCII strings that match
the particular regular expression of [A-Za-z]{1,10}. Finally, to generate the output strings, we execute the program on the
input strings.

However, the extracted heuristics do not always encapsulate all preconditions exactly, as there are some edge cases that
may prevent successful execution. If the program could not be executed on an input string (e.g., say one expression in
our sampled program is SubStr(GetToken(word, 2), 1, 10)), but the 2nd word isnt 10 characters long), we simply reject
the input string and re-sample until we ﬁnd one that executes successfully. We ﬁnd that in practice, the pre-conditions are
usually sufﬁcient conditions for efﬁcient generation of viable input strings.

D. Synthetic Evaluation Details

Results on synthetically generated examples are largely omitted from the paper since, in a vacuum, the synthetic dataset can
be made arbitrarily easy or difﬁcult via different generation procedures, making summary statistics difﬁcult to interpret.
We instead report results on an external real-world dataset to verify that the model has learned function semantics which
are at least as expressive as programs observed in real data.

Nevertheless, we include additional details about our experiments on synthetically generated programs for readers inter-
ested in the details of our approach. As described in the paper, programs were randomly generated from the DSL by ﬁrst
determining a program length up to a maximum of 10 expressions, and then independently sampling each expression. We
used a simple set of heuristics to restrict potential inputs to strings which will produce non-empty outputs (e.g. any program
which references the third occurrence of a number will cause us to sample strings containing at least three numbers). We
rejected any degenerate samples e.g. those resulting in empty outputs, or outputs longer than 100 characters.

Figure 4 shows several random synthetically generated samples.

Figure 2 shows the accuracy of each model on the synthetically generated validation set. Model accuracy on the synthetic
validation set is generally consistent with accuracy on the FlashFill dataset, with stronger models on the synthetic dataset
also demonstrating stronger performance on the real-world data.

Figure 2. Generalization accuracy for different models on the synthetic validation set

E. Examples of Synthesized Programs

Figure 5 shows several randomly sampled (anonymized) examples from the FlashFill test set, along with their predicted
programs outputted by the synthesis model.

Figure 6 shows several examples which were hand-selected to demonstrate interesting limitations of the model. In the
case of the ﬁrst example, the task is to reformat international telephone numbers. Here, the task is underconstrained given
the observed input-output examples, because there are many different programs which are consistent with the observed
examples. Note that to extract the ﬁrst two digits, there are many other possible functions which would produce the correct
output in the observed examples, some of which would generalize and some which would not: for exampling, getting the
second and third characters, getting the ﬁrst two digits, or getting the ﬁrst number. In this case, the predicted program
extracts the country code by taking the ﬁrst two digits, a strategy which fails to generalize to examples with different
country codes. The third example demonstrates a difﬁculty of using real world data. Because examples can come from a
variety of sources, they may be irregularly formatted. In this case, although the program is consistent with the observed
examples, it does not generalize when the second space in the address is removed. In the ﬁnal example, the synthesis model
completely fails, and none of the 100 highest scoring programs from the model were consistent with the observed output
examples. The selected program is the closest program scored by character edit distance.

F. Induction Network Architecture

The network architecture used in the program induction setting is described in Section 6.1 of the paper. The network
structure is a modiﬁcation of synthesis Attention-A, using double attention to jointly attend to I x and Oj, and an additional
LSTM to encode I x. We include a complete diagram below in Figure 3.

Figure 3. The network architecture used for program induction. A dotted line from x to y means that x attends to y.

Reference program: GetToken_Alphanum_3 | GetFrom_Colon | GetFirst_Char_4
Ud 9:25,JV3 Obb
zLny xmHg 8:43 A44q
A6 g45P 10:63 Jf
cuL.zF.dDX,12:31
ZiG OE bj3u 7:11

2525,JV3 ObbUd92
843 A44qzLny
1063 JfA6g4
dDX31cuLz
bj3u11ZiGO

Reference program: Get_Word_-1(GetSpan(Word, 1, Start, ‘(’, 5,
Start)) | GetToken_Number_-5 | GetAll_Proper | SubStr(-24, -14) |
GetToken_Alphanum_-2 | EOS
4 Kw ( )SrK (11 (3 CHA xVf )4 )8 Qagimg ) (
)(vs
iY) )hspA.5 ( )8,ZsLL (nZk.6 (E4w )2(Hpprsqr
)2(Z
Cqg) ) ( (1005 ( ( )VCE hz ) (10 Hadj )zg
Tqwpaxft-7 5 6
JvY) (Ihitux ) ) ( (6 SFl (7 XLTD sfs )
)11,lU7 (6 9
NjtT(D7QV (4 (yPuY )8.sa ( ) )6 aX 4 )DXR (
@6 ) Ztje

Qagimg4Kw Sr Vf QagimgVf )4
)8 QaQagimg
Hpgjprsqr8Zs Zk Hpprsqrk.6
(E4w )22
hz10005Cqg Hadj Tqwpaxft
Hadj )zg T5
lU7Jv Ihitux Frl XLTD sfs )6

DXR4Njt Pu Ztje)6 aX 4 )DX6

Reference program: GetToken_AllCaps_-2(GetSpan(AllCaps, 1, Start,
AllCaps, 5, Start)) | EOS
YDXJZ @ZYUD Wc-YKT GTIL BNX
JUGRB.MPKA.MTHV,tEczT-GZJ.MFT
VXO.OMQDK.JC-OAR,HZGH-DJKC
HCUD-WDOC,RTTRQ-KVETK-whx-DIKDI
JFNB.Avj,ODZBT-XHV,KYB @,RHVVW

W
MTHV
JC
RTTRQ
ODZBT

Reference program: SubStr(-20, -8) | GetToken_AllCaps_-3 | SubStr(11,
19) | GetToken_Alphanum_-5 | EOS
DvD 6X xkd6 OZQIN ZZUK,nCF aQR IOHR

IN ZZUK,nCF aCFv OZQIN
ZOZQIN
CRCUC,ONFZA.mONFZAy,44-CRCU44

BHP-euSZ,yy,44-CRCUC,ONFZA.mgOJ.Hwm

NGM-8nay,xrL.GmOc.PFLH,CMFEX-JPFA,iIcj,329

,CMFEX-JPFA,iCMFEXrL.GmOc.PPFLH

hU TQFLD Lycb NCPYJ oo FS TUM l6F

OHHS NNDQ XKQRN KDL 8Ucj dUqh Cpk Kafj

NCPSYJ oo FS FScb NCPYJ
NCPYJ
L 8Ucj dUqh CUXKQRN KDLKDL

Figure 4. Randomly sampled programs and corresponding input-output examples, drawn from training data. Multi-line examples are all
broken into lines on spaces.

Model prediction: GetSpan(‘[’, 1, Start, Number, 1, End) | Const(]) |
EOS
[CPT-101
[CPT-101
[CPT-11]
[CPT-1011]
[CPT-1011
[CPT-1012
[CPT-101]
[CPT-111]
[CPT-1011]
[CPT-101]

[CPT-101]
[CPT-101]
[CPT-11]
[CPT-1011]
[CPT-1011]
[CPT-1012]
[CPT-101]
[CPT-111]
[CPT-1011]
[CPT-101]

[CPT-101]
[CPT-101]
[CPT-11]
[CPT-1011]
[CPT-1011]
[CPT-1012]
[CPT-101]
[CPT-111]
[CPT-1011]
[CPT-101]

Jacob,Ethan,James,Alexander.-
Michael
Elijah,Daniel,Aiden,Matthew.-
Lucas
Jackson,Oliver,Jayden,Chris.-
Kevin
Earth,Fire,Wind,Water.Sun

Jacob,Ethan,James,Alexander.-
Michael
Elijah,Daniel,Aiden,Matthew.-
Lucas
Jackson,Oliver,Jayden,Chris.-
Kevin
Earth,Fire,Wind,Water.Sun

Model prediction: Replace_Space_Comma(GetSpan(Proper, 1, Start, Proper,
4, End) | Const(.) | GetToken_Proper_-1 | EOS
Jacob Ethan James
Alexander Michael
Elijah Daniel Aiden
Matthew Lucas
Jackson Oliver
Jayden Chris Kevin
Earth Fire Wind
Water Sun
Tom Mickey Minnie
Donald Daffy
Jacob Mickey Minnie
Donald Daffy
Gabriel Ethan James
Alexander Michael
Rahul Daniel Aiden
Matthew Lucas
Steph Oliver Jayden
Chris Kevin
Pluto Fire Wind
Water Sun

Jacob,Mickey,Minnie,Donald.-
Daffy
Gabriel,Ethan,James,Alexander-
.Michael
Rahul,Daniel,Aiden,Matthew.-
Lucas
Steph,Oliver,Jayden,Chris.KevinSteph,Oliver,Jayden,Chris.Kevin

Jacob,Mickey,Minnie,Donald.-
Daffy
Gabriel,Ethan,James,Alexander.-
Michael
Rahul,Daniel,Aiden,Matthew.-
Lucas

Tom,Mickey,Minnie,Donald.DaffyTom,Mickey,Minnie,Donald.Daffy

Pluto,Fire,Wind,Water.Sun

Pluto,Fire,Wind,Water.Sun

Model prediction: GetAll_Proper | EOS
Emma Anders
Olivia Berglun
Madison Ashworth
Ava Truillo
Isabella
Mia
Emma Stevens
Chris Charles
Liam Lewis
Abigail Jones

Emma Anders
Olivia Berglun
Madison Ashworth
Ava Truillo
Isabella
Mia
Emma Stevens
Chris Charles
Liam Lewis
Abigail Jones

Emma Anders
Olivia Berglun
Madison Ashworth
Ava Truillo
Isabella
Mia
Emma Stevens
Chris Charles
Liam Lewis
Abigail Jones

Figure 5. Random samples from the FlashFill test set. The ﬁrst two columns are InStr and OutStr respectively, and the third column
is the execution result of the predicted program. Example strings which do not ﬁt on a single line are broken on spaces, or hyphenated
when necessary. All line-ending hyphens are inserted for readability, and are not part of the example.

|

Model prediction: GetToken_Proper_1 | Const(.)
GetToken_Char_1(GetToken_Proper_-1) | Const(@) | EOS
Mason Smith
Lucas Janckle
Emily Jacobnette
Charlotte Ford
Harper Underwood
Emma Stevens
Chris Charles
Liam Lewis
Olivia Berglun
Abigail Jones

Mason.S@
Lucas.J@
Emily.B@
Charlotte.F@
Harper.U@
Emma.S@
Chris.C@
Liam.L@
Olivia.B@
Abigail.J@

Mason.S@
Lucas.J@
Emily.B@
Charlotte.F@
Harper.U@
Emma.S@
Chris.C@
Liam.L@
Olivia.B@
Abigail.J@

Figure 5. Random samples from the FlashFill test set. The ﬁrst two columns are InStr and OutStr respectively, and the third column
is the execution result of the predicted program. Example strings which do not ﬁt on a single line are broken on spaces, or hyphenated
when necessary. All line-ending hyphens are inserted for readability, and are not part of the example.

| GetToken_Number_2 |

| GetToken_Alpha_-1 | EOS

Model prediction: GetFirst_Digit_2 | Const(.)
Const(.) | GetToken_Number_3 | Const(.)
+32-2-704-33
+44-118-909-3574
+90-212-326 5264
+44 118 909 3843
+386 1 5800 839
+1 617 225 2121
+91-2-704-33
+44-101-909-3574
+90-212-326 2586
+44 118 212 3843

32.2.704.33
44.118.909.3574
90.212.326.5264
44.118.909.3843
386.1.5800.839
1.617.225.2121
91.2.704.33
44.101.909.3574
90.212.326.2586
44.118.212.3843

32.2.704.33
44.118.909.3574
90.212.326.5264
44.118.909.3843
38.1.5800.839
16.617.225.2121
91.2.704.33
44.101.909.3574
90.212.326.2586
44.118.212.3843

Model prediction: GetFirst_Char_1 | Const(.)

| GetFirst_Char_1(

GetToken_Proper_4 ) | Const(.) | EOS
Milk 4, Yoghurt 12, Juice 2 Lassi 5
Alpha 10 Beta 20 Charlie 40 60
Epsilon
Sumit 7 Rico 12 Wolfram 15 Rick 19
Us 38 China 35 Russia 27 India 1
10 Apple 2 Oranges 13 Bananas 40
Pears
10 Bpple 2 Oranges 13 Bananas 40
Pears
Milk 4, Yoghurt 12, Juice 2 Massi 5
Alpha 10 Beta 20 Charlie 40 60 Delta

Parul 7 Rico 12 Wolfram 15 Rick 19
Us 38 China 35 Russia 27 America 1

M.L.
A.E.

S.R.
U.I.
A.P.

B.P.

M.M.
A.D.

P.R.
U.A.

M.L.
A.E.

S.R.
U.I.
1.P.

1.P.

M.M.
A.D.

P.R.
U.A.

Model prediction: Replace_Space_Dash(GetSpan(AlphaNum, 1, Start, Proper,
1, End)) | EOS
212 2nd Avenue
124 3rd Avenue
123 4th Avenue
999 5th Avenue
123 1st Avenue
223 1stAvenue
112 2nd Avenue
224 3rd Avenue
123 5th Avenue
99 5th Avenue

212-2nd-Avenue
124-3rd-Avenue
123-4th-Avenue
999-5th-Avenue
123-1st-Avenue
223-1st-Avenue
112-2nd-Avenue
224-3rd-Avenue
123-5th-Avenue
99-5th-Avenue

212-2nd-Avenue
124-3rd-Avenue
123-4th-Avenue
999-5th-Avenue
123-1st-Avenue
223-1stAvenue
112-2nd-Avenue
224-3rd-Avenue
123-5th-Avenue
99-5th-Avenue

Figure 6. Selected samples of incorrect model predictions on the Flashﬁll test set. These include both inconsistent programs, and
consistent programs which failed to generalize.

Excel-Meetings

DSI-Application

Excel-Meetings-OneNote-Word

SP Workflow Solut-
ions-Excel-Excel
Services-BI
PowerPoint-Meetings-OneNote-WordPowerPoint-Meetings

Model prediction: GetToken_Word_1 | Const(-) | GetToken_Proper_1(GetSpan(‘;’,
-5, Start, ‘#’, 5, Start)) | GetUpto_Comma Replace_Space_Dash
| GetToken_Word_1(GetSpan(Proper, 4, End, ‘$’, 5, End)) |
GetToken_Number_-5 | GetSpan(‘#’, 5, End, ‘$’, 5, Start) | EOS
28;#DSI;#139;#ApplicationVirt-
DSI-ApplicationVirtualization-B-
ualization;#148;#BPOS;#138;#Mi-
POS-Microsoft PowerPoint
crosoft PowerPoint
102;#Excel;#14;#Meetings;#55;-
#OneNote;#155;#Word
19;#SP Workflow
Solutions;#102;#Excel;#194;-
#Excel Services;#46;#BI
37;#PowerPoint;#141;#Meetings;-
#55;#OneNote;#155;#Word
148;#Access;#102;#Excel;#194-
;#Excel Services;#46;#BI
248;#Bccess;#102;#Excel;#194;-
#Excel Services;#46;#BI
28;#DCI;#139;#ApplicationVirt-
ualization;#148;#BPOS;#138;#-
Microsoft PowerPoint
12;#Word;#141;#Meetings;#55;#O-
neNote;#155;#Word
99;#AP Workflow Solutions;-
#102;#Excel;#194;#Excel
Services;#46;#BI
137;#PowerPoint;#141;#Meetings;-
#55;#OneNote;#155;#Excel

Access-Excel-Excel
Services-BI
Bccess-Excel-Excel
Services-BI
DCI-ApplicationVirtualizat-
ion-BPOS-Microsoft
PowerPoint
Word-Meetings-OneNote-Word

PowerPoint-Meetings-OneNo-
te-Excel

AP Workflow Solutions-Ex-
cel-Excel Services-BI

AP Workflow
Solutions-Excel

SP Workflow
Solutions-Excel

PowerPoint-Meetings

DCI-Application

Word-Meetings

Access-Excel

Bccess-Excel

Figure 6. Selected samples of incorrect model predictions on the Flashﬁll test set. These include both inconsistent programs, and
consistent programs which failed to generalize.

