Evaluating the Variance of Likelihood-Ratio Gradient Estimators

Seiya Tokui 1 2 Issei Sato 3 2

Abstract
The likelihood-ratio method is often used to es-
timate gradients of stochastic computations, for
which baselines are required to reduce the esti-
mation variance. Many types of baselines have
been proposed, although their degree of optimal-
ity is not well understood. In this study, we es-
tablish a novel framework of gradient estima-
tion that includes most of the common gradi-
ent estimators as special cases. The framework
gives a natural derivation of the optimal estima-
tor that can be interpreted as a special case of
the likelihood-ratio method so that we can eval-
uate the optimal degree of practical techniques
with it.
It bridges the likelihood-ratio method
and the reparameterization trick while still sup-
porting discrete variables. It is derived from the
exchange property of the differentiation and in-
tegration. To be more speciﬁc, it is derived by
the reparameterization trick and local marginal-
ization analogous to the local expectation gradi-
ent. We evaluate various baselines and the opti-
mal estimator for variational learning and show
that the performance of the modern estimators is
close to the optimal estimator.

1. Introduction

The success of deep learning owes much to efﬁcient gradi-
ent computation using backpropagation (Rumelhart et al.,
1986). When the model of interest
includes internal
stochasticities, the objective function is often written as a
stochastic computational graph (Schulman et al., 2015). In
this case, the exact gradient computation is intractable in
general, and an approximate estimation is required. The
variance introduced by the approximation often degrades
the optimization performance for deep models, and there-

1Preferred Networks, Tokyo, Japan 2The University of
Tokyo, Tokyo, Japan 3RIKEN, Tokyo, Japan. Correspondence
to: Seiya Tokui <tokui@preferred.jp>, Issei Sato <sato@k.u-
tokyo.ac.jp>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

fore variance reduction is crucial for practical learning.
However, few things are known about its theoretical as-
pects, and we often struggle with model-speciﬁc heuristics
whose degree of optimality is difﬁcult to know.

The likelihood-ratio method (Glynn, 1990; Williams, 1992)
and the reparameterization trick (Williams, 1992; Kingma
& Welling, 2014; Rezende et al., 2014; Titsias & Lzaro-
gredilla, 2014) are widely used for the gradient estima-
tion. The likelihood-ratio method only requires the compu-
tation of density functions and their derivatives, and there-
fore it is applicable to a wide range of models including
those with discrete variables. It requires variance reduction
techniques in practice. The most common technique is the
use of a baseline value (Paisley et al., 2012; Bengio et al.,
2013; Ranganath et al., 2014; Mnih & Gregor, 2014; Gu
et al., 2016a) which is subtracted from a sampled objective
value. The optimal baseline is difﬁcult to compute in gen-
eral, and we often use alternatives that are efﬁciently com-
puted, some of which are based on model-speciﬁc heuris-
tics. The reparameterization trick, on the other hand, has a
small estimation variance in practice and is only applicable
to models with certain continuous variables. Various mod-
els with continuous variables have been proposed using it,
whereas less progress on the research of deep discrete vari-
able models has been made because of the inapplicability
of this method.

In this paper, we give a novel framework to formulate gra-
dient estimators.
It is derived by the reparameterization
and the local marginalization analogous to the local ex-
pectation gradient (Titsias & L´azaro-Gredilla, 2015). The
likelihood-ratio method and the reparameterization trick
can be formalized under this framework, and therefore it
bridges these two families of estimators. We can derive the
optimal estimator, which gives a lower bound of the vari-
ance of all estimators covered by the framework. Since the
estimator is derived by applying local marginalization to
the reparameterized gradient, we named it the reparame-
terization and marginalization (RAM) estimator. This esti-
mator is an instance of the likelihood-ratio estimator with
the optimal baseline, and therefore it can be used to evalu-
ate the variance of existing baseline techniques.

When the variable of interest follows a Bernoulli distribu-
tion, we can derive a tighter connection of a wider range of

Evaluating the Variance of Likelihood-Ratio Gradient Estimators

estimators to the framework. For example, the local expec-
tation gradient (Titsias & L´azaro-Gredilla, 2015) becomes
covered by our framework, and the straight-through estima-
tor (Hinton, 2012; Bengio et al., 2013; Raiko et al., 2015)
approximates the optimal estimator where the ﬁnite differ-
ence of the objective function is replaced by the inﬁnites-
imal ﬁrst-order approximation. Furthermore, the optimal
estimator is reduced to a likelihood-ratio estimator with
an input-dependent baseline, which implies that a practical
baseline technique might achieve a near-optimal variance.

The rest of this paper is organized as follows. We overview
the related work in Sec.2 and formulate the gradient esti-
mation problem in Sec.3. We introduce our framework in
Sec.4 and derive important estimators with it in Sec.5. We
also introduce a wider range of estimators for Bernoulli
variables in Sec.6. We then show experimental results in
Sec.7 and give a conclusion in Sec.8.

2. Related Work

The gradient estimation problem was being studied in the
ﬁeld of simulation around 1990, which is well summa-
rized in L’Ecuyer (1991). The likelihood-ratio method
(Glynn, 1989) is a general approach for solving the prob-
lem, in which the parametric density qφ(z) is replaced by
qφ(z)
q0(z) q0(z) where q0 := qφ is ﬁxed against φ on differentia-
tion. The ratio qφ(z)
q0(z) is called the likelihood ratio, hence the
name of this method. It can be seen as an importance sam-
pling method that uses a proposal q0 (Jie & Abbeel, 2010),
with which there is a study on reducing the variance by us-
ing a proposal better than q0 (Ruiz et al., 2016a). Another
approach is the ﬁnite-difference method, in which the use
of common random numbers, i.e., using the same random
numbers to run two perturbed simulations, is effective in
reducing the variance. The common random numbers nat-
urally appear in the formulation of the optimal estimator of
our framework.

The likelihood-ratio method has been combined with base-
lines and was introduced to the policy gradient methods for
reinforcement learning, which is called the REINFORCE
algorithm (Williams, 1992). The baseline technique is used
for reducing the variance. A simple estimation of the av-
erage reward is commonly used as the baseline, and the
optimal constant baseline that minimizes the variance is
also derived (Weaver & Tao, 2001). The likelihood-ratio
estimator has also been used for black-box variational in-
ference (Ranganath et al., 2014). The likelihood-ratio es-
timator is used to derive the gradient estimation without
depending on the speciﬁc form of the distributions. From
a statistical point of view, the baseline can be seen as a
special form of control variates, for which the optimal one
can be derived again. The baseline technique has been

further made sophisticated by involving the variable-wise
baselines and those depending on the varaible of interest
(Mnih & Gregor, 2014; Gu et al., 2016a). Some of them are
also exported to policy-gradient methods (Gu et al., 2016b).
Taking the local expectation of the likelihood-ratio estima-
tor (Titsias & L´azaro-Gredilla, 2015) is another approach
of variance reduction.

For variational inference of models with continuous vari-
ables, the reparameterization trick (Kingma & Welling,
2014; Rezende et al., 2014; Titsias & Lzaro-gredilla, 2014)
is widely used. It is easy to implement with modern frame-
works of automatic differentiation. It also has low variance
in practice, although the superiority to the likelihood-ratio
estimator is not guaranteed in general (Gal, 2017). This
method is also applied to the continuous relaxation of dis-
crete variables (Jang et al., 2016; Maddison et al., 2016).

On the one hand, the connection between the likelihood-
ratio method and the reparameterization trick is studied
in some literature, especially on continuous variables for
which a tractable reparameterization is not available (Ruiz
et al., 2016b). On the other hand, there are fewer studies for
discrete variables. This paper provides a bridge between
these estimators for discrete variables.

3. Problem Formulation

Our task is to optimize an expectation over a parame-
terized distribution. The objective function is given as
F (φ; x) = Eqφ(z|x)f (x, z), where f is a feasible function,
qφ(z|x) = (cid:81)M
i=1 qφi(zi|pai) is a directed graphical model
of M variables z = (z1, . . . , zM ) conditioned on an input
to the system x, pai are the parent nodes of zi, and φ are
the model parameters. Each conditional qφi(zi|pai) is con-
tinuously differentiable w.r.t. φi and is typically a simple
distribution such as a Bernoulli or Gaussian whose param-
eters are computed by a neural network with weights φi.
For simplicity, we will assume that φi and φi(cid:48) for i (cid:54)= i(cid:48)
do not share any parameters; however, this assumption can
be easily removed. We want to optimize F by stochastic
gradient methods, which require an unbiased estimation of
its gradient ∇φF .

A motivating example is variational learning of a genera-
tive model pθ(x, z) with an approximate posterior qφ(z|x).
In this case, the objective function is the expectation of
f (x, z) = log pθ(x, z) − log qφ(z|x), which gives a lower
bound of the log likelihood log pθ(x). On the one hand,
the gradient w.r.t. the generative parameter θ is easily es-
timated by a Monte Carlo simulation. On the other hand,
estimating the gradient w.r.t. φ is not trivial, which falls
into the above general setting. Note that we omit the gra-
dient incurred from the dependency of the second term
− log qφ(z|x) on φ from our discussions since this gradi-

Evaluating the Variance of Likelihood-Ratio Gradient Estimators

ent term is easy to estimate with low variance.

4. Proposed Framework

Here we give a general formulation of our framework of
gradient estimation. The framework is based on the repa-
rameterization of variables, which we also review.

Suppose that each sample drawn from a conditional is repa-
rameterized as follows.

H(µi(pai; φi) − (cid:15)i) is not continuous in general. For cate-
gorical variables, we can use the Gumbel-Max trick (Gum-
bel, 1954; Jang et al., 2016; Maddison et al., 2016) for the
reparameterization in a similar way.

5. Derivation of Gradient Estimators

We derive existing estimators on the basis of our general
framework (1). We also derive the estimator that is optimal
in terms of the estimation variance.

zi ∼ qφi(zi|pai) ⇔ zi = gφi(pai, (cid:15)i), (cid:15)i ∼ p((cid:15)i).

5.1. Likelihood-Ratio Estimator

Here (cid:15)i is a noise variable. We will give concrete examples
of reparameterization later, and here we only emphasize
that gφi might be a non-continuous function. We write the
whole reparameterization as z = gφ(x, (cid:15)).

form of gradient

reparameterization, we derive the gen-
Using this
(cid:15)\i =
eral
{(cid:15)1, . . . , (cid:15)i−1, (cid:15)i+1, . . . , (cid:15)M }. We partially exchange the
differentiation and integration as follows.

estimation.

Let

∇φiF (φ; x) = ∇φi

E(cid:15)f (x, gφ(x, (cid:15)))

= E(cid:15)\i∇φi

E(cid:15)if (x, gφ(x, (cid:15))).

(1)

Unlike the reparameterization trick, this equation holds
even if the function gφ is not continuous because the lo-
cal expectation E(cid:15)if (x, gφ(x, (cid:15))) is differentiable. The
technique of separating variables in leave-one-out man-
(8) of Titsias & L´azaro-Gredilla
ner is similar to Eq.
(2015), whereas it is applied to reparameterized, mutually-
independent noise variables in our case.

Equation (1) gives our framework of gradient estima-
Given a way to estimate the local gradient
tion.
E(cid:15)i f (x, gφ(x, (cid:15))), we can estimate ∇φiF (φ; x) by
∇φi
sampling (cid:15)\i and estimating the local gradient. Many exist-
ing estimators are derived by specifying a method of local
gradient estimation, which we review in the next section.

Examples of Reparameterization: We introduce typi-
cal ways of reparameterizing popular distributions. When
qφi(zi|pai) = N (zi|µi, σ2
i ) is a Gaussian distribution, zi
can be reparameterized as zi = µi + (cid:15)iσi, (cid:15)i ∼ N ((cid:15)i; 0, 1)
(Kingma & Welling, 2014).
In this case, the change-of-
variable formula gφi(pai, (cid:15)i) = µi(pai; φi) + (cid:15)iσi(pai; φi)
is differentiable w.r.t. φi. We can derive a reparame-
terization for Bernoulli variables as well. Suppose zi ∈
{0, 1} is a binary variable following a Bernoulli distribu-
tion qφi(zi|pai) = µzi
i (1 − µi)1−zi. It can be reparameter-
ized using a uniform noise (cid:15)i ∼ U (0, 1) as zi = H(µi−(cid:15)i),

where H(x) =

is the Heaviside step func-

(cid:40)

1 (x > 0)
0 (x ≤ 0)

tion.

In this case, the change-of-variable formula zi =

The likelihood-ratio estimator is derived by using the log-
derivative trick for the local gradient estimation. Let
bi(x, (cid:15)) be a baseline for zi, and (cid:15)\i ∼ p((cid:15)\i). We use
z = gφ(x, (cid:15)) and omit the dependency of z on (cid:15). The
likelihood-ratio estimator with baseline bi is a Monte Carlo
estimate of the following expectation.

E(cid:15)if (x, gφ(x, (cid:15)))

∇φi
= E(cid:15)i(f (x, z) − bi(x, (cid:15)))∇φi log qφi(zi|pai) + Ci(x, (cid:15)\i).
(2)

Here Ci(x, (cid:15)\i) = E(cid:15)ibi(x, (cid:15))∇φi log qφi(zi|pai), which
has to be analytically computed.

There are many baseline techniques for variance reduction.
We classify them into four categories as follows.

• Constant baseline is a constant of all variables {x, (cid:15)}.
It is a common choice for the baseline. In this case, it
holds that Ci = 0. An exponential moving average of
the simulated function f is often used.

• Independent baseline is a baseline that is constant
against (cid:15)i. It can depend on other variables, {x, (cid:15)\i}.
In this case, it again holds that Ci = 0. Two tech-
niques proposed by Mnih & Gregor (2014) can be
seen as examples of baselines in this class. One is the
input-dependent baseline, which is a neural network
that predicts the sampled objective value f (x, z) from
x and pai. The other one is the use of local signals,
where the terms of f that are not descendants of zi
in the stochastic computational graphs are omitted. It
can be seen as a baseline that includes all these terms.

• Linear baseline is a baseline that is a linear function of
zi, i.e., bi = z(cid:62)
i ui(x, (cid:15)\i) + vi(x, (cid:15)\i) 1, where ui and
vi are arbitrary functions. In this case, we can write
Ci = (∇φiµi)(cid:62)ui(x, (cid:15)\i), where µi = Eqφi (zi|pai)zi
is the mean of zi. The MuProp estimator (Gu et al.,

1When zi is a binary or continuous scalar, the transposition is
not needed. When zi is a categorical variable, we represent it by a
one-hot vector, for which z(cid:62)
i ui is the innerproduct of two vectors.

Evaluating the Variance of Likelihood-Ratio Gradient Estimators

2016a) is an example of estimators with linear base-
lines, where the baseline is given as the ﬁrst-order ap-
proximation of the mean-ﬁeld network of f at µi.

• Fully-informed baseline is a baseline that depends on
all of x and (cid:15), possibly in a nonlinear way. This is the
most general class of baselines.

It is easily expected that the fully-informed baseline can
achieve the lowest variance. We will show that the optimal
estimator under the framework (1) falls into this category.

5.2. Reparameterization Trick Estimator

The reparameterization trick (Kingma & Welling, 2014;
Rezende et al., 2014; Titsias & Lzaro-gredilla, 2014) is a
common way to estimate the gradient for models with con-
tinuous variables. It is derived by exchanging the differ-
entiation and integration of the local gradient as follows.

∇φi

E(cid:15)if (x, gφ(x, (cid:15))) = E(cid:15)i∇φif (x, gφ(x, (cid:15))).

(3)

Note that this equation holds only if the function gφ(x, (cid:15))
is differentiable, and therefore the reparameterization trick
is only applicable to continuous variables.

The reparameterization trick often gives a better estimation
of the gradient compared with the likelihood-ratio estima-
tor, although there is no theoretical guarantee. Indeed, we
can construct an example for which the likelihood-ratio es-
timator gives a better estimation (Gal, 2017).

5.3. Optimal Estimator

E(cid:15)if (x, gφ(x, (cid:15))). Let z\i

The optimal estimator is obtained by analytically comput-
:=
ing the local gradient ∇φi
{z1, . . . , zi−1, zi+1, . . . , zM }. When we ﬁx (cid:15)\i and mod-
ify the value of zi, the descendant variables of zi might be
changed because they are functions of zi and noise vari-
ables. We denote the resulting values of z\i by z\i =
hφ\i(x, zi, (cid:15)\i). The function hφ\i(x, zi, (cid:15)\i) represents
the ancestral sampling procedure of z\i with given (cid:15)\i and
clamped zi. Using the reparameterization again, we obtain
E(cid:15)if (x, gφ(x, (cid:15))) = Eqφi (zi|pai)f (x, z). The local gradi-
ent is then computed as follows.

∇φi

E(cid:15)if (x, gφ(x, (cid:15)))
(cid:88)

(cid:12)
(cid:12)
f (x, z)∇φiqφi(zi|pai)
(cid:12)z\i=hφ\i

.

(4)

(x,zi,(cid:15)\i)

=

zi

If zi is continuous, the summation is replaced by an in-
tegral, which is approximated numerically. The resulting
algorithm is shown in Alg. 1, which we name the repa-
rameterization and marginalization (RAM) estimator.
It
requires M times evaluations of h, and therefore it scales

Algorithm 1 Algorithm for RAM estimator (4) for discrete
zi’s. If zi is continuous, the loop over all the conﬁgurations
of zi is replaced by a loop over integration points.
Require: a set of parameters φ and an input variable x.
1: Sample (cid:15) ∼ p((cid:15)).
2: for i = 1, . . . , M do
3:
4:
5:
end for
6:
7: ∆i := (cid:80)
zi
8: end for
9: return (∆1, . . . , ∆M ) as an estimation of ∇F (φ; x).

z\i := hφ\i(x, zi, (cid:15)\i).
fzi := f (x, z)∇φiqφi(zi|pai).

for all conﬁgurations of zi do

fzi.

worse than other estimators 2. However, these evaluations
are easily parallelized, and it runs fast enough for models
of moderate size.

The optimality of this estimator is stated in the following
theorem. Let φij be the j-th element of the vector of pa-
rameters φi, and let ∂ij = ∂/∂φij for notational simplicity.
Theorem 1. Suppose an unbiased estimator δij of the local
derivative ∂ijE(cid:15)if (x, gφ(x, (cid:15))), i.e., δij is a random vari-
able whose expectation matches the local derivative. Let
Vij be the variance of the estimator δij and V (cid:63)
ij be the vari-
ance of the RAM estimator. Then, it holds that V (cid:63)
ij ≤ Vij.

Proof. This
Blackwellization argument.

follows

from the

standard

Rao-

We brieﬂy review the relationships between the RAM esti-
mator and existing ones.

Relationship to the Likelihood-Ratio Estimator: The
RAM estimator can be seen as an example of
the
likelihood-ratio estimators with fully-informed baselines.
Let bi(x, (cid:15)) = f (x, gφ(x, (cid:15))). Then, the log-derivative term
of Eq. (2) is canceled, and only the residual Ci(x, (cid:15)\i) =
E(cid:15)i f (x, gφ(x, (cid:15))) remains. The analytically-computed
∇φi
residual is equivalent to the RAM estimator. Since this es-
timator gives the minimum variance, our likelihood-ratio
formulation (2) contains the optimal estimator.

While the fully-informed baseline is too general in practice
to be efﬁciently computed, much more restrictive indepen-
dent baselines can achieve the optimal estimator when zi
follows a Bernoulli distribution. Let V LR
ij (bi) be the vari-
ance of the likelihood-ratio estimator with baseline bi.
Theorem 2. Suppose that qφi(zi|pai) is a Bernoulli distri-
bution. Then, there is one and only one baseline b(cid:63)
i such

2 The difference in computational cost against the local expec-
tation gradient (Titsias & L´azaro-Gredilla, 2015) comes from the
inapplicability of pivot samples.

Evaluating the Variance of Likelihood-Ratio Gradient Estimators

that b(cid:63)

i is constant against (cid:15)i and V (cid:63)

ij = V LR

ij (b(cid:63)

i ).

The proof is given in Sec.6. This result implies that, for
Bernoulli variables, the optimal variance might be obtained
by a practical class of baseline techniques. Note that the
optimal baseline b(cid:63)
i might depend on the noise variables
corresponding to the descendants of zi, which are not used
by existing baseline techniques.

The RAM estimator can be seen as an application of the
same technique to the reparameterized expectation (3).
Thanks to the reparameterization, there is no need to solve
the inference problem qφ(zi|mbi), and therefore the prob-
lematic density ratio factor does not appear. The evaluation
of f (x, z) with ﬁxed z\i does not reﬂect the full inﬂuence
of the choice of zi, whereas the reparameterized counter-
part f (x, z)|z\i=hφ\i

(x,zi,(cid:15)\i) does reﬂect it.

Relationship to the Reparameterization Trick: Theo-
rem 1 also states that the RAM estimator gives a variance
not larger than that of the reparameterization trick.
In-
deed, the RAM estimator is based on an analytical com-
putation of the integral (3), and therefore gives the lower
or equal variance. In practice, it is infeasible to compute
the local gradient analytically, and numerical approxima-
tion is required. We can approximate the integral with high
precision in practice, because zi is usually a scalar vari-
able and therefore we only need to evaluate the function
f (x, gφ(x, (cid:15))) at a few integration points of zi.

Relationship to the Local Expectation Gradient: The
local expectation gradient (Titsias & L´azaro-Gredilla,
2015) is an application of local marginalization to the
likelihood-ratio estimator. Let mbi be the Markov blanket
of zi. This estimator is then derived as follows.

∇φiF (φ; x)
= Eqφ(z|x)f (x, z)∇φi log qφi(zi|pai)
= Eqφ(z\i|x)Eqφ(zi|mbi)f (x, z)∇φi log qφi(zi|pai)

= Eqφ(z\i|x)

(cid:88)

zi

qφ(zi|mbi)
qφi(zi|pai)

f (x, z)∇φiqφi(zi|pai). (5)

For the Monte Carlo simulation of z\i, z is ﬁrst sampled
from qφ(z|x), and then zi is discarded.
It corresponds
to sampling (cid:15) and computing z\i by using it in the repa-
If the latent variables z1, . . . , zM
rameterized notation.
are mutually independent given x, the density ratio factor
qφ(zi|mbi)/qφi(zi|pai) equals 1, and therefore this estima-
tor is equivalent to the RAM estimator (4). Otherwise, the
density ratio factor remains, and these estimators do not
match in general. The inference distribution qφ(zi|mbi)
can be computed as

qφ(zi|mbi) =

qφ(zi, mbi \ pai|pai)

qφ(zi, mbi \ pai|pai)

.

(cid:80)

zi

Therefore, the density ratio is proportional to qφ(zi, mbi \
pai|pai). It tends to concentrate on zi used in the sampling
of mbi \ pai, in which case the estimator degenerates to
the plain likelihood-ratio estimator. Therefore, it cannot be
guaranteed to have a lower variance than the likelihood-
ratio estimator with baselines in general.

6. Analyzing Estimators for Binary Variables

A Bernoulli variable is the most fundamental example of a
discrete variable, and some estimators are dedicated for it.
It is beneﬁcial to study the applications of any estimators
to Bernoulli variables because they facilitate understanding
and still contain most of the essential characteristics of dis-
crete distributions. In some cases, an estimator has a con-
nection to other estimators only when applied to Bernoulli
variables. Here we focus on Bernoulli variables and intro-
duce how each estimator can be formalized and related to
others. The derivations are given in the supplementary ma-
terial 3

Suppose that qφi(zi|pai) is a Bernoulli distribution of the
mean parameter µi = µi(pai, φi). Let fk = f (x, zi =
k, z\i = hφ\i(x, zi, (cid:15)\i)) for k ∈ {0, 1}, i.e., fk is the repa-
rameterized objective value for zi = k. All estimators we
introduce here can be written as an estimation of the gra-
dient w.r.t. µi multiplied by ∇φiµi, and therefore we only
focus on the gradient w.r.t. µi denoted by ∆i.

6.1. Likelihood-Ratio Estimator

The likelihood-ratio estimator for a Bernoulli variable with
an independent baseline bi is written as follows.

(cid:40)

∆LR

i =

(f1 − bi)/µi

w.p. µi,

−(f0 − bi)/(1 − µi) w.p. 1 − µi.

(6)

It can be interpreted as an importance sampling estimation
of the sum of f1 −bi and −(f0 −bi). Indeed, the likelihood-
ratio estimator for the general class of distributions can be
seen as an importance sampling estimation of the expecta-
tion. When the distribution has low entropy (i.e., µi is close
to 0 or 1), the variance of ∆LR
becomes large. However,
i
it does not always mean that the variance of the gradient
w.r.t. φi becomes huge, because in this case the sigmoid
activation that outputs µi is in a ﬂat regime so that its small
derivative somehow alleviates the large variance. Neither
does it mean that the variance is always small enough to
optimize complex models.

3The supplementary material is attached to the arXiv version

of this paper.

Evaluating the Variance of Likelihood-Ratio Gradient Estimators

6.2. Optimal Estimator

It is further rewritten as follows.

The RAM estimator of the gradient w.r.t. µi is simply writ-
ten as the difference of the f value at zi = 1 and zi = 0.

∆LEG
i

=




f1− 1−πi
1−µi

((1−µi)f1+µif (cid:48)
0)

f0− πi
µi



−

µi

((1−µi)f (cid:48)
1−µi

1+µif0)

w.p. µi,

w.p. 1 − µi.

∆(cid:63)

i = f1 − f0.

(7)

Thus, it can be seen as a likelihood-ratio estimator with
baseline

Using this formulation, we can prove Theorem 2.

Proof of Theorem 2. Let bi = (1 − µi)f1 + µif0. Then, the
likelihood-ratio estimator (6) with baseline bi is equivalent
to the RAM estimator (7). In this case, both cases of (6)
are equal to ∆(cid:63)
i . This baseline does not depend on (cid:15)i, and
therefore we conclude the proof by letting b(cid:63)

i = bi.

Interestingly, the optimal baseline is an expectation of fk
with the mean of k being 1 − µ instead of µ. This is differ-
ent from the mean objective value ¯f = µif1 + (1 − µi)f0,
which a constant mean baseline approximates. The differ-
ence becomes large when µi is close to 0 or 1.

The optimal estimator still has a positive variance since
the noise variables (cid:15)\i are not integrated out. In Eq. (7),
f1 and f0 are evaluated with the same conﬁgurations of
these noise variables. The likelihood-ratio estimator can
also be seen as an estimator that separately samples f1
and f0 at different iterations in which they use the sep-
arate samples of (cid:15)\i. When the number of variables is
large, the inﬂuence of one variable zi on the objective
value f (x, z) is small, and we can expect that f1 and f0
have a positive covariance. In general, the estimation vari-
ance of the difference of two random variables X, Y is re-
duced by estimating them with a positive covariance since
V[X − Y ] = VX + VY − 2Cov(X, Y ), and therefore
our estimator effectively reduces the variance by using the
same conﬁguration of the noise variables. This technique
is known as common random numbers, which is also used
to reduce the variance of the gradient estimations with the
ﬁnite difference method for stochastic systems (L’Ecuyer,
1991).

6.3. Local Expectation Gradient

The local expectation gradient (5) has a special view as a
likelihood-ratio estimator when zi is a Bernoulli variable.
Let πi = qφ(zi = 1|mbi). Let f (cid:48)
k = f (x, zi = k, z\i =
hφ\i(x, zi = 1 − k, (cid:15)\i)), i.e., f (cid:48)
1−k is the objective value
with ﬁxed z\i and ﬂipped zi. Note that f (cid:48)
k can be different
from fk when some variables in z\i depend on zi. Then,
the local expectation gradient is written as follows.

∆LEG
i

=

(cid:40) πi
µi
πi
µi

f1 − 1−πi
1−µi
1 − 1−πi
f (cid:48)
1−µi

f (cid:48)
0 w.p. µi,
f0 w.p. 1 − µi.

bLEG
i

=

1 − qφ(zi|mbi)
1 − qφi(zi|pai)

b(cid:48)
ik

ik = (1 − qφi(zi|pai))fk + qφi(zi|pai)f (cid:48)

where b(cid:48)
1−k. The
unweighted value b(cid:48)
ik has a similar form as the optimal
i , where f1−k is replaced by f (cid:48)
baseline b(cid:63)
1−k. The ﬁnal
baseline bLEG
is given by multiplying b(cid:48)
ik by the density
i
ratio. We have seen that it tends to be close to 0, in which
case the baseline is also close to 0 so that the estimator de-
generates to the plain likelihood-ratio estimator. Even if
the weight does not vanish, Theorem 2 shows that the lo-
cal expectation gradient estimator for Bernoulli variables
has higher variance than the optimal one unless all latent
variables are mutually independent given x.

6.4. Straight-Through Estimator

We give one example of an estimator dedicated for
Bernoulli variables, the straight-through estimator (Hinton,
2012; Bengio et al., 2013; Raiko et al., 2015). It is a bi-
ased estimator that leverages the gradient of f so that we
can obtain the high-dimensional information of the direc-
tion towards which the objective would be decreasing. The
estimator is written as follows.



(8)




∂f
∂zi

∂f
∂zi

∆ST

i =

w.p. µi,

w.p. 1 − µi.

(cid:12)
(cid:12)
(cid:12)zi=1
(cid:12)
(cid:12)
(cid:12)zi=0
Observing that Eq. (7) gives the ﬁnite difference of f be-
tween zi = 1 and zi = 0, we can see that the straight-
through estimator is its inﬁnitesimal counterpart at the sam-
pled zi. Thus, this estimator is equivalent to our estima-
tor (and is therefore unbiased) when f is a linear function
of zi. The difference between these estimators becomes
large when the nonlinearity of f increases. If we consider
a general class of the evaluation function f , we can con-
struct an adversarial function f such that the derivative at
zi ∈ {0, 1} has the opposite sign against the ﬁnite differ-
ence (7). For example, when f (x, z) = (cid:80)
i zi, this estima-
tor is equivalent to the optimal one. However, if we modify
it to ˜f (x, z) = (cid:80)
i zi), the straight-through
estimator always gives a gradient opposite to the steepest
direction of the expectation, which does not change as a
result of the modiﬁcation, i.e., E ˜f (x, z) = Ef (x, z).

i zi − sin (2π (cid:80)

7. Experiments

We conduct experiments to empirically verify Theorem 1
and to demonstrate a procedure to analyze the optimal de-

Evaluating the Variance of Likelihood-Ratio Gradient Estimators

gree of a given estimator covered by our framework. All
the methods are implemented with Chainer (Tokui et al.,
2015).

7.1. Experimental Settings

The task is variational learning of sigmoid belief networks
(SBN) (Neal, 1992), which is a directed graphical model
with layers of Bernoulli variables. Let x ∈ {0, 1}d be a
binary vector of input data and Z(cid:96) = (z(cid:96),1, . . . , z(cid:96),N(cid:96)) ∈
{0, 1}N(cid:96) be a binary vector of the latent variables at the (cid:96)-
th layer. Denote the input layer as Z0 = x for notational
simplicity. Let L be the number of latent layers. The gen-
erative model is speciﬁed by a conditional of each layer
pθ(Z(cid:96)|Z(cid:96)+1) and the prior of the deepest layer pθ(ZL).
In our experiments, the prior of each variable zL,i ∈ ZL
is independently parameterized by its logit. The condi-
tional pθ(Z(cid:96)|Z(cid:96)+1) is modeled by an afﬁne transformation
of Z(cid:96)+1 that outputs the logit of Z(cid:96). The parameters of the
afﬁne transformation are optimized through the learning.
We use two models with L = 2 and L = 4, respectively.
Each layer consists of N(cid:96) = 200 Bernoulli variables.

We model the approximate posterior qφ(z|x) by a reverse-
directional SBN. In this case, the prior q(x) is not modeled,
and each conditional qφ(Z(cid:96)+1|Z(cid:96)) is speciﬁed by its logit
as an afﬁne transformation of Z(cid:96).

Both the generative parameter θ and the variational param-
eter φ are optimized simultaneously to maximize the fol-
lowing variational lower bound.

the mean equal to the pixel intensity (Salakhutdinov &
Murray, 2008). The binarization is done in an online man-
ner, i.e., we sample binarized vectors at each iteration. For
the MNIST dataset, we use the standard split of 60,000
training images and 10,000 test images. The training im-
ages are further split into 50,000 images and 10,000 im-
ages, the latter of which are used for validation. For the
Omniglot dataset, we use the standard split of 24,345 train-
ing images and 8,070 test images used in the ofﬁcial im-
plementation of Burda et al. (2015) 4. The training images
are further split into 20,288 images and 4,057 images, the
latter of which are used for validation.

We used RMSprop (Tieleman & Hinton, 2012) with a mini-
batch size of 100 to optimize the variational lower bound.
We apply a weight decay of the coefﬁcient 0.001 for all pa-
rameters. All the weights are initialized with the method of
Glorot & Bengio (2010). The learning rate is chosen from
{3 × 10−4, 10−3, 3 × 10−3}. We evaluate the model on
the validation set during training, and choose the learning
rate with which the best validation performance with early-
stopping beats the others. After each evaluation, we also
measure the variance of the gradient estimations of varia-
tional parameters for the training set with the same mini-
batch size.

Each experiment is done on an Intel(R) Xeon(R) CPU E5-
2623 v3 at 3.00 GHz and an NVIDIA GeForce Titan X.
Thanks to the parallel computation using the GPU, the
computational time of the RAM estimator is only two times
larger than the plain likelihood-ratio estimator.

log pθ(x) = log Eqφ(z|x)

7.2. Results

pθ(x, z)
qφ(z|x)
pθ(x, z)
qφ(z|x)

≥ Eqφ(z|x) log

= L.

The second line follows Jensen’s inequality with the con-
cavity of log. The gradient w.r.t. θ is estimated by a Monte
Carlo simulation of ∇θL = Eqφ(z|x)∇θ log pθ(x, z). We
use gradient estimators for approximating the gradient
w.r.t. φ.

The plain likelihood-ratio estimator is denoted by LR,
whereas the constant baseline using the moving average
of f (x, z) = log pθ(x, z) − log qφ(z|x) and the input-
dependent baseline of Mnih & Gregor (2014) are expressed
by the postﬁxes +C and +IDB, respectively. We also run
experiments for MuProp and the Local Expectation Gradi-
ent (LEG). Algorithm 1 is used to obtain the results for the
optimal estimator.

We use MNIST (Lecun et al., 1998) and Omniglot (Lake
et al., 2015) for our experiments. These are sets of 28x28
pixel gray-scale images of hand-written digits and hand-
written characters from various languages. We binarize
each pixel by sampling from a Bernoulli distribution with

The results for the two-layer SBN and four-layer SBN are
shown in Fig. 1 and Fig. 2, respectively. The results for
these models have almost the same trends. As is predicted
by Theorem 1, the optimal estimator gives the lower bound
of the estimation variance. The plots imply that the modern
baseline techniques effectively reduce the estimation vari-
ance, which is approaching the optimal value. However, the
gap between these practical methods and the optimal one
is not negligible, and there is still room for improvements.
The local expectation gradient actually does not degenerate
to the plain likelihood-ratio estimator, whereas the variance
reduction effect is limited so that its variance stays at a sim-
ilar level to that of the likelihood-ratio estimator with a con-
stant baseline. The validation score almost agrees with the
variance level, although there are some exceptions caused
by the differences in selected learning rates.

Note that we do not align the computational cost by sam-
pling multiple values in the experiments because the pur-
pose of these experiments is evaluating the optimal degree

4https://github.com/yburda/iwae

Evaluating the Variance of Likelihood-Ratio Gradient Estimators

Figure 1. Results of two-layer SBN. Left: results using MNIST dataset. Right: results using Omniglot dataset. The mean of the gradient
variances of the variational parameters are plotted in the top ﬁgures. The validation performance is plotted in the bottom ﬁgures.

Figure 2. Results of four-layer SBN. Left: results using MNIST dataset. Right: results using Omniglot dataset.

of each method. We can infer the performance with aligned
computational budget by comparing the variance and the
computational cost.

8. Conclusion

We introduced a novel framework of gradient estimation
for stochastic computations using reparameterization. The
framework serves as a bridge between the likelihood-ratio
method and the reparameterization trick. The optimal esti-
mator is naturally derived under the framework. It provides
the minimum variance attainable by the likelihood-ratio es-
timators with the general class of baselines, and therefore
can be used to evaluate the optimal degree of each practi-
cal baseline technique. We actually evaluated the common
baseline techniques against the optimal estimator for varia-
tional learning of sigmoid belief networks and showed that
the modern techniques achieve a variance level close to the
lower bound.

Comparison between continuous variable models and dis-
crete variable models is needed for the further development
of deep probabilistic modeling, which should consider the
adequacy of the use of these variables in each task and the
efﬁciency of gradient estimators available for these mod-
els. While this study does not provide a way to compare
such models in general, it bridges the gradient estimators
of them through the optimal case, and therefore provides
some insights on their relationships. Observing the exper-
imental results, the modern estimators for Bernoulli vari-
ables achieve variance close to the optimal one, and there-
fore we can expect that the modern estimators for Bernoulli
variables are maturing and could be applied to much larger
models capturing discrete phenomena.

ACKNOWLEDGMENTS

We thank members of Preferred Networks, especially
Daisuke Okanohara, for the helpful discussions.

100102104Gradient varianceLRLR+CLR+C+IDBMuProp+C+IDBLEGoptimal025050075010001250150017502000Iteration (x1000)−140−120−100Variational lower boundMNIST (200-200-784)100102104Gradient varianceLRLR+CLR+C+IDBMuProp+C+IDBLEGoptimal025050075010001250150017502000Iteration (x1000)−140−120Variational lower boundOmniglot (200-200-784)100102104Gradient varianceLRLR+CLR+C+IDBMuProp+C+IDBLEGoptimal025050075010001250150017502000Iteration (x1000)−140−120−100Variational lower boundMNIST (200-200-200-200-784)100102104Gradient varianceLRLR+CLR+C+IDBMuProp+C+IDBLEGoptimal025050075010001250150017502000Iteration (x1000)−140−120Variational lower boundOmniglot (200-200-200-200-784)Evaluating the Variance of Likelihood-Ratio Gradient Estimators

References

Bengio, Yoshua, L´eonard, Nicholas, and Courville,
Aaron C. Estimating or propagating gradients through
stochastic neurons for conditional computation. ArXiv,
1308.3432, 2013.

Burda, Yuri, Grosse, Roger, and Salakhutdinov, Ruslan.
In Proceedings of
Importance weighted autoencoders.
the 3rd International Conference on Learning Represen-
tations (ICLR), 2015.

Gal, Yarin. Uncertainty in Deep Learning. PhD thesis,
Department of Engineering, University of Cambridge,
2017.

Glorot, Xavier and Bengio, Yoshua. Understanding the dif-
ﬁculty of training deep feedforward neural networks. In
In Proceedings of the International Conference on Arti-
ﬁcial Intelligence and Statistics (AISTATS10), 2010.

Glynn, P. W. Optimization of stochastic systems via sim-
ulation. In Proceedings of the 21st Conference on Win-
ter Simulation, pp. 90–105, 1989. doi: 10.1145/76738.
76750.

Glynn, Peter W. Likelihood ratio gradient estimation for
stochastic systems. Communication of the ACM, 33(10):
75–84, 1990. doi: 10.1145/84537.84552.

Gu, Shixiang, Levine, Sergey, Sutskever, Ilya, and Mnih,
Andriy. Muprop: Unbiased backpropagation for stochas-
tic neural networks. In Proceedings of the 4th Interna-
tional Conference on Learning Representations (ICLR),
2016a.

Gu, Shixiang, Lillicrap, Timothy, Ghahramani, Zoubin,
Turner, Richard E., and Levine, Sergey.
Q-prop:
Sample-efﬁcient policy gradient with an off-policy critic.
In NIPS 2016 Deep Reinforcement Learning Workshop,
2016b.

Gumbel, Emil Julius. Statistical theory of extreme values
and some practical applications. U. S. Govt. Print. Of-
ﬁce, 1954.

Hinton, Geoffrey. Neural networks for machine learning.

Coursera, video lectures, 2012.

Jang, E., Gu, S., and Poole, B. Categorical Reparameteri-
zation with Gumbel-Softmax. ArXiv e-prints, 2016. To
appear in ICLR 2017.

Jie, Tang and Abbeel, Pieter. On a connection between im-
portance sampling and the likelihood ratio policy gradi-
ent. In Advances in Neural Information Processing Sys-
tems 23, pp. 1000–1008. 2010.

Kingma, Diederik P. and Welling, Max. Auto-encoding
In Proceedings of the International
variational bayes.
Conference on Learning Representations (ICLR), 2014.

Lake, Brenden M., Salakhutdinov, Ruslan, and Tenen-
baum, Joshua B. Human-level concept learning through
probabilistic program induction. Science, 350(6266):
1332–1338, 2015. doi: 10.1126/science.aab3050.

Lecun, Yann, Bottou, L´eon, Bengio, Yoshua, and Haffner,
Patrick. Gradient-based learning applied to document
recognition. In Proceedings of the IEEE, pp. 2278–2324,
1998.

L’Ecuyer, Pierre. An overview of derivative estimation. In
Proceedings of the 23rd Conference on Winter Simula-
tion, pp. 207–217, 1991. ISBN 0-7803-0181-1.

Maddison, Chris J., Mnih, Andriy, and Teh, Yee Whye. The
concrete distribution: A continuous relaxation of dis-
crete random variables. CoRR, abs/1611.00712, 2016.
To appear in ICLR 2017.

Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of
the 31st International Conference on Machine Learning
(ICML), pp. 1791–1799, 2014.

Neal, Radford M. Connectionist learning of belief net-

works. Artiﬁcial Intelligence, 56(1):71–113, 1992.

Paisley, John, Blei, David M., and Jordan, Michael I. Varia-
tional bayesian inference with stochastic search. In Pro-
ceedings of the 29 th International Conference on Ma-
chine Learning (ICML), 2012.

Raiko, Tapani, Berglund, Mathias, Alain, Guillaume, and
Dinh, Laurent. Techniques for learning binary stochastic
feedforward neural networks. In Proceedings of the 3rd
International Conference on Learning Representations
(ICLR), 2015.

Ranganath, Rajesh, Gerrish, Sean, and Blei, David M.
Black box variational inference. In Artiﬁcial Intelligence
and Statistics (AISTATS), pp. 814–822, 2014.

Rezende, Danilo Jimenez, Mohamed, Shakir, and Wierstra,
Daan. Stochastic backpropagation and approximate in-
In Proceedings of
ference in deep generative models.
the 31st International Conference on Machine Learning
(ICML), pp. 1278–1286, 2014.

Ruiz, F. J. R., Titsias, M. K., and Blei, D. M. Overdis-
persed black-box variational inference. In Uncertainty
in Artiﬁcial Intelligence (UAI), 2016a.

Ruiz, F. J. R., Titsias, M. K., and Blei, D. M. The general-
ized reparameterization gradient. In Advances in Neural
Information Processing Systems, 2016b.

Evaluating the Variance of Likelihood-Ratio Gradient Estimators

Rumelhart, David E., Hinton, Geoffrey E., and Williams,
Ronald J. Neurocomputing: Foundations of research.
chapter Learning Representations by Back-propagating
Errors, pp. 696–699. MIT Press, 1986.

Salakhutdinov, Ruslan and Murray, Iain. On the quantita-
tive analysis of Deep Belief Networks. In Proceedings
of the 25th Annual International Conference on Machine
Learning (ICML), pp. 872–879, 2008.

Schulman, John, Heess, Nicolas, Weber, Theophane, and
Abbeel, Pieter. Gradient estimation using stochastic
In Proceedings of the 28th Inter-
computation graphs.
national Conference on Neural Information Processing
Systems, pp. 3528–3536, 2015.

Tieleman, Tijmen and Hinton, Geoffrey. Lecture 6.5-
rmsprop: Divide the gradient by a running average of
its recent magnitude. In CORSERA: Neural Networks
for Machine Learning, 2012.

Titsias, Michalis and L´azaro-Gredilla, Miguel. Local ex-
pectation gradients for black box variational inference.
In Advances in Neural Information Processing Systems
28 (NIPS), pp. 2638–2646. 2015.

Titsias, Michalis and Lzaro-gredilla, Miguel. Doubly
stochastic variational bayes for non-conjugate inference.
In Proceedings of the 31st International Conference on
Machine Learning (ICML-14), pp. 1971–1979, 2014.

Justin.

Chainer:

Tokui, Seiya, Oono, Kenta, Hido, Shohei, and Clay-
a next-generation open
ton,
In Pro-
source framework for deep learning.
ceedings of Workshop on Machine Learning Sys-
tems (LearningSys) in The Twenty-ninth Annual Con-
Information Processing Systems
ference on Neural
(NIPS), 2015. URL http://learningsys.org/
papers/LearningSys_2015_paper_33.pdf.

Weaver, Lex and Tao, Nigel. The optimal reward baseline
for gradient-based reinforcement learning. In Proceed-
ings of the Seventeenth Conference on Uncertainty in
Artiﬁcial Intelligence, UAI’01, pp. 538–545, San Fran-
cisco, CA, USA, 2001. Morgan Kaufmann Publishers
ISBN 1-55860-800-1. URL http://dl.acm.
Inc.
org/citation.cfm?id=2074022.2074088.

Williams, Ronald J. Simple statistical gradient-following
learning.

algorithms for connectionist reinforcement
Machine Learning, 8(3):229–256, 1992.

