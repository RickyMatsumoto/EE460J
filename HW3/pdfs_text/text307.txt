An Adaptive Test of Independence with Analytic Kernel Embeddings

Supplementary Material

A. Type-I Errors

In this section, we show that all the tests have correct type-I errors (i.e., the probability of reject H0 when it is true) in real
problems. We permute the joint sample so that the dependency is broken to simulate cases in which H0 holds. The results
are shown in Figure 5.

(a) MSD problem (permuted sample).

(b) Videos & Captions problem (permuted
sample).

Figure 5: Probability of rejecting H0 as n increases. α = 0.01.

B. Redundant Test Locations

Here, we provide a simple illustration to show that two locations t1 = (v1, w1) and t2 = (v2, w2) which are too close
to each other will reduce the optimization objective. We consider the Sinusoid problem described in Section 3.1 with
ω = 1, and use J = 2 test locations. In Figure 6, t1 is ﬁxed at the red star, while t2 is varied along the horizontal line. The
objective value ˆλn as a function of t2 is shown in the bottom ﬁgure. It can be seen that ˆλn decreases sharply when t2 is
in the neighborhood of t1. This property implies that two locations which are too close will not maximize the objective
function (i.e., the second feature contains no additional information when it matches the ﬁrst). For J > 2, the objective
sharply decreases if any two locations are in the same neighborhood.

Figure 6: Plot of optimization objective values as location t2 moves along the green line. The objective sharply drops when
the two locations are in the same neighborhood.

C. Test Power vs. J

It might seem intuitive that as the number of locations J increases, the test power should also increase. Here, we empirically
show that this statement is not always true. Consider the Sinusoid toy example described in Section 3.1 with ω = 2 (also see
the left ﬁgure of Figure 7). By construction, X and Y are dependent in this problem. We run NFSIC test with a sample size
of n = 800, varying J from 1 to 600. For each value of J, the test is repeated for 500 times. In each trial, the sample is
π, π)2). There is no optimization of the test locations. We use
redrawn and the J test locations are drawn from Uniform((
−
Gaussian kernels for both X and Y , and use the median heuristic to set the Gaussian widths to 1.8. Figure 7 shows the test
power as J increases.

500100015002000Samplesizen0.000.010.02Type-IerrorNFSIC-optNFSIC-medQHSICNyHSICFHSICRDC500100015002000Samplesizen0.000.010.02Type-Ierror2000400060008000Samplesizen0.010.02Type-Ierror−2.50.02.5x−2.50.02.5yω=1.000.000.250.500.751.001.251.501.752.00x−202y−202t2175200225250ˆλn(t1,t2)An Adaptive Test of Independence with Analytic Kernel Embeddings

Figure 7: The Sinusoid problem and the plot of test power vs. the number of test locations.

We observe that the test power does not monotonically increase as J increases. When J = 1, the difference of pxy and pxpy
cannot be adequately captured, resulting in a low power. The power increases rapidly to roughly 0.6 at J = 10, and stays at
1 until about J = 100. Then, the power starts to drop sharply when J is higher than 400 in this problem.

Unlike random Fourier features, the number of test locations in NFSIC is not the number of Monte Carlo particles used to
approximate an expectation. There is a tradeoff: if the test locations are in key regions (i.e., regions in which there is a big
difference between pxy and pxpy), then they increase power; yet the statistic gains in variance (thus reducing test power) as
J increases. As can be seen in Figure 7, there are eight key regions (in blue) that can reveal the difference of pxy and pxpy.
Using an unnecessarily high J not only makes the covariance matrix ˆΣ harder to estimate accurately, it also increases the
computation as the complexity on J is

(J 3).

O

We note that NFSIC is not intended to be used with a large J. In practice, it should be set to be large enough so as to capture
the key regions as stated. As a practical guide, with optimization of the test locations, a good starting point is J = 5 or 10.

D. Proof of Proposition 3

Recall Proposition 3,
Proposition (A product of Gaussian kernels is characteristic and analytic). Let k(x, x(cid:48)) = exp (cid:0)
−
l(y, y(cid:48)) = exp (cid:0)
matrices A and B. Then, g((x, y), (x(cid:48), y(cid:48))) = k(x, x(cid:48))l(y, y(cid:48)) is characteristic and analytic on (Rdx

y(cid:48))(cid:1) be Gaussian kernels on Rdx

x(cid:48))(cid:1) and
x(cid:48))(cid:62)A(x
Rdy respectively, for positive deﬁnite
Rdy ).
Rdy )

Rdx and Rdy

−
(Rdx

y(cid:48))(cid:62)B(y

(x

(y

−

×

×

−

−

−

×

×

×

Proof. Let z := (x(cid:62), y(cid:62))(cid:62) and z(cid:48) := (x(cid:48)(cid:62), y(cid:48)(cid:62))(cid:62) be vectors in Rdx+dy . We prove by reducing the product kernel to one
Gaussian kernel with g(z, z(cid:48)) = exp (cid:0)
z(cid:48)) where
Ψ(t) := exp (cid:0)
t(cid:62)Ct(cid:1). Since C is positive deﬁnite, we see that the ﬁnite measure ζ corresponding to Ψ as deﬁned in
Lemma 12 has support everywhere in Rdx+dy . Thus, Sriperumbudur et al. (2010, Theorem 9) implies that g is characteristic.
Rdx+dy , z

. Write g(z, z(cid:48)) = Ψ(z

(cid:18) A 0
0 B

z(cid:48))(cid:1) where C :=

z(cid:48))(cid:62)C(z

(z

(z

−

−

−

−

−

(cid:19)

To see that g is analytic, we observe that for each z(cid:48)
in z, which is known to be analytic. Using the fact that t
functions is analytic, we see that z

∈
z(cid:48))(cid:62)C(z

exp (cid:0)

(z

(cid:55)→ −

z(cid:48))(cid:62)C(z

z(cid:48)) is a multivariate polynomial
exp(t) is analytic on R, and that a composition of analytic
z(cid:48))(cid:1) is analytic on Rdx+dy for each z(cid:48).

−

−

(cid:55)→

−

−

(cid:55)→
−

E. Proof of Theorem 5

Recall Theorem 5,
Theorem 5 (Independence test based on (cid:92)NFSIC2 is consistent). Let ˆΣ be a consistent estimate of Σ based on the joint
J
sample Zn, where Σ is deﬁned in Proposition 4. Assume that VJ =
η where η is absolutely continuous wrt
i=1 ∼
}
the Lebesgue measure. The (cid:92)NFSIC2 statistic is deﬁned as ˆλn := nˆu(cid:62) (cid:16) ˆΣ + γnI
parameter. Assume that

0 is a regularization

(vi, wi)
{

ˆu where γn

(cid:17)−1

≥

1. Assumption A holds.

2. Σ is invertible η-almost surely.

−2.50.02.5x−2.50.02.5yω=2.000.000.250.500.751.001.251.501.752.0010200400600J0.51.0TestpowerAn Adaptive Test of Independence with Analytic Kernel Embeddings

3. limn→∞ γn = 0.

Then, for any k, l and VJ satisfying the assumptions,

1. Under H0, ˆλn

χ2(J) as n

d
→

2. Under H1, for any r

is consistent.

∈

.
→ ∞
R, limn→∞ P

(cid:16)ˆλn

(cid:17)

r

≥

= 1 η-almost surely. That is, the independence test based on (cid:92)NFSIC2

Proof. Assume that H0 holds. The consistency of ˆΣ and the continuous mapping theorem imply that
which is a constant. Let a be a random vector in RJ following
d
→

(cid:2)a, Σ−1(cid:3) where u = 0 almost surely by Proposition 2, and √nˆu d
(cid:17)−1(cid:19)

(cid:16) ˆΣ + γnI

(cid:20)
√nˆu,

Σ−1
(0, Σ). By van der Vaart (2000, Theorem 2.7 (v)), it follows

(0, Σ) by Proposition

(cid:17)−1(cid:21)

→ N

(cid:17)−1

that

N

(cid:18)

(cid:16) ˆΣ + γnI

(cid:17)−1 p
→

(cid:16) ˆΣ + γnI

f (a, Σ−1). Equivalently, nˆu(cid:62) (cid:16) ˆΣ + γnI

4. Since f (x, S) := x(cid:62)Sx is continuous, f

√nˆu,

ˆu d
→

d
→

a(cid:62)Σ−1a

χ2(J) by Anderson (2003, Theorem 3.3.3). This proves the ﬁrst claim.

∼

The proof of the second claim has a very similar structure to the proof of Proposition 2 of Chwialkowski et al. (2015).
= 0 almost surely by Proposition 2. Since k and l are bounded, it follows that
Assume that H1 holds. Then, u
ht(z, z(cid:48))
u by Serﬂing (2009, Section 5.4, Theorem A). Thus,
|
| ≤
ˆu(cid:62) (cid:16) ˆΣ + γnI

2BkBl for any z, z(cid:48) (see (8)), and we have that ˆu a.s.
→
(cid:17)−1

u(cid:62)Σ−1u by the continuous mapping theorem, and the consistency of ˆΣ. Consequently,

ˆu

r
n

d
→

−

P

(cid:16)ˆλn

(cid:17)

r

lim
n→∞

= 1

lim
n→∞

−

(cid:18)
ˆu(cid:62) (cid:16) ˆΣ + γnI

(cid:17)−1

(cid:19)

< 0

r
n

ˆu

−

(a)
= 1

P (cid:0)u(cid:62)Σ−1u < 0(cid:1) (b)

= 1,

−

≥

P

(cid:55)→

where at (a) we use the Portmanteau theorem (van der Vaart, 2000, Lemma 2.2 (i)) guaranteeing that xn
P(xn < t)
Σ is positive deﬁnite so that u(cid:62)Σ−1u > 0, and t

d
→
(cid:55)→
P(u(cid:62)Σ−1u < t) (a step function) is continuous at 0.

x if and only if
P(x < t). Step (b) is justiﬁed by noting that the covariance matrix

P(x < t) for all continuity points of t

→

F. Proof of Theorem 7

Recall Theorem 7,
Theorem 7 (A lower bound on the test power). Let NFSIC2(X, Y ) := λn := nu(cid:62)Σ−1u. Let
be a kernel class for l, and

be a collection with each element being a set of J locations. Assume that

K

be a kernel class for k,

L

V

1. There exist ﬁnite Bk and Bl such that supk∈K supx,x(cid:48)∈X |
2. ˜c := supk∈K supl∈L supVJ ∈V (cid:107)
Then, for any k

.
∞
r, the test power satisﬁes P

F <
(cid:107)

Σ−1

| ≤

, and λn

, VJ

, l

k(x, x(cid:48))

∈ K

∈ L

∈ V

≥

Bk and supl∈L supy,y(cid:48)∈Y |

l(y, y(cid:48))

Bl.

| ≤

(cid:16)ˆλn

(cid:17)

r

≥

≥

L(λn) where

L(λn) = 1

62e−ξ1γ2

n(λn−r)2/n

−

−

2e−[(λn−r)γn(n−1)/3−ξ3n−c3γ2

−

2e−(cid:98)0.5n(cid:99)(λn−r)2/[ξ2n2]
/[ξ4n2(n−1)],

nn(n−1)]2

is the ﬂoor function, ξ1 :=

(cid:98)·(cid:99)
ξ3 := 8c1B2J, c3 := 4B2J ˜c2, ξ4 := 28B4J 2c2
ﬁxed n, L(λn) is increasing in λn.

32c2

1

1J 2B∗ , B∗ is a constant depending on only Bk and Bl, ξ2 := 72c2

2JB2, B := BkBl,
1, c1 := 4B2J√J ˜c, and c2 := 4B√J ˜c. Moreover, for sufﬁciently large

(cid:54)
An Adaptive Test of Independence with Analytic Kernel Embeddings

ˆλn
λn
/n. The bound is in turn upper bounded by
Overview of the proof We ﬁrst derive a probabilistic bound for
|
|
ˆu
u
F . The difference
an expression involving
2 can be bounded by applying the bound for
(cid:107)
(cid:107)
−
ˆΣ
Σ
U-statistics given in Serﬂing (2009, Theorem A, p. 201). For
F , we decompose it into a sum of smaller components,
(cid:107)
(cid:107)
and bound each term with a product variant of the Hoeffding’s inequality (Lemma 9). L(λn) is obtained by combining all
the bounds with the union bound.

u
2 and
(cid:107)

ˆΣ
(cid:107)

Σ
(cid:107)

−
−

−

−

ˆu

(cid:107)

F.1. Notations

(cid:104)

A, B

A
(cid:107)

X × Y

. We write t := (v, w) to denote a pair of test locations from

(cid:105)F := tr(A(cid:62)B) denote the Frobenius inner product, and

Let
z := (x, y) to denote a pair of points from
brevity, an expectation over (x, y) (i.e., E(x,y)∼Pxy ) will be written as Ez or Exy. Deﬁne ˜k(x, v) := k(x, v)
and ˜l(y, w) := l(y, w)
−
Similarly, deﬁne BF (r) :=
| (cid:107)
Denote the max operation by (x1, . . . , xm)+ = max(x1, . . . , xm).
For a product of marginal mean embeddings µx(v)µy(w), we write (cid:91)µxµy(v, w) := 1
to denote the unbiased plug-in estimator, and write ˆµx(v)ˆµy(w) := 1
i=1 k(xi, v) 1
n
n
estimator. Deﬁne ˆub(v, w) := ˆµxy(v, w)
stands for “biased”. To avoid confusing with a positive deﬁnite kernel, we will refer to a U-statistic kernel as a core.

F := (cid:112)tr(A(cid:62)A) be the Frobenius norm. Write
(cid:107)
. For
X × Y
Ex(cid:48)k(x(cid:48), v),
be a closed ball with radius r centered at the origin.
J matrices under the Frobenius norm.

j(cid:54)=i k(xi, v)l(yj, w)
j=1 l(yj, w) which is a biased
where the superscript b

Ey(cid:48)l(y(cid:48), w). Let B2(r) :=
F
(cid:107)

ˆµx(v)ˆµy(w) so that ˆub := (cid:0)ˆub(t1), . . . , ˆub(tJ )(cid:1)(cid:62)

2
(cid:107)
to be a closed ball with radius r of J

n(n−1)
(cid:80)n

A
{

x
{

(cid:80)n

(cid:80)n

| (cid:107)

(cid:80)

i=1

A

−

−

≤

×

≤

x

}

}

r

r

F.2. Proof

We will ﬁrst derive a bound for P(
P(ˆλn
≥
considering

/n.

ˆλn

λn

ˆλn
|

|

−

|

t), which will then be reparametrized to get a bound for the target quantity
r). We closely follow the proof in Jitkrittum et al. (2016, Section C.1) up to (12), then we diverge. We start by

| ≥

λn

−

ˆλn
|

λn

/n =
|

−

(cid:12)
u(cid:62)Σ−1u
(cid:12)
(cid:12)

=

(cid:12)
(cid:12)ˆu(cid:62)( ˆΣ + γnI)−1 ˆu
(cid:12)
(cid:12)
(cid:17)−1
ˆu(cid:62) (cid:16) ˆΣ + γnI
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ˆu(cid:62) (cid:16) ˆΣ + γnI

(cid:17)−1

−

ˆu

ˆu

≤
:= ((cid:70))1 + ((cid:70))2 .

u(cid:62) (Σ + γnI)−1 u + u(cid:62) (Σ + γnI)−1 u
(cid:12)
(cid:12)
u(cid:62) (Σ + γnI)−1 u
(cid:12)
(cid:12)

−
(cid:12)
(cid:12)u(cid:62) (Σ + γnI)−1 u
(cid:12)

+

−

−

−

(cid:12)
(cid:12)
u(cid:62)Σ−1u
(cid:12)
(cid:12)

(cid:12)
u(cid:62)Σ−1u
(cid:12)
(cid:12)

We next bound ((cid:70)1) and ((cid:70)2) separately.

((cid:70))1 =

ˆu(cid:62) (cid:16) ˆΣ + γnI

(cid:17)−1

(cid:12)
(cid:12)
u(cid:62) (Σ + γnI)−1 u
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ˆu

ˆu

−

−

ˆu

−
(cid:17)−1

ˆu(cid:62) (cid:16) ˆΣ + γnI

(cid:17)−1

=

(cid:17)−1

ˆu(cid:62) (cid:16) ˆΣ + γnI
(cid:28)

ˆuˆu(cid:62),

(cid:16) ˆΣ + γnI

≤

=

ˆu(cid:62) (Σ + γnI)−1 ˆu + ˆu(cid:62) (Σ + γnI)−1 ˆu
(cid:12)
(cid:12)
ˆu(cid:62) (Σ + γnI)−1 ˆu
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

−
(cid:12)
(cid:12)ˆu(cid:62) (Σ + γnI)−1 ˆu
(cid:12)
(cid:12)
(cid:68)
(cid:12)
(cid:12)

(Σ + γnI)−1

ˆuˆu(cid:62)

+

+

(cid:29)

−

−
uu(cid:62), (Σ + γnI)−1(cid:69)

(cid:12)
(cid:12)
(cid:12)

F

(cid:12)
(cid:12)
u(cid:62) (Σ + γnI)−1 u
(cid:12)
(cid:12)

(cid:12)
u(cid:62) (Σ + γnI)−1 u
(cid:12)
(cid:12)

F
F +

−
uu(cid:62)

ˆuˆu(cid:62)
ˆuˆu(cid:62)

(cid:107)

F

F

(cid:107)
ˆuˆu(cid:62)

≤ (cid:107)
=

(cid:107)
(a)

≤ (cid:107)
(b)

≤

( ˆΣ + γnI)−1
(cid:107)
( ˆΣ + γnI)−1[(Σ + γnI)
(cid:107)

−

(Σ + γnI)−1

−

ˆuˆu(cid:62)
F
(cid:107)
( ˆΣ + γnI)](Σ + γnI)−1

−

(cid:107)

(cid:107)

(Σ + γnI)−1
F +

ˆuˆu(cid:62)
(cid:107)

(cid:107)

(cid:107)

F
(cid:107)
ˆuu(cid:62) + ˆuu(cid:62)

uu(cid:62)

(Σ + γnI)−1

−

F
(cid:107)

(cid:107)

F

(cid:107)

F
(cid:107)

( ˆΣ + γnI)−1
(cid:107)
2
ˆu
2(cid:107)
(cid:107)

ˆΣ
F
(cid:107)

F
(cid:107)
Σ−1
(cid:107)

Σ

−

Σ

(cid:107)
−
F + (cid:0)

(cid:107)

√J
γn (cid:107)

ˆΣ
F
(cid:107)

Σ−1
(cid:107)

F +

ˆuˆu(cid:62)

ˆuu(cid:62) + ˆuu(cid:62)

(cid:107)

−

ˆu(ˆu
(cid:107)

−

F +
(cid:107)

(ˆu
(cid:107)

−

u)u(cid:62)

(cid:1)

F

(cid:107)

(cid:107)

(cid:107)
u)(cid:62)

−
Σ−1

F
(cid:107)

−
uu(cid:62)

Σ−1
(cid:107)

F
(cid:107)

F

(cid:107)

An Adaptive Test of Independence with Analytic Kernel Embeddings

√J
γn (cid:107)

≤

ˆu
(cid:107)

2
2(cid:107)

Σ

−

ˆΣ

Σ−1
(cid:107)

F
(cid:107)

F + (
(cid:107)

(cid:107)

ˆu
2 +
(cid:107)

2)
u
(cid:107)
(cid:107)

ˆu
(cid:107)

u
(cid:107)

2

−

where at (a) we used
For ((cid:70))2, we have

(Σ + γnI)−1
(cid:107)

F
(cid:107)

≤ (cid:107)

Σ−1

F , at (b) we used
(cid:107)

√J

( ˆΣ + γnI)−1

F
(cid:107)

≤

(cid:107)

√J/γn.

2

(cid:107)

≤

Σ−1
(cid:107)

F ,
(cid:107)
( ˆΣ + γnI)−1
(cid:107)

(cid:12)
u(cid:62)Σ−1u
(cid:12)
(cid:12)
(cid:12)
Σ−1(cid:11)
(cid:12)
F
Σ−1
F
(cid:107)
(Σ + γnI)] Σ−1
Σ−1
(cid:107)

−
F
(cid:107)

−

(cid:107)

F

F
(cid:107)

≤ (cid:107)
=

(cid:12)
(cid:12)u(cid:62) (Σ + γnI)−1 u
((cid:70))2 =
(cid:12)
−
= (cid:12)
(cid:10)uu(cid:62), (Σ + γnI)−1
(cid:12)
−
uu(cid:62)
(Σ + γnI)−1
F
(cid:107)
(cid:107)
(Σ + γnI)−1 [Σ
2
u
2(cid:107)
(cid:107)
(Σ + γnI)−1
2
u
2(cid:107)
(cid:107)
2
u
2(cid:107)
(cid:107)
(cid:107)
Σ−1
F .
(cid:107)

(cid:107)
γn

2
F ,
(cid:107)

Σ−1

(cid:107)
γn

≤
(a)

≤ (cid:107)

F
(cid:107)

≤

where at (a) we used

(Σ + γnI)−1
(cid:107)

Combining (5) and (6), we have
(cid:12)
(cid:12)ˆu(cid:62)( ˆΣ + γnI)−1 ˆu
(cid:12)

(cid:12)
u(cid:62)Σ−1u
(cid:12)
(cid:12)

−

√J
γn (cid:107)

≤

2

ˆu
(cid:107)

Σ
(cid:107)

−

ˆΣ

F
(cid:107)

(cid:107)

Σ−1

F + (

(cid:107)

ˆu
2 +
(cid:107)
(cid:107)

u
(cid:107)
(cid:107)

2)

ˆu
(cid:107)

u
2
(cid:107)

(cid:107)

−

Σ−1

F + γn

(cid:107)

u
(cid:107)
(cid:107)

2
2(cid:107)

Σ−1

2
F .
(cid:107)

2
2
ˆu
2 Here, we show that by the boundedness of the kernels k and l, it follows that
u
Bounding
2 and
(cid:107)
(cid:107)
(cid:107)
(cid:107)
k(x, x(cid:48))
Recall that supx,x(cid:48)∈X |
| ≤
zi := (xi, yi). We ﬁrst show that the U-statistic core h is bounded.

2
2 is bounded.
Bl, our notation t = (v, w) for the test locations, and

l(y, y(cid:48))
|

Bk, supy,y(cid:48)

ˆu
(cid:107)
(cid:107)

| ≤

where we deﬁne B := BkBl. It follows that

ht((x, y), (x(cid:48), y(cid:48)))
|

|

=

−

(k(x, v)

(cid:12)
1
(cid:12)
(cid:12)
2
(cid:12)
1
2
2BkBl := 2B,

k(x, v)
(
|

+

|

k(x(cid:48), v))(l(y, w)

l(y(cid:48), w))

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)

k(x(cid:48), v)
|

l(y, w)
) (
|
|
|

+

l(y(cid:48), w)
|
|

)

≤

≤

2

−

2
ˆu
2 =
(cid:107)

(cid:107)

2
2 =
u
(cid:107)

(cid:107)





J
(cid:88)

m=1

J
(cid:88)

m=1

n(n

1)

(cid:88)

i<j

htm (zi, zj)



[2BkBl]2 = 4B2J,


2

J
(cid:88)

≤

m=1

[EzEz(cid:48)htm (z, z(cid:48))]2

4B2J.

≤

Using the upper bounds on

2
2 ,(7) and the deﬁnition of ˜c, we have

u
(cid:107)
(cid:107)

2
ˆu
2,
(cid:107)
(cid:107)
(cid:12)
(cid:12)ˆu(cid:62)( ˆΣ + γnI)−1 ˆu
(cid:12)

(cid:12)
u(cid:62)Σ−1u
(cid:12)
(cid:12)

−

Σ

√J
γn
c1
γn (cid:107)

4B2J ˜c
(cid:107)
ˆΣ
(cid:107)

Σ

−

≤

=:

ˆΣ
F + 4B√J ˜c
(cid:107)
(cid:107)

ˆu

2 + 4B2J ˜c2γn
u
(cid:107)

−

−

F + c2

ˆu
(cid:107)

2 + c3γn,
u
(cid:107)

−

where we deﬁne c1 := 4B2J√J ˜c, c2 := 4B√J ˜c, and c3 := 4B2J ˜c2. This upper bound implies that

ˆλn

|

λn

−

| ≤

c1
γn

n

Σ
(cid:107)

−

ˆΣ

F + c2n
(cid:107)

(cid:107)

ˆu

u
(cid:107)

−

2 + c3nγn.

We will separately upper bound

Σ

(cid:107)

−

ˆΣ
F and
(cid:107)

ˆu
(cid:107)

u
2, and combine them with a union bound.
(cid:107)

−

(5)

(6)

(7)

(8)

(9)

(10)

(11)

(12)

An Adaptive Test of Independence with Analytic Kernel Embeddings

u
F.2.1. BOUNDING
2
(cid:107)
Let t∗ = arg maxt∈{t1,...,tJ } |

−

(cid:107)

ˆu

ˆu(t)

u(t)

−

. Recall that u = (u(t1), . . . , u(tJ ))(cid:62) = (u1, . . . , uJ )(cid:62).
|

ˆu
(cid:107)

u
(cid:107)

−

2 = sup

b∈B2(1) (cid:104)

b, ˆu

u

−

(cid:105)2 ≤

sup
b∈B2(1)

bj
|

||

ˆu(tj)

u(tj)

−

|

J
(cid:88)

j=1

ˆu(t∗)

u(t∗)
|

−

sup
b∈B2(1)

J
(cid:88)

j=1

bj
|

|

√J

ˆu(t∗)
|

−

u(t∗)
|

sup
b∈B2(1) (cid:107)

b
2
(cid:107)

≤ |

(a)

≤

u(t∗)
|

,

−

= √J

ˆu(t∗)

|
2 for any a
(cid:107)

where at (a) we used
bounding the difference of a U-statistic ˆu(t∗) (see (4)) to its expectation u(t∗). Combining (13) and (12), we have

RJ . From (13), it can be seen that bounding

u
2 amounts to
(cid:107)

ˆu
(cid:107)

a
(cid:107)

a
(cid:107)

√J

1
(cid:107)

−

≤

∈

ˆλn
|

λn

−

| ≤

c1
γn

n

Σ
(cid:107)

−

ˆΣ
(cid:107)

F + c2n√J

ˆu(t∗)
|

−

u(t∗)

+ c3nγn.

|

F.2.2. BOUNDING

ˆΣ

(cid:107)

Σ
F
(cid:107)

−

The plan is to write ˆΣ = ˆS
−
ˆS
ˆub ˆub(cid:62)
separately
(cid:107)
Recall that Σij = η(ti, tj), η(t, t(cid:48)) = Exy[(cid:0)˜k(x, v)˜l(y, w)
Ex(cid:48)k(x(cid:48), v), and ˜l(y, w) = l(y, w)
k(x, v)
where

ˆub ˆub(cid:62), Σ = S
uu(cid:62)
F .
(cid:107)

S
F and
(cid:107)

−

−

−

−

−

(cid:107)

uu(cid:62), so that

ˆΣ
(cid:107)

Σ
F
(cid:107)

−

ˆS

≤ (cid:107)

−

F +
S
(cid:107)

ˆub ˆub(cid:62)
(cid:107)

−

uu(cid:62)

F and bound
(cid:107)

u(v(cid:48), w(cid:48))(cid:1)] where ˜k(x, v) =
Ey(cid:48)l(y(cid:48), w). Its empirical estimator (see Proposition 6) is ˆΣij = ˆη(ti, tj)

u(v, w)(cid:1)(cid:0)˜k(x, v(cid:48))˜l(y, w(cid:48))

−

−

ˆη(t, t(cid:48)) =

[(cid:0)k(xi, v)l(yi, w)

ˆub(v, w)(cid:1)(cid:0)k(xi, v(cid:48))l(yi, w(cid:48))

ˆub(v(cid:48), w(cid:48))(cid:1)]

−

−

=

k(xi, v)l(yi, w)k(xi, v(cid:48))l(yi, w(cid:48))

ˆub(v, w)ˆub(v(cid:48), w(cid:48)),

−

1
n

1
n

n
(cid:88)

i=1
n
(cid:88)

i=1

that

(cid:80)n

:=
1
n

k(x, v)
i=1 k(xi, v)l(yi, w)

We
:=
m=1 k(xm, vi)l(ym, wi)k(xm, vj)l(yi, wj), and deﬁne similarly its population counterpart S such that

k(x, v)
note
1
n
Sij := Exy[˜k(x, v)˜l(y, w)˜k(x, v(cid:48))˜l(y, w(cid:48))]. We have

i=1 l(yi, w).
such that

i=1 k(xi, v),
=

:=
We deﬁne

and
ˆub(v, w).

l(y, w)
ˆS

l(y, w)

ˆSij

(cid:80)n

−

∈

1
n
−
RJ×J

(cid:80)n

1
n

(cid:80)n

−

ˆub ˆub(cid:62),
uu(cid:62),

ˆΣ = ˆS

Σ = S
−
ˆS
ˆS

F =

(cid:107)

≤ (cid:107)

S

(ˆub ˆub(cid:62)

−

−

−
F +
S
(cid:107)

−
ˆub ˆub(cid:62)
(cid:107)

uu(cid:62))
F
(cid:107)
uu(cid:62)

−

F .

(cid:107)

ˆΣ
(cid:107)

Σ
(cid:107)

−

With (16), (14) becomes

ˆλn

|

λn

−

| ≤

c1n
γn (cid:107)

ˆS

S
(cid:107)

−

F +

c1n
γn (cid:107)

ˆub ˆub(cid:62)

uu(cid:62)

F + c2n√J

−

(cid:107)

ˆu(t∗)
|

−

u(t∗)

+ c3nγn.

|

We will further separately bound

S
(cid:107)

−

F and

ˆub ˆub(cid:62)
(cid:107)

−

uu(cid:62)

F .
(cid:107)

F.2.3. BOUNDING

ˆub ˆub(cid:62)

(cid:107)

−

ˆS
(cid:107)
uu(cid:62)

F
(cid:107)

ˆub ˆub(cid:62)
(cid:107)

−

uu(cid:62)

F =

(cid:107)

ˆub ˆub(cid:62)
(cid:107)

−

ˆubu(cid:62) + ˆubu(cid:62)

uu(cid:62)

−

F

(cid:107)

(13)

(14)

(15)

(16)

(17)

An Adaptive Test of Independence with Analytic Kernel Embeddings

≤ (cid:107)
=

ˆub(ˆub
−
ˆub
ˆub
2
(cid:107)
(cid:107)
(cid:107)
ˆub
4B√J
(cid:107)

u)(cid:62)

F +
(cid:107)
2 +

(ˆub
(cid:107)
ˆub

u)u(cid:62)

−
u
2
(cid:107)

F
(cid:107)
u
2
(cid:107)
(cid:107)

−

u
(cid:107)
u
(cid:107)
2B√J which can be shown similarly to (9) as

2,

≤

−

−

(cid:107)

where we used (10) and the fact that

ˆub
(cid:107)

2
(cid:107)

≤

ˆub
(cid:107)

2
2 =
(cid:107)

J
(cid:88)

m=1

[ˆµxy(vm, wm)

ˆµx(vm)ˆµy(wm)]2 =

−

J
(cid:88)

n
(cid:88)

n
(cid:88)





1
n2

m=1

i=1

j=1


2

J
(cid:88)

≤

m=1

htm(zi, zj)



[2BkBl]2 = 4B2J.

Let (˜v, ˜w) := ˜t = arg maxt∈{t1,...,tJ } |

ˆub(t)

u(t)
|

−

. We bound

ˆub
(cid:107)

u
2 by
(cid:107)

−

ˆub

(cid:107)

u
2
(cid:107)

−

u(˜t)
|

(a)

ˆub(˜t)
√J
|
−
≤
= √J (cid:12)
(cid:12)ˆµxy(˜t)
= √J (cid:12)
(cid:12)ˆµxy(˜t)
√J (cid:12)
(cid:12)ˆµxy(˜t)
≤
= √J (cid:12)
(cid:12)ˆu(˜t)

−

−

u(˜t)(cid:12)
ˆµx(˜v)ˆµy( ˜w)
(cid:12)
(cid:91)µxµy(˜t) + (cid:91)µxµy(˜t)
(cid:91)µxµy(˜t)

−

−
(cid:12) + √J (cid:12)

u(˜t)(cid:12)
−
(cid:12) + √J (cid:12)
(cid:12)(cid:91)µxµy(˜t)
where at (a) we used the same reasoning as in (13). The bias (cid:12)
as

−
u(˜t)(cid:12)

(cid:12)(cid:91)µxµy(˜t)

−

−

−

u(˜t)(cid:12)
ˆµx(˜v)ˆµy( ˜w)
(cid:12)
−
ˆµx(˜v)ˆµy( ˜w)(cid:12)
(cid:12)(cid:91)µxµy(˜t)
(cid:12)
−
ˆµx(˜v)ˆµy( ˜w)(cid:12)
(cid:12) ,
ˆµx(˜v)ˆµy( ˜w)(cid:12)

(18)

(cid:12) in the second term can be bounded

ˆµx(˜v)ˆµy( ˜w)(cid:12)
(cid:12)

1

1

=

=

n(n

n(n

(cid:12)
(cid:12)(cid:91)µxµy(˜t)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

−

−

=

≤

(cid:18)

(cid:18)

1

1

B

−

1)

−

1)

−

n

−

n

−

n

n

+

n
(cid:88)

(cid:88)

i=1

j(cid:54)=i

n
(cid:88)

n
(cid:88)

i=1

j=1

(cid:19) 1
n2

1

(cid:19) 1
n2

1

B

n
(cid:88)

n
(cid:88)

i=1

j=1

n
(cid:88)

n
(cid:88)

i=1

j=1

=

2B

.

1

k(xi, ˜v)l(yj, ˜w)

1
n2

−

n
(cid:88)

n
(cid:88)

i=1

j=1

(cid:12)
(cid:12)
(cid:12)
k(xi, ˜v)l(yj, ˜w)
(cid:12)
(cid:12)
(cid:12)

k(xi, ˜v)l(yj, ˜w)

k(xi, ˜v)l(yi, ˜w)

k(xi, ˜v)l(yj, ˜w)

1

−

n
(cid:88)

i=1

−

n(n

1)

1
n2

−

n
(cid:88)

n
(cid:88)

j=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

k(xi, ˜v)l(yj, ˜w) +

n(n

1)

k(xi, ˜v)l(yj, ˜w)

+

i=1
(cid:12)
(cid:12)
(cid:12)
k(xi, ˜v)l(yi, ˜w)
(cid:12)
(cid:12)
(cid:12)

n
(cid:88)

i=1

n
(cid:88)

i=1

(cid:12)
(cid:12)
(cid:12)
k(xi, ˜v)l(yi, ˜w)
(cid:12)
(cid:12)

1

−

1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

n(n

1)

−

≤

n

1

n

1

n

−
Combining this upper bound with (18), we have

−

−

ˆub ˆub(cid:62)
(cid:107)

−

uu(cid:62)

F

(cid:107)

≤

4BJ (cid:12)

(cid:12)ˆu(˜t)

u(˜t)(cid:12)

(cid:12) +

−

8B2J
1
n

.

−

(19)

With (19), (17) becomes

ˆλn
|

λn

−

| ≤

c1n
γn (cid:107)

ˆS

F +
S
(cid:107)

−

4BJc1n
γn

(cid:12)
(cid:12)ˆu(˜t)

u(˜t)(cid:12)

(cid:12) +

−

c1n
γn

8B2J
1
n

−

+ c2n√J

ˆu(t∗)
|

−

|

u(t∗)

+ c3nγn.

(20)

F.2.4. BOUNDING

ˆS

(cid:107)

S
F
−
(cid:107)
t1, . . . , tJ

, ˆSij = ˆS(ti, tj) = 1
Recall that VJ =
n
}
S(ti, tj) = Exy[˜k(x, vi)˜l(y, wi)˜k(x, vj)˜l(y, wj)]. Let (t(1), t(2)) = arg max(s,t)∈VJ ×VJ |

{

(cid:80)n

ˆS(s, t)

S(s, t)

.
|

−

m=1 k(xm, vi)l(ym, wi)k(xm, vj)l(ym, wj), and Sij =

An Adaptive Test of Independence with Analytic Kernel Embeddings

ˆS
(cid:107)

F = sup
S
(cid:107)

B∈BF (1)

−

(cid:68)
B, ˆS

(cid:69)

S

−

F

sup
B∈BF (1)

≤

J
(cid:88)

J
(cid:88)

i=1

j=1

Bij

|

ˆSij
||

Sij

|

−

(cid:12)
ˆS(t(1), t(2))
(cid:12)
(cid:12)

−

S(t(1), t(2))

(cid:12)
(cid:12)
(cid:12)

sup
B∈BF (1)

J
(cid:88)

J
(cid:88)

i=1

j=1

Bij
|

|

≤

(a)

≤

J

ˆS(t(1), t(2))

(cid:12)
(cid:12)
(cid:12)

(cid:12)
S(t(1), t(2))
(cid:12)
(cid:12)

= J

(cid:12)
ˆS(t(1), t(2))
(cid:12)
(cid:12)

S(t(1), t(2))

J

F for any matrix A
A
(cid:107)
(cid:107)
ˆS(t(1), t(2))

∈
S(t(1), t(2))

sup
B∈BF (1) (cid:107)

B
F
(cid:107)

(cid:12)
(cid:12)
(cid:12) ,
RJ×J . We arrive at

(cid:12)
(cid:12)
(cid:12) +

4BJc1n
γn

(cid:12)
(cid:12)ˆu(˜t)

u(˜t)(cid:12)
(cid:12)

−

+ c2n√J

ˆu(t∗)

u(t∗)
|

−

+ c3nγn.

−

−

−

|

i=1

(cid:80)J

Aij

j=1 |

ˆλn
|

λn

−

| ≤

| ≤
c1Jn
γn
c1n
γn

(cid:12)
(cid:12)
(cid:12)
8B2J
1
n

−

+

(21)

(22)

S(t, t(cid:48))

(cid:12)
(cid:12)
(cid:12) will allow us to bound (22). To keep the notations uncluttered, we will

where at (a) we used (cid:80)J

F.2.5. BOUNDING

(cid:12)
(cid:12)
(cid:12)

ˆS(t, t(cid:48))

Having an upper bound for
deﬁne the following shorthands.

(cid:12)
(cid:12)
S(t, t(cid:48))
(cid:12)

−
(cid:12)
ˆS(t, t(cid:48))
(cid:12)
(cid:12)

−

Expression

Shorthand

Expression

Shorthand

k(x, v)

k(x, v(cid:48))

k(xi, v)
k(xi, v(cid:48))
Ex∼Px k(x, v)
Ex∼Pxk(x, v(cid:48))
(cid:80)n
1
i=1 k(xi, v)
n
1
i=1 k(xi, v(cid:48))
n

(cid:80)n

a

a(cid:48)

ai
a(cid:48)
i
˜a

˜a(cid:48)

a
a(cid:48)

l(y, w)

l(y, w(cid:48))

l(yi, w)
l(yi, w(cid:48))
Ey∼Py l(y, w)
Ey∼Py l(y, w(cid:48))
(cid:80)n
1
i=1 l(yi, w)
n
i=1 l(yi, w(cid:48))

(cid:80)n

1
n

b

b(cid:48)

bi
b(cid:48)
i
˜b
˜b(cid:48)

b
(cid:48)
b

to denote a empirical expectation over x, or y, or (x, y). The argument under

·

(cid:80)n

We will also use
mine the variable over which we take the expectation. For instance, aa(cid:48) = 1
n
1
n
(cid:102)aa(cid:48) = Ex [k(x, v)k(x, v(cid:48))] and (cid:103)aba(cid:48) = Exy [k(x, v)l(y, w)k(x, v(cid:48))].
With these shorthands, we can rewrite ˆS(t, t(cid:48)) and S(t, t(cid:48)) as

i=1 k(xi, v)l(yi, w)k(xi, v(cid:48)), and so on. We deﬁne in the same way for the population expectation using (cid:101)·

(cid:80)n

will deter-
i=1 k(xi, v)k(xi, v(cid:48)) and aba(cid:48) =
i.e.,

·

By expanding S(t, t(cid:48)), we have

1
n

n
(cid:88)

i=1
(cid:104)

ˆS(t, t(cid:48)) =

(ai

a)(bi

−

−

b)(a(cid:48)

a(cid:48))(b(cid:48)

i −

i −

S(t, t(cid:48)) = Exy

(a

˜a)(b

˜b)(a(cid:48)

˜a(cid:48))(b(cid:48)

−

−

−

−

(cid:48)
b

),

(cid:105)
˜b(cid:48))

.

S(t, t(cid:48)) = Exy

(cid:2) + aba(cid:48)b(cid:48)

aba(cid:48)˜b(cid:48)

ab˜a(cid:48)b(cid:48) + ab˜a(cid:48)˜b(cid:48)

−

−

An Adaptive Test of Independence with Analytic Kernel Embeddings

−

a˜ba(cid:48)b(cid:48) + a˜ba(cid:48)˜b(cid:48) + a˜b˜a(cid:48)b(cid:48)
˜aba(cid:48)b(cid:48) + ˜aba(cid:48)˜b(cid:48) + ˜ab˜a(cid:48)b(cid:48)
˜a˜ba(cid:48)˜b(cid:48)

a˜b˜a(cid:48)˜b(cid:48)
˜ab˜a(cid:48)˜b(cid:48)
−
˜a˜b˜a(cid:48)˜b(cid:48) + ˜a˜b˜a(cid:48)˜b(cid:48)(cid:3)

−
+ ˜a˜ba(cid:48)b(cid:48)

−

= +(cid:94)aba(cid:48)b(cid:48)

−

−

−

−

−
(cid:103)aba(cid:48)˜b(cid:48)
(cid:93)aa(cid:48)b(cid:48)˜b + (cid:102)aa(cid:48)˜b˜b(cid:48) + (cid:102)ab(cid:48)˜a(cid:48)˜b
(cid:103)a(cid:48)bb(cid:48)˜a + (cid:102)a(cid:48)b˜a˜b(cid:48) + ˜a˜a(cid:48) (cid:102)bb(cid:48)
˜a˜b˜a(cid:48)˜b(cid:48)
(cid:103)aba(cid:48)˜b(cid:48)

(cid:103)abb(cid:48)˜a(cid:48) + (cid:101)ab˜a(cid:48)˜b(cid:48)
˜a˜b˜a(cid:48)˜b(cid:48)
˜a˜b˜a(cid:48)˜b(cid:48)
−
˜a˜b˜a(cid:48)˜b(cid:48) + ˜a˜b˜a(cid:48)˜b(cid:48)
(cid:103)abb(cid:48)˜a(cid:48) + (cid:101)ab˜a(cid:48)˜b(cid:48)
−
(cid:93)aa(cid:48)b(cid:48)˜b + (cid:102)aa(cid:48)˜b˜b(cid:48) + (cid:102)ab(cid:48)˜a(cid:48)˜b + (cid:103)a(cid:48)b(cid:48)˜a˜b
3˜a˜b˜a(cid:48)˜b(cid:48).
(cid:103)a(cid:48)bb(cid:48)˜a + (cid:102)a(cid:48)b˜a˜b(cid:48) + ˜a˜a(cid:48) (cid:102)bb(cid:48)

−

−

−

−
+ (cid:103)a(cid:48)b(cid:48)˜a˜b
= +(cid:94)aba(cid:48)b(cid:48)

−

−

(cid:12)
(cid:12)
(cid:12)

ˆS(t, t(cid:48))

−
The expansion of ˆS(t, t(cid:48)) can be done in the same way. By the triangle inequality, we have
(cid:103)abb(cid:48)˜a(cid:48)(cid:12)
(cid:12)
(cid:12) +
(cid:12)
(cid:102)ab(cid:48)˜a(cid:48)˜b
(cid:12)
(cid:12) +
(cid:12)
(cid:12)
(cid:12) + 3

(cid:12)
(cid:103)aba(cid:48)˜b(cid:48)(cid:12)
(cid:12)abb(cid:48)a(cid:48)
(cid:12)
(cid:12)
(cid:12) +
−
(cid:12)
(cid:102)aa(cid:48)˜b˜b(cid:48)(cid:12)
(cid:12)ab(cid:48)a(cid:48)b
(cid:12)
(cid:12)
(cid:12) +
−
(cid:12)
(cid:102)a(cid:48)b˜a˜b(cid:48)(cid:12)
(cid:12)a a(cid:48)bb(cid:48)
(cid:12)
(cid:12)
(cid:12) +

(cid:12)
(cid:12)
(cid:12) +
(cid:12)
(cid:93)aa(cid:48)b(cid:48)˜b
(cid:12)
(cid:12) +
(cid:12)
(cid:12)
(cid:103)a(cid:48)bb(cid:48)˜a
(cid:12) +

(cid:12)
(cid:12)
(cid:12)aba(cid:48) b
(cid:12)
(cid:12)
(cid:12)aa(cid:48) b b
(cid:12)
(cid:12)
(cid:12)a(cid:48)bab

(cid:12)
(cid:12)
(cid:12)aba(cid:48)b(cid:48)
(cid:12)
(cid:12)
(cid:12)aa(cid:48)b(cid:48) b
(cid:12)
(cid:12)
(cid:12)a(cid:48)bb(cid:48)a

S(t, t(cid:48))

(cid:12)
(cid:12)
(cid:12) ≤

(cid:94)aba(cid:48)b(cid:48)

˜a˜a(cid:48) (cid:102)bb(cid:48)

−
(cid:48)

−

−

−

−

−

(cid:48)

(cid:48)

−

−

−

(cid:48)

(cid:12)
(cid:12)aba(cid:48)b
(cid:12)
−
(cid:12)
(cid:12)
(cid:12)a(cid:48)b(cid:48)ab
(cid:12)
(cid:12)aba(cid:48)b
(cid:12)

−
(cid:48)

(cid:101)ab˜a(cid:48)˜b(cid:48)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:103)a(cid:48)b(cid:48)˜a˜b
(cid:12)
(cid:12)
˜a˜b˜a(cid:48)˜b(cid:48)(cid:12)
(cid:12)
(cid:12) .

−

The ﬁrst term
applying Lemma 9. Recall that we write (x1, . . . , xm)+ for max(x1, . . . , xm).

−

(cid:12)
(cid:12)
(cid:12) can be bounded by applying the Hoeffding’s inequality. Other terms can be bounded by

(cid:12)
(cid:12)
(cid:12)aba(cid:48)b(cid:48)

(cid:94)aba(cid:48)b(cid:48)

Bounding

(cid:12)
(cid:12)
(cid:12)aba(cid:48)b(cid:48)

−

(cid:94)aba(cid:48)b(cid:48)

(cid:12)
(cid:12)
(cid:12) (1st term). Since
(cid:16)(cid:12)
(cid:12)
(cid:12)aba(cid:48)b(cid:48)

P

−

≤

−

(cid:94)aba(cid:48)b(cid:48)

≤
(cid:12)
(cid:12)
(cid:12) ≤

(cid:17)

t

1

2 exp

≥

−

(cid:18)

(cid:19)

.

nt2
2B4

−

B2

aba(cid:48)b(cid:48)

B2, by the Hoeffding’s inequality (Lemma 14), we have

Bounding

note that

(cid:48)

(cid:12)
(cid:12)
(cid:12)aba(cid:48) b
f1(x, y)
|

−

| ≤

(cid:103)aba(cid:48)˜b(cid:48)(cid:12)
(cid:12)
(cid:12) (2nd term). Let f1(x, y) = aba(cid:48) = k(x, v)l(y, w)k(x, v(cid:48)) and f2(y) = b(cid:48) = l(y, w(cid:48)). We
(BBk, Bl)+ and

(BBk, Bl)+. Thus, by Lemma 9 with E = 2, we have

f2(y)
|
(cid:16)(cid:12)
(cid:48)
(cid:12)
(cid:12)aba(cid:48) b

| ≤
(cid:103)aba(cid:48)˜b(cid:48)(cid:12)
(cid:12)
(cid:12) ≤

−

P

(cid:17)

t

1

4 exp

≥

−

(cid:18)

nt2
8(BBk, Bl)4
+

−

(cid:19)

.

(cid:12)
(cid:12)
(cid:12)aba(cid:48)b
Bounding
l(y, w(cid:48)). We can see that

−

(cid:48)

(cid:101)ab˜a(cid:48)˜b(cid:48)(cid:12)
(cid:12)
(cid:12) (4th term). Let f1(x, y) = ab = k(x, v)l(y, w), f2(x) = a(cid:48) = k(x, v(cid:48)) and f3(y) = b(cid:48) =
f1(x, y)
|
|
|
(cid:16)(cid:12)
(cid:12)aba(cid:48)b
(cid:12)

(B, Bk, Bl)+. Thus, by Lemma 9 with E = 3, we have

f2(x)
,
f3(y)
|
|
(cid:101)ab˜a(cid:48)˜b(cid:48)(cid:12)
(cid:12)
(cid:12) ≤

nt2
18(B, Bk, Bl)6
+

| ≤
(cid:17)

6 exp

−

−

≥

−

(cid:19)

(cid:18)

P

1

t

,

.

(cid:48)

(cid:12)
(cid:12)
(cid:12)aba(cid:48)b

(cid:48)

Bounding
−
f4(y) = b(cid:48) = l(y, w(cid:48)). It can be seen that
we have

˜a˜b˜a(cid:48)˜b(cid:48)(cid:12)
(cid:12)
(cid:12) (last term). Let f1(x) = a = k(x, v), f2(y) = b = l(y, w), f3(x) = a(cid:48) = k(x, v(cid:48)) and
(Bk, Bl)+. Thus, by Lemma 9 with E = 4,

,

,

,
f1(x)
|

|

f2(y)
|

|

f3(x)
|

|

f4(y)
|

| ≤

(cid:16)

3

P

(cid:12)
(cid:12)aba(cid:48)b
(cid:12)

(cid:48)

˜a˜b˜a(cid:48)˜b(cid:48)(cid:12)
(cid:12)
(cid:12) ≤

(cid:17)
t

−

1

8 exp

≥

−

(cid:18)

nt2

−

32

32(Bk, Bl)8
+

(cid:19)

.

Bounds for other terms can be derived in a similar way to yield

(3rd term) P

(cid:16)(cid:12)
(cid:12)abb(cid:48)a(cid:48)
(cid:12)

(cid:103)abb(cid:48)˜a(cid:48)(cid:12)
(cid:12)
(cid:12) ≤

(cid:17)
t

−

1

4 exp

≥

−

nt2
8(BBl, Bk)4
+

−

(cid:19)

,

·

(cid:18)

An Adaptive Test of Independence with Analytic Kernel Embeddings

(5th term) P

(6th term) P

(7th term) P

(8th term) P

(9th term) P

(10th term) P

(11th term) P

(cid:16)(cid:12)
(cid:12)
(cid:12)aa(cid:48)b(cid:48) b

(cid:48)

(cid:16)(cid:12)
(cid:12)
(cid:12)aa(cid:48) b b
(cid:16)(cid:12)
(cid:12)ab(cid:48)a(cid:48)b
(cid:12)
(cid:16)(cid:12)
(cid:12)
(cid:12)a(cid:48)b(cid:48)ab
(cid:16)(cid:12)
(cid:12)
(cid:12)a(cid:48)bb(cid:48)a
(cid:16)(cid:12)
(cid:12)
(cid:12)a(cid:48)bab

(cid:48)

(cid:16)(cid:12)
(cid:12)a a(cid:48)bb(cid:48)
(cid:12)

(cid:12)
(cid:93)aa(cid:48)b(cid:48)˜b
(cid:12)
(cid:12) ≤

(cid:102)aa(cid:48)˜b˜b(cid:48)(cid:12)
(cid:12)
(cid:12) ≤
(cid:12)
(cid:102)ab(cid:48)˜a(cid:48)˜b
(cid:12)
(cid:12) ≤
(cid:12)
(cid:103)a(cid:48)b(cid:48)˜a˜b
(cid:12)
(cid:12) ≤
(cid:12)
(cid:12)
(cid:103)a(cid:48)bb(cid:48)˜a
(cid:12) ≤

(cid:102)a(cid:48)b˜a˜b(cid:48)(cid:12)
(cid:12)
(cid:12) ≤
(cid:12)
(cid:12)
(cid:12) ≤

˜a˜a(cid:48) (cid:102)bb(cid:48)

−

−

−

−

−

−

−

(cid:17)
t

(cid:17)
t

(cid:17)
t

(cid:17)
t

(cid:17)
t

(cid:17)
t

(cid:17)
t

1

1

1

1

1

1

1

4 exp

≥

−

6 exp

≥

−

6 exp

≥

−

6 exp

≥

−

4 exp

≥

−

6 exp

≥

−

6 exp

≥

−

,

,

(cid:18)

(cid:18)

(cid:18)

(cid:18)

(cid:18)

(cid:18)

(cid:18)

−

−

−

−

−

−

−

(cid:19)

18(B2

nt2
8(BBk, Bl)4
+
(cid:19)
nt2
k, Bl)6
+
nt2
18(B, Bk, Bl)6
+
nt2
18(B, Bk, Bl)6
+
(cid:19)
nt2
8(BBl, Bk)4
+
nt2
18(B, Bk, Bl)6
+
(cid:19)
nt2
18(Bk, B2

l )6
+

(cid:19)

(cid:19)

,

(cid:19)

,

,

,

.

By the union bound, we have

P

(cid:12)
(cid:16)(cid:12)
(cid:17)
ˆS(t, t(cid:48)) − S(t, t(cid:48))
(cid:12)
(cid:12)
(cid:12) ≤ 12t
(cid:12)
(cid:19)

(cid:18)

(cid:20)

(cid:18)

≥ 1 −

2 exp

−

+ 4 exp

−

nt2
2B4

= 1 −

2 exp

−

+ 8 exp

−

+ 8 exp

−

4 exp

−

4 exp

−

(cid:18)

(cid:18)

(cid:18)

(cid:20)

(cid:18)

+ 6 exp

−

(cid:19)

(cid:19)

nt2
8(BBk, Bl)4
+
nt2
8(BBl, Bk)4
+
(cid:19)
nt2
2B4

nt2
k, Bl)6
18(B2
+
(cid:19)

nt2
8(BBk, Bl)4
+
(cid:18)

+ 6 exp

−

(cid:18)

+ 6 exp

−

(cid:19)

18(B2

nt2
k, Bl)6
+
nt2
18(B, Bk, Bl)6
+

(cid:18)

(cid:19)

(cid:19)

nt2
8(BBk, Bl)4
+

(cid:18)

+ 6 exp

−

nt2
l )6
18(Bk, B2
+
(cid:18)
(cid:19)

+ 8 exp

−

+ 8 exp

(cid:18)

+ 8 exp

−

(cid:19)

+ 6 exp

122nt2
B∗
122nt2
B∗

−

(cid:18)

(cid:19)

(cid:20)

(cid:18)

≥ 1 −

2 exp

−

+ 6 exp

(cid:18)

= 1 − 62 exp

−

(cid:18)

122nt2
B∗
122nt2
B∗
122nt2
B∗

−

(cid:19)

,

(cid:19)

(cid:18)

+ 4 exp

−

(cid:19)

nt2
8(BBl, Bk)4
+

+ 6 exp

−

(cid:18)

(cid:19)

(cid:19)

(cid:19)

nt2
18(B, Bk, Bl)6
+
(cid:18)

+ 6 exp

−

(cid:18)

+ 8 exp

−

(cid:19)

nt2
18(B, Bk, Bl)6
+
nt2
32 · 32(Bk, Bl)8
+
(cid:19)

(cid:19) (cid:21)

(cid:19)

(cid:18)

+ 24 exp

−

nt2
18(B, Bk, Bl)6
+

nt2
18(B, Bk, Bl)6
+
(cid:18)

nt2
18(Bk, B2

l )6
+

(cid:18)

+ 6 exp

−

(cid:19)

(cid:18)

(cid:19)

+ 6 exp

−

nt2
8(BBl, Bk)4
+
(cid:18)

+ 8 exp

−

(cid:19) (cid:21)

nt2
32 · 32(Bk, Bl)8
+
(cid:19)
122nt2
B∗

−

(cid:18)

(cid:19)

122nt2
B∗
122nt2
B∗

−

(cid:18)

+ 24 exp

(cid:19) (cid:21)

where

B∗ :=

1
122 max(2B4, 8(BBk, Bl)4
By reparameterization, it follows that
(cid:18) c1Jn
γn

(cid:12)
(cid:12)
(cid:12)

P

+, 8(BBl, Bk)4

+, 18(B, Bk, Bl)6

+, 18(B2

k, Bl)6

+, 18(Bk, B2

l )6

+, 32

32(Bk, Bl)8

+).

·

ˆS(t, t(cid:48))

S(t, t(cid:48))

−

(cid:19)

t

(cid:12)
(cid:12)
(cid:12) ≤

1

62 exp

≥

−

(cid:18)

γ2
nt2
c2
1J 2nB∗

−

(cid:19)

.

(23)

F.2.6. UNION BOUND FOR

Recall from (22) that

(cid:12)
(cid:12)
(cid:12)

ˆλn

−

(cid:12)
(cid:12)
(cid:12) AND FINAL LOWER BOUND

λn

ˆλn
|

λn

−

| ≤

ˆS(t(1), t(2))

S(t(1), t(2))

(cid:12)
(cid:12)
(cid:12) +

4BJc1n
γn

(cid:12)
(cid:12)ˆu(˜t)

u(˜t)(cid:12)
(cid:12)

−

−

|

+ c2n√J

ˆu(t∗)

u(t∗)
|

−

+ c3nγn.

c1Jn
γn
c1n
γn

(cid:12)
(cid:12)
(cid:12)
8B2J
1
n

−

+

An Adaptive Test of Independence with Analytic Kernel Embeddings

We will bound terms in (22) separately and combine all the bounds with the union bound. As shown in (8), the U-statistic
core h is bounded between

2B and 2B. Thus, by Lemma 13 (with m = 2), we have

−

Bounding c1n
γn

8B2J
n−1 + c3nγn + 4BJc1n

γn

(cid:12)
(cid:12)ˆu(˜t)

u(˜t)(cid:12)

(cid:12). By Lemma 13 (with m = 2), it follows that

(cid:16)

P

c2n√J

ˆu(t∗)

u(t∗)

|

(cid:17)

t

1

2 exp

| ≤

≥

−

(cid:18)

t2
0.5n
(cid:99)
2n2JB2

(cid:98)
8c2

−

(cid:19)

.

−

−

P

(cid:18) c1n
γn

8B2J
1
n


−

1

2 exp

≥

−

(cid:98)


−

+ c3nγn +

4BJc1n
γn

(cid:12)
(cid:12)ˆu(˜t)

u(˜t)(cid:12)
(cid:12)

−

(cid:104)
t

0.5n

γ2
n
(cid:99)

c1n
γn
−
27B4J 2c2

8B2J
n−1 −
1n2

c3nγn

≤
(cid:105)2

(cid:19)
t






(cid:32)

−
(cid:32)

= 1

2 exp

−

(cid:2)tγn(n

0.5n
(cid:98)

(cid:99)

1)

−
−
27B4J 2c2

8c1B2nJ
1n2(n

−
1)2

c3n(n

−

(cid:3)2

(cid:33)

1)γ2
n

(a)

≥

1

2 exp

−

−

(cid:2)tγn(n

−

1)

8c1B2nJ

−
28B4J 2c2

−
1n2(n

−
c3n(n
1)

−

(cid:3)2

(cid:33)

1)γ2
n

,

−

(24)

(25)

where at (a) we used
bound (22) with

(cid:98)

(cid:99) ≥

−

0.5n

(n

1)/2. Combining (23), (24), and (25) with the union bound (set T = 3t), we can

P

(cid:16)(cid:12)
(cid:12)
(cid:12)

ˆλn

λn

(cid:12)
(cid:12)
(cid:12) ≤

−

(cid:17)

T

1

62 exp

≥

−

(cid:19)

(cid:18)

γ2
nT 2
32c2
1J 2nB∗
1)/3

−
(cid:2)T γn(n

−

2 exp

−

8c1B2nJ
1n2(n

28B4J 2c2

−

(cid:19)

T 2
0.5n
(cid:99)
2n2JB2
nn(n

−

(cid:98)
72c2
−
c3γ2
1)

(cid:18)

−
−

(cid:33)

1)(cid:3)2

.

(cid:32)

2 exp

−

−

Since

(cid:12)
(cid:12)
(cid:12)

ˆλn

λn

(cid:12)
(cid:12)
(cid:12) ≤

−

T implies ˆλn

≥

−

λn

T , a reparametrization with r = λn

T gives

P

(cid:16)ˆλn

(cid:17)

r

1

62 exp

≥

≥

−

(cid:19)

γ2
n(λn
32c2

r)2
−
1J 2nB∗

2 exp

−

−

−

(cid:18)

(cid:19)

r)2

0.5n
(λn
(cid:99)
−
(cid:98)
72c2
2n2JB2
c3γ2
nn(n

(cid:33)

1)(cid:3)2

−

r)γn(n

−

1)/3
−
28B4J 2c2

−

8c1B2nJ
1n2(n

−
1)

−

(cid:18)

−
(cid:2)(λn

(cid:32)

2 exp

−

−

:= L(λn).

Grouping constants into ξ1, . . . ξ5 gives the result.

The lower bound L(λn) takes the form

1

−

62 exp (cid:0)

C1(λn

−

−

Tα)2(cid:1)

2 exp (cid:0)

C2(λn

Tα)2(cid:1)

−

−

−

2 exp

−

−

(cid:18)

[(λn

−

Tα)C3
C5

−

C4]2

(cid:19)

,

where C1, . . . , C5 are positive constants. For ﬁxed large enough n such that λn > Tα, and ﬁxed signiﬁcance level α,
increasing λn will increase L(λn). Speciﬁcally, since n is ﬁxed, increasing u(cid:62)Σ−1u in λn = nu(cid:62)Σ−1u will increase
L(λn).

G. Helper Lemmas

This section contains lemmas used to prove the main results in this work.

Lemma 8 (Product to sum). Assume that
BE−1 (cid:80)E

.

aj

bj

j=1 |

−

|

ai
|

| ≤

B,

bi
|

| ≤

B for i = 1, . . . , E. Then

(cid:12)
(cid:12)
(cid:12)

(cid:81)E

i=1 ai

−

(cid:81)E

i=1 bi

(cid:12)
(cid:12)
(cid:12) ≤

aE

≤ |

−

= BE−1

bE
|
E
(cid:88)

j=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

E−1
(cid:89)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

i=1
BE−1 +

aj

|

bj

|

−

(cid:35)

|
x(i)
j }

{
(cid:34) E
(cid:89)

−

i=1

An Adaptive Test of Independence with Analytic Kernel Embeddings

Proof.

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

E
(cid:89)

i=1

ai

E
(cid:89)

bj

−

j=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

E
(cid:89)

i=1

≤

ai

−

E−1
(cid:89)

i=1

(cid:12)
E−1
(cid:12)
(cid:89)
(cid:12)
(cid:12)
(cid:12)

i=1

E−2
(cid:89)

−

i=1

aibE

+

aibE

aibE−1bE

+ . . . +

(cid:12)
(cid:12)
(cid:12)
a1
(cid:12)
(cid:12)
(cid:12)

E
(cid:89)

j=2

bj

E
(cid:89)

bj

−

j=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

aE

bE

|

−

≤ |

ai

+

aE−1
|

−

bE−1

ai

bE

+ . . . +

a1
|

b1

|

−

aE−1

bE−1

−

|

|

a1
|

b1

|

−

BE−1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

E
(cid:89)

j=2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

bj

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:32)E−2
(cid:89)

(cid:33)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

|

i=1
BE−1 + . . . +

applying triangle inequality, and the boundedness of ai and bi-s.

Lemma 9 (Product variant of the Hoeffding’s inequality). For i = 1, . . . , E, let
a distribution Pi, and fi :
x(E)
x(1)
j }
j }
{
{
empirical distribution based on the sample

R be a measurable function. Note that it is possible that P1 = P2 =
for all x

i be an i.i.d. sample from
= PE and
i and i = 1, . . . , E. Write ˆPi to denote an

i
X
nE
j=1. Assume that

B <
fi(x)
| ≤
ni
j=1. Then,

n1
j=1 =

∈ X

· · ·

· · ·

∞

(cid:55)→

=

x(i)
j }
{

ni
j=1 ⊂ X

P

(cid:32)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:34) E
(cid:89)

E

i=1

x(i)∼ ˆPi

fi(x(i))

E
x(i)∼Pifi(x(i))

(cid:33)

T

(cid:35)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12) ≤

1

2

≥

−

E
(cid:88)

i=1

exp

(cid:18)

niT 2
2E2B2E

−

(cid:19)

.

Proof. By Lemma 8, we have

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:34) E
(cid:89)

E

i=1

(cid:35)

(cid:34) E
(cid:89)

−

i=1

x(i)∼ ˆPi

fi(x(i))

E
x(i)∼Pifi(x(i))

BE−1

(cid:35)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12) ≤

x(i)∼ ˆPi

fi(x(i))

−

(cid:12)
E
x(i)∼Pifi(x(i))
(cid:12)
(cid:12) .

E
(cid:88)

i=1

(cid:12)
(cid:12)
(cid:12)

E

(cid:16)(cid:12)
(cid:12)
(cid:12)

E

x(i)∼ ˆPi

fi(x(i))

E
x(i)∼Pifi(x(i))

−

(cid:17)

t

(cid:12)
(cid:12)
(cid:12) ≤

≥

By applying the Hoeffding’s inequality to each term in the sum, we have P

. The result is obtained with a union bound.

1

2 exp

−

(cid:16)

−

(cid:17)

2nit2
4B2

H. External Lemmas

In this section, we provide known results referred to in this work.
Lemma 10 (Chwialkowski et al. (2015, Lemma 1)). If k is a bounded, analytic kernel (in the sense given in Deﬁnition 1) on
Rd

Rd, then all functions in the RKHS deﬁned by k are analytic.

Lemma 11 (Chwialkowski et al. (2015, Lemma 3)). Let Λ be an injective mapping from the space of probability measures
into a space of analytic functions on Rd. Deﬁne

×

d2
VJ

(P, Q) =

[ΛP ](vj)
|

−

[ΛQ](vj)

2 ,
|

J
(cid:88)

j=1

vi
{

J
i=1 are vector-valued i.i.d. random variables from a distribution which is absolutely continuous with
}

where VJ =
respect to the Lebesgue measure. Then, dVJ (P, Q) is almost surely (w.r.t. VJ ) a metric.
Lemma 12 (Bochner’s theorem (Rudin, 2011)). A continuous function Ψ : Rd
the Fourier transform of a ﬁnite nonnegative Borel measure ζ on Rd, that is, Ψ(x) = (cid:82)
Lemma 13 (A bound for U-statistics (Serﬂing, 2009, Theorem A, p. 201)). Let h(x1, . . . , xm) be a U-statistic kernel for
an m-order U-statistic such that h(x1, . . . , xm)
h(xi1 , . . . , xim )
(cid:1) combinations of m distinct elements
be a U-statistic computed with a sample of size n, where the summation is over the (cid:0) n
. Then, for t > 0 and n
i1, . . . , im

R is positive deﬁnite if and only if it is

Rd e−ix(cid:62)ω dζ(ω), x

. Let Un = (cid:0) n

[a, b] where a

(cid:1)−1 (cid:80)

i1<···<im

from

Rd.

b <

m,

→

∞

≤

∈

∈

m

m

{

}

1, . . . , n
{

}
P(Un

≥
Eh(x1, . . . , xm)

−

t)

≥

≤

exp (cid:0)

2
−

n/m
(cid:99)

(cid:98)

t2/(b

a)2(cid:1) ,

−

An Adaptive Test of Independence with Analytic Kernel Embeddings

P(

Un
|

−

Eh(x1, . . . , xm)

t)

| ≥

≤

2 exp (cid:0)

2
(cid:98)

−

n/m

t2/(b

(cid:99)

−

a)2(cid:1) ,

denotes the greatest integer which is smaller than or equal to x. Hoefﬁnd’s inequality is a special case when

Lemma 14 (Hoeffding’s inequality). Let X1, . . . , Xn be i.i.d. random variables such that a
Deﬁne X := 1
n

i=1 Xi. Then,

(cid:80)n

Xi

≤

≤

b almost surely.

P (cid:0)(cid:12)

(cid:12)X

E[X](cid:12)
(cid:12)

α(cid:1)

−

≤

≥

−

1

2 exp

(cid:18)

2nα2

−

(b

a)2

−

(cid:19)

.

where
x
(cid:98)
m = 1.

(cid:99)

References

[sup4] K. P. Chwialkowski, A. Ramdas, D. Sejdinovic, and A. Gretton. Fast Two-Sample Testing with Analytic Representations

of Probability Measures. In Advances in Neural Information Processing Systems (NIPS), pages 1981–1989. 2015.

[sup14] W. Jitkrittum, Z. Szabó, K. Chwialkowski, and A. Gretton. Interpretable Distribution Features with Maximum Testing

Power. 2016. URL http://arxiv.org/abs/1605.06796.

[sup3] W. Rudin. Fourier analysis on groups. John Wiley & Sons, 2011.

[sup20] R. J. Serﬂing. Approximation Theorems of Mathematical Statistics. John Wiley & Sons, 2009.

