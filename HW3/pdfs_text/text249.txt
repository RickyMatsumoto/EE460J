Robust Guarantees of Stochastic Greedy Algorithms

Avinatan Hassidim 1 Yaron Singer 2

Abstract

In this paper we analyze the robustness of
stochastic variants of the greedy algorithm for
submodular maximization. Our main result
shows that for maximizing a monotone submod-
ular function under a cardinality constraint, itera-
tively selecting an element whose marginal con-
tribution is approximately maximal in expecta-
tion is a sufﬁcient condition to obtain the opti-
mal approximation guarantee with exponentially
high probability, assuming the cardinality is suf-
ﬁciently large. One consequence of our result is
that the linear-time STOCHASTIC-GREEDY algo-
rithm recently proposed in (Mirzasoleiman et al.,
2015) achieves the optimal running time while
maintaining an optimal approximation guaran-
tee. We also show that high probability guaran-
tees cannot be obtained for stochastic greedy al-
gorithms under matroid constraints, and prove an
approximation guarantee which holds in expec-
tation. In contrast to the guarantees of the greedy
algorithm, we show that the approximation ratio
of stochastic local search is arbitrarily bad, with
high probability, as well as in expectation.

1. Introduction

In this paper we study the guarantees of stochastic opti-
mization algorithms for submodular maximization. A func-
tion f : 2N → R is submodular if it exhibits a diminishing
returns property. That is, for any S ⊆ T ⊆ N and any
a /∈ T , the function respects:

fS(a) ≥ fT (a)

where fH (x) denotes the marginal contribution of an ele-
ment x ∈ N to a set H ⊆ N , i.e. fH (x) = f (H ∪ x) −

*Equal

contribution

and
Google
to:
Avinatan Hassidim <avinatan@cs.biu.ac.il>, Yaron Singer
<yaron@seas.harvard.edu>.

Ilan University
Correspondence

2Harvard University.

1Bar

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

f (H). Many fundamental measures such as entropy, di-
versity, and clustering can be modeled as submodular func-
tions, and as a result submodular optimization is heavily
studied in machine learning for well over a decade now.

It is well known that for the problem of maximizing a
monotone (S ⊆ T =⇒ f (S) ≤ f (T )) submodular func-
tion under a cardinality constraint, the celebrated greedy al-
gorithm which iteratively adds the element whose marginal
contribution is maximal, obtains an approximation guaran-
tee of 1 − 1/e (Nemhauser et al., 1978). This is optimal un-
less P=NP (Feige) or alternatively, assuming polynomially-
many function evaluations (Nemhauser & Wolsey, 1978).

In recent years, there have been various adaptations of
the classic greedy algorithm to allow for scalable, dis-
tributed, and noise-resilient optimization. Most notably,
the STOCHASTIC-GREEDY algorithm recently proposed
by (Mirzasoleiman et al., 2015) is a linear-time algorithm
which at every step takes an element, which approximates
in expectation the element with the maximal marginal con-
tribution. Mirzasoleiman et al. show that STOCHASTIC-
GREEDY gives an approximation guarantee which is arbi-
trarily close to 1 − 1/e in expectation, and does very well
in practice (Mirzasoleiman et al., 2015; Lucic et al., 2016).
Variants of this algorithm are used in clustering (Malioutov
et al., 2016), sparsiﬁcation (Lindgren et al., 2016), Gaus-
sian RBF kernels (Sharma et al., 2015), sensing (Li et al.,
2016), and social data analysis (Zhuang et al., 2016).

More generally, a greedy algorithm that iteratively adds el-
ements that are only approximately maximal in expecta-
tion, may not necessarily be due to a design decision, but
rather an artifact of its application on large and noisy data
sets (see e.g. (Azaria et al., 2013)). One can model this
uncertainty with a probability distribution D: at every it-
eration, a value ξ ∼ D is being sampled, and the greedy
algorithm adds an element whose marginal contribution is
a ξ-approximation to the maximal marginal contribution.

In general, we refer to an algorithm that iteratively adds an
element whose marginal contribution is approximately op-
timal in expectation as a stochastic greedy algorithm. It is
easy to show that stochastic greedy algorithms give an ap-
proximation ratio of 1 − 1/eµ in expectation, where µ is
the mean of the distribution modeling the uncertainty. This
however is a weak guarantee as it leaves a non-negligible

Robust Guarantees of Stochastic Greedy Algorithms

likelihood that the algorithm terminates with a solution
with a poor approximation guarantee. Indeed, as we later
show, there are cases where stochastic greedy algorithms
have desirable guarantees in expectation, but with constant
probability have arbitrarily bad approximation guarantees.

Do stochastic optimization algorithms for submodular
maximization have robust approximation guarantees?

1.1. Our results

We prove the following results:

• Optimization under cardinality constraints. For
the problem of maximizing a monotone submodular
function under cardinality constraint k, with uncer-
tainty distribution D with expectation µ, we show that
for any ε ∈ [0, 1], when k ≥ 1
µε2 a stochastic greedy
algorithm obtains an approximation of 1 − 1/e(1−ε)µ
w.p. at least 1 − e−µkε2/2. Furthermore, we prove that
this bound is optimal by showing that for any δ > 0
no algorithm can obtain an approximation ratio better
than 1 − 1/e(1−ε)µ w.p. 1 − δ. For the special case in
which the function is modular, we prove an improved
bound of (1 − ε)µ w.p. at least 1 − e−µkε2/2;

• Optimization under matroid constraints. To fur-
ther study the difference between guarantees that oc-
cur in expectation and guarantees which appear w.h.p,
we study a generalization, where the greedy algorithm
is used to maximize a monotone submodular function
under intersection of matroid constraints, where a dis-
tribution D with mean µ generates uncertainty. We
show that in this case, with P matroids the algorithm
obtains an approximation ratio of µ/(P + 1) in expec-
tation. However, we show that even for a single ma-
troid no algorithm can give a ﬁnite approximate guar-
antee w.p. at least 1−µ−o(1), implying that in general
stochastic greedy algorithms cannot obtain high prob-
ability guarantees under general matroid constraints;

• Stochastic local search. Finally, a natural alternative
to greedy is local search. We show that even for car-
dinality constraints local search performs poorly, and
does not give any meaningful approximation guaran-
tees when there is probabilistic uncertainty about the
quality of the elements. We contrast this with the
case where there is deterministic uncertainty about the
quality of the elements, in which we get an approxi-
mation ratio of (1 + 1/µ)−1, where µ is our uncer-
tainty. This implies that local search does not enjoy
the same robustness guarantees of the greedy algo-
rithms under uncertainty of the quality of elements.

1.2. Applications

The above results have several immediate consequences:

• Fast algorithms for submodular optimization. Our
analysis applies to the STOCHASTIC-GREEDY algo-
rithm (Mirzasoleiman et al., 2015), thus showing its
approximation guarantee holds with high probability,
implying it is the optimal algorithm in terms of run-
ning time and approximation guarantee for the prob-
lem of maximizing a submodular function under a car-
dinality constraint; 1 The same guarantee holds for the
variants studied in (Malioutov et al., 2016; Lindgren
et al., 2016; Sharma et al., 2015; Li et al., 2016);

• Submodular optimization under noise.

In (Has-
sidim & Singer, 2017) the problem of maximization
of submodular functions under a cardinality constraint
is considered when given access to a noisy oracle. Our
result simpliﬁes the analysis of one of the algorithms
in this setting, and gives high probability results for
the inconsistent noise model (Singla et al., 2016).

1.3. Organization of the paper

We describe the results for general monotone submodular
functions in Section 2, and the improved analysis for mod-
ular functions in Section 3. In Section 4 we consider the
more general problem of maximizing a submodular func-
tion under matroid constraints, and show the inapproxima-
bilities of stochastic local search algorithms in Section 5.
Finally, we discuss experiments in Section 6.

2. Submodular Functions

In this section we analyze the stochastic greedy algorithm
for general monotone submodular functions. We ﬁrst ana-
lyze the algorithm, and then show the bound is tight.

2.1. Upper bound

For a given cardinality constraint k, the standard greedy al-
gorithm begins with the empty set as its solution and at each
step {1, . . . , k} adds the element whose marginal contribu-
tion to the existing solution is largest. In the stochastic ver-
sion, the algorithm may no longer add the element whose
marginal contribution is largest. Rather, the algorithm adds
the element whose marginal contribution is at least a fac-
tor of ξ from the maximal marginal contribution, where ξ
is drawn i.i.d from some distribution D with mean µ. We
give a formal description below.

1Formally, the algorithm in (Mirzasoleiman et al., 2015) does
not assume that the expected marginal contribution of the element
selected is approximately optimal, but rather that in expectation
its marginal contribution approximates that of some element in
the optimal solution. Nevertheless our analysis still applies.

Algorithm 1 STOCHASTIC-GREEDY

and using the inductive hypothesis:

Robust Guarantees of Stochastic Greedy Algorithms

input k
1: S ← ∅
2: while |S| < k do
3:
4:
5: end while
output S

ξ ∼ D
S ← S ∪ arbitrary a s.t. fS(a) ≥ ξ maxx∈N fS(x)

The following lemma shows that when the sampled mean
of the distribution is close to 1, stochastic greedy algo-
rithms obtain a near optimal performance guarantee.

Lemma 1. Let S be the set of k elements selected by a
stochastic greedy algorithm s.t.
in each iteration i ∈ [k]
the algorithm selects an element whose marginal contribu-
tion is an ξi approximation to the marginal contribution of
the element with the largest marginal contribution at that
stage, and let ˆµ = 1
i=1 ξi. Then:
k

(cid:80)k

f (S) ≥

1 −

OPT.

(cid:18)

(cid:19)

1
eˆµ

Proof. Let Si = {a1, . . . , ai}, and let the optimal solution
be O, i.e. O ∈ argmaxT :|T |≤k f (T ). Note that for any
i < k we have that:

f (Si+1) − f (Si) = fSi(ai+1)
≥ ξi+1 max
o∈O

fSi(o)

≥

=

≥

ξi+1
k
ξi+1
k
ξi+1
k

fSi(O)

(f (O ∪ Si) − f (Si))

(f (O) − f (Si))

Rearranging, we get:

f (Si+1) ≥

f (O) − f (Si)

+ f (Si)

(1)

(cid:17)

(cid:16)

ξi+1
k

We will show by induction that in every iteration i ∈ [k]:

f (Si+1)
ξi+1
k

≥

≥

ξi+1
k



=

1 −

f (O) +

1 −

f (O) +

1 −

(cid:18)

(cid:18)

(cid:19)

f (Si)



(cid:19)

1 −

ξi+1
k

ξi+1
k

i+1
(cid:89)

(cid:18)

1 −

j=1

ξj
k



(cid:19)

 f (O)

i
(cid:89)

(cid:18)

1 −

j=1

ξj
k



(cid:19)

 f (O)

Since 1 − x ≤ e−x, the above inequality implies:

f (S) = f (Sk)



=

1 −

k
(cid:89)

(cid:18)

1 −

j=1

(cid:16)

(cid:80)k

k

i=1 ξi

1 − e− 1
≥
= (cid:0)1 − e−ˆµ(cid:1) f (O).

ξj
k

(cid:17)



(cid:19)

 f (O)

f (O)

We can now apply concentration bounds on the previous
lemma and prove the main theorem.

Theorem 2. Let f be a monotone submodular function,
which is evaluated with uncertainty coming from a distri-
bution D with mean µ. For any ε ∈ (0, 1), suppose a
stochastic greedy algorithm is being used with k ≥ 2
ε2µ .
Then, w.p. 1 − e− εµ·k

the algorithm returns S s.t.:

2

(cid:18)

f (S) ≥

1 −

(cid:19)

1
e(1−ε)µ

OPT

Proof. Consider an application of the stochastic greedy al-
gorithm with mean µ, and let ξ1, . . . , ξk be the approxi-
mations to the marginal contributions made by i.i.d sam-
ples from a distribution in all iterations 1, . . . , k. Since all
the values {ξi}k
i=1 drawn from the distribution are bounded
from above by 1, by the Chernoff bound we have:

Pr

(cid:34)

1
k

k
(cid:88)

i=1

(cid:35)

ξi < (1 − ε)µ

εµ·k
2

< e



f (Si) ≥

1 −

i
(cid:89)

(cid:18)

1 −

j=1

ξj
k



(cid:19)

 f (O)

By applying Lemma 1 we get our result.

2.2. Tight lower bound

The base case is when i = 1, and S0 = ∅ and by (1):

f (S1) ≥

f (O) − f (S0)

= 1 −

1 −

f (O)

(cid:17)

(cid:18)

(cid:19)

ξ1
k

(cid:16)

ξi+1
k

For a general iteration i + 1, applying (1) for iteration i + 1

Claim 3. For any δ ∈ [0, 1) the competitive ratio of
stochastic greedy with mean µ is at most (1 − 1/eµ) + o(1)
with probability at least 1 − δ.

Proof. Consider maximizing a submodular function when
the oracle has probability µ of returning the element with

Robust Guarantees of Stochastic Greedy Algorithms

the largest marginal contribution, and probability 1 − µ to
return a random element. We present an instance where
greedy returns an approximation ratio of at most 1−1/eµ +
o(1) with probability at least 1 − 1/k. We use the same bad
instance regardless of µ.

The construction is as follows. There are k special ele-
ments, m = 4k3 plain elements and n = 4(m + k)k2
dummy elements (note that the total number of elements
is not n). The value f (S) depends only on the number of
special elements, plain elements and dummy elements con-
tained in S (all special elements are identical). Moreover,
dummy elements contribute nothing to f , and hence, we
can write f (S) = f (i, j), where i is the number of special
elements in S, and j is the number of plain elements.

For i ≥ 1, the value of f depends on j as follows:

f (i, j) =





kk-(k-1)jkk-j-1(k-i)
kk-(k-1)k-2((k-i)(2k-2-j))
kk-(k-1)k-2(3k-i-j-3)
kk

0 ≤ j ≤ k-1

k ≤ j ≤ 2k-3

2k-2 ≤ j ≤ 3k-3-i

3k − i − 2 ≤ j

Note that for i = 0, we have f (0, j) = f (1, j − 1), and
f (0, 0) = 0. Also, one can verify, by case-by-case analysis
that this function is indeed monotone and submodular.

Since f (0, j) = f (1, j − 1) for every j ≥ 1, as long as the
greedy algorithm did not choose any special element yet,
the marginal contribution of a special elements is equal to
the marginal contribution of a plain element.

Let t be the number of times in which the oracle sup-
plied the greedy algorithm with the element with the max-
imal marginal contribution. By an additive version of
the Chernoff bound we have that with probability at least
1 − 24 log k = 1 − k4:

√

t < kµ + 2

k log k

We condition on this event. Next, we argue that with prob-
ability at least 1 − 1/3k all the elements for which the al-
gorithm selected a random element (i.e. did not take an
element whose marginal contribution is a µ approximation
to the largest marginal contribution) are dummy elements.
Consider one of the times in which greedy was given a ran-
dom element. The probability that it was not a dummy el-
4(m+k)k2−k . Applying a union bound,
ement is at most
the probability that in the k − t cases in which greedy was
supplied with a random element it was always a dummy
element is at least 1 − 1/3k. We condition on this event.

m+k

We will now argue that with probability at least 1−1/3k all
the non-dummy elements selected are plain. Consider the
ﬁrst non dummy element chosen by the algorithm. With
probability at least 1 − k/4k3 it is a plain element. We

condition on this event. Assuming by induction that the last
i − 1 non dummy elements which were chosen by greedy
were plain, the probability that i’th non dummy element is
plain is 1 − k
4k3−1 . Taking a union bound over all t such
elements, gives that with probability 1 − 1/3k all t non-
dummy elements chosen by greedy were plain.

√

Combining this together with a union bound, we get that
with probability at least 1 − 1/k greedy chose no special
k log k plain elements, and
elements, at most t = µk + 4
the rest are dummy elements that do not contribute to the
value of the function. This means that the value of the solu-
tion is at most kk − (k − 1)tkk−t, and thus with probability
at least 1 − 1/k the ratio between the value of greedy and
the optimal value is at least:

kk − (k − 1)tkk−t
kk

= 1 −

(cid:19)t

(cid:18) k − 1
k

(cid:32)(cid:18)

(cid:19)k(cid:33)µ+ 4 log k

√

k

≥ 1 −

1 −

1
k

≥ 1 − e−(µ+4 log k/
= 1 − e−µ + o(1)

√

k)

Choosing k = 1/δ we get our desired bound.

3. Modular Functions

In this section we show a tight upper bound for the spe-
cial case in which the function is modular. Recall that a
function f : 2N → R is modular if for every set S ⊆ N
we have that f (S) = (cid:80)
a∈S f (a). Note that in this case
fS(a) = f (a) for all S ⊆ N and a ∈ N .
Theorem 4. Let S ⊆ N be the set returned when applying
a stochastic greedy algorithm with mean µ ∈ [0, 1] on a
modular function f : 2N → R. Then, for any ε ∈ [0, 1],
when k ≥ 2

ε2µ w.p. 1 − e−µkε2/2:

f (S) ≥ (1 − ε)µOPT.

Proof. Suppose that at every stage i ∈ [k] element ai ∈ N
is selected and its marginal contribution is at least ξi of
the optimal marginal contribution at that stage. Let O be
the optimal solution and o(cid:63) ∈ argmaxo∈O\S f (o), where
S is the solution retuned by the algorithm, i.e. S =
{a1, . . . , ak}. The basic idea in this proof is to observe
that since o(cid:63) is not in the solution and throughout the iter-
ations of the algorithm is always a feasible candidate, this
implies that every element ai in the solution S \O has value
at least as large as ξif (o(cid:63)). Intuitively, if there are enough
elements in S \ O for concentration bounds to kick in, we
j∈S\O ξj = (1 − ε)µ and we would be
have that
done since f (S) = f (S \ O) + f (O ∩ S) ≥ (1 − ε)µf (O).

1
|S\O|

(cid:80)

Robust Guarantees of Stochastic Greedy Algorithms

The problem is that S \ O may not be sufﬁciently large, and
we therefore need slightly more nuanced arguments.

We will partition O ∩ S to two disjoint sets of low and high
valued elements: L = {o ∈ O ∩ S : f (o) < f (o(cid:63))} and
H = {o ∈ O ∩ S : f (o) ≥ f (o(cid:63))}. Notice that:

f (O)

=

≤

(cid:88)

o∈O\S
(cid:88)

o∈O\S

= f (O \ S) + f (L) + f (H)

f (o) +

f (o) +

f (o)

(cid:88)

o∈H

(cid:88)

o∈H

(cid:88)

o∈L
(cid:88)

o∈L

(cid:88)

o∈H

= k · f (o(cid:63)) +

(f (o)-f (o(cid:63)))

f (o(cid:63)) +

f (o(cid:63)) +

f (o(cid:63)) +

f (o)-f (o(cid:63))

(cid:16)

(cid:17)

Since o(cid:63) ∈ O \ S, it is a feasible choice for the algorithm at
every stage, and therefore by the deﬁnition of the stochastic
greedy algorithm, for every element ai ∈ S we have that:

f (ai) ≥ ξi max
a∈N

fS(a) = ξi max
a∈N \S

f (a) ≥ ξif (o(cid:63))

Thus, for k ≥ 2/ε2 with probability 1 − e− kµε2

2

:

f (o(cid:63)) + f (o)-f (o(cid:63))

(cid:17)

= f (S \ O) + f (H) + f (L)

f (S)

=

≥

(cid:88)

ai∈S\O
(cid:88)

ai∈S\O

= f (o(cid:63))

= f (o(cid:63))













f (ai) +

f (ai) +

f (o)

(cid:88)

ai∈L

(cid:88)

ai∈L



(cid:88)

o∈H

(cid:88)

o∈H

ξif (o(cid:63)) +

ξif (o(cid:63)) +

f (o)

ai∈(S\O)∪L

(cid:88)

(cid:88)

ξi

 +

f (o)

(cid:88)

o∈H



ξi

 +

(cid:88)

(cid:16)

ai∈(S\O)∪L

o∈H



ξi

 +

≥ f (o(cid:63))

(cid:88)

(cid:88)

(cid:16)

f (o)-f (o(cid:63))

(2)

(cid:17)

ai∈(S\O)∪L∪H

o∈H

≥ (1 − ε)µ · kf (o(cid:63)) +

(cid:88)

(cid:16)

f (o)-f (o(cid:63))

(cid:17)

(3)

(cid:32)

≥ (1 − ε)µ

kf (o(cid:63)) +

f (o)-f (o(cid:63))

(cid:33)

(cid:17)

o∈H

(cid:88)

(cid:16)

o∈H

≥ (1 − ε)µf (O)

where inequality (2) is due to the fact that f (o(cid:63)) ≥ ξif (o(cid:63))
since ξi ≤ 1; inequality (3) is an application of the Cher-
noff bound for k ≥ 2/ε2µ; the last inequality is due to the
upper bound we established on f (O).

The upper bound is tight. An obvious lower bound
holds for the degenerate case where in every stage the
marginal contribution of the element returned is a µ ∈ [0, 1]
approximation to the maximal marginal contribution with
probability 1. Clearly in this case, the approximation ra-
tio is no better than µ (consider n = 2k elements where k
elements have value 1 and k elements have value µ).

4. General Matroid Constraints

In this section we consider the more general problem of
maximizing a monotone submodular function under ma-
troid constraints. Recall that a matroid is a pair (N, I)
where N is the ground set and I is a family of subsets
of N called independent that respects two axioms:
(1)
A ∈ I, A(cid:48) ⊂ A =⇒ A(cid:48) ∈ I and (2) if A, B ∈ I and
|B| < |A| then ∃x ∈ A \ B, s.t. B ∪ {x} ∈ I. The rank
of the matroid is the size of the largest set in I. The car-
dinality constraint, is a special case of optimization under
matroid constraints, where the matroid is uniform.

Submodular maximization under matroid constraints.
The greedy algorithm for maximization under matroid con-
straints is a simple generalization of the uniform case: the
algorithm iteratively identiﬁes the element whose marginal
contribution is maximal and adds it to the solution if it does
not not violate the matroid constraint (i.e. if adding the el-
ement to the set keeps the set in the family of feasible sets
I). This algorithm obtains an approximation ratio of 1/2. 2
More generally, for an intersection of P matroids, this al-
gorithm obtains an approximation guarantee of 1/(1 + P ).

Stochastic greedy under intersection of matroids.
Consider an intersection of matroids, a monotone submod-
ular function f deﬁned over the independent sets, and an
uncertainty distribution D with mean µ. The stochastic
greedy algorithm begins with the solution S = ∅ and set of
elements not yet considered X = N . In every iteration the
algorithm maintains a solution S of elements that are in the
intersection of the P matroids and a value ξ ∼ D is sam-
pled. The algorithm then considers an arbitrary element
a ∈ X whose marginal contribution is ξ maxx∈X fS(x),
and adds a to S if S ∪ a is independent in all P matroids,
and discards a from X.

4.1. Stochastic greedy fails with high probability

We ﬁrst show that unlike the special case of uniform ma-
troids, even for a single matroid, it is generally impossible
to obtain high probability guarantees for maximization un-

2We note that unlike the uniform case, here greedy is not op-
timal. The optimal guarantee of 1 − 1/e can be obtained via an
algorithm based on a continuous relaxation (Vondrák, 2008) or
through local search (Filmus & Ward, 2012).

Robust Guarantees of Stochastic Greedy Algorithms

der matroid constraints, even when the function is modular
and the rank of the matroid is sufﬁciently large.
Claim 5. Even for a modular function and arbitrarily large
k, a stochastic greedy algorithm with mean µ cannot obtain
an approximation better than 0 with probability greater
than µ + o(1), for maximization under matroid of rank k.

Proof. Consider the following example, where the ground
set has two types of elements A = {a1, . . . , am}, and B =
{b1, . . . , bk−1} where m = k2. The rank of the matroid
is k, and a set is independent as long as it contains just a
single ai ∈ A. Deﬁne a modular function: f (a1) = 1, but
f (aj) = 0 for j (cid:54)= 1, and also f (bj) = 0 for any j ∈ [k−1].
The distribution returns 1 w.p. p < 1/2 and 0 otherwise.

In the ﬁrst iteration of the algorithm, the element a1 is
correctly evaluated with probability p, and with probabil-
ity 1 − p it is evaluated as having value 0, in which case
we may assume that a random element is selected instead.
Therefore, w.p. p the algorithm takes a1, and obtains the
optimal solution. However, if this is not the case, then w.p.
m − 1/(m + k) = (k2 − 1)/(k2 + k) the algorithm chooses
an element from A whose value is 0.
In this case, even
if a1 is later correctly evaluated it could not be considered
into the solution since its inclusion violates independence.
Hence, while the expected value of greedy is slightly larger
than p, with probability at least (1 − p) − o(1) the value of
the solution would be 0.

4.2. The guarantee holds in expectation

Although the approximation guarantee cannot hold with
high probability, we now show that in expectation stochas-
tic greedy algorithms achieves the approximation guaran-
tee of non-stochastic greedy when maximizing a monotone
submodular functions under an intersection of P matroids.
Theorem 6. Let F denote the intersection of P ≥ 1 ma-
troids on the ground set N , and f : 2N → R be a monotone
submodular function. The stochastic greedy algorithm re-
turns a solution S ∈ F s.t.:

E[f (S)] ≥

µ
(P + 1)

OPT

.

An equivalent algorithm. To simplify the analysis, it
will be useful to consider the equivalent algorithm, which
at every iteration when the existing solution is S, discards
all elements x for which S ∪ x /∈ F. The following claim
due to Nemhauser et al. is later employed in our analysis:
Claim 7 (Prop. 2.2 in (Nemhauser et al., 1978)). If for
∀t ∈ [k] (cid:80)t−1
i=0 σi ≤ t and pi−1 ≥ pi, with σi, pi ≥ 0 then:

k−1
(cid:88)

i=0

piσi ≤

pi.

k−1
(cid:88)

i=0

Algorithm 2 STOCHASTIC-MATROID-GREEDY

1: S ← ∅, X ← N
2: while X (cid:54)= S do
3: X ← X \ {x : S ∪ {x} /∈ F}
4:
5:
6: end while

ξ ∼ D.
S ← S ∪ arbitrary a s.t. fS(a) ≥ ξ maxx∈X fS(x)

Proof of Lemma 6. Consider the value obtained by the
following procedure. An adversary chooses some maxi-
mal independent set a1, . . . ak. Let Si = {a1, a2, . . . , ai}
with S0 = ∅, and for every i ∈ [k] let a(cid:63)
i be the element
that maximizes the marginal contribution given Si, where
the maximization is over elements a such that Si ∪ {a} is
independent in all P matroids. That is a(cid:63)

i is deﬁned as:

The value of the procedure is then:

max
Si∪{a}∈F

fSi(a)

k−1
(cid:88)

i=0

fSi (a(cid:63)
i )

We will bound the value obtained by the procedure against
that of the optimal solution, and then argue that the value
obtained by the stochastic greedy is equivalent.

Let O denote the optimal solution. We have that:

f (O) ≤ f (O ∪ Sk) ≤ f (Sk) +

fSk (x)

(4)

(cid:88)

x∈O\Sk

For a set S and a matroid Mp in the family F, we deﬁne
rp(S), called the rank of S in Mp to be the cardinality of
the largest subset of S which is independent in Mp, and
deﬁne spp(S), called the span of S in Mp by:

spp(S) = {a ∈ N : rp(S ∪ a) = rp(S)}

If S is independent in Mp, we have that rp(spp(S)) =
rp(S) = |S|. In particular, we have that rp(spp(Si)) = i
for every Si. Now in each 1 ≤ p ≤ P , since O is an
independent set in Mp we have:

rp(spp(Si) ∩ (O)) = |spp(Si) ∩ (O)|

which implies that |spp(Si) ∩ (O)| ≤ i.
Deﬁne Ui = ∪P
p=1spp(Si), to be the set of elements which
are not part of the maximization in step i + 1 of the proce-
dure, and hence cannot give value at that stage. We have:

|Ui ∩O| = |(∪P

p=1spp(Si))∩O| ≤

|spp(Si)∩O| ≤ iP

P
(cid:88)

p=1

Robust Guarantees of Stochastic Greedy Algorithms

Let Vi = (Ui \ Ui−1) ∩ O be the elements of O which are
not part of the maximization in step i, but were part of the
maximization in step i − 1. If x ∈ Vi then it must be that:

fSk (x) ≤ fSi(x) ≤ fSi(a(cid:63)
i )

since x was not chosen in step i. Hence, we can upper
bound:

search algorithms converge in polynomial time, the con-
vention is to seek approximate local maxima. A solution S
is an α-approximate local maximum if no element ai in S
can be exchanged for another element aj not in S whose
marginal contribution to S−i is greater by a factor of α. It
is easy to show that an α-approximate local maximum is a
(1 + 1/α)−1 approximation (Filmus & Ward, 2012).

fSk (x) ≤

fSi(a(cid:63)
i )

x∈O\Sk

(cid:88)

k
(cid:88)

i=1

k
(cid:88)

(cid:88)

i=1

x∈Vi

k
(cid:88)

i=1

=

|Vi|fSi(a(cid:63)) ≤ P

fSi(a(cid:63))

where the last inequality uses (cid:80)i
t=1 |Vt| = |Ui ∩ O| ≤
P i and the arithmetic claim proven in Claim 7 due
to (Nemhauser et al., 1978). Together with (4), we get:

f (O) ≤ (P + 1)

fSi (a(cid:63)
i )

k
(cid:88)

i=1

Finally, note that STOCHASTIC-MATROID-GREEDY ob-
tains a µ = Eξ∼D[ξ] approximation of the value of the
procedure, in expectation. In each stage, one can add the
element chosen by the algorithm to the procedure. Hence,
at each stage STOCHASTIC-MATROID-GREEDY and the
procedure have the same set of elements available, and the
same a(cid:63)
i which maximizes the marginal contribution.

5. Inapproximability of Local Search

In this section we consider variants of stochastic local
search algorithms. We show that unlike the greedy algo-
rithm, stochastic local search algorithms can end up with
arbitrarily bad approximation guarantees.

Local search for submodular maximization. For N =
{a1, . . . , an}, given a set of elements T ⊆ N we will use
T−i to denote the set without element ai, i.e. T−i = T \
{ai}. A solution S is a local maximum if no single element
ai in S can be exchanged for another element aj not in S
whose marginal contribution to S−i is greater. That is, S is
a local maximum if for every ai ∈ S we have that:

fS−i(ai) ≥ max
x /∈S

fS−i(x).

It is not hard to show that for any monotone submod-
ular function, if S is a local maximum it is a 1/2 ap-
proximation to the optimal solution. A local search algo-
rithm begins with an arbitrarily set of size k, and at ev-
ery stage exchanges one of its elements with the element
whose marginal contribution is maximal to the set, un-
til it reaches a local maximum. To guarantee that local

Stochastic local search. A natural question is whether
local search enjoys the same robustness guarantees as the
greedy algorithm. We say that a solution S is a stochas-
tic local maximum up to approximation µ if no single ele-
ment in S can be exchanged for another element not in S
whose expected marginal contribution is greater by a factor
µ. That is, S is a stochastic local maximum with mean µ if
for every ai ∈ S we have that:

E[fS−i(ai)] ≥ µ · max
x /∈S

fS−i(x)

If we have uncertaintiy modeled by a distribution D ⊆
[0, 1], a solution is a stochastic local maximum w.r.t D if
for every element ai in S we draw ξi ∼ D s.t.

fS−i(ai) ≥ ξi · max
b /∈S

fS−i(b)

A stochastic local search algorithm will therefore begin
from an arbitrary solution S of size k, and at every iter-
ation swap an element from the solution with an element
outside the solution if S is not a stochastic local maximum
w.r.t. D. More speciﬁcally, the stochastic local search al-
gorithm selects an element ai from S and replaces it with
another element aj whose expected marginal contribution
to S−i is at least fS−i(ai)/ξi, and repeats this process until
no such elements are found. This is a similar abstraction of
stochastic greedy algorithms, applicable in settings when
one cannot evaluate the optimal marginal contribution ex-
actly, but approximately well in expectation.

Consistent and inconsistent stochasticity. We consider
two approaches to model the way in which the random vari-
ables ξi are assigned to an element ai in the solution:

1. Consistent: For each element ai ∈ N , ξi is a random
variable drawn independently from D ⊆ [0, 1], and
ﬁxed for the entire run of the algorithm;

2. Inconsistent: At each step of the algorithm, for ev-
ery element ai ∈ S, ξi is a random variable drawn
independently from D.

Note that the solution converges, as the distribution D
makes the algorithm more conservative.

Robust Guarantees of Stochastic Greedy Algorithms

Figure 1: Function value as a function of solution size for greedy and local search with uncertainty

Inapproximability of stochastic local search. We show
that in both consistent and inconsistent models, stochastic
local search performs poorly, even for modular functions.
Consider a setting where there are n elements, and a mod-
ular function. For every i > 1, we have f (ai) = ε/i for
some negligible ε > 0 (e.g. ε = 2−n), but f (a1) = 1. As
for D, w.p. 0.99 it returns 1, and 0 o.w. Assume k = 1.
Lemma 8. The expected approximation guarantee of
stochastic local search is at most 2−O(n) + ε.

Proof. At the ﬁrst iteration, local search chooses an.
If
ξ = 0, we are done, and this is a local maxima. Otherwise,
local search chooses an−1. At iteration i local search starts
with ai, halts w.p. 0.01 (the probability that D outputs 0),
and otherwise continues. The probability that it will not
halt for n steps and reach ai is 0.99n = 2−O(n).

We note that in the above proof we assumed that the local
search algorithm chooses an arbitrary element at every iter-
ation. If one allows the stochastic local search to randomly
choose an element in every iteration a similar construction
shows an inapproximability of O( log n

n ) + ε.

6. Experiments

to

applied

algorithms

ego-network
an
the
We
from (Leskovec & Krevl, 2014).
This network has
333 nodes and 5038 edges. The submodular function
we used is coverage, which models inﬂuence in social
networks. In order to emphasize the implications of having
results w.h.p, the graphs do not depict the average of many
runs, but instead each graph is a single run of the algorithm.
In greedy, we present the value of the solution at each
iteration k. In local search and in random we sort elements
of the solution according to marginal contributions.

We start with greedy and describe the different distribu-
tions we used to model uncertainty. The same distributions
were used for local search. Both left panes include the
greedy algorithm without uncertainty (greedy, blue line),
and choosing a random set (random, black line). When
running stochastic greedy, we ﬁrst sample a value ξ ∈ D,

and then pick a random element out of the elements that
have marginal contribution at least ξ maxa fS(a). The dis-
tribution D varies between the different lines. In the left-
most pane, APX (red line) depicts a D which is the con-
stant distribution 0.5. In Stochastic greedy with mean 0.75,
D is the uniform distribution on [0.5, 1] (purple line), and
in Stochastic greedy with mean 0.5, D is the uniform dis-
tribution on [0, 1].
It is expected that APX will behave
smoothly, as D is a degenerate distribution in this case
(note that there is still randomization in which element to
choose at every stage out of the eligible elements). How-
ever, we see that the h.p. result kicks in, and the APX line
is similar (across many values of k) to stochastic greedy
with mean 0.5. Raising the mean to 0.75 makes stochas-
tic greedy behave almost like greedy when k gets large,
so in some cases stochastic greedy makes the same choice
greedy would make.

In the second pane, The purple line (exponential) depicts
D as an exponential distribution with λ = 4, which gives
a mean of 0.25. The red line is uniform in [0, 5], and the
yellow is a Gaussian with µ = 0.25 and σ = 0.1. We see
that all graphs are further away from Greedy compared to
the leftmost pane, and that higher variance is generally not
a good thing, although the differences are small.

The two right panes depict the same noise distributions as
the two left panes, but this time we use local search (or
stochastic local search) instead of greedy. It is easy to see
that D affects local search more than it affects greedy. The
plateau is caused since we sort the ﬁnal solution and then
plot the elements, and since if some elements have a low
value of ξi they are likely to stay in the solution even if
they contribute very little, as in Lemma 8.

7. Acknowledgements

A.H. was supported by ISF 1394/16; Y.S. was supported
by NSF grant CCF-1301976, CAREER CCF-1452961, a
Google Faculty Research Award, and a Facebook Faculty
Gift. We thank Andreas Krause for pointing the connection
between our result and (Mirzasoleiman et al., 2015).

llllllllllllllllllllllllllllll13579111315171921232527290200budget kfunction valuelllGREEDYAPX−GREEDY w. apx 0.5STOCHASTIC−GREEDY w. mean 0.75STOCHASTIC−GREEDY w. mean 0.5RANDOMllllllllllllllllllllllllllllll13579111315171921232527290200budget kfunction valuelllGREEDYuniformexponentialnormalRANDOMllllllllllllllllllllllllllllll13579111315171921232527290200budget kfunction valuelllLSAPX−LS w. apx 0.5STOCHASTIC−LS w. mean 0.75STOCHASTIC−LS w. mean 0.5RANDOMllllllllllllllllllllllllllllll13579111315171921232527290200budget kfunction valuelllLSuniformexponentialnormalRANDOMRobust Guarantees of Stochastic Greedy Algorithms

Vondrák, Jan. Optimal approximation for the submodular
In STOC,

welfare problem in the value oracle model.
2008.

Zhuang, Hao, Rahman, Rameez, Hu, Xia, Guo, Tian, Hui,
Pan, and Aberer, Karl. Data summarization with social
contexts. In CIKM, 2016.

References

Azaria, Amos, Hassidim, Avinatan, Kraus, Sarit, Eshkol,
Adi, Weintraub, Ofer, and Netanely, Irit. Movie recom-
mender system for proﬁt maximization. In Proceedings
of the 7th ACM conference on Recommender systems,
pp. 121–128. ACM, 2013.

Feige, Uriel. A threshold of ln n for approximating set

cover. Journal of the ACM, 45(4).

Filmus, Yuval and Ward, Justin. A tight combinatorial al-
gorithm for submodular maximization subject to a ma-
troid constraint. In FOCS, 2012.

Hassidim, Avinatan and Singer, Yaron. Submodular opti-

mization under noise. In COLT, 2017.

Leskovec, Jure and Krevl, Andrej. SNAP Datasets: Stan-
ford large network dataset collection. http://snap.
stanford.edu/data, June 2014.

Li, Chengtao, Sra, Suvrit, and Jegelka, Stefanie. Gaussian
quadrature for matrix inverse forms with applications. In
ICML, 2016.

Lindgren, Erik, Wu, Shanshan, and Dimakis, Alexan-
dros G. Leveraging sparsity for efﬁcient submodular
data summarization. In NIPS, 2016.

Lucic, Mario, Bachem, Olivier, Zadimoghaddam, Morteza,
and Krause, Andreas. Horizontally scalable submodular
maximization. In ICML, 2016.

Malioutov, Dmitry, Kumar, Abhishek, and Yen, Ian En-
Hsu. Large-scale submodular greedy exemplar selection
with structured similarity matrices. In UAI, 2016.

Mirzasoleiman, Baharan, Badanidiyuru, Ashwinkumar,
Karbasi, Amin, Vondrák, Jan, and Krause, Andreas.
Lazier than lazy greedy. In AAAI, 2015.

Nemhauser, George L and Wolsey, Leonard A. Best algo-
rithms for approximating the maximum of a submodular
set function. Mathematics of operations research, 3(3):
177–188, 1978.

Nemhauser, George L, Wolsey, Laurence A, and Fisher,
Marshall L. An analysis of approximations for maxi-
mizing submodular set functions—i. Mathematical Pro-
gramming, 14(1):265–294, 1978.

Sharma, Dravyansh, Kapoor, Ashish, and Deshpande,
In ICML,

Amit. On greedy maximization of entropy.
2015.

Singla, Adish, Tschiatschek, Sebastian, and Krause, An-
dreas. Noisy submodular maximization via adaptive
sampling with applications to crowdsourced image col-
lection summarization. In AAAI, 2016.

