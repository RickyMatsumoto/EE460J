Convergence Analysis of Proximal Gradient with Momentum for Nonconvex
Optimization

Qunwei Li 1 Yi Zhou 1 Yingbin Liang 1 Pramod K. Varshney 1

Abstract

Algorithm 1 APG

In this work, we investigate the accelerated prox-
imal gradient method for nonconvex program-
ming (APGnc). The method compares between
a usual proximal gradient step and a linear ex-
trapolation step, and accepts the one that has a
lower function value to achieve a monotonic de-
crease. In speciﬁc, under a general nonsmooth
and nonconvex setting, we provide a rigorous ar-
gument to show that the limit points of the se-
quence generated by APGnc are critical points
of the objective function. Then, by exploit-
ing the Kurdyka-Łojasiewicz (KŁ) property for
a broad class of functions, we establish the linear
and sub-linear convergence rates of the function
value sequence generated by APGnc. We further
propose a stochastic variance reduced APGnc
(SVRG-APGnc), and establish its linear conver-
gence under a special case of the KŁ property.
We also extend the analysis to the inexact ver-
sion of these methods and develop an adaptive
momentum strategy that improves the numerical
performance.

1. Introduction

Many problems in machine learning, data mining, and sig-
nal processing can be formulated as the following compos-
ite minimization problem

min
x∈Rd

F (x) = f (x) + g(x).

(P)

Typically, f : Rd → R captures the loss of data ﬁtting and
can be written as f = 1
l=1 fl with each fl correspond-
n
ing to the loss of one sample. The second term g : Rd → R
is the regularizer that promotes desired structures on the so-
lution based on prior knowledge of the problem.

(cid:80)n

Input: y1 = x1 = x0, t1 = 1, t0 = 0, η < 1
L .
for k = 1, 2, · · · do
yk = xk + tk−1−1
(xk − xk−1).
tk
xk+1 = proxηg(yk − η∇f (yk)).

√

4t2
k+1+1
2

.

tk+1 =

end for

In practice, many problems of (P) are formulated, either
naturally or intensionally, into a convex model to guaran-
tee the tractability of algorithms. In particular, such con-
vex problems can be efﬁciently minimized by many ﬁrst-
order algorithms, among which the accelerated proximal
gradient (APG) method (also referred to as FISTA (Beck
& Teboulle, 2009b)) is proven to be the best for minimiz-
ing such class of convex functions. We present one of its
basic forms in Algorithm 1. Compared to the usual prox-
imal gradient step, the APG algorithm takes an extra lin-
ear extrapolation step for acceleration. It has been shown
(Beck & Teboulle, 2009b) that the APG method reduces the
function value gap at a rate of O(1/k2) where k denotes
the number of iterations. This convergence rate meets the
theoretical lower bound of ﬁrst-order gradient methods for
minimizing smooth convex functions. The reader can refer
to (Tseng, 2010) for other variants of APG.

Algorithm 2 Monotone APG (mAPG)

Input: y1 = x1 = x0, t1 = 1, t0 = 0, η < 1
L .
for k = 1, 2, · · · do
yk = xk + tk−1
tk
tk
zk+1 = proxηg(yk − η∇f (yk)).
vk+1 = proxηg(xk − η∇f (xk)).

(zk − xk) + tk−1−1

√

(xk − xk−1).

4t2
k+1+1
tk+1 =
2
if F (zk+1) ≤ F (vk+1) then

.

xk+1 = zk+1,

else if F (vk+1) ≤ F (zk+1) then

1Syracuse University, NY, USA. Correspondence to: Qunwei

xk+1 = vk+1.

Li <qli33@syr.edu>.

end if
end for

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

Although convex problems are tractable and can be glob-

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

Algorithm 3 APG non-convex problem (APGnc)

1.1. Main Contributions

Input: y1 = x0, βk = k
for k = 1, 2, · · · do

k+3 , η < 1
L .

xk = proxηg(yk − η∇f (yk)).
vk = xk + βk(xk − xk−1).
if F (xk) ≤ F (vk) then

else if F (vk) ≤ F (xk) then

yk+1 = xk,

yk+1 = vk.

end if
end for

ally minimized, many applications naturally require to
solve nonconvex optimization problems of (P). Recently,
several variants of the APG method have been proposed
for nonconvex problems, and two major ones are presented
in Algorithm 2 and Algorithm 3, respectively. The major
difference to the original APG is that the modiﬁed methods
only accept the new iterate when the corresponding func-
tion value is sufﬁciently decreased, which leads to a more
stable convergence behavior. In particular, (Li & Lin, 2015)
analyzed mAPG (Algorithm 2) by exploiting the Kurdyka-
Łojasiewicz (KŁ) property, which is a local geometrical
structure very generally held by a large class of nonconvex
objective functions, and has been successfully exploited to
characterize the asymptotic convergence behavior of many
ﬁrst order methods. It was shown in (Li & Lin, 2015) that
mAPG achieves the O(1/k2) convergence rate for convex
problems of (P), and converges to a critical point at sublin-
ear and linear rates under different cases of the KL prop-
erty for nonconvex problems. Despite the desirable con-
vergence rate, mAPG requires two proximal steps, which
doubles the computational complexity of the original APG.
In comparison, the APGnc (Algorithm 3) requires only one
proximal step, and hence computes faster than mAPG in
each iteration. However, the analysis of APGnc in (Yao &
Kwok, 2016) does not exploit the KL property and no con-
vergence rate of the function value is established. Hence,
there is still no formal theoretical comparison of the overall
performance (which depends on both computation per iter-
ation and convergence rate) between mAPG and APGnc. It
is unclear whether the computational saving per iteration in
APGnc is at the cost of lower convergence rate.

The goal of this paper is to provide a comprehensive anal-
ysis of the APGnc algorithm under the KL framework,
thus establishing a rigorous comparison between mAPG
and APGnc and formally justifying the overall advantage
of APGnc.

This paper provides the convergence analysis of APGnc
type algorithms for nonconvex problems of (P) under the
KL framework as well as the inexact situation. We also
study the stochastic variance reduced APGnc algorithm and
its inexact situation. Our analysis requires novel techni-
cal treatments to exploit the KŁ property due to the joint
appearance of the following ingredients in the algorithms
including momentum terms, inexact errors, and stochastic
variance reduced gradients. Our contributions are summa-
rized as follows.

For APGnc applied to nonconvex problems of (P), we
show that the limit points of the sequences generated by
APGnc are critical points of the objective function. Then,
by exploiting different cases of the Kurdyka-Łojasiewicz
property of the objective function, we establish the linear
and sub-linear convergence rates of the function value se-
quence generated by APGnc. Our results formally show
that APGnc (with one proximal map per iteration) achieves
the same convergence properties as well as the convergence
rates as mAPG (with two proximal maps per iteration) for
nonconvex problems, thus establishing its overall compu-
tational advantage.

We further propose an APGnc+ algorithm, which is an im-
proved version of APGnc by adapting the momentum step-
size (see Algorithm 4), and shares the same theoretical con-
vergence rate as APGnc but numerically performs better
than APGnc.

Furthermore, we study the inexact APGnc in which the
computation of the gradient and the proximal mapping may
have errors. We show that the algorithm still achieves the
convergence rate at the same order as the exact case as long
as the inexactness is properly controlled. We also explic-
itly characterize the impact of errors on the constant factors
that affect the convergence rate.

To facilitate the solution to large-scale optimization prob-
lems, we study the stochastic variance reduced APGnc
(SVRG-APGnc), and show that such an algorithm achieves
linear convergence rate under a certain case of the KŁ prop-
erty. We further analyze the inexact SVRG-APGnc and
show that it also achieves the linear convergence under the
same KŁ property as long as the error in the proximal map-
ping is bounded properly. This is the ﬁrst analysis of the
SVRG proximal algorithm with momentum that exploits
the KŁ structure to establish linear convergence rate for
nonconvex programming.

Our numerical results further corroborate the theoretic
analysis. We demonstrate that APGnc/APGnc+ out-
performs APG and mAPG for nonconvex problems in
both exact and inexact cases, and in both deterministic
and stochastic variants of the algorithms. Furthermore,

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

APGnc+ outperforms APGnc due to properly chosen mo-
mentum stepsize.

1.2. Comparison to Related Work

APG algorithms: The original accelerated gradient
method for minimizing a single smooth convex function
dates back to (Nesterov, 1983), and is further extended as
APG in the composite minimization framework in (Beck &
Teboulle, 2009b; Tseng, 2010). While these APG variants
generate a sequence of function values that may oscillate,
(Beck & Teboulle, 2009a) proposed another variant of APG
that generates a non-increasing sequence of function val-
ues. Then, (Li & Lin, 2015) further proposed an mAPG that
generates a sufﬁciently decreasing sequence of function
values, and established the asymptotic convergence rates
under the KŁ property. Recently, (Yao & Kwok, 2016)
proposed APGnc, which is a more efﬁcient version of APG
for nonconvex problems, but the analysis only character-
izes ﬁxed points and did not exploit the KŁ property to
characterize the convegence rate. A uniﬁed treatment of
accelerated gradient method for nonconvex stochastic opti-
mization is presented in (Ghadimi & Lan, 2016). But the
discussion does not exploit the KŁ property, and requires
function g to be convex. Our study establishes the conver-
gence rate analysis of APGnc under the KŁ property.

Nonconvex optimization under KŁ: The KŁ property
(Bolte et al., 2007) is an extension of the Łojasiewicz gradi-
ent inequality (Łojasiewicz, 1965) to the nonsmooth case.
Many ﬁrst-order descent methods, under the KŁ property,
can be shown to converge to a critical point (Attouch &
Bolte, 2009; Attouch et al., 2010; Bolte et al., 2014) with
different types of asymptotic convergence rates.
(Li &
Lin, 2015) and our paper focuses on the ﬁrst-order algo-
rithms with momentum, and respectively analyze mAPG
and APGnc by exploiting the KŁ property.

Inexact algorithms under KŁ:
(Attouch et al., 2013;
Frankel et al., 2015) studied the inexact proximal algorithm
under the KŁ property. This paper studies the inexact prox-
imal algorithm with momentum (i.e., APGnc) under the KŁ
property. While (Yao & Kwok, 2016) also studied the in-
exact APGnc, the analysis did not exploit the KŁ property
to characterize the convergence rate.

Nonconvex SVRG: SVRG was ﬁrst proposed in (John-
son & Zhang, 2013), to accelerate the stochastic gradient
method for strongly convex objective functions, and was
studied for the convex case in (Zhu & Yuan, 2016). Re-
cently, SVRG was further studied for smooth nonconvex
optimization in Reddi et al. (2016a). Then in (Reddi et al.,
2016b), the proximal SVRG was proposed and studied for
nonsmooth and nonconvex optimization. Our paper further
incorporates SVRG for the proximal gradient with momen-
tum in the nonconvex case. Furthermore, we exploit a cer-

tain KŁ property in our analysis that is very different from
the PL property exploited in (Reddi et al., 2016a), and re-
quires special technical treatment in convergence analysis.

2. Preliminaries and Assumptions

In this section, we ﬁrst introduce some technical deﬁnitions
that are useful later on, and then describe the assumptions
on the problem (P) that we take in this paper.
Throughout this section, h : Rd → (−∞, +∞] is an ex-
tended real-valued function that is proper, i.e., its domain
dom h := {x ∈ Rd : h(x) < ∞} is nonempty, and is
closed, i.e., its sublevel sets {x ∈ Rd : h(x) ≤ α} are
closed for all α ∈ R. Note that a proper and closed function
h can be nonsmooth and nonconvex, hence we consider the
following generalized notion of derivative.

Deﬁnition 1 (Subdifferential, (Rockafellar & Wets, 1997)).
The Frech´et subdifferential ˆ∂h of h at x ∈ dom h is the set
of u ∈ Rd such that

lim inf
z(cid:54)=x,z→x

h(z)−h(x)−u(cid:62)(z−x)
(cid:107)z−x(cid:107)

≥ 0,

while the (limiting) subdifferential ∂h at x ∈ dom h is the
graphical closure of ˆ∂h:

{u : ∃(xk, h(xk)) → (x, h(x)), ˆ∂h(xk) (cid:51) uk → u}.

In particular, this generalized derivative reduceds to ∇h
when h is continuously differentiable, and reduces to the
usual subdifferential when h is convex.
Deﬁnition 2 (Critical point). A point x ∈ Rd is a critical
point of h iff 0 ∈ ∂h(x).
Deﬁnition 3 (Distance). The distance of a point x ∈ Rd to
a closed set Ω ⊆ Rd is deﬁned as:

distΩ(x) := miny∈Ω (cid:107)y − x(cid:107).

(1)

Deﬁnition 4 (Proximal map, e.g.
(Rockafellar & Wets,
1997)). The proximal map of a point x ∈ Rd under a
proper and closed function h with parameter η > 0 is de-
ﬁned as:

proxηh(x) := argminz h(z) + 1

2η (cid:107)z − x(cid:107)2,

(2)

where (cid:107) · (cid:107) is the Euclidean l2 norm.

We note that when h is convex, the corresponding proximal
map is the minimizer of a strongly convex function, i.e., a
singleton. But for nonconvex h, the proximal map can be
set-valued, in which case proxηh(x) stands for an arbitrary
element from that set. The proximal map is a popular tool
to handle the nonsmooth part of the objective function, and
is the key component of proximal-like algorithms (Beck &
Teboulle, 2009b; Bolte et al., 2014).

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

Deﬁnition 5 (Uniformized KŁ property, (Bolte et al.,
2014)). Function h is said to satisfy the uniformized KŁ
property if for every compact set Ω ⊂ domh on which h is
constant, there exist ε, λ > 0 such that for all ¯x ∈ Ω and
all x ∈ {x ∈ Rd : distΩ(x) < ε} ∩ [x : h(¯x) < h(x) <
h(¯x) + λ], one has

ϕ(cid:48) (h(x) − h(¯x)) · dist∂h(x)(0) ≥ 1,
(3)
where the function ϕ : [0, λ) → R+ takes the form ϕ(t) =
c
θ tθ for some constants c > 0, θ ∈ (0, 1].

The above deﬁnition is a modiﬁed version of the original
KŁ property (Bolte et al., 2010; Kurdyka, 1998), and is
more convenient for our analysis later. The KŁ property is
a generalization of the Łojasiewicz gradient inequality to
nonsmooth functions (Bolte et al., 2007), and it is a power-
ful tool to analyze a class of ﬁrst-order descent algorithms
(Attouch & Bolte, 2009; Attouch et al., 2010; Bolte et al.,
2014). In particular, the class of semi-algebraic functions
satisfy the above KŁ property. This function class covers
most objective functions in real applications, for instance,
all lp where p ≥ 0 and is rational, real polynomials, rank,
etc. For a more detailed discussion and a list of examples
of KŁ functions, see (Bolte et al., 2014) and (Attouch et al.,
2010).

We adopt the following assumptions on the problem (P) in
this paper.
Assumption 1. Regarding the functions f, g (and F = f +
g) in (P)

1. They

are

semicontinous;
set
sublevel
inf x∈Rd F (x)
{x ∈ Rd : F (x) ≤ α} is bounded for all α ∈ R;

proper
>

lower

−∞;

and

the

2. They satisfy the uniformized KŁ property;
3. Function f is continuously differentiable and the gradi-

ent ∇f is L-Lipschitz continuous.

Note that the sublevel set of F is bounded when either f or
g has bounded sublevel set, i.e., f (x) or g(x) → +∞ as
(cid:107)x(cid:107) → +∞. Of course, we do not assume convexity on
either f or g, and the KŁ property serves as an alternative
in this general setting.

3. Main Results

In this section, we provide our main results on the con-
vergence analysis of APGnc and SVRG-APGnc as well as
inexact variants of these algorithms. All proofs of the the-
orems are provided in supplemental materials.

3.1. Convergence Analysis

In this subsection, we characterize the convergence of
APGnc. Our ﬁrst result characterizes the behavior of the
limit points of the sequence generated by APGnc.

Theorem 1. Let Assumption 1.{1,3} hold for the problem
(P). Then with stepsize η < 1
L , the sequence {xk} gener-
ated by APGnc satisﬁes

1. {xk} is a bounded seuqence;
2. The set of limit points Ω of {xk} forms a compact set,

on which the objective function F is constant;

3. All elements of Ω are critical points of F .

Theorem 1 states that the sequence {xk} generated by
APGnc eventually approaches a compact set (i.e., a closed
and bounded set in Rd) of critical points, and the objective
function remains constant on it. Here, approaching criti-
cal points establishes the ﬁrst step for solving general non-
convex problems. Moreover, the compact set Ω meets the
requirements of the uniform KŁ property, and hence pro-
vides a seed to exploit the KŁ property around it. Next,
we further utilize the KŁ property to establish the asymp-
totic convergence rate for APGnc. In the following theo-
rem, θ is the parameter in the uniformized KŁ property via
the function ϕ that takes the form ϕ(t) = c
θ tθ for some
c > 0, θ ∈ (0, 1].

Theorem 2. Let Assumption 1.{1,2,3} hold for the prob-
lem (P). Let F (x) ≡ F ∗ for all x ∈ Ω (the set of limit
points), and denote rk := F (xk) − F ∗. Then with stepsize
η < 1
L , the sequence {rk} satisﬁes for k0 large enough

1. If θ = 1, then rk reduces to zero in ﬁnite steps;
2. If θ ∈ [ 1
3. If θ ∈ (0, 1

2 , 1), then rk ≤ ( c2d1
)k−k0rk0 ;
1+c2d1
c
2 ), then rk ≤ (
(k−k0)d2(1−2θ) )
η + L)2/( 1
2η − L
2θ−2 − 1)r2θ−1
}.

where d1 = ( 1
min{ 1
,
2cd1

c
1−2θ (2

1
1−2θ ,

2θ−1

k0

2 ) and d2 =

Theorem 2 characterizes three types of convergence behav-
iors of APGnc, depending on θ that parameterizes the KŁ
property that the objective function satisﬁes. An illustrative
example for the ﬁrst kind (θ = 1) can take a form similar to
F (x) = |x| for x ∈ R around the critical points. The func-
tion is ‘sharp’ around its critical point x = 0 and thus the
iterates slide down quickly onto it within ﬁnite steps. For
the second kind (θ ∈ [ 1
2 , 1)), example functions can take
a form similar to F (x) = x2 around the critical points.
That is, the function is strongly convex-like and hence the
convergence rate is typically linear. Lastly, functions of
the third kind are ‘ﬂat’ around its critical points and thus
the convergence is slowed down to sub-linear rate. We
note that characterizing the value of θ for a given function
is a highly non-trivial problem that takes much indepen-
dent effort (Kurdyka & Spodzieja, 2011; Li & Kei, 2016).
Nevertheless, KŁ property provides a general picture of the
asymptotic convergence behaviors of APGnc.

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

Algorithm 4 APGnc with adaptive momentum (APGnc+)

1. g is convex;
2. g is nonconvex, and (cid:15) = 0.

Input: y1 = x0, β, t ∈ (0, 1), η < 1
L .
for k = 1, 2, · · · do

xk = proxηg(yk − η∇f (yk)).
vk = xk + β(xk − xk−1).
if F (xk) ≤ F (vk) then
yk+1 = xk, β ← tβ.
else if F (vk) ≤ F (xk) then
yk+1 = vk, β ← min{ β

t , 1}.

end if
end for

3.2. APGnc with Adaptive Momentum

The original APGnc sets the momentum parameter βk =
k
k+3 , which can be theoretically justiﬁed only for convex
problems. We here propose an alternative choice of the
momentum stepsize that is more intuitive for nonconvex
problems, and refer to the resulting algorithm as APGnc+
(See Algorithm 4). The idea is to enlarge the momentum
β to further exploit the opportunity of acceleration when
the extrapolation step vk achieves a lower function value.
Since the proofs of Theorem 1 and Theorem 2 do not de-
pend on the exact value of the momentum stepsize, APGnc
and APGnc+ have the same order-level convergence rate.
However, we show in Section 4 that APGnc+ improves
upon APGnc numerically.

3.3. Inexact APGnc

We further consider inexact APGnc, in which computation
of the proximal gradient step may be inexact, i.e.,

xk = prox(cid:15)k

ηg(yk − η(∇f (yk) + ek)),

where ek captures the inexactness of computation of
∇f (yk), and (cid:15)k captures the inexactness of evaluation of
the proximal map as given by

x = prox(cid:15)

ηg(y)

= {u | g(u) + 1

2η (cid:107)u − y(cid:107)2

In the ﬁrst case, ∂g(x) reduces to the usual subdifferential
of convex functions, and the inexactness (cid:15) naturally induces
the following (cid:15)-subdifferential

∂(cid:15)g(x) = {u | g(y) ≥ g(x) + (cid:104)y − x, u(cid:105) − (cid:15), ∀y ∈ Rd}.

Moreover, since the KŁ property utilizes the information of
∂F , we then need to characterize the perturbation of ∂g un-
der the inexactness (cid:15). This leads to the following deﬁnition.

Deﬁnition 6. For any x ∈ Rd, let u(cid:48) ∈ ∂(cid:15)g(x) such that
∇f (x) + u(cid:48) has the minimal norm. Then the perturbation
between ∂g and ∂(cid:15)g is deﬁned as ξ := dist∂g(x)(u(cid:48)).

The following theorem states that for nonconvex functions,
as long as the inexactness parameters ek, (cid:15)k and ξk are
properly controlled, then the inexact APGnc converges at
the same order-level rate as the corresponding exact algo-
rithm.

Theorem 3. Consider the above two cases for inexact
APGnc under Assumption 1.{1,2,3}. If for all k ∈ N

(cid:107)ek(cid:107) ≤ γ(cid:107)xk − yk(cid:107),
(cid:15)k ≤ δ(cid:107)xk − yk(cid:107)2,
ξk ≤ λ(cid:107)xk − yk(cid:107),

(5)

(6)

(7)

then all the statements in Theorem 1 remain true and the
convergence rates in Theorem 2 remain at the same or-
der with the constants d1 = ( 1
2 −
C), where C > 0 depends on γ, δ and λ, and d2 =
min{ 1
}. Correspondingly, a
2cd1
smaller stepsize η < 1

k0
2C+L should be used.

η + L + C)2/( 1

2θ−2 − 1)r2θ−1

2η − L

c
1−2θ (2

2θ−1

,

It can be seen that, due to the inexactness, the constant fac-
tor d1 in Theorem 2 is enlarged, which further leads to a
smaller d2 in Theorem 2. Hence, the corresponding con-
vergence rates are slower compared to the exact case, but
remain at the same order.

≤ (cid:15) + g(v) + 1

2η (cid:107)v − y(cid:107)2,

∀v ∈ Rd}.

(4)

3.4. Stochastic Variance Reduced APGnc

The inexact proximal algorithm has been studied in (At-
touch et al., 2013) for nonconvex functions under the KŁ
property. Our study here is the ﬁrst treatment of inexact
proximal algorithms with momentum (i.e., APG-like algo-
rithms). Furthermore, previous studies addressed only the
inexactness of gradient computation for nonconvex prob-
lems, but our study here also includes the inexactness of
the proximal map for nonconvex problems requiring only g
to be convex as the second case we specify below.

We study the following two cases.

In this subsection, we study the stochastic variance reduced
APGnc algorithm, referred to as SVRG-APGnc. The main
steps are presented in Algorithm 5. The major difference
from APGnc is that the single proximal gradient step is re-
placed by a loop of stochastic proximal gradient steps using
variance reduced gradients.

Due to the stochastic nature of the algorithm, the iterate
sequence may not stably stay in the local KŁ region, and
hence the standard KŁ approach fails. We then focus on the
analysis of the special but important case of the global KŁ

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

Algorithm 5 SVRG-APGnc
0, βk = k

Input: y0 = x0
for k = 0, 1, 2, · · · do

k+3 , m, η < 1

2mL .

x0
k = yk, gk = ∇f (yk).
for t = 0, 1, · · · , m − 1 do

k) − ∇fξ(yk) + gk.
k − ηvt

sample ξ from {1, 2, · · · , n}.
vt
k = ∇fξ(xt
xt+1
k = proxηg(xt
end for
zk = xm
if F (xm

k + βk(xm
k − xm
k ) ≤ F (zk) then

k−1).

k).

else if F (zk) ≤ F (xm

k ) then

yk+1 = xm
k ,

yk+1 = zk.

end if
end for

property with θ = 1
2 . In fact, if g = 0, the KŁ property in
such a case reduces to the well known Polyak-Łojasiewicz
(PL) inequality studied in (Karimi et al., 2016). Various
nonconvex problems have been shown to satisfy this prop-
erty such as quadratic phase retrieval loss function (Zhou
et al., 2016) and neural network loss function (Hardt &
Ma, 2016). The following theorem characterizes the con-
vergence rate of SVRG-APGnc under the KŁ property with
θ = 1
2 .
Theorem 4. Let η = ρ/L, where ρ < 1/2 and satisﬁes
4ρ2m2 +ρ ≤ 1. If the problem (P) satisﬁes the KŁ property
globally with θ = 1/2, then the sequence {yk} generated
by Algorithm 5 satisﬁes

Here, we focus on the case where g is convex and ek = 0.
The following theorem characterizes the convergence rate
under such an inexact case.
Theorem 5. Let g be convex and consider only the in-
exactness (cid:15) in the proximal map. Assume the KŁ prop-
erty is globally satisﬁed with θ = 1/2. Set η = ρ/L
where ρ < 1/2 and satisﬁes 8ρ2m2 + ρ ≤ 1. Assume that
m−1
k(cid:107)2(cid:3) for some α > 0,
(cid:80)
k] ≤ α
t=0
and deﬁne ¯xt+1
k)). Then the se-
quence {yk} satisﬁes

m−1
(cid:80)
t=0
k = proxηg(xt

k − xt
k − η∇f (xt

E (cid:2)(cid:107)¯xt+1

3E [(cid:15)t

E [F (yk) − F ∗] ≤

(F (y0) − F ∗) ,

(9)

(cid:17)k

(cid:16) d
d+1

where d =

function value.

c2(L+ 1

+2ηL2m+ 1
2η

η )2
1
2η −L−α

, and F ∗ is the optimal

The convergence analysis for stochastic methods in inex-
act case has never been addressed before. To incorporate
the KŁ property in deriving the convergence rate, we use a
reference sequence generated by exact proximal mapping.
Even though this sequence is not actually generated by the
algorithm, we can reach to the convergence rate by ana-
lyzing the relation between the reference sequence and the
actual sequence generated by the algorithm.

Compared to the exact case, the convergence rate remains
at the same order, i.e., the linear convergence, but the con-
vergence is slower due to the larger parameter d caused by
the error parameter α.

E [F (yk) − F ∗] ≤

(F (y0) − F ∗) ,

(8)

(cid:17)k

(cid:16) d
d+1

4. Experiments

η )2
c2(L+ 1
1
2η −L

+ηL2m

where d =

value.

, and F ∗ is the optimal function

Hence, SVRG-APGnc also achieves the linear convergence
rate under the KŁ property with θ = 1
2 . We note that Theo-
rem 4 differs from the linear convergence result established
in (Reddi et al., 2016b) for the SVRG proximal gradient in
two folds: (1) we analyze proximal gradient with momen-
tum but (Reddi et al., 2016b) studied proximal gradient al-
gorithm; (2) the KŁ property with θ = 1
2 here is different
from the generalized PL inequality for composite functions
adopted by (Karimi et al., 2016). In order to exploit the
KŁ property, our analysis of the convergence rate requires
novel treatments of bounds, which can be seen in the proof
of Theorem 4 in ??.

3.5. Inexact SVRG-APGnc

In this section, we compare the efﬁciency of APGnc and
SVRG-APGnc with other competitive methods via numer-
ical experiments.
In particular, we focus on the non-
negative principle component analysis (NN-PCA) problem,
which can be formulated as
(cid:32) n
(cid:88)

(cid:33)

zizT
i

x + γ(cid:107)x(cid:107)2.

(10)

min
x≥0

−

1
2

xT

i=1

(cid:33)

It can be equivalently written as

min
x

−

1
2

xT

(cid:32) n
(cid:88)

i=1

zizT
i

x + γ(cid:107)x(cid:107)2 + 1{x≥0}.

(11)

Here, f corresponds to the ﬁrst two terms, and g is the indi-
cator of the nonnegative orthant, i.e., 1{x≥0}. This problem
is nonconvex due to the negative sign and satisﬁes Assump-
tion 1. In particular, it satisﬁes the KŁ property since it is
quadratic.

We further study the inexact SVRG-APGnc algorithm, and
the setting of inexactness is the same as that in Section 3.3.

For the experiment, we set n = 2000, γ = 10−3 and ran-
domly generate the samples zi from normal distribution.

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

All samples are then normalized to have unit norm. The
initialization is randomly generated, and is applied to all
the methods. We then compare the function values versus
the number of effective passes through n samples.

t ∈ (1/3, 2/3).

We further study the inexact case in Figure 1 (b), where we
introduce the proximal error (cid:15)k = 1
100k3 at the kth iteration.
One can see that inexact APGnc+ and inexact APGnc also
outperform other two inexact algorithms. Furthermore, in
Figure 2 (a) and (b), we compare exact and inexact algo-
rithms respectively for APGnc+ and APGnc. It can been
that even with a reasonable amount of inexactness, both
methods converge comparably to their corresponding exact
methods. Although initially the function value drops faster
in exact algorithms, both exact and inexact algorithms con-
verge to the optimal point almost at the same time. Such
a fact demonstrates the robustness of the algorithms. We
note that the relative comparison of the performance among
the algorithms does not change under other choices like
(cid:15)k = 1/100k2, 1/100k4.

(a)

(b)

Figure 3. Performance comparison of SVRG-APGnc+, SVRG-
APGnc, and the traditional proximal SVRG. (a) Error free. (b)
There exists the proximal error.

(a)

(b)

Figure 4. Performance comparison of the same algorithm with
and without the proximal error. (a) Performance comparison of
SVRG-APGnc+. (b) Performance comparison of SVRG-APGnc.

4.2. Comparison among SVRG-APG variants

We then compare the performance among SVRG-APGnc,
SVRG-APGnc+ and the original proximal SVRG methods,
and pick the stepsize η = 1/8mL with m = n. The results
are presented in Figures 3 and 4. In the error free case in
Figure 3 (a), one can see that SVRG-AGPnc+ method out-
performs the others due to the adaptive momentum, and the
SVRG-APGnc method also performs better than the origi-
nal proximal SVRG method.

For the inexact case, we set the proximal error as (cid:15)k =

(a)

(b)

Figure 1. Performance comparison of APGnc+, APGnc, mAPG,
and the traditional proximal method.
(b) There
exists the proximal error.

(a) Error free.

(a)

(b)

Figure 2. Performance comparison of the same algorithm with
and without the proximal error. (a) Performance comparison of
APGnc+. (b) Performance comparison of APGnc.

4.1. Comparison among APG variants

zizT

n
(cid:80)
i=1

the sample matrix

We ﬁrst compare among the deterministic APG-like meth-
ods in Algorithms 2 - 4 and the standard proximal gradient
method. The original APG in Algorithm 1 is not consid-
ered since it is not a descent method and does not have
convergence guarantee in nonconvex cases. We tuned a
ﬁxed step size η = 0.05/L, where L is the spectral norm of
i . We set t = 1/2 for APGnc+.
The results are shown in Figures 1 and 2. In Figure 1 (a),
we show the performance comparison of the methods when
there is no error in gradient or proximal calculation. One
can see that APGnc and APGnc+ outperform all other APG
In particular, APGnc+ performs the best with
variants.
our adaptive momentum strategy, justifying its empirical
advantage. We note that the mAPG requires two passes
over all samples at each iteration, and is, therefore, less
data efﬁcient compared to other APG variants. We further
note that other choices of stepsize less than the standard
choice 0.5/L does not change the relative comparison of
the performance among the algorithms, and we observed
that the adaptive momentum performs practically well for

510152025020040060080010001200Number of effective passesFunction value  APGnc+APGncmAPGProximal method510152025020040060080010001200Number of effective passesFunction value  APGnc+APGncmAPGProximal method510152025020040060080010001200Number of effective passesFunction value  APGnc+Inexact APGnc+510152025020040060080010001200Number of effective passesFunction value  APGncInexact APGnc0102030405002004006008001000Number of effective passesFunction value  SVRG−APGnc+SVRG−APGncProximal SVRG0102030405040060080010001200Number of effective passesFunction value  SVRG−APGnc+SVRG−APGncProximal SVRG1020304050020040060080010001200Number of effective passesFunction value  SVRG−APGnc+Inexact SVRG−APGnc+1020304050020040060080010001200Number of effective passesFunction value  SVRG−APGncInexact SVRG−APGncConvergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

1

100k3 , 10−7), where 10−7 is chosen to suppress the
min(
large inexactness during the initial few iterations. One can
see from Figure 3 (b) that the performance is degraded
compared to the exact case, and converges to a different lo-
cal minimum. In this result, all the methods are no longer
monotone due to the inexactness and the stochastic nature
of SVRG. Nevertheless, the SVRG-APGnc+ still yields the
best performance.

We also compare the results corresponding to SVRG-
APGnc+ and SVRG-APGnc, with and without the proxi-
mal error, in Figure 4 (a) and (b), respectively. It is clear
that the SVRG-based algorithms are much more sensitive
to the error comparing with APG-based ones. Even though
the error is set to be smaller than in the inexact case with
APG-based methods, one can observe more signiﬁcant per-
formance gaps than those in Figure 2.

5. Conclusion

In this paper, we provided comprehensive analysis of the
convergence properties of APGnc as well as its inex-
act and stochastic variance reduced forms by exploiting
the KŁ property. We also proposed an improved algo-
rithm APGnc+ by adapting the momentum parameter. We
showed that APGnc shares the same convergence guaran-
tee and the same order of convergence rate as the mAPG,
but is computationally more efﬁcient and more amenable
to adaptive momentum. In order to exploit the KŁ property
for accelerated algorithms in the situations with inexact er-
rors and/or with stochastic variance reduced gradients, we
developed novel convergence analysis techniques, which
can be useful for exploring other algorithms for nonconvex
problems.

Acknowledgements

This work was supported in part by the NSF grant ECCS
1609916.

References

Attouch, H. and Bolte, J. On the convergence of the prox-
imal algorithm for nonsmooth functions involving ana-
lytic features. Mathematical Programming, 116(1-2):5–
16, 2009. ISSN 0025-5610.

Attouch, H., Bolte, J., Redont, P., and Soubeyran, A. Prox-
imal alternating minimization and projection methods
for nonconvex problems: An approach based on the
Kurdyka-Łojasiewicz inequality. Mathematics of Oper-
ations Research, 35(2):438–457, 2010.

Attouch, H., Bolte, J., and Svaiter, B. Convergence of de-
scent methods for semi-algebraic and tame problems:

proximal algorithms, forward-backward splitting, and
regularized Gauss-Seidel methods. Mathematical Pro-
gramming, 137(1-2):91–129, 2013.

Beck, A. and Teboulle, M. Fast gradient-based algorithms
for constrained total variation image denoising and de-
blurring problems. Transactions on Image Processing,
18(11):2419–2434, November 2009a.

Beck, A. and Teboulle, M. A fast iterative shrinkage-
inverse problems.
thresholding algorithm for
SIAM Journal of Image Science., 2(1):183–202, 2009b.

linear

Bolte, J., Daniilidis, A., and Lewis, A. The Łojasiewicz in-
equality for nonsmooth subanalytic functions with appli-
cations to subgradient dynamical systems. SIAM Journal
on Optimization, 17:1205–1223, 2007.

Bolte, J., Danilidis, A., Ley, O., and Mazet, L. Charac-
terizations of Łojasiewicz inequalities and applications:
Subgradient ﬂows, talweg, convexity. Transactions of
the American Mathematical Society, 362(6):3319–3363,
2010.

Bolte, J., Sabach, S., and Teboulle, M. Proximal alternating
linearized minimization for nonconvex and nonsmooth
problems. Mathematical Programming, 146(1-2):459–
494, 2014.

Frankel, P., Garrigos, G., and Peypouquet, J. Splitting
methods with variable metric for kurdyka–łojasiewicz
Journal of
functions and general convergence rates.
Optimization Theory and Applications, 165(3):874–900,
2015.

Ghadimi, S. and Lan, G. Accelerated gradient methods
for nonconvex nonlinear and stochastic programming.
Mathematical Programming, 156(1-2):59–99, 2016.

Gong, P., Zhang, C., Lu, Z., Huang, J. Z., and Ye, J. A gen-
eral iterative shrinkage and thresholding algorithm for
non-convex regularized optimization problems. In Inter-
national Conference on Machine Learning, 2013.

Hardt, M. and Ma, T.

Identity matters in deep learning.
Arxiv preprint, 2016. URL http://arxiv.org/
abs/1611.04231.

Johnson, R. and Zhang, T. Accelerating stochastic gradient
descent using predictive variance reduction. In Advances
in Neural Information Processing Systems, pp. 315–323,
2013.

Karimi, H., Nutini, J., and Schmidt, M. Linear conver-
gence of gradient and proximal-gradient methods un-
der the Polyak-Łojasiewicz condition. Machine Learn-
ing and Knowledge Discovery in Databases: European
Conference, pp. 795–811, 2016.

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

Kurdyka, K. On gradients of functions deﬁnable in o-
minimal structures. Annales de l’institut Fourier, 48(3):
769–783, 1998.

Zhu, Z. and Yuan, Y. Improved SVRG for non-strongly-
In Interna-

convex or sum-of-non-convex objectives.
tional Conference on Machine Learning, 2016.

Kurdyka, K.

and Spodzieja, S.

Separation of
real algebraic sets and the Łojasiewicz exponent.
Wydział Matematyki Informatyki. Uniwersytet ł´odzki,
URL https://books.google.com/
2011.
books?id=CL6PMwEACAAJ.

Li, G. and Kei, T. Calculus of the exponent of Kurdyka-
Łojasiewicz inequality and its applications to linear con-
vergence of ﬁrst-order methods. ArXiv preprint, Febru-
ary 2016. URL https://arxiv.org/abs/1602.
02915.

Li, H. and Lin, Z. Accelerated proximal gradient meth-
ods for nonconvex programming. In Advances in Neural
Information Processing Systems, pp. 379–387. 2015.

Łojasiewicz, S. Ensembles semi-analytiques. Institut des

Hautes Etudes Scientiﬁques, 1965.

Nesterov, Y. A method of solving a convex programming
problem with convergence rate O(1/k2). Soviet Mathe-
matics Doklady, 27:372–376, 1983.

Reddi, S., Hefny, A., Sra, S., Poczos, B., and Smola, A.
Stochastic variance reduction for nonconvex optimiza-
tion. ArXiv preprint, 2016a. URL https://arxiv.
org/abs/1603.06160.

Reddi, S., Sra, S., Poczos, B., and Smola, A. Proximal
stochastic methods for nonsmooth nonconvex ﬁnite-sum
In Advances in Neural Information Pro-
optimization.
cessing Systems 29, pp. 1145–1153. 2016b.

Rockafellar, R.T. and Wets, R.J.B. Variational Analysis.

Springer, 1997.

Schmidt, M., Roux, N.L., and Bach, F.R. Convergence
rates of inexact proximal-gradient methods for convex
In Advances in Neural Information Pro-
optimization.
cessing Systems 24, pp. 1458–1466. 2011.

Tseng, P. Approximation accuracy, gradient methods, and
error bound for structured convex optimization. Mathe-
matical Programming, 125(2):263–295, 2010.

Yao, Q. and Kwok, J.T. More efﬁcient accelerated proxi-
mal algorithm for nonconvex problems. ArXiv preprint,
December 2016. URL https://arxiv.org/abs/
1612.09069.

Zhou, Y., Zhang, H., and Liang, Y. Geometrical properties
and accelerated gradient solvers of non-convex phase re-
trieval. The 54th Annual Allerton Conference, 2016.

