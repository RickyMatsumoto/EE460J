Re-revisiting Learning on Hypergraphs:
Conﬁdence Interval and Subgradient Method

Chenzi Zhang * 1 Shuguang Hu * 1 Zhihao Gavin Tang 1 T-H. Hubert Chan 1 2

Abstract

We revisit semi-supervised learning on hyper-
Same as previous approaches, our
graphs.
method uses a convex program whose objective
function is not everywhere differentiable. We
exploit the non-uniqueness of the optimal solu-
tions, and consider conﬁdence intervals which
give the exact ranges that unlabeled vertices take
in any optimal solution. Moreover, we give
a much simpler approach for solving the con-
vex program based on the subgradient method.
Our experiments on real-world datasets conﬁrm
that our conﬁdence interval approach on hyper-
graphs outperforms existing methods, and our
sub-gradient method gives faster running times
when the number of vertices is much larger than
the number of edges.

1. Introduction

Given a dataset, similarity relationship between examples
can be represented by a graph in which each example is
represented by a vertex. While pairwise relationship be-
tween two vertices can be represented by an edge in a nor-
mal graph, a higher order relationship involving multiple
vertices can be captured by a hyperedge, which means that
all the corresponding examples are similar to one another.
Hypergraphs have been used in several learning applica-
tions such as clustering of categorical data (Gibson et al.,
1998), multi-label classiﬁcation (Sun et al., 2008), Lapla-
cian sparse coding (Gao et al., 2013), image classiﬁca-
tion (Yu et al., 2012), image retrieval (Huang et al., 2010),
mapping users across different social networks (Tan et al.,
2014) and predicting edge labels in hypernode graphs (Ri-
catte et al., 2014).

*Equal contribution 1University of Hong Kong, Hong Kong.
2This research was partially supported by the Hong Kong RGC
under the grant 17200214. Correspondence to: T-H. Hubert Chan
<hubert@cs.hku.hk>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

In this paper, we consider semi-supervised learning on
an edge-weighted hypergraph H = (V, E, w), with a set
L of labeled vertices, whose labels are given by f ∗
L ∈
{−1, +1}L. The task is to predict the labels of the unla-
beled vertices N , with the working principle that vertices
contained in a hyperedge e ∈ E are more similar to one
another if the edge weight we is larger. This problem is
also known as transductive inference and has been studied
in (Zhou et al., 2006) and (Hein et al., 2013).

However, the methods in (Zhou et al., 2006) have been
criticized by (Agarwal et al., 2006), because essentially
a hypergraph is converted into a normal graph. For in-
stance, given a hyperedge e containing vertices S, either
(i) a clique is added between the vertices in S, or (ii) a star
is formed by adding a new vertex ve connecting every ver-
tex in S to ve. Then, a standard convex program using a
regularization potential function for normal graphs can be
applied (Zhu et al., 2003). By choosing appropriate edge
weights, it was shown in (Agarwal et al., 2006) that the two
approaches are equivalent to the following convex program
relaxation:

min Φold(f ) :=

1
2

(cid:88)

e∈E

we

(cid:88)

(fu − fv)2

{u,v}∈(e
2)

subject to fu ∈ [−1, 1],

∀u ∈ V

fu = f ∗
u,

∀u ∈ L.

On the other hand, it was proposed in (Hein et al., 2013)
that the following regularization function is more suitable
to capture hyperedge expansion:

Φnew(f ) :=

we · (max
u∈e

fu − min
v∈e

fv)2.

1
2

(cid:88)

e∈E

Indeed, it was shown in (Hein et al., 2013) that their ap-
proach outperforms (Zhou et al., 2006) on several datasets
from the UCI Machine Learning Repository (Lichman,
2013).

Loss Function. In (Hein et al., 2013), a squared loss func-
tion was added by considering the convex program with ob-
jective function Φnew(f ) + µ (cid:107)f − f ∗(cid:107)2
2 on f ∈ [−1, 1]V ,
where µ > 0 is a parameter to be tuned, f ∗
L is given by the
labeled vertices L, and for the unlabeled vertices f ∗
N = 0.

Re-revisiting Learning on Hypergraphs

The loss function allows errors in the labeled vertices, and
also ensures that the minimizer is unique. However, as a
result, unlabeled vertices have a tendency to acquire f val-
ues close to 0. This might remove useful information as
illustrated in the following example.

Example. In Figure 1.1, ver-
tices a, b ∈ L are labeled
as +1 and c ∈ L is la-
beled as −1. Vertices x, y ∈
N are unlabeled.
There
are three (undirected) edges:
{a, x}, {b, x} and {x, y, c},
each with unit weight.

Figure 1.1. Example

By choosing µ = 1
squared loss function, the unique minimizer gives fx = 1
5
and fy = 0. Hence, this solution gives no useful informa-
tion regarding the label for vertex y.

2 for

On the other hand, if we just use the objective function
Φnew(f ) with the constraints fL = f ∗
L, then in an opti-
mal solution, fx = 1
3 , but fy could be anywhere in the
conﬁdence interval [−1, 1
3 ]. Hence, in this case, we could
use the average value − 1
3 to predict −1 for vertex y.

Our Contributions. In this paper, we revisit the approach
used in (Hein et al., 2013) and consider several extensions
and simpliﬁcations. We summarize our results and give an
outline of the paper as follows.

1. Uniﬁed Framework for Directed Hypergraphs. In-
spired also from the recent result on Laplacians for di-
rected normal graphs (Yoshida, 2016), we introduce a semi-
supervised learning framework using directed hypergraphs
that can capture higher order causal relationships. This no-
tion of directed hypergraph was ﬁrst introduced in (Gallo
et al., 1993), who considered applications in propositional
logic, analyzing dependency in relational database, and
trafﬁc analysis. On a high level, a directed hyperedge e
consists of a tail set Te pointing to a head set He such that
a vertex in Te labeled +1 implies that a vertex in He is
more likely to be labeled +1.
(Equivalently in terms of
its contrapositive, a vertex in He labeled −1 implies that a
vertex in Te is more likely to be labeled −1.) In Section 2,
we formally deﬁne the model and the corresponding poten-
tial function Φ. An additional advantage of our potential
function is that there is no need to tune any parameters.

2. Conﬁdence Interval for Unlabeled Vertices. Observe
that the minimizer for our convex program might not be
unique. In Section 3, we introduce the concept of conﬁ-
dence interval for each unlabeled vertex that can be useful
for predicting its label. Furthermore, we provide an algo-
rithm to calculate the conﬁdence interval given an optimal
solution.

3. Simpler Subgradient Method. Since the new potential
function is not everywhere differentiable but still convex,
we use the subgradient method (Shor et al., 1985) to ob-
tain an estimated minimizer for label prediction. Inspired
by the diffusion processes used for deﬁning Laplacians in
hypergraphs (Louis, 2015) and directed graphs (Yoshida,
2016), in Section 4, we deﬁne a simple Markov operator
that returns a subgradient for Φ, which is used to solve the
underlying convex program. We remark that our frame-
work is very easy to understand, because it is a variation on
the well-known gradient descent.

In contrast, the primal-dual approach in (Hein et al., 2013)
considers the convex conjugate of the primal objective and
involves complicated update operations on the primal and
dual variables. The subgradient used in our approach gives
the update direction, and we can actually solve exactly the
same convex program with a much simpler method.

4. Experimental Results on Real-World Datasets.
In
Section 5, we revisit some datasets in the UCI Machine
Learning Repository (Lichman, 2013), and experiments
conﬁrm that our prediction model based on conﬁdence in-
terval gives better accuracy than that in (Hein et al., 2013).
Our simpler subgradient method takes more iterations than
the primal-dual method (Hein et al., 2013), but each iter-
ation is much faster. Experiments show that overall both
methods have similar running times, and the subgradient
method has an advantage when the number of vertices is
much larger than the number of edges.

Moreover, using the DBLP dataset (Ley, 2009), our ex-
periments also support that using directed hypergraphs to
capture causal relationships can improve the prediction ac-
curacy. The experiments for directed hypergraphs are de-
scribed in the full version.

2. Preliminaries

We consider an edge-weighted directed hypergraph H =
(V, E, w) with vertex set V (with n = |V |), edge set E and
weight function w : E → R+. Each hyperedge e ∈ E
consists of a tail set Te ⊆ V and a head set He ⊆ V
(which are not necessarily disjoint); we use the convention
that the direction is from tail to head. For x ∈ R, we denote
[x]+ := max{x, 0}.

In our application, each vertex v ∈ V is supposed to have a
label in {−1, +1}. Intuitively, the directed hypergraph at-
tempts to capture the rule that for each edge e ∈ E, if there
is a vertex in Te having label +1, then it is more likely for
vertices in He to receive label +1. In terms of its contra-
positive, if there is a vertex in He having label −1, then it
is more likely for vertices in Te to receive label −1.
We use f ∈ RV to denote a vector, where the coordi-

Re-revisiting Learning on Hypergraphs

nates are labeled by vertices in V . For U ⊆ V , we use
fU ∈ RU to denote the vector restricting f to coordinates
in U . In semi-supervised learning, we consider a set L ⊆ V
of labeled vertices, which have labels f ∗
L ∈ {−1, +1}L.
Typically, |L| (cid:28) |V | and the task is to assign a label in
{−1, +1} to each unlabeled vertex in N := V \ L, using
information from the directed hypergraph H.

By relaxing labels to be in the interval [−1, 1], we consider
the following regularization potential function Φ : RV →
R:

Φ(f ) =

we · ([∆e(f )]+)2,

1
2

(cid:88)

e∈E

where ∆e(f )
maxu∈Te fu − minv∈He fv.

:= max(u,v)∈Te×He(fu − fv) =

In particular, there is a penalty due to edge e only if some
vertex in Te receives a label larger than that of some vertex
in He. The convexity of Φ is proved in the full version.

Our approach is to consider the following convex program
to obtain an estimated minimizer f ∈ [−1, 1]V , which can
be rounded to an integer solution for labeling all vertices.

min Φ(f )
subject to fu ∈ [−1, 1],

fu = f ∗
u,

(CP1)

∀u ∈ V

∀u ∈ L

Since the f values for the labeled vertices L are ﬁxed in
(CP1), we also view Φ : RN → R as a function on the
f values of unlabeled vertices N . We use OPT ⊂ RV to
denote the set of optimal solutions to (CP1).

Trivial Edges. An edge e ∈ E is trivial if there exist ver-
tices u ∈ Te ∩ L and v ∈ He ∩ L such that f ∗
u = +1
and f ∗
v = −1. As trivial edges contribute constant towards
the objective function Φ, we shall assume that there are no
trivial edges in the convex program (CP1).

Special Cases. Our directed hypergraph model can capture
other graph models as follows.

1. Undirected Hypergraphs. For each hyperedge e, we
can set Te = He to the corresponding subset of ver-
tices.

2. Undirected Normal Graphs. For each edge e =
{u, v}, we can set Te = He = e. Observe that
in this case, the potential function becomes Φ(f ) =
(cid:80)
(u,v)∈E wuv(fu − fv)2, which is differentiable, and
hence, (CP1) can be solved by standard techniques
like gradient descent.

f ∗
u ∈ {−1, +1} is. The following relaxation is considered.

min (cid:98)Φ(f ) := Φ(f ) +

µu(fu − f ∗

u)2

(CP2)

(cid:88)

1
2

u∈L
subject to fu ∈ [−1, 1], ∀u ∈ V.

Observe that (CP2) can also be expressed in the framework
of (CP1). We simply consider an augmented hypergraph
(cid:98)H such that all vertices V are treated as unlabeled, and for
each u ∈ L, we add a new vertex (cid:98)u with label f ∗
u and a new
undirected edge {u, (cid:98)u} with weight µu. Then, it follows
that the convex program (CP1) for the augmented instance
for (cid:98)H is exactly the same as (CP2).

Challenges Ahead. We next outline how we resolve
the encountered challenges when we use (CP1) for semi-
supervised learning.

• Unlike the case for normal graphs, the set OPT can
contain more than one optimal solution for (CP1). In
Section 3, we prove some structural properties of the
convex program, and illustrate that each u ∈ N has
some conﬁdence interval from which we can predict
its label.

• The function Φ is not everywhere differentiable.
Hence, we use the subgradient method (Shor et al.,
1985). In Section 4, we give a method to generate a
subgradient, which is inspired by the continuous diffu-
sion processes for hypergraphs (Louis, 2015) and di-
rected graphs (Yoshida, 2016), and our method can in
fact be viewed as a discretized version.

3. Conﬁdence Interval for Semi-supervised

Learning

In general, a minimizer for (CP1) might not be unique.
Hence, we introduce the concept of conﬁdence interval.

Deﬁnition 3.1 (Conﬁdence Interval) For each u ∈ V ,
we deﬁne its conﬁdence interval to be [mu, Mu], where
mu := minf ∈OPT fu and Mu := maxf ∈OPT fu. The con-
ﬁdence intervals induce the lower and the upper conﬁdence
vectors, (cid:126)m and (cid:126)M ∈ RV , respectively.

In Section 3.1, we give the proof of the following lemma,
which states that the conﬁdence vectors (cid:126)m and (cid:126)M are opti-
mal solutions, and so are their convex combinations.

Lemma 3.1 (Conﬁdence Vectors Give Optimal Solu-
tions) For any λ ∈ [0, 1], the convex combination λ (cid:126)m +
(1 − λ) (cid:126)M ∈ OPT is optimal for (CP1).

Soft Constraints.
In (Hein et al., 2013), each labeled
vertex u ∈ L can also have some weight µu ∈ R+,
which can, for instance, indicate how trustworthy the label

Semi-supervised Learning via Conﬁdence Interval.
Lemma 3.1 suggests what one can do when (CP1) has more
than one optimal solution. Speciﬁcally, in Algorithm 1, the

Re-revisiting Learning on Hypergraphs

2 ( (cid:126)m + (cid:126)M ) ∈ OPT can be used for label
average vector 1
prediction. We show that the conﬁdence vectors (cid:126)m and
(cid:126)M can be recovered from any optimal solution f ∈ OPT,
which in turn can be estimated by the subgradient method
described in Section 4.
Algorithm 1 Semi-Supervised Learning
1: Input: Directed hypergraph H = (V, E, w), labels f ∗
L

for labeled vertices L

2: Compute (estimated) conﬁdence vectors ( (cid:126)m, (cid:126)M ) ∈

RN × RN , either by Algorithm 2 or 3.

2 ( (cid:126)m + (cid:126)M ).
u∈N f u.

(cid:80)

if f u ≥ θ then
(cid:98)fu ← +1;

3: Compute average vector f N ← 1
4: Compute threshold θ ← 1
|N |
5: for each u ∈ N do
6:
7:
8:
9:
end if
10:
11: end for
12: return (cid:98)fN

(cid:98)fu ← −1;

else

Fine-Tuning Parameters.
In view of Lemma 3.1, one
could further optimize the choice of λ ∈ [0, 1] in deﬁn-
ing f N ← λ (cid:126)m + (1 − λ) (cid:126)M in Line 3. Similarly, one could
pick the threshold θ to be the ϑ-percentile of the sorted co-
ordinates of f N , for some choice of ϑ ∈ [0, 1]. The param-
eters λ and ϑ can be tuned using standard techniques like
cross-validation. However, to illustrate our concepts, we
keep the description simple without introducing too many
free parameters.

3.1. Properties of Conﬁdence Vectors

We derive some properties of the conﬁdence vectors to
prove Lemma 3.1. The full proofs of Lemma 3.2 and 3.3
are given in the full version.
Given a feasible solution f ∈ RV to (CP1), we deﬁne the
following:

1. Se(f ) := arg maxu∈Te fu ⊆ Te and Ie(f ) :=

arg minv∈He fv ⊆ He.

2. f (Se) := maxu∈Te fu and f (Ie) := minv∈He fv.

Hence, we have ∆e(f ) = f (Se) − f (Ie).

3. The set of active edges with respect to f is E(f ) :=

{e ∈ E : ∆e(f ) > 0}.

The following lemma states even though a minimizer for
(CP1) might not be unique, there are still some structural
properties for any optimal solution.

timal solution is uniquely determined. Hence, for e ∈ E∗,
we can deﬁne the corresponding ∆∗

e = ∆e(f ).

Deﬁnition 3.2 (Pinned Vertex) An unlabeled vertex u is
pinned in a solution f ∈ RV if there exist active edges e
and e(cid:48) ∈ E(f ) such that u ∈ Se(f ) ∩ Ie(cid:48)(f ), in which case
we say that the edges e and e(cid:48) pin the vertex u under f .

Lemma 3.3 (Extending an Active Edge) Suppose
edge
e ∈ E(f ) is active in an optimal solution f . If He does
not contain a vertex labeled with −1,
then there exist
u ∈ Ie(f ) and another active edge e(cid:48) ∈ E(f ) such that
the following holds.

(a) The edges e and e(cid:48) pin u under f , i.e., u ∈ Se(cid:48)(f ).
(b) If g is an optimal solution, then Ie(f ) ∩ Se(cid:48)(f ) =

Ie(g) ∩ Se(cid:48)(g) and fu = gu.

An analogous result holds when Te does not contain any
vertex labeled with +1.

In particular, for any active edge e ∈ E∗, the extremal
values f ∗(Se) := maxu∈Te fu and f ∗(Ie) := minu∈He fu
are uniquely determined by any optimal solution f .

Corollary 3.1 (Pinned Vertices) In any optimal solution,
the set of pinned vertices is uniquely determined. We use
L∗ to denote the set of labeled or pinned vertices in an
optimal solution. Then, for each u ∈ L∗, its value f ∗
u in
any optimal solution is also uniquely determined.

From Corollary 3.1, the conﬁdence interval for any u ∈ L∗
contains exactly one value, namely the unique value f ∗
u in
any optimal solution. The following lemma gives a charac-
terization of an optimal solution.

Lemma 3.4 Characterization of Optimal Solutions A
solution f to (CP1) is optimal iff the following conditions
hold.

(a) For each u ∈ L∗, fu = f ∗
u.
(b) For each active edge e ∈ E∗, both the maximum
maxu∈Te fu and the minimum minv∈He fv are at-
tained by vertices in L∗.

(c) For each inactive edge e /∈ E∗, for all u ∈ Te and

v ∈ He, fu ≤ fv.

Proof: We ﬁrst observe that Corollary 3.1 states that the
values of the vertices in L∗ are uniquely determined in any
optimal solution. Hence, any optimal solution must satisfy
the three conditions. We next show that the three conditions
implies that the objective value is optimal.

Lemma 3.2 (Active Edges in an Optimal Solution) Sup-
pose f and g are optimal solutions to (CP1). Then, for all
e ∈ E, [∆e(f )]+ = [∆e(g)]+. In particular, this implies
that the set of active edges E∗ := E(f ) = E(g) in any op-

Once the values for vertices in L∗ are ﬁxed, Lemma 3.3
and condition (b) implies that the contribution of all active
edges E∗ are determined and are the same as any optimal
solution.

Re-revisiting Learning on Hypergraphs

Finally, condition (c) implies that edges not in E∗ do
not have any contribution towards the objective function.
Hence, any solution satisfying the three conditions must be
optimal.

step (b), for every active edge e ∈ E∗, minv∈He mv can be
attained by some vertex in L∗. Since only mv for v /∈ L∗
can be increased in step (c), it follows that in the end, the
minimum can still be attained by some vertex in L∗.

Deriving Conﬁdence Vectors. To prove Lemma 3.5, we
deﬁne a procedure that returns a vector (cid:126)m ∈ V R such that
for any optimal f ∈ OPT, we have f ≥ (cid:126)m. Moreover,
we shall show that (cid:126)m ∈ OPT and hence (cid:126)m is the lower
conﬁdence vector. The argument for the upper conﬁdence
vector (cid:126)M is similar. For the special case of undirected hy-
pergraphs, the procedure can be simpliﬁed to Algorithm 2
in Section 3.2.

Lemma 3.5 (Conﬁdence Vectors are Optimal: Proof of
Lemma 3.1) The conﬁdence vectors (cid:126)m and (cid:126)M deﬁned in
Deﬁnition 3.1 are optimal solutions to (CP1). This implies
that any of their convex combination is also optimal.

Proof: We give a procedure that returns a vector (cid:126)m such
that at any moment during the procedure, the following in-
variant is maintained: for any f ∈ OPT, f ≥ (cid:126)m.

The following steps correspond to maintaining the condi-
tions in Lemma 3.4.

v ; for v /∈ L∗,
(a) Initialization. For v ∈ L∗, set mv := f ∗
set mv := −1. This satisﬁes the invariant, because for any
f ∈ OPT and any v ∈ L∗, fv = f ∗
v .
(b) Preserving Active Edges. For each v /∈ L∗, set
mv ← max{mv, maxe∈E∗:v∈He f ∗(Ie)}. Observe that
Lemma 3.4(b) implies that for any optimal f ∈ OPT, any
e ∈ E∗ and any v ∈ He, fv ≥ f ∗(Ie). Hence, the invariant
is maintained.

(c) Preserving Inactive Edges. While there is an inactive
edge e /∈ E∗ such that u ∈ Te, v ∈ He and mu > mv,
set mv ← mu. We argue why each such update preserves
the invariant. Consider any optimal f ∈ OPT. Before this
update, the invariant holds. Hence, we have mu ≤ fu.
Moreover, Lemma 3.4 implies that fu ≤ fv. Therefore,
after setting mv ← mu, we still have mv ≤ fv.

Finally, observe that after step (b), the coordinates of (cid:126)m
can take at most n distinct values. Moreover, after each up-
date in step (c), one coordinate of (cid:126)m must increase strictly.
Hence, this procedure will terminate.

We next argue that (cid:126)m is an optimal solution by checking
that it satisﬁes the conditions in Lemma 3.4.

Condition (a). Observe that for each v ∈ L∗, mv is ini-
tialized to f ∗
v . Afterwards the value mv could only be in-
creased. However, because the invariant holds when the
procedure terminates, it must be the case that mv = f ∗
v at
the end.

Condition (b). The procedure makes sure that at the end of

Next, consider u ∈ Te, where e ∈ E∗. For any optimal
solution f , Lemma 3.3 implies that fu ≤ f ∗(Se). Hence,
the invariant implies that mu ≤ fu ≤ f ∗(Se). Since condi-
tion (a) holds, this means that maxv∈Te mv can be attained
by some vertex in L∗.

Condition (c). This is clearly satisﬁed because of the
while-termination condition.

Therefore, we have (cid:126)m ∈ OPT, as required.
The proof for the upper conﬁdence vector (cid:126)M is similar.
We omit the detailed proof and just give the corresponding
procedure to return (cid:126)M .

(a) Initialization. For v ∈ L∗, set Mv := f ∗
set Mv := +1.
(b) Preserving Active Edges. For each v /∈ L∗, set Mv ←
min{Mv, mine∈E∗:v∈Te f ∗(Se)}.

v ; for v /∈ L∗,

(c) Preserving Inactive Edges. While there is an inactive
edge e /∈ E∗ such that u ∈ Te, v ∈ He and Mu > Mv, set
Mu ← Mv.

The same argument can show that for any optimal f ∈
OPT, we have f ≤ (cid:126)M . Moreover, we also have (cid:126)M ∈
OPT.

3.2. Computing the Conﬁdence Interval

As mentioned before, the proof of Lemma 3.5 implicitly
gives a procedure to compute the conﬁdence vectors from
any optimal solution. For the special case of undirected
hypergraphs, a simpliﬁed version of the procedure is given
in Algorithm 2.

Alternatively, we can try to solve the convex pro-
gram (CP1), for example using Algorithm 5 in Section 4,
from two initial feasible solutions to heuristically estimate
the conﬁdence vectors. In Algorithm 3, one instance ap-
proaches an optimal solution from high f values and the
other from low f values.

4. Subgradient Method via Markov Operator

Resolving Ties. Observe that Φ : RN → R is differen-
tiable at fN ∈ RN that has distinct coordinates. For the
purpose of computing a subgradient, we assume that there
is some global ordering π on V to resolve ties among coor-
dinates with the same value. In particular, the vertices in L
having label +1 are the highest, and those in L labeled −1
are the lowest. Hence, in this section, we may assume that
any arg max or arg min operator over a subset of vertices

Re-revisiting Learning on Hypergraphs

Algorithm 2 Conﬁdence Intervals for Undirected Hyper-
graphs

1: Input: Undirected hypergraph H = (V, E, w), label

vector f ∗

L and tolerance (cid:15) ≥ 0.

Algorithm 3 Estimate conﬁdence interval
1: Input: Directed hypergraph H = (V, E, w), labels f ∗
L

for labeled vertices L
2: Construct feasible f (0,+)

N ← +1 ∈ RN with all entries

2: Let f be a solution of (CP1), either by Algorithm 5 or

being +1;

3: Construct feasible f (0,−)

N ← −1 ∈ RN with all entries

by PDHG method (Hein et al., 2013)

end for

p(v) ← p(x)

(cid:98)E ← ( (cid:98)E \ {e1, e2}) ∪ {e1 ∪ e2}

x ← an arbitrary vertex in e
for each vertex v ∈ e do

3: For all v ∈ V , set p(v) ← v, mv ← −1, Mv ← +1.
4: (cid:98)E := {e ∈ E : ∆e(f ) ≤ (cid:15)}
5: while ∃e1 (cid:54)= e2 ∈ (cid:98)E, e1 ∩ e2 (cid:54)= ∅ do
6:
7: end while
8: for each e ∈ (cid:98)E do
9:
10:
11:
12:
13: end for
14: for each vertex v ∈ L do
15: mp(v) ← f ∗
16: end for
17: for each edge e ∈ E such that ∆e(f ) > (cid:15) do
18:
19:
20:
21:
22: end for
23: for each vertex v ∈ V do
24: mv ← mp(v), Mv ← Mp(v)
25: end for
26: return vectors ( (cid:126)m, (cid:126)M )

mp(v) ← max{mp(v), f (Ie)}
Mp(v) ← min{Mp(v), f (Se)}

for each vertex v ∈ e do

v , Mp(v) ← f ∗
v

end for

will return a unique vertex.

We next deﬁne a Markov operator that is inspired from the
diffusion processes on hypergraphs (Louis, 2015) and di-
rected graphs (Yoshida, 2016) in the context of deﬁning
Laplacians. We denote the projection operator ΠN : RV →
RN that takes f ∈ RV and returns the restricted vector
fN ∈ RN .

Lemma 4.1 For f ∈ [−1, 1]V that is feasible in (CP1),
the Markov operator Mf given in Algorithm 4 returns a
subgradient of Φ : RN → R at fN .

(Sketch) Observe that if fN ∈ RN has distinct co-
Proof:
ordinates, then Φ is differentiable at fN , and Mf gives ex-
actly the gradient (which is the only possible subgradient in
this case). Observe that in our subgradient method applica-
tion, we could imagine that at every iteration, inﬁnitesimal
perturbation is performed on the current solution to ensure
that all coordinates are distinct, and ties are resolved ac-
cording to our global ordering π.

being −1;

4: (cid:126)M ← SGM(f (0,+)
);
5: (cid:126)m ← SGM(f (0,−)
);
6: return the vectors ( (cid:126)m, (cid:126)M )

N

N

Algorithm 4 Markov Operator M : RV → RN
1: Input: Directed hypergraph H = (V, E, w), feasible

f ∈ RV for (CP1)

(The same is done for Avu because A is symmetric.)

u ← arg maxu∈Te fu;
v ← arg minv∈He fv;

2: Construct symmetric matrix A ∈ RV ×V ; set A ← 0.
3: for each e ∈ E such that ∆e(f ) > 0 do
4:
5:
6: Auv ← Auv + we;
7:
8: end for
9: Construct diagonal matrix W ∈ RN ×N ; set W ← 0.
10: for each u ∈ N do
11: Wuu ← (cid:80)
12: end for
13: return (W ΠN − ΠN A)f

v∈V Auv;

Hence, as the magnitude of the perturbation tends to zero,
if the global ordering π is preserved, then the gradient re-
mains the same, which implies that the gradient is also the
subgradient when the perturbation reaches 0.

Using the Markov operator M as a subroutine to generate
a subgradient, we have the following subgradient method
(SGM) (Shor et al., 1985).
Algorithm 5 Subgradient Method SGM(f (0)

N ∈ RN )

1: Input: Directed hypergraph H = (V, E, w) with la-
L for labeled vertices L, initial feasible solution

bels f ∗
f (0)
N ∈ RN , step size {ηt := 1
2: t ← 1;
3: (Throughout the algorithm, f (t)

t }t≥1

L = f ∗

L is given by the

N has not “stabilized” do

labeled vertices.)
4: while Solution f (t)
5:

6:

g(t)
N ← Mf (t−1) ∈ RN ;
g(t)
N = f (t−1)
f (t)
N(cid:13)
(cid:13)
(cid:13)g(t)
(cid:13)
(cid:13)
(cid:13)2
N
t ← t + 1;

− ηt ·

N

;

7:
8: end while
9: return f (t)

Re-revisiting Learning on Hypergraphs

Stabilizing Condition. Our experiments in Section 5 sug-
gest that it sufﬁces to run the solver for a short time, after
which a better feasible solution f does not improve the pre-
diction accuracy.

5. Experimental Results

Our experiments are run on a standard PC. In our graphs,
each point refers to a sample mean, and the height of the
vertical bar is the standard error of the mean.

5.1. Undirected Hypergraph: Comparing Accuracy of

Prediction Methods

We show that our treatment of hypergraphs performs better
than the previously best method in (Hein et al., 2013).

Hypergraph Model. We use three datasets from the UCI
Machine Learning Repository (Lichman, 2013): mush-
room, covertype45 and covertype67. As in (Hein et al.,
2013), each dataset ﬁts into the hypergraph learning model
in the following way. Each entry in the dataset corresponds
to a vertex, which is labeled either +1 or −1. Moreover,
each entry has some categorical attributes. For each at-
tribute and each realized value for that attribute, we form
a unit-weight hyperedge containing all the vertices corre-
sponding to entries having that attribute value. To summa-
rize, below are the properties of the resulting hypergraphs.

Dataset

mushroom covertype45

covertype67

n = |V |
m = |E|
=
k
(cid:80)
e∈E |e|
m

8124
112
1523

12240
104
1412

37877
123
3695

Semi-supervised Learning Framework. We compare
our semi-supervised learning framework with that in (Hein
et al., 2013), which was previously the best (compared
to (Zhou et al., 2006), for instance). Speciﬁcally, we com-
pare the prediction accuracy of the following two predic-
tion algorithms.

1. Conﬁdence Interval

(CI). We use hard con-
straints (CP1) and conﬁdence intervals for prediction,
as described in Algorithm 1 in Section 3.

2. Hein et al. We implement the method described
in (Hein et al., 2013), which uses soft constraints (reg-
ularized version), plus 5-fold cross validation to deter-
mine the regularization parameter.

Testing Methodology. Since we focus on prediction ac-
curacy, using either subgradient method or PDHG (Hein
et al., 2013) for solving the underlying convex programs in
each algorithm produces the same results. For each algo-
rithm candidate, we try different sizes of labeled vertices
L, where l = |L| ranges from 20 to 200. For each size l

of labeled vertices, we randomly pick l vertices from the
dataset to form the set L and treat the rest as unlabeled ver-
tices; we re-sample if only one label (+1 or −1) appears
in L. For each size l, we perform 100 trials to report the
average error rate together with its standard error.

Results. Our experiment can recover the results reported
in (Hein et al., 2013). The test error for the two algorithms
on the three datasets is presented in Figure 5.1, which
shows that our CI method consistently has lower test error
than the one in (Hein et al., 2013).

5.2. Comparing Running Times of Solvers

Different Solvers. We compare the running times of the
following two convex program solvers:

cally, the step size ηt :=

• Subgradient Method (SG), proposed by us. Empiri-
105 ,1) gives good
performance. For large t, ηt grows like 1
t and so the
method converges; however, for small t, we would
like a larger step size to speed up convergence.

min( 0.16t

(t+1)

1

• Primal-Dual Hybrid Gradient

in (Hein et al., 2013). We choose σ = τ = 1√
where d is the maximum degree.

1+d

(PDHG), proposed
,

Theoretical Analysis. Given a hypergraph with n vertices
and m edges, where the average size of an edge is k, each
vertex on average appears in mk
n edges. For SG, we use a
heap-based data structure to maintain the vertices within a
hyperedge. Vertices attaining the maximum and the min-
imum value within a hyperedge can be retrieved in O(1)
time, and a value update takes O(log k) time. In each iter-
ation, at most 2m vertices will have their values updated.
Hence, in each iteration, SG takes time 2m· mk
n ·O(log k) =
O( m2k
n log k). In the description of PDHG in (Hein et al.,
2013), each iteration takes O(mk log k) time. Hence, when
n (cid:29) m, each iteration of SG will be signiﬁcantly faster, al-
though in general, the number of iterations required by the
subgradient method can be larger than that for PDHG.

Testing Methodology.
In each experiment, we consider
the hypergraph from one of the above three datasets. We
pick l = 160 vertices at random as the labeled vertices
L, and form the corresponding convex program (CP1) for
the two solvers, where the initial values for unlabeled ver-
tices are chosen independently to be uniformly at random
from [−1, 1]. To compare the performance, we run the
two solvers on the same convex program, and record each
trajectory of the objective value versus the time duration.
According to experience, 100 seconds is good enough for
either solver to reach an almost optimal solution, and we
use the minimum value achieved by the two solvers after
100 seconds as an estimate for the true optimal value OPT.
Then, we scan each trajectory, and for each relative gap

Re-revisiting Learning on Hypergraphs

Figure 5.1. Prediction Accuracy of CI vs Hein .et al.

Figure 5.2. Comparing Running Times of the Two Solvers

Figure 5.3. Test Error vs Relative Gap for the Two Solvers

(cid:15) ∈ {10−i : i = 1, 2, . . . , 6}, we ﬁnd the smallest time
T ((cid:15)) after which the objective value is at most (cid:15)OPT away
from the estimate OPT. Each instance of the experiment is
repeated 100 times (with different sets of labeled vertices)
to obtain an average of those T ((cid:15))’s and their standard er-
ror. For each relative gap (cid:15), we also report the test error
for using a feasible solution that is (cid:15)OPT away from the
presumed optimal value OPT.

Results. Both solvers have similar performance. As pre-
dicted by our theoretical analysis, we see in Figure 5.2
that SG has an advantage when the number n of vertices
is much larger than the number m of edges, which is the
case for the the last dataset covertype67. Moreover, in
Figure 5.3, we see that achieving a relative gap smaller than
10−4 has almost no effect on improving the prediction ac-
curacy. Hence, we can conclude that for either solver, it
takes roughly 10 to 20 seconds to produce a solution for
the underlying convex program that can give good predic-

tion accuracy.

5.3. Directed Hypergraph: More Powerful

DBLP Dataset. We use the DBLP (Ley, 2009) dataset.
Each paper is represented by a vertex. We include papers
from year 2000 to 2015 from conferences belonging to the
following research areas to conduct our experiments:

• 7049 papers from machine learning (ML): NIPS,

ICML

STOC, FOCS

• 2539 papers from theoretical computer science (TCS):

• 3374 papers from database (DB): VLDB, SIGMOD

We perform the following prediction tasks: (a) ML (+1) vs
TCS (-1), and (b) ML (+1) vs DB (-1).

The details of the experiment setup and the results are given
in the full version.

Re-revisiting Learning on Hypergraphs

Tan, Shulong, Guan, Ziyu, Cai, Deng, Qin, Xuzhen, Bu,
Jiajun, and Chen, Chun. Mapping users across networks
In AAAI, vol-
by manifold alignment on hypergraph.
ume 14, pp. 159–165, 2014.

Yoshida, Yuichi. Nonlinear laplacian for digraphs and its
applications to network analysis. In Proceedings of the
Ninth ACM International Conference on Web Search and
Data Mining, pp. 483–492. ACM, 2016.

Yu, Jun, Tao, Dacheng, and Wang, Meng. Adaptive hy-
pergraph learning and its application in image classiﬁ-
cation. IEEE Transactions on Image Processing, 21(7):
3262–3272, 2012.

Zhou, Dengyong, Huang, Jiayuan, and Sch¨olkopf, Bern-
hard. Learning with hypergraphs: Clustering, classiﬁca-
tion, and embedding. In Advances in neural information
processing systems, pp. 1601–1608, 2006.

Zhu, Xiaojin, Ghahramani, Zoubin, and Lafferty, John D.
Semi-supervised learning using gaussian ﬁelds and har-
monic functions. In ICML, pp. 912–919. AAAI Press,
2003.

References

Agarwal, Sameer, Branson, Kristin, and Belongie, Serge.
Higher order learning with graphs. In Proceedings of the
23rd international conference on Machine learning, pp.
17–24. ACM, 2006.

Gallo, Giorgio, Longo, Giustino, Pallottino, Stefano, and
Nguyen, Sang. Directed hypergraphs and applications.
Discrete applied mathematics, 42(2):177–201, 1993.

Gao, Shenghua, Tsang, Ivor Wai-Hung, and Chia, Liang-
Tien. Laplacian sparse coding, hypergraph laplacian
sparse coding, and applications. Pattern Analysis and
Machine Intelligence, IEEE Transactions on, 35(1):92–
104, 2013.

Gibson, David, Kleinberg, Jon, and Raghavan, Prabhakar.
Clustering categorical data: An approach based on dy-
namical systems. Databases, 1, 1998.

Hein, Matthias, Setzer, Simon, Jost, Leonardo, and Ran-
The total variation on
gapuram, Syama Sundar.
In Ad-
hypergraphs-learning on hypergraphs revisited.
vances in Neural Information Processing Systems, pp.
2427–2435, 2013.

Huang, Yuchi, Liu, Qingshan, Zhang, Shaoting, and
Image retrieval via probabilis-
Metaxas, Dimitris N.
In Computer Vision and Pat-
tic hypergraph ranking.
tern Recognition (CVPR), 2010 IEEE Conference on, pp.
3376–3383. IEEE, 2010.

Ley, Michael. Dblp: some lessons learned. Proceedings of

the VLDB Endowment, 2(2):1493–1500, 2009.

Lichman, M. UCI machine learning repository, 2013. URL

http://archive.ics.uci.edu/ml.

Louis, Anand. Hypergraph markov operators, eigenvalues
In Proceedings of the
and approximation algorithms.
Forty-Seventh Annual ACM on Symposium on Theory of
Computing, pp. 713–722. ACM, 2015.

Ricatte, Thomas, Gilleron, R´emi, and Tommasi, Marc. Hy-
pernode graphs for spectral learning on binary relations
In Joint European Conference on Machine
over sets.
Learning and Knowledge Discovery in Databases, pp.
662–677. Springer, 2014.

Shor, N. Z., Kiwiel, Krzysztof C., and Ruszcay`nski, An-
drzej. Minimization Methods for Non-differentiable
Functions. Springer-Verlag New York, Inc., New York,
NY, USA, 1985. ISBN 0-387-12763-1.

Sun, Liang, Ji, Shuiwang, and Ye, Jieping. Hypergraph
In Pro-
spectral learning for multi-label classiﬁcation.
ceedings of the 14th ACM SIGKDD international con-
ference on Knowledge discovery and data mining, pp.
668–676. ACM, 2008.

