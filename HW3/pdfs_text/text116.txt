Supplementary Material for
Priv’IT: Private and Sample Eﬃcient Identity Testing

Bryan Cai
EECS, MIT
bcai@mit.edu

Constantinos Daskalakis
EECS and CSAIL, MIT
costis@csail.mit.edu

Gautam Kamath
EECS and CSAIL, MIT
g@csail.mit.edu

1 Proof of Theorem 3

We will prove the theorem for the case where β = 1/3, the general case follows at the cost of
a multiplicative log(1/β) in the sample complexity from a standard ampliﬁcation argument. To
be more precise, we can consider splitting our dataset into O(log(1/β)) sub-datasets and run the
β = 1/3 test on each one independently. We return the majority result – since each test is correct
with probability ≥ 2/3, correctness of the overall test follows by Chernoﬀ bound. It remains to argue
privacy – note that a neighboring dataset will only result in a single sub-dataset being changed.
Since we take the majority result, conditioning on the result of the other sub-tests, the result on
this sub-dataset will either be irrelvant to or equal to the overall output. In the former case, any
test is private, and in the latter case, we know that the individual test is ε-diﬀerentially private.
Overall privacy follows by applying the law of total probability.

We require the following two claims, which give bounds on the random variables Ni and Yi. Note

that, due to the fact that we draw P oisson(m) samples, each Ni ∼ P oisson(mpi) independently.

Claim 1. |Yi| ≤ 2

c2ε log

1
1−(1−c2)1/|A|

(cid:16)

(cid:17)

simultaneously for all i ∈ A with probability exactly 1 − c2.

Proof. The survival function of the folded Laplace distribution with parameter 2/c2ε is exp (−c2εx/2),
is equal to
and the probability that a sample from it exceeding the value
1 − (1 − c2)1/|A|. The probability that probability that it does not exceed this value is (1 − c2)1/|A|,
and since the Yi’s are independent, the probability that none exceeds this value is 1 − c2, as de-
sired.
Claim 2. |Ni − mpi| ≤ max (cid:8)4
least 1 − 2

mpi log n, log n(cid:9) simultaneously for all i ∈ A with probability at

1
1−(1−c2)1/|A|

2
c2ε log

√

(cid:16)

(cid:17)

n0.84 − 1.1
n .

Proof. We consider this in two cases. Let X be a P oisson(λ) random variable. First, assume that
λ ≥ e−3 log n. By Bennett’s inequality, we have the following tail bound [Pol15, Can17]:

where

Consider x = 4

λ log n. At this point, we have

√

Pr [|X − λ| ≥ x] ≤ 2 exp

−

(cid:18)

x2
2λ

ψ

(cid:16) x
λ

(cid:17)(cid:19)

,

ψ(t) =

(1 + t) log(1 + t) − t
t2/2

.

ψ(x/λ) = ψ(4(cid:112)log n/λ) ≥ ψ(4e3/2) ≥ 0.23.

1

Thus,

(cid:104)
|X − λ| ≥ 4(cid:112)λ log n

(cid:105)

Pr

≤ 2 exp (−0.23 · 8 log n)

≤ 2n−1.84.

Now, we focus on the other case, where λ ≤ e−3 log n. Here, we appeal to Proposition 1 of

[Kla00], which implies the following via Stirling’s approximation:

Pr [|X − λ| ≥ kλ] ≤

exp(−λ + kλ − kλ log k).

k
k − 1

We set kλ = log n, giving the upper bound

k
k − 1

n1−log k ≤ 1.1 · n−2.

We conclude by taking a union bound over [n], with the argument for each i ∈ [n] depending on

whether λ = mpi is large or small.

We proceed with proving the two desiderata of this algorithm, correctness and privacy.

Correctness. We use the following two properties of the statistic Z(D), which rely on the con-
n/α2). The proofs of these properties are identical to the proofs of Lemma 2
dition that m = Ω(
and 3 in [ADK15], and are omitted.

√

Claim 3. If p = q, then E[Z] = 0. If dTV(p, q) ≥ α, then E[Z] ≥ 1.

Claim 4. If p = q, then Var[Z] ≤ 1/1000. If dTV(p, q) ≥ α, then Var[Z] ≤ 1/1000 · E[Z]2.

First, we note that, by Claim 1, the probability that we return in line 5 is exactly c2. We now
consider the case where p = q. We note that by Claim 2, the probability that we output “p (cid:54)= q” in
line 10 is o(1), and thus negligible. By Chebyshev’s inequality, we get that Z ≤ 1/10 with probability
at least 9/10, and we output “p = q” with probability at least c2/2 + (1 − c2) · (9/10 − c2)2 ≥ 2/3
(note that we subtract c2 from 9/10 since we are conditioning on an event with probability 1 − c2,
and by union bound). Similarly, when dTV(p, q) ≥ α, Chebyshev’s inequality gives that Z ≥ 9/10
with probability at least 9/10, and therefore we output “p (cid:54)= q” with probability at least 2/3.

Privacy. We will prove (0, c2ε/2)-diﬀerential privacy. By Claim 1, the probability that we return
in line 5 is exactly c2. Thus the minimum probability of any output of the algorithm is at least
c2/2, and therefore (0, c2ε/2)-diﬀerential privacy implies (ε, 0)-diﬀerential privacy.

We ﬁrst consider the possibility of rejecting in line 11. Consider two neighboring datasets D
and D(cid:48), which diﬀer by 1 in the frequency of symbol i. Coupling the randomness of the Yj’s on
these two datasets, the only case in which the output diﬀers is when Yi is such that the value of
|Ni + Yi − mqi| lies on opposite sides of the threshold for the two datasets. Since Ni diﬀers by 1
in the two datasets, and the probability mass assigned by the PDF of Yi to any interval of length
1 is at most c2ε/4, the probability that the outputs diﬀer is at most c2ε/4. Therefore, this step is
(0, c2ε/4)-diﬀerentially private.

We next consider the value of Z for two neighboring datasets D and D(cid:48), where D(cid:48) has one fewer
occurrence of symbol i. We only consider the case where we have not already returned in line 11,

2

as otherwise the value of Z is irrelevant for determining the output of the algorithm.

Z(D) − Z(D(cid:48))

=

=

=

(cid:20) (Ni − mqi)2 − Ni
1
mα2
mqi
(cid:20) (Ni − mqi)2 − Ni
1
mα2
mqi
2(Ni − mqi − 1)
m2α2qi

.

−

−

Since we did not return in line 11,

(Ni − 1 − mqi)2 − (Ni − 1)
mqi

(cid:21)

(Ni − mqi)2 − 2(Ni − mqi) + 1 − Ni + 1
mqi

(cid:21)

|Ni − mqi| ≤

(cid:18)

log

4
c2ε
4 log(n/c2)
c2ε

≤

1
1 − (1 − c2)1/n

(cid:19)

+ max

(cid:110)
4(cid:112)mqi log n, log n

(cid:111)

+ max

(cid:110)
4(cid:112)mqi log n, log n

(cid:111)

This implies that

|Z(D) − Z(D(cid:48))| =

2|Ni − mqi − 1|
m2α2qi
2
m2α2qi

(cid:18) 6 log(n/c2)
c2ε

≤

+ 4(cid:112)mqi log n

(cid:19)

.

We will enforce that each of these terms are at most c2ε/8.

12 log(n/c2)
m2α2qic2ε
√
log n
8
m1.5α2√

qi

≤

≤

c2ε
8

c2ε
8

⇒ m ≥

⇒ m ≥

(cid:115)

96
c2
2c1
(cid:18) 64
√
c2

(cid:112)n log(n/c2)
α1.5ε

(cid:19)2/3 (n log n)1/3
α5/3ε2/3

c1

Since both terms are at most c2ε/8, this step is (0, c2ε/4)-diﬀerentially private. Combining
with the previous step gives the desired (0, c2ε/2)-diﬀerential privacy, and thus (as argued at the
beginning of the privacy section of this proof) ε-pure diﬀerential privacy.

References

[ADK15] Jayadev Acharya, Constantinos Daskalakis, and Gautam Kamath. Optimal testing for
In Advances in Neural Information Processing Systems 28,

properties of distributions.
NIPS ’15, pages 3577–3598. Curran Associates, Inc., 2015.

[Can17] Clément L. Canonne. A short note on Poisson tail bounds. http://www.cs.columbia.

edu/~ccanonne/files/misc/2017-poissonconcentration.pdf, 2017.

[Kla00] Bernhard Klar. Bounds on tail probabilities of discrete distributions. Probability in the

Engineering and Informational Sciences, 14(02):161–171, 2000.

[Pol15] David Pollard. A few good inequalities. http://www.stat.yale.edu/~pollard/Books/

Mini/Basic.pdf, 2015.

3

