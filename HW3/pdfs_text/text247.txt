Deep IV: A Flexible Approach for Counterfactual Prediction

Jason Hartford 1 Greg Lewis 2 Kevin Leyton-Brown 1 Matt Taddy 2

Abstract

Counterfactual prediction requires understanding
causal relationships between so-called treatment
and outcome variables. This paper provides a
recipe for augmenting deep learning methods to
accurately characterize such relationships in the
presence of instrument variables (IVs)—sources
of treatment randomization that are conditionally
independent from the outcomes. Our IV speciﬁ-
cation resolves into two prediction tasks that can
be solved with deep neural nets: a ﬁrst-stage net-
work for treatment prediction and a second-stage
network whose loss function involves integration
over the conditional treatment distribution. This
Deep IV framework1 allows us to take advantage
of oﬀ-the-shelf supervised learning techniques
to estimate causal eﬀects by adapting the loss
function. Experiments show that it outperforms
existing machine learning approaches.

1. Introduction

Supervised machine learning (ML) provides many eﬀec-
tive methods for tasks in which a model is learned based
on samples from some data generating process (DGP) and
then makes predictions about new samples from the same
distribution. However, decision makers would often like to
predict the eﬀects of interventions into the DGP through pol-
icy changes. Such changes impact the relationship between
inputs and outcomes, making straightforward prediction ap-
proaches inappropriate. In order to accurately answer such
counterfactual questions it is necessary to model the struc-
tural (or causal) relationship between policy (or “treatment”)
and outcome variables.

For example, consider an airline that wants to use historical

1University of British Columbia, Canada 2Microsoft Research,
New England, USA. Correspondence to: Jason Hartford <jason-
har@cs.ubc.ca>, Matt Taddy <taddy@microsoft.com>.

Proceedings of the 34th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by
the author(s).

1Implementation with all simulation experiments is available

at https://github.com/jhartford/DeepIV

data to optimize the prices it charges its customers: in this
case, price is the treatment variable and the customer’s deci-
sion about whether to buy a ticket is the outcome. There are
two ways that a naive analysis could lead to incorrect coun-
terfactual predictions. First, imagine that price varies in the
training data because the airline gradually increases prices
as a plane ﬁlls. Around holidays, more people want to ﬂy
and hence planes become fuller leading to higher prices. So,
in our training set we observe examples with high prices and
high sales. A direct ML approach might incorrectly predict
that if the airline were to increase prices at other times in the
year they would also observe increased sales, whereas the
true relationship between price and sales is surely negative.
Typically we can observe holidays, and include them in the
model, so that we can correct for their eﬀects. This case
where an observable feature (holidays) is correlated with
both the outcome and treatment variable is called “selection
on observables”.

But say there is also sometimes high demand because of
conferences, which the airline is not able to observe. This
presents a more challenging problem: even if price dis-
tortions due to holidays were taken into account, a naive
analysis could conclude that higher prices drive higher de-
mand, whereas in fact high price is only correlated with
high demand via the latent conference variable. This is the
more challenging case of “selection on unobservables”.

The gold standard for establishing causal relationships is
to conduct “AB” experiments, with subjects randomly as-
signed to diﬀerent values of the treatment variable. In the
airline example, this would mean assigning passengers ran-
dom prices that do not depend on the number of seats sold.
Enough data collected in this way would make it straight-
forward to identify the true relationship between price and
demand even if the latent variable were never observed.
However, such a strategy would be exceedingly expensive
(the airline would sometimes turn away interested passen-
gers for nearly-empty ﬂights and oﬀer steep discounts for
nearly-full ﬂights). Depending on the timescale over which
such randomization were conducted, it could also hurt the
airline’s long-term interests (because it could be perceived
as unfair) and could fail if passengers were able to hide their
identities (e.g., by logging in from a diﬀerent computer if
they didn’t like the price).

Deep IV: A Flexible Approach for Counterfactual Prediction

The alternative is to work with observational data, but doing
so requires explicit assumptions about the causal structure of
the DGP (Bottou et al., 2013). Most recent approaches to us-
ing machine learning methods such as trees (Wager & Athey,
2015; Athey & Imbens, 2016) and deep networks (Johans-
son et al., 2016; Shalit et al., 2016) for causal inference in
observational data leverage an “unconfoundedness” assump-
tion that the treatment is conditionally independent of any
latent variables given the observed features. This amounts
to assuming away selection on unobservables, which may
or may not be reasonable depending on the setting.

We can do without this assumption and get around both
types of selection if we can identify one or more instru-
mental variables (IVs) that only aﬀect treatment assignment
and not the outcome variable. In our airline example, the
cost of fuel could be such an instrument: its variation is
independent of demand for airline tickets and it aﬀects sales
only via ticket prices. Changes in the cost of fuel thus create
movement in ticket prices that is independent of our latent
variable, and this movement is as good as randomization for
the purposes of causal inference. See Figure 1 for an graph-
ical illustration of this example and of the general class of
causal graphs that we consider.

The IV framework has a long history, especially in eco-
nomics (e.g., Wright, 1928; Reiersøl., 1945). It provides
methods for learning the regression function that relates the
treatment and response variables under the “interventional
distribution” for DGPs that conform to the graphical model
shown in Figure 1 (Pearl, 2009). Most IV applications make
use of a two-stage least squares procedure (2SLS; e.g., An-
grist & Pischke, 2008) that applies a model of linear and
homogeneous treatment eﬀects (e.g., all airline customers
must have the same price sensitivity). Nonparametric IV
methods from the econometrics literature relax these as-
sumptions (e.g., Newey & Powell, 2003; Darolles et al.,
2011). However, these methods typically work by modeling
the outcome as an unknown linear combination of a pre-
speciﬁed set of basis functions of the treatment and other
covariates (e.g. Hermite polynomials, wavelets, or splines)
and then modeling the conditional expectation of each of
these basis functions in terms of the instruments (i.e., the
number of parameters is quadratic in the number of basis
functions). This requires a strong prior understanding of
the DGP by the researcher; also, the complexity of both
speciﬁcation and estimation explodes when there are more
than a handful of inputs.

Advances in deep learning have demonstrated the power of
learning latent representations of complex features spaces
(for recent surveys, see eg. LeCun et al., 2015; Schmid-
huber, 2015). This paper’s goal is to use these powerful
learning algorithms for IV analysis. We do this by breaking
IV analysis into two supervised stages that can each be tar-

geted with deep networks and that, when solved, allow us
to make counterfactual claims and perform causal inference.
Speciﬁcally, we ﬁrst model the conditional distribution of
the treatment variable given the instruments and covariates
and then target a loss function involving integration over the
conditional treatment distribution from the ﬁrst stage. Both
stages use deep neural nets trained via stochastic gradient
descent (Robbins & Monro, 1951; Bottou, 2010). We also
present an out-of-sample causal validation procedure for
selecting hyper-parameters of the models on a validation set.
We refer to this setup as the Deep IV framework.

Section 2 describes our general IV speciﬁcation and its de-
composition into two learning tasks. Section 3 outlines
neural network estimation for these tasks with particular
attention paid to the SGD routine used in model training
and our causal validation procedure. Section 4 presents ex-
perimental results that illustrate the beneﬁts of our methods.

2. Counterfactual prediction

We aim to predict the value of some outcome variable y (e.g.,
sales in our airline example) under an intervention in a policy
or treatment variable p (e.g., price). There exists a set of
observable covariate features x (e.g., holidays) that we know
aﬀect both p and y. There also exist unobservable latent
variables e that may aﬀect x, p and y (e.g., conferences).
Counterfactual prediction aims to recover E[y| do(p), x] in
the context of the graphical model given by Figure 1, where
the do(·) operator indicates that we have intervened to set
the value of the policy variable p (as per Pearl, 2009). We
assume the y is structurally determined by p, x and e as

y = g (p, x) + e.

(1)

That is, g (·) is some unknown and potentially non-linear
continuous function of both x and p, and we assume that the
latent variables (or “error”) e enter additively with uncondi-
tional mean E e = 0. We allow for errors that are potentially
correlated with the inputs: E[e|x, p] (cid:44) 0 and, in particular,
E[pe|x] (cid:44) 0.

Deﬁne the counterfactual prediction function

h (p, x) ≡ g (p, x) + E[e|x],

(2)

which is the conditional expectation of y given the observ-
ables p and x, holding the distribution of e constant as p is
changed. Note that we condition only on x and not p in the
term E[e|x]; this term is typically nonzero, but it will remain
constant under arbitrary changes to our policy variable p.2
Thus h (p, x) is the structural equation that we estimate. It is

2It may be easier to think about a setting where e ⊥⊥ x, so that
the latent error is simply deﬁned as being due to factors orthogonal
to the observable controls. In that case, h (p, x) = g (p, x). All of
our results apply in either setup.

Deep IV: A Flexible Approach for Counterfactual Prediction

Figure 1. (Left) Our air-travel demand example, with arrows representing causal eﬀects. Price is the policy variable, sales is the outcome,
and holidays are observable covariates. There is a big ‘conference’, unobserved to the policy-maker, that drives demand and (due to
the airline’s pricing algorithms) price. The instrument is the cost of fuel, which inﬂuences sales only via price. (Right) The general
structure of the DGP under our IV speciﬁcation; x represents observable features, p is our treatment variable of interest, z represents the
instruments, and latent eﬀects e inﬂuence the outcome y additively.

useful because to evaluate policy options (e.g. changing the
ticket price from p0 to p1) we can look at the diﬀerence in
outcomes h (p1, x) − h (p0, x) = g (p1, x) − g (p0, x).
In standard supervised learning settings, the prediction
model is trained to ﬁt E[y|p, x]. This will typically be biased
against our structural objective because

E[y|p, x] = g (p, x) + E[e|p, x] (cid:44) h (p, x)

(3)

since our treatment is not independent of the latent errors
by assumption and hence E[e|p, x] (cid:44) E[e|x]. This object is
inappropriate for policy analysis as it will lead to biased
counterfactuals:

E[y|p1, x] − E[y|p0, x]

= g (p1, x) − g (p0, x) +

(cid:19)
(cid:18)
E[e|p1, x] − E[e|p0, x]

.

(4)

In our airline example, high prices during conferences imply
that E[e|p1, x] − E[e|p0, x] will be positive, resulting in the
incorrect prediction that higher prices are associated with
higher sales if this bias is suﬃciently large.

Fortunately, the presence of instruments allows us to esti-
mate an unbiased ˆh (p, x) that captures the structural rela-
tionship between p and y. These are sets of variables z that
satisfy the following three conditions.

Relevance F(p|x, z), the distribution of p given x and z, is

not constant in z.

Exclusion z does not enter Eq. (1)—i.e., z ⊥⊥ y | (x, p, e).

Unconfounded Instrument z is conditionally independent

of the error—i.e., z ⊥⊥ e | x.3

3Under the additive error assumption made in Eq. (1), uncon-
foundedness of the instrument is not necessary: we could replace
this assumption with the weaker mean independence assumption
E[e|x, z] = 0 without changing anything that follows. We use the
stronger assumption to facilitate extensions, e.g.
to estimating
counterfactual quantiles. Our assumption is similar to the ‘un-
confoundedness’ assumption in the Neyman–Rubin potential out-
comes framework (Rosenbaum & Rubin, 1983) (i.e. p ⊥⊥ e | x). But
our assumption is weaker—in particular, we allow for p (cid:54)⊥⊥ e|x—
and so the matching and propensity-score re-weighting approaches
often used in that literature will not work here.

Taking the expectation of both sides of Equation (1) condi-
tional on [x, z] and applying these assumptions establishes
the relationship (cf. Newey & Powell, 2003):

E[y|x, z] = E[ g (p, x)|x, z] + E[e|x]

(cid:90)

=

h (p, x)dF(p|x, z),

(5)

where, again, dF(p|x, z) is the conditional treatment distri-
bution. The relationship in Equation (5) deﬁnes an inverse
problem for h in terms of two directly observable functions:
E[y|x, z] and F(p|x, z). IV analysis typically splits this into
two stages: ﬁrst estimating ˆF(p|xt, zt) ≈ F(p|xt, zt), and then
estimating ˆh after replacing F with ˆF.
Most existing approaches to IV analysis assume linear mod-
els for the treatment density function ˆF and the counterfac-
tual prediction function ˆh to solve Equation (5) in closed
form. For example, the two-stage least-squares (2SLS) pro-
cedure (e.g., Angrist et al., 1996) posits y = γp + xβy + e
and p = τz + xβp + v, with the assumptions that E[e|x, z] = 0,
E[v|x, z] = 0, and E[ev] (cid:44) 0 (which implies E[ep] (cid:44) 0). This
procedure is straightforward: ﬁt a linear model for p given
x and z and use the predicted values ˆp in a second linear
model of y. This is a statistically eﬃcient way to estimate
the eﬀect of the policy variable (i.e. γ) as long as two strong
assumptions hold: linearity (i.e., both ﬁrst- and second-stage
regressions are correctly speciﬁed) and homegeneity (i.e.,
the policy aﬀects all individuals in the same way).4

Flexible nonparametric extensions of 2SLS either replace
the linear regressions with a linear projection onto a series
of known basis functions (Newey & Powell, 2003; Blundell
et al., 2007; Chen & Pouzo, 2012) or use kernel-based meth-
ods as in Hall & Horowitz (2005) and Darolles et al. (2011).
This system of series estimators is an eﬀective strategy for
introducing ﬂexibility and heterogeneity with low dimen-
sional inputs, but the approach faces the same limitations as
kernel methods in general: their performance depends on
the choice of kernel function; and they often become com-

4The estimated ˆγ remains interpretable as a ‘local average
treatment eﬀect’ (LATE) under less stringent assumptions (see
Angrist et al., 1996, for an overview).

holidaysconferencesalesfuelcostspricexeyzpDeep IV: A Flexible Approach for Counterfactual Prediction

putationally intractable in high-dimensional feature spaces
[x, z] or with large numbers of training examples.

3. Estimating and validating DeepIV

We now describe how to use deep networks to perform ﬂex-
ible, scalable IV analysis in a framework we call DeepIV.
We make two contributions that are each necessary compo-
nents of the approach. First, we propose a loss function and
optimization procedure that allows us to optimize deep net-
works for counterfactual prediction. Second, we describe a
general procedure for out-of-sample validation of two-stage
instrument variable methods. This allows us to perform
causally valid hyper-parameter optimization, which in gen-
eral is necessary for achieving good predictive performance
using deep networks.

Our approach is conceptually simple given the counterfac-
tual prediction framework described in Section 2. Rather
than constraining ourselves to analytic solutions to the in-
tegral in Equation (5), we instead directly optimize our
estimate of the structural equation, ˆh . Speciﬁcally, to mini-
mize (cid:96)2 loss given n data points and given a function space
H (which may not include the true h ), we solve
(cid:33)2
(cid:90)
ˆh (p, xt)dF(p|xt, zt)

yt −

n(cid:88)

(6)

(cid:32)

.

min
ˆh ∈H

t=1

Since the treatment distribution is unknown, we estimate
ˆF(p|x, z) in a separate ﬁrst stage.

So the DeepIV procedure has two stages: a ﬁrst stage den-
sity estimation procedure to estimate ˆF(p|x, z) and a second
that optimizes the loss function described in Equation (6).
In both stages hyper-parameters can be chosen to minimize
the respective loss functions on a held out validation set, and
improvements in performance against this metric will cor-
relate with improvements on the true structural loss which
cannot be evaluated directly. We brieﬂy discuss these two
stages before describing our methods for optimizing the loss
given in Equation (6) and our causal validation procedure.

First stage: Treatment network In the ﬁrst stage we
learn F(p|x, z) using an appropriately chosen distribution
parameterized by a deep neural network (DNN), say ˆF =
Fφ(p|x, z) where φ is the set of network parameters. Since
we will be integrating over Fφ in the second stage, we must
fully specify this distribution.

In the case of discrete p, we model Fφ(p|x, z) as a categorical
Cat (p | π(x, z; φ)) with p(p = pk) = πk(x, z; φ) for each treat-
ment category pk and where πk(x, z; φ) is given by a DNN
with softmax output. For continuous treatment, we model F
as a mixture of Gaussian distributions where component
weights πk(x, z; θ) and parameters (cid:2)µk(x, z; φ), σk(x, z; φ)(cid:3)
form the ﬁnal layer of a neural network parametrized by

φ. This model is known as a mixture density network, as
detailed in §5.6 of Bishop (2006). With enough mixture
components it can approximate arbitrary smooth densities.
To obtain mixed continuous–discrete distributions we re-
place some mixture components with point masses. In each
case, ﬁtting Fφ is a standard supervised learning problem.

Second stage: Outcome network In the second stage,
our counterfactual prediction function h is approximated
by a DNN with real-valued output, say hθ. We optimize
network parameters θ to minimize the integral loss function
in Equation (6) over training data D of size T = |D| from the
joint DGP D,

L(D; θ) = |D|−1 (cid:88)

(cid:32)

(cid:90)

yt −

t

hθ(p, xt)d ˆFφ(p|xt, zt)

.

(7)

(cid:33)2

Note that this loss involves the estimated treatment distribu-
tion function, ˆFφ, from our ﬁrst stage.5

3.1. Optimization for DeepIV networks

We use stochastic gradient descent (SGD; see algorithms
in, e.g., Duchi et al., 2011; Kingma & Ba, 2014) to train
the network weights. For Fφ, standard oﬀ-the-shelf meth-
ods apply, but second stage optimization (for hθ) needs to
account for the integral in Equation (7). SGD convergence
only requires that each sampled gradient ∇θLt is unbiased
for the population gradient, ∇θL(D; θ). Lower variance for
∇θLt will tend to yield faster convergence (Zinkevich, 2003)
while the computational eﬃciency of SGD on large datasets
requires limiting the number of operations going into each
gradient calculation (Bousquet & Bottou, 2008).

We can approximate the integral with respect to a probabil-
ity measure with the average of draws from the associated
b h (pb) for
probability distribution:
iid∼ F. Hence we can get an unbiased estimate of Equa-
{pb}B
1
tion (7) by replacing the integral with a sum over samples
from our ﬁtted treatment distribution function, ˆFφ:

h (p)dF(p) ≈ B−1 (cid:80)

(cid:82)

L(D; θ) ≈ |D|−1 (cid:88)





t

yt −

1
B

(cid:88)

˙p∼ ˆFφ(p|xt,zt)


2



hθ( ˙p, xt)

:= ˆL(D; θ).

(8)
This equation can be used to estimate ∇θL with an important
caveat: if we want to maintain unbiased gradient estimates,
independent samples must be used for each instance of the
integral in the gradient calculation. To see this, note that the

5 We can replace Eq. (7) with other functions, e.g., a softmax
for categorical outcomes, but use (cid:96)2 loss for most of our exposition.

Deep IV: A Flexible Approach for Counterfactual Prediction

gradient of Equation (8) has expectation

ED∇θLt = −2ED

(cid:105)

(cid:18)
(cid:104)
EFφ(p|xt,zt)
(cid:20)
· EFφ(p|xt,zt)

yt − hθ(pk, xt)
(cid:21)(cid:19)
h (cid:48)
θ(pk, xt)
(cid:104)(cid:16)
(cid:44) −2EDEFφ(p|xt,zt)

(cid:17)
yt − hθ(pk, xt)

(9)
(cid:105)
h (cid:48)
θ(pk, xt)

,

the
(cid:104)(cid:16)

so
(cid:105) (cid:44) 0.

inequality
(cid:17)
yt − hθ(pk, xt)

long
as
holds
where
h (cid:48)
θ(pk, xt)
We thus
covFφ(p|xt,zt)
need a gradient estimate based on unbiased MC estimates
for each EFφ(p|xt,zt) term in Equation (9). We obtain such an
iid∼ Fφ(p|xt, zt)
estimate by taking two samples { ˙pb}B
and calculating the gradient as

1 , { ¨pb}B
1

(cid:98)∇B

θ Lt ≡ −2

hθ( ˙pb, xt)

h (cid:48)
θ( ¨pb, xt). (10)


yt − B−1 (cid:88)


b





B−1 (cid:88)

b

Independence of the two samples ensures that E(cid:98)∇B
θ Lt =
ED∇θLt = ∇θL(D; θ), as desired. The variance of our es-
timate depends on B, the number of samples that we draw.
Each of these samples is relatively expensive to compute
because they require a forward pass through the network
ˆhθ( ˙p, xt). If this varies signiﬁcantly with ˙p we might need a
large number of samples to get a low-variance estimate of
the gradient, which is computationally intensive.

An alternative is to optimize an upper bound on Equation (8).
By using Jensen’s inequality and the fact that the squared
error function is convex we get that

ˆL(D; θ) ≤ |D|−1 (cid:88)

(cid:88)

(cid:16)

yt − hθ( ˙p, xt)

(cid:17)2

.

(11)

t

˙p∼ ˆFφ(p|xt,zt)

Taking the RHS of Equation (11) as the objective and cal-
culating the gradient leads to a version of Equation (10) in
which a single draw can be used instead of two independent
draws. This objective is easy to implement in practice as
it just involves drawing samples during training. This is
well-supported in deep network implementations because it
is analogous to the data augmentation procedures that are
commonly used to encourage invariance in deep networks.
The analogy is more than just aesthetic—by optimizing this
loss, we are essentially encouraging the network to be invari-
ant to variations in the treatment that cannot be explained by
our features and instrument. This encourages the network
to ignore the eﬀects of unobserved confounding variables.

However, we do not have theoretical guarantees that optimiz-
ing this upper bound on L(D; θ) leads to good counterfactual
performance. While it may converge more quickly because
it exhibits lower variance, it will have worse asymptotic per-
formance as it only approximates the desired loss function.
We evaluated this tradeoﬀ experimentally by comparing
optimizing the upper bound to the more computationally

expensive unbiased procedure. In our simulations, we found
that upper bound loss tended to give better performance
under practical computational limitations.

Discrete treatment and outcome spaces The discussion
thus far has focused on continuous treatment and outcome
spaces because they are more challenging mathematically.
When the treatment space is discrete and low dimensional,
Fφ is modeled as a categorical response so the gradient of
Equation (7) can be expressed exactly as

∇θLt = −2

πk(xt, zt; φ)hθ(pk, xt)


yt −



(cid:88)

k




πk(xt, zt; φ)h (cid:48)

(cid:88)

·

k

θ(pk, xt).

(12)

Thus when the outcome space is discrete, we also have less
to worry about with respect to bias in gradient updates. For
discrete outcomes, we use the softmax loss and can use
single-sample MC gradient estimates without introducing
bias or large amounts of variance because the gradient with
respect to the softmax loss does not involve a product of
random variables.

3.2. Causal validation

There is a widespread belief that “[s]tandard methods for
hyperparameter selection, such as cross-validation, are not
applicable when there are no samples of the counterfactual
outcome” (Shalit et al., 2016). This would be a signiﬁ-
cant problem in our setting because out-of-sample (OOS)
validation procedures are crucial for tuning deep network
hyper-parameters and optimization rules. Fortunately, both
steps in our Deep IV procedure can be validated by simply
evaluating the respective losses on held out data. Consider
a held-out dataset Dh-o. Our ﬁrst stage, ﬁtting Fφ, is a
standard density estimation problem and can be tuned to
minimize the OOS deviance criterion

min
φ

(cid:88)

dl∈Dh-o

− log fφ(pl|xl, zl),

(13)

where fφ is either the probability mass function or density
function associated with Fφ, as appropriate. Second stage
validation proceeds conditional upon a ﬁtted Fφ, and we
seek to minimize the held-out loss criterion

(cid:32)

(cid:88)

(cid:90)

min
θ

dl∈Dh-o

yl −

hθ(p, xl)dFφ(p|xl, zl)

.

(14)

(cid:33)2

The integral here can either be exact or MC approximate via
sampling from Fφ.

Each stage is evaluated in turn, with second stage validation
using the best-possible network as selected in the ﬁrst stage.

Deep IV: A Flexible Approach for Counterfactual Prediction

This procedure guards against the ‘weak instruments’ bias
(Bound et al., 1995) that can occur when the instruments
are only weakly correlated with the policy variable. To
see why, consider the worst case where the instruments are
independent of the policy variable, i.e., F(p|z) = F(p). With-
out validation, a suﬃciently powerful model will perfectly
overﬁt by approximating the conditional distribution F(p|zi)
with a point mass at pi. As a result, the causal loss function
will approximate the standard prediction loss, leading to
spurious conclusions. By contrast, the expected ﬁrst-stage
loss minimizer on the validation set is the model that best
approximates the unconditional distribution F(p), and given
that, the second stage minimizer best approximates g(p) = ¯y
which predicts no relationship when there is no evidence in
favor of it. That said, it should be noted that these criteria
provide relative performance guidance: improving on each
criterion will improve performance on counterfactual pre-
diction problems, but without giving any information about
how far hθ(p, x) is from true h (p, x).

Our causal validation procedure is sequential: stage two’s
validation depends on the model chosen in the ﬁrst stage.
This greedy procedure is computationally eﬃcient and
causally valid, but potentially suboptimal because the ﬁrst-
stage loss is not of independent interest. Peysakhovich &
Eckles (2017) concurrently developed a casual validation
framework that considers both stages jointly in domains with
categorical instruments and no observable features. These
assumptions are too restrictive for the problems we consider,
but it would be interesting to investigate whether there exists
a joint optimization approach that oﬀers practical beneﬁts
under more permissive assumptions.

4. Experiments

We evaluated our approach on both simulated and real
data. We used simulations to assess DeepIV’s ability to
recover an underlying counterfactual function both in a low-
dimensional domain with informative features and in a high-
dimensional domain with features consisting of pixels of a
handwritten image. We compared our approach to 2SLS and
to a standard feed-forward network, evaluated the eﬀective-
ness of hyper-parameter optimization, and contrasted our
biased and unbiased loss functions with various numbers
of samples underlying the SGD step. We also considered
a real-world dataset where ground truth was not available,
showing that we could replicate the ﬁndings of a previous
study in a dramatically more automatic fashion.

4.1. Simulations

Our simulation models a richer version of the airline ex-
ample described in Section 1. We assume that there are 7
customer types s ∈ {1, ..., 7} that each exhibit diﬀerent lev-
els of price sensitivity. We model the holiday eﬀect on

(cid:16)

(t − 5)4/600 + exp

sales by letting the customer’s price sensitivity vary continu-
ously throughout the year according to a complex non-linear
(cid:17)
−4(t − 5)2(cid:105) + t/10 − 2
(cid:104)
function, ψt = 2
.
The time of year t is an observed variable, generated as
t ∼ unif(0, 10). Prices are a function of ψt and of the fuel
price z, with the motivation that they are chosen strategically
by the airline in order to move with average price sensitivity.
In our example, the high demand that results from con-
ferences breaks the conditional independence between our
treatment variable p and the latent eﬀects e, thereby vio-
lating the “unconfoundedness” assumption. We model this
abstractly by generating our latent errors e with a parameter
ρ that allows us to smoothly vary the correlation between p
and e. Sales y are then generated as

y = 100 + (10 + p)sψt − 2p + e,
z, v ∼ N(0, 1) and e ∼ N(ρv, 1 − ρ2).

p = 25 + (z + 3)ψt + v

Our target counterfactual function is h (t, s, p) = (10 +
p)sψt − 2p. To evaluate the model, we consider the coun-
terfactual question, “What would sales have been if prices
had been changed to p(cid:48)?” Thus the price in our test set is set
deterministically over a ﬁxed grid of price values that spans
the range of training set prices. The observed features [t, s]
are sampled as in the original data generating process and
we compare estimated ˆh against the ground truth h .

Low dimensional domain We evaluated structural mean
square error (MSE) while varying both the number of train-
ing examples and ρ, the correlation between e and p. In
addition to Deep IV, we considered a regular feed-forward
network (FFNet) with the same architecture as our outcome
network, a non-parametric IV polynomial kernel regres-
sion (NonPar, Darolles et al., 2011) using Hayﬁeld et al.
(2008)’s R implementation, and standard two-stage least
squares (2SLS). Full details of model architectures and hy-
perparameter choices for all the models are given in the
Appendix.

The results are summarized in Figure 2. The performance of
NonPar, of 2SLS, and of our Deep IV model was mostly un-
aﬀected by changes in ρ, reﬂecting the fact that these models
are designed to be resilient to unobserved confounders. For
1000 data points, NonPar’s mean performance was better
than 2SLS but failed to match DeepIV. Because of Non-
Par’s excessive computational requirements we were not
able to ﬁt it to the larger datasets. 2SLS is constrained by
its homogeneity and linearity assumptions, and so did not
improve with increasing amounts of data. Adding regu-
larized polynomial basis functions to 2SLS (2SLS(poly))
gives some empirical improvements in performance over
2SLS on larger datasets but the procedure is not causally
valid because it violates 2SLS’s linearity assumptions. Both
forms of 2SLS performed far better than FFNet which did a

Deep IV: A Flexible Approach for Counterfactual Prediction

Figure 2. Out-of-sample predictive performance for diﬀerent levels of endogeneity (ρ). Note that the test samples were generated with
independent errors conditional upon a ﬁxed grid of price values, breaking the endogeneity that existed in the training sample; this is why
the feed-forward network did so poorly. Each model was ﬁtted on 40 random samples from the DGP for each sample size and ρ-level.

classes, but may instead observe a large number of features
that correlate with such types. To simulate this, we replaced
the customer type label s ∈ {0, 1, ..., 7} with the pixels of the
corresponding handwritten digit from the MNIST dataset
(LeCun & Cortes, 2010). The task remained the same, but
the model was no longer explicitly told that there were 7
customer types and instead had to infer the relationship
between the image data and the outcome.

In this far more challenging domain, performance is sensi-
tive to the choice of hyper-parameters, necessitating opti-
mization on a validation set. Figure 3 shows an evaluation of
the appropriateness of our loss function for hyper-parameter
tuning, comparing our validation-set loss after grid search
over Dropout and L2-regularization parameters to test set
loss. We found a clear linear relationship between the losses;
the best performing validation set model was among the best
ﬁve performing models under the true causal loss.

We can get an upper bound on the performance of a partic-
ular model architecture by comparing its performance to
the same architecture trained on data from a simulated ran-
domized experiment on the same data-generating process.
We simulated this by generating the outcome y with inde-
pendent noise e and by generating p uniformly at random
over its support. Thus the controlled model had to solve
a standard supervised learning problem where errors were
generated independently and there was no test-time covari-
ate shift. As before, the naive deep network also shared
the same architecture in addition to taking the instrument
as input. This experiment showed that DeepIV was able to
make up most of the loss in counterfactual prediction perfor-
mance that the naive network suﬀered by not accounting for
the causal prediction problem. However, there was still a
gap in performance: with 20 000 data points the controlled
experiment achieved an average mean squared error of 0.20
while DeepIV managed 0.32.

Figure 3. For the high-dimensional feature space problem we used
a four-layer convolutional network to build an embedding of the
image features which was concatenated with the observed time
features and the instrument (ﬁrst stage) and the treatment samples
(second stage) and fed the resulting vector through another hidden
(Left) Grid search over L2 and
layer before the output layer.
dropout parameters for the embedding used in the convolution
network. (Right) Performance on an image experiment.

good job of estimating h (t, s, p) + E[e|p] but a terrible job of
recovering the true counterfactual. As ρ dropped, decreas-
ing E[e|p], FFNet’s performance improved but even with
low levels of correlation between p and e it remained far
worse than simple 2SLS. This occurred because we eval-
uated the models with respect to a ﬁxed grid of treatment
values which induced a covariate shift at test time. In con-
trast, Deep IV was the best performing model throughout
and its performance improved as the amount of data grew.

High dimensional feature space
In real applications, we
do not typically get to observe variables like customer type
that cleanly delineate our training examples into explicit

1510200.020.100.502.0010.00r = 0.9ll1510200.020.100.502.0010.00llll1510200.020.100.502.0010.00lll1510200.020.100.502.0010.00l1510200.020.100.502.0010.001510200.020.100.502.0010.00r = 0.751510200.020.100.502.0010.00l1510200.020.100.502.0010.00lll1510200.020.100.502.0010.001510200.020.100.502.0010.00ll1510200.020.100.502.0010.00r = 0.51510200.020.100.502.0010.00l1510200.020.100.502.0010.00ll1510200.020.100.502.0010.00l1510200.020.100.502.0010.00lll1510200.020.100.502.0010.00r = 0.25l1510200.020.100.502.0010.00lll1510200.020.100.502.0010.001510200.020.100.502.0010.00lll1510200.020.100.502.0010.00l1510200.020.100.502.0010.00r = 0.1ll1510200.020.100.502.0010.00lll1510200.020.100.502.0010.00ll1510200.020.100.502.0010.00ll1510200.020.100.502.0010.00Training Sample in 1000sOut−of−Sample MSE (log scale)FFNet2SLS2SLS(poly)NonParDeepIVlllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll2.62.83.03.23.40.20.40.60.81.01.2Counterfactual loss (MSE)Validation loss (MSE)lllllll1e−045e−040.0010.0050.010.050.1l1510200.050.200.502.005.0020.00lllllllllllllTraining Samples in 1000sOut−of−Sample Counterfactual MSEControlled ExperimentDeepIV2SLSNaive deep netDeep IV: A Flexible Approach for Counterfactual Prediction

Loss Function

# Samples Mean

Stdev

Upper bound
Unbiased
Unbiased
Unbiased
Unbiased

1
2
4
8
16

0.32
0.48
0.50
0.44
0.39

0.085
0.107
0.158
0.100
0.098

Table 1. Comparing loss functions on the high-dimensional image
task. Bold indicates best performing models. Although the upper
bound loss oﬀered better mean performance, the two results are
not statistically signiﬁcantly diﬀerent.

Performance of the unbiased loss relative to the upper
bound loss We tested how our two approaches to op-
timization aﬀected performance on the image task with
20 000 training examples. The results are summarized in
Table 1. The upper bound loss loss gave signiﬁcantly better
performance than all but the unbiased loss version based
on 16 samples, without requiring multiple passes through
the network to evaluate the gradient. Thus, the bias intro-
duced by the upper bound did not meaningfully degrade
counterfactual performance in our experiments.

4.2. Application: Search-advertisement position eﬀects

Our experiments so far have considered synthetic data. We
now evaluate the utility of our approach on real data for
which we do not have access to ground truth. This means
that we cannot evaluate models in terms of their predictions;
instead, we show that we can replicate the results of a pre-
viously published study in a dramatically more automated
fashion. Speciﬁcally, we examine how advertiser’s position
on the Bing search page (their “slot”) aﬀects the probability
of a user click, allowing for diﬀerent treatment eﬀects for
diﬀerent advertiser-query pairs. For example, we aim to de-
tect diﬀerences in the importance of ad position when Coke
bids on the word “Coke” (an “on-brand query”) versus when
Pepsi bids on “Coke” (an “oﬀ-brand query”) versus when
Coke bids on “www.coke.com” (an “on-nav query”, occur-
ring when a user types a url in the search box by mistake)
versus when Pepsi bids on “www.coke.com” (an “oﬀ-nav
query”). This question was studied extensively by Gold-
man & Rao (2014) using a nonparametric IV estimation
approach that involved a detailed construction of optimal
instruments, as well as a separate hand-coded classiﬁcation
of advertiser–query pairs into the four categories above.

Our goal is to replicate these results in an automated fashion.
Advertiser position is correlated with latent user intent (e.g.
when a user searches for “Coke”, it is likely both that they
will click and that “Coke” will be the top advertiser), so we
need instruments to infer causation. The instruments pro-
posed by Goldman & Rao (2014) are a series of indicators
for experiments run by Bing in which advertiser–query pairs

Figure 4. The inter-quartile range in advertiser-query speciﬁc esti-
mates of the relative drop in click rate from moving from position
1 to position 2 (i.e. y-axis denotes cr1−cr2
%), as the popularity of
the advertiser varies along the x-axis (as measured by visit rank on
Alexa.com), for on-brand versus oﬀ-brand queries (left panel) and
on-nav versus oﬀ-nav queries (right panel) for a single combination
of advertiser and search-query text.

cr1

were randomly assigned to diﬀerent algorithms that in turn
scored advertisers diﬀerently in search auctions, resulting
in random variation in position. Our estimation algorithm
takes the experiment ID directly as an instrument.

As features, we gave the deep nets the query url and user
query as text. The url was parsed into tokens on dashes
and dots and these tokens were then parsed on punctuation
and whitespace. Given the outcome variable (an indica-
tor for user click), the features, and the instruments, we
applied our methodology directly to the data without any
of the additional feature engineering and construction of
optimal instruments performed by Goldman & Rao (2014).
This approach was tractable despite the fact that the dataset
contained over 20 million observations. Figure 4 shows
the results. We were able to replicate the original study’s
broad ﬁndings, namely that (i) that for “on-brand” queries,
position was worth more to small websites; and (ii) that the
value of position for on-nav queries was much smaller than
for oﬀ-nav queries. A naive non-causal regression found an
unrealistic average treatment eﬀect (ATE; across sampled
advertisers and queries) drop in click rate of 70% from 1st
to 2nd position; in contrast, the causal estimate of the ATE
was a more modest 12% drop.

5. Discussion

We have presented DeepIV, an approach that leverages in-
strument variables to train deep networks that directly min-
imize the counterfactual prediction error and validate the
resulting models on held-out data. DeepIV signiﬁcantly
reduced counterfactual error measured in simulation ex-
periments and was able to replicate previous IV experi-
ments without extensive feature engineering. In future work,
we plan to discuss interference techniques for the DeepIV
framework and explore how this approach generalizes to
other causal graphs given appropriate assumptions.

2004006008001000203040506070on_brandoff_brand2004006008001000405060708090on_navoff_navwebsite US rankrelative click rateDeep IV: A Flexible Approach for Counterfactual Prediction

Blundell, Richard, Chen, Xiaohong, and Kristensen, Den-
nis. Semi-nonparametric iv estimation of shape-invariant
engel curves. Econometrica, 75:1630–1669, 2007.

ture, 2015.

Acknowledgements

We would like to thank Susan Athey, Xiaohong Chen and
Demian Pouzo for their helpful discussions and the anony-
mous reviewers for their useful comments on the paper. We
would also like to thank Holger Hoos for the use of the Ada
cluster, without which the experiments would not have been
possible.

References

Angrist, J. D., Imbens, G.W., and Rubin, D. B. Identiﬁcation
of causal eﬀects using instrumental variables. Journal of
the American Statistical Association, 91(434):444–455,
1996.

Angrist, Joshua D and Pischke, J¨orn-Steﬀen. Mostly harm-
less econometrics: An empiricist’s companion. Princeton
university press, 2008.

Athey, Susan and Imbens, Guido. Recursive partitioning for
heterogeneous causal eﬀects. Proceedings of the National
Academy of Sciences, 113:7353–7360, 2016.

Bishop, Christopher M. Pattern Recognition and Machine

Learning. Springer, 2006.

Bottou, L. Large-scale machine learning with stochastic
gradient descent. In Proceedings of COMPSTAT’2010,
pp. 177–186. Springer, 2010.

Bottou, L´eon, Peters, Jonas, Qui˜nonero-Candela, Joaquin,
Charles, Denis X, Chickering, D Max, Portugaly, Elon,
Ray, Dipankar, Simard, Patrice, and Snelson, Ed. Coun-
terfactual reasoning and learning systems: The example
of computational advertising. The Journal of Machine
Learning Research, 14(1):3207–3260, 2013.

Bound, John, Jaeger, David A, and Baker, Regina M. Prob-
lems with instrumental variables estimation when the
correlation between the instruments and the endogenous
explanatory variable is weak. Journal of the American
Statistical Association, 90:443–450, 1995.

Bousquet, Olivier and Bottou, L´eon. The tradeoﬀs of large
scale learning. In Advances in neural information pro-
cessing systems (NIPS), pp. 161–168, 2008.

Chen, X. and Pouzo, D. Estimation of nonparametric condi-
tional moment models with possibly nonsmooth general-
ized residuals. Econometrica, 80:277–321, 2012.

Darolles, Serge, Fan, Yanqin, Florens, Jean-Pierre, and
Renault, Eric. Nonparametric instrumental regression.
Econometrica, 79:1541–1565, 2011.

Duchi, John, Hazan, Elad, and Singer, Yoram. Adaptive
subgradient methods for online learning and stochastic
optimization. Journal of Machine Learning Research, 12:
2121–2159, 2011.

Goldman, Mathew and Rao, Justin M. Experiments as
instruments: heterogeneous position eﬀects in sponsored
search auctions. 2014.

Hall, Peter and Horowitz, Joel L. Nonparametric methods
for inference in the presence of instrumental variables.
Ann. Statist., 33(6):2904–2929, 12 2005.

Hayﬁeld, Tristen, Racine, Jeﬀrey S, et al. Nonparametric
econometrics: The np package. Journal of statistical
software, 27(5):1–32, 2008.

Johansson, F. D., Shalit, U., and Sontag, D. Learning repre-
sentations for counterfactual inference. In Proceedings of
the 33nd International Conference on Machine Learning,
(ICML), pp. 3020–3029, 2016.

Kingma, Diederik and Ba, Jimmy. ADAM: A method for
International Conference on

stochastic optimization.
Learning Representations (ICLR), 2014.

LeCun, Y., Bengio, Y., and Hinton, G. Deep learning. Na-

LeCun, Yann and Cortes, Corinna. MNIST handwritten
digit database. 2010. URL http://yann.lecun.com/
exdb/mnist/.

Newey, W. K. and Powell, J. L. Instrumental variable esti-
mation of nonparametric models. Econometrica, 71(5):
1565–1578, 2003.

Pearl, J. Causality. Cambridge University Press, 2009.

Peysakhovich, A. and Eckles, D. Learning causal eﬀects
from many randomized experiments using regularized
instrumental variables. ArXiv e-prints, January 2017.

Reiersøl., O. Conﬂuence analysis by means of instrumental
sets of variables. Arkiv f¨or Matematik, Astronomi och
Fysik, 32a(4):1–119, 1945.

Robbins, H. and Monro, S. A stochastic approximation
method. The Annals of Mathematical Statistics, pp. 400–
407, 1951.

Rosenbaum, P. R. and Rubin, D. B. Assessing sensitivity to
an unobserved binary covariate in an observational study
with binary outcome. Journal of the Royal Statistical
Society. Series B (Methodological), 45(2):212–218, 1983.

Schmidhuber, J. Deep learning in neural networks: An

overview. Neural Networks, 2015.

Deep IV: A Flexible Approach for Counterfactual Prediction

Shalit, U., Johansson, F., and Sontag, D. Estimating indi-
vidual treatment eﬀect: generalization bounds and algo-
rithms. ArXiv e-prints, June 2016.

Wager, Stefan and Athey, Susan.

Inference of het-
erogeneous treatment eﬀects using random forests.
arXiv:1510.04342, 2015.

Wright, P. G. The Tariﬀ on Animal and Vegetable Oils.

Macmillan, 1928.

Zinkevich, Martin. Online convex programming and gener-
alized inﬁnitesimal gradient ascent. In Proceedings of the
Twentieth International Conference on Machine Learning
(ICML), 2003.

